{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.958304762840271, "xcomet_qe_score": 0.9632421731948853, "metricx_score": 0.26475995779037476, "metricx_qe_score": 0.28221702575683594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎来到我们的演示,我们将展示 De plain,一个用于德语文本识别的新语料库,适用于文档级别和句子级别。", "metrics": {"bleu_score": 14.882455879385487, "chrf_score": 17.570565808162435, "xcomet_score": 0.8517769575119019, "xcomet_qe_score": 0.8131486177444458, "metricx_score": 3.2226696014404297, "metricx_qe_score": 4.150745391845703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫 Regina Stoden,我将引导大家完成演示的第一部分。", "metrics": {"bleu_score": 44.77845944135174, "chrf_score": 58.12182893940402, "xcomet_score": 0.905113697052002, "xcomet_qe_score": 0.9729478359222412, "metricx_score": 2.3683815002441406, "metricx_qe_score": 3.7770559787750244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先定义文本简化。", "metrics": {"bleu_score": 26.008181229347326, "chrf_score": 25.730100827778298, "xcomet_score": 0.9712696075439453, "xcomet_qe_score": 0.9715811014175415, "metricx_score": 0.25107619166374207, "metricx_qe_score": 0.275246798992157, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "文本简化是适应文本以提高特定目标群体对文本的理解的过程,例如阅读有困难的人或非母语人士。", "metrics": {"bleu_score": 52.61653408541365, "chrf_score": 46.949846767307434, "xcomet_score": 0.9038965702056885, "xcomet_qe_score": 0.8944981098175049, "metricx_score": 0.6060832738876343, "metricx_qe_score": 0.5202444791793823, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练文本简化模型,我们需要平行文本对,例如文档或句子。", "metrics": {"bleu_score": 73.59287727151016, "chrf_score": 67.06147167784839, "xcomet_score": 0.9839011430740356, "xcomet_qe_score": 0.8662941455841064, "metricx_score": 1.833242654800415, "metricx_qe_score": 2.478898048400879, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里的例子中,您可以看到一个复杂的德语句子及其平淡语言翻译的平行对齐句子对。", "metrics": {"bleu_score": 63.29336507270698, "chrf_score": 58.930563605486206, "xcomet_score": 0.8205435276031494, "xcomet_qe_score": 0.7135074138641357, "metricx_score": 2.862658739089966, "metricx_qe_score": 2.661604881286621, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了简化句子,可以采用不同的技术,如您在例子中看到的,例如词汇替换、从句扩展、交叉删除重排或插入单词。", "metrics": {"bleu_score": 39.044969497817796, "chrf_score": 38.63717171980786, "xcomet_score": 0.8411011695861816, "xcomet_qe_score": 0.7414453029632568, "metricx_score": 2.0702524185180664, "metricx_qe_score": 2.7386882305145264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在提出我们的新语料库 D plane,因为近年来现有的语料库存在一些问题。", "metrics": {"bleu_score": 57.92522119509501, "chrf_score": 46.160328703961824, "xcomet_score": 0.6358246803283691, "xcomet_qe_score": 0.6714344620704651, "metricx_score": 7.079899311065674, "metricx_qe_score": 7.578893661499023, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这些语料库太小,无法训练分类模型。", "metrics": {"bleu_score": 35.743397031672636, "chrf_score": 32.20663918239359, "xcomet_score": 0.8950200080871582, "xcomet_qe_score": 0.8340485095977783, "metricx_score": 3.0722250938415527, "metricx_qe_score": 2.363635540008545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来提出的其他三个模型都是自动对齐的,这意味着它们的对齐可能存在错误。", "metrics": {"bleu_score": 57.46388731356058, "chrf_score": 50.42078987723587, "xcomet_score": 0.9855239391326904, "xcomet_qe_score": 0.9838825464248657, "metricx_score": 0.6832425594329834, "metricx_qe_score": 0.8456329107284546, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们提出了我们的新语料库 Dplane,它分为两个子语料库,Deplane APA 和 Deplane web。", "metrics": {"bleu_score": 34.38468902500841, "chrf_score": 24.942174817773143, "xcomet_score": 0.7510270476341248, "xcomet_qe_score": 0.6414834260940552, "metricx_score": 5.406425476074219, "metricx_qe_score": 5.93564510345459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Deplane APA 基于使用文本。", "metrics": {"bleu_score": 22.31618068926665, "chrf_score": 13.394349291771226, "xcomet_score": 0.7852209210395813, "xcomet_qe_score": 0.7495477795600891, "metricx_score": 6.263320446014404, "metricx_qe_score": 10.441879272460938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在 Deplane APA 中,我们手动对齐了 483 个文档。", "metrics": {"bleu_score": 70.18491170272205, "chrf_score": 50.022616220244075, "xcomet_score": 0.9514169692993164, "xcomet_qe_score": 0.9631012678146362, "metricx_score": 2.1097240447998047, "metricx_qe_score": 2.448667287826538, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这大约产生了三十万个句子对。对于", "metrics": {"bleu_score": 35.83129187641355, "chrf_score": 26.96648661143778, "xcomet_score": 0.628640353679657, "xcomet_qe_score": 0.6314189434051514, "metricx_score": 8.414071083068848, "metricx_qe_score": 6.06922721862793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Deplane web,这个语料库包括不同的领域,我们还手动对齐了这七百五十个文档,另一方面也使用了自动对齐方法。", "metrics": {"bleu_score": 45.043332207221106, "chrf_score": 33.86518951858689, "xcomet_score": 0.7961879372596741, "xcomet_qe_score": 0.6863123178482056, "metricx_score": 3.9979279041290283, "metricx_qe_score": 5.548993110656738, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共有 30 450 个句子对。", "metrics": {"bleu_score": 11.900880628516905, "chrf_score": 26.407528784304272, "xcomet_score": 0.8529877662658691, "xcomet_qe_score": 0.8539358377456665, "metricx_score": 1.89359712600708, "metricx_qe_score": 2.0523765087127686, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子对进行了更多的分析,例如简化的类型。", "metrics": {"bleu_score": 49.52181959754728, "chrf_score": 43.467869946746475, "xcomet_score": 0.8341208696365356, "xcomet_qe_score": 0.7722188234329224, "metricx_score": 3.7208263874053955, "metricx_qe_score": 4.439391136169434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,您可以看到圣经文本比新闻文本或语言学习文本在所有级别", "metrics": {"bleu_score": 46.74955271500788, "chrf_score": 45.139969632852484, "xcomet_score": 0.5369433164596558, "xcomet_qe_score": 0.35342937707901, "metricx_score": 8.67713737487793, "metricx_qe_score": 7.771341323852539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "上都更强地简化了,例如词汇简化、结构简化以及整体简化水平。", "metrics": {"bleu_score": 68.02997246791152, "chrf_score": 70.74877832017421, "xcomet_score": 0.5207384824752808, "xcomet_qe_score": 0.5252127051353455, "metricx_score": 5.55543851852417, "metricx_qe_score": 5.96105432510376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,您可以看到我们的深层语料库具有高度多样化的不同简化变换,", "metrics": {"bleu_score": 36.29453416382384, "chrf_score": 29.629292943458662, "xcomet_score": 0.6935168504714966, "xcomet_qe_score": 0.7188674211502075, "metricx_score": 2.785649299621582, "metricx_qe_score": 2.8244481086730957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如在 Deplane API 语料库中,我们有更多的重排和添加单词,而在 web 语料库", "metrics": {"bleu_score": 16.008869879314716, "chrf_score": 18.431011909841672, "xcomet_score": 0.4734450876712799, "xcomet_qe_score": 0.47559982538223267, "metricx_score": 8.791467666625977, "metricx_qe_score": 7.471858978271484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中,我们有更多的改写。", "metrics": {"bleu_score": 16.404210784979526, "chrf_score": 21.01687967300105, "xcomet_score": 0.28108879923820496, "xcomet_qe_score": 0.2579508423805237, "metricx_score": 7.771971702575684, "metricx_qe_score": 10.883877754211426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在让我们看看我们可以用这个语料库做什么。", "metrics": {"bleu_score": 64.6417393808886, "chrf_score": 54.68491490163318, "xcomet_score": 0.993862509727478, "xcomet_qe_score": 0.9793002605438232, "metricx_score": 0.2663712799549103, "metricx_qe_score": 0.461933434009552, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是 Omar,我现在将谈谈我们数据集 d plane 的使用案例。", "metrics": {"bleu_score": 15.709043840934823, "chrf_score": 23.26864676669198, "xcomet_score": 0.9119777679443359, "xcomet_qe_score": 0.8478167057037354, "metricx_score": 4.08785343170166, "metricx_qe_score": 4.999423027038574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个使用案例是评估自动对齐方法。", "metrics": {"bleu_score": 46.286925169624936, "chrf_score": 42.90534544962063, "xcomet_score": 0.9868135452270508, "xcomet_qe_score": 0.9882485866546631, "metricx_score": 0.941636323928833, "metricx_qe_score": 1.1274603605270386, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,出现了很多对齐方法,但在机器翻译的背景下,我们有两个用不同语言编写的平行文档,我们想要从后置文档中提取句子对齐。", "metrics": {"bleu_score": 57.87790528885919, "chrf_score": 51.741312381255455, "xcomet_score": 0.7546029090881348, "xcomet_qe_score": 0.7419705390930176, "metricx_score": 2.388295888900757, "metricx_qe_score": 3.104029417037964, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的使用案例中,我们试图提取两个平行文档之间句子之间的对齐,这两个文档具有相同语言和相同内容", "metrics": {"bleu_score": 37.927474644016534, "chrf_score": 31.16845535789508, "xcomet_score": 0.8146920204162598, "xcomet_qe_score": 0.8178171515464783, "metricx_score": 4.578073501586914, "metricx_qe_score": 5.77886438369751, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",但它们在复杂性级别上有所不同。现在我们有了手动对齐句子的数据集 d plane,我们可以使用这些句子作为金标准对齐来评估一些提出的对齐方法。", "metrics": {"bleu_score": 40.88619551285248, "chrf_score": 34.87946806914762, "xcomet_score": 0.46845152974128723, "xcomet_qe_score": 0.24826893210411072, "metricx_score": 6.046861171722412, "metricx_qe_score": 6.60711669921875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提出的方法进行了一些改编,并在论文中发表了所有这些改编和运行实验的代码。", "metrics": {"bleu_score": 33.533048581960514, "chrf_score": 30.22339221688426, "xcomet_score": 0.9760477542877197, "xcomet_qe_score": 0.9815609455108643, "metricx_score": 1.6106516122817993, "metricx_qe_score": 1.3464195728302002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们得出结论,用于德语文本简化的最佳自动对齐方法是质量对齐方法。", "metrics": {"bleu_score": 64.94501259165521, "chrf_score": 55.88619054428552, "xcomet_score": 0.8174997568130493, "xcomet_qe_score": 0.8103809356689453, "metricx_score": 4.203429222106934, "metricx_qe_score": 3.976728677749634, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在论文中找到在您自己的文档上运行此方法的代码。", "metrics": {"bleu_score": 43.75579994350345, "chrf_score": 38.60666604288338, "xcomet_score": 0.992317795753479, "xcomet_qe_score": 0.9805800914764404, "metricx_score": 0.4939131736755371, "metricx_qe_score": 0.48299628496170044, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示的第二个使用案例是通过微调语言模型来自动简化文本的案例。", "metrics": {"bleu_score": 50.59549385281685, "chrf_score": 48.30636403675405, "xcomet_score": 0.9823939800262451, "xcomet_qe_score": 0.9820965528488159, "metricx_score": 1.0921305418014526, "metricx_qe_score": 1.3271886110305786, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们微调了两个不同的模型:我们微调了", "metrics": {"bleu_score": 27.098211583470043, "chrf_score": 24.976711361419262, "xcomet_score": 0.5777478218078613, "xcomet_qe_score": 0.5860896110534668, "metricx_score": 3.9367709159851074, "metricx_qe_score": 4.585167407989502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "长部分模型以生成文档级别的简化,我们还微调了正常基线长部分以生成句子级别的简化。", "metrics": {"bleu_score": 14.638210010451983, "chrf_score": 13.843888443920532, "xcomet_score": 0.524425745010376, "xcomet_qe_score": 0.5112336874008179, "metricx_score": 8.326390266418457, "metricx_qe_score": 8.283979415893555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以找到所有检查点,并在论文中查看我们实验的详细分数和评估指标。我们得出", "metrics": {"bleu_score": 54.65317609455904, "chrf_score": 48.55527973066808, "xcomet_score": 0.7491294145584106, "xcomet_qe_score": 0.7328386902809143, "metricx_score": 6.1299333572387695, "metricx_qe_score": 3.2584521770477295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结论,这种基本的微调可以产生或获得比基准分数更好的分数,我们提出了这些结果作为自动文本简化问题的基准。", "metrics": {"bleu_score": 58.37732743997061, "chrf_score": 51.79400486025811, "xcomet_score": 0.8219877481460571, "xcomet_qe_score": 0.7657260894775391, "metricx_score": 2.646993398666382, "metricx_qe_score": 3.24013614654541, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,我们希望在会议期间见到大家。", "metrics": {"bleu_score": 46.11411579665311, "chrf_score": 40.155067083822956, "xcomet_score": 0.9945908784866333, "xcomet_qe_score": 0.9959206581115723, "metricx_score": 0.6428474187850952, "metricx_qe_score": 0.37971922755241394, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集,感谢大家。", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 13.88888888888889, "xcomet_score": 0.5856402516365051, "xcomet_qe_score": 0.5132632851600647, "metricx_score": 3.4826180934906006, "metricx_qe_score": 3.5140843391418457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫亚当·什里科夫斯基,今天我要讲的主题是并列句的依存结构。", "metrics": {"bleu_score": 9.149503306016932, "chrf_score": 8.431112843931363, "xcomet_score": 0.6091547012329102, "xcomet_qe_score": 0.587837815284729, "metricx_score": 2.4412431716918945, "metricx_qe_score": 1.769256353378296, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "众所周知,不同的理论和语料库方法假设了不同的依存结构。", "metrics": {"bleu_score": 64.57665807819532, "chrf_score": 63.353047287232236, "xcomet_score": 0.9861482381820679, "xcomet_qe_score": 0.8996410369873047, "metricx_score": 0.4768948256969452, "metricx_qe_score": 0.6572664976119995, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在普遍依存理论中,丽莎、巴特和玛姬的并列结构是,第一个并列成分是整个并列结构的词头。", "metrics": {"bleu_score": 25.345356610281893, "chrf_score": 18.324671620967965, "xcomet_score": 0.7584091424942017, "xcomet_qe_score": 0.7093499898910522, "metricx_score": 2.107332944869995, "metricx_qe_score": 3.5097391605377197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在伊戈尔·米尔丘克的", "metrics": {"bleu_score": 3.435488317233919, "chrf_score": 1.1904761904761907, "xcomet_score": 0.14150115847587585, "xcomet_qe_score": 0.13988156616687775, "metricx_score": 13.606161117553711, "metricx_qe_score": 15.13949966430664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "意义文本理论中也假设了类似的方法,即整个并列结构由第一个并列成分领导。因此,", "metrics": {"bleu_score": 36.52028843627739, "chrf_score": 27.399832120786304, "xcomet_score": 0.5830720663070679, "xcomet_qe_score": 0.4863570034503937, "metricx_score": 7.042755603790283, "metricx_qe_score": 6.059202671051025, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两种方法都是不对称的,", "metrics": {"bleu_score": 90.36020036098445, "chrf_score": 89.11315536315534, "xcomet_score": 0.9953523874282837, "xcomet_qe_score": 0.9697904586791992, "metricx_score": 0.36860373616218567, "metricx_qe_score": 0.4781116247177124, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.22008275985717773, "xcomet_qe_score": 0.15493544936180115, "metricx_score": 2.700258255004883, "metricx_qe_score": 1.051820158958435, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们单列出了一个并列成分。", "metrics": {"bleu_score": 49.73567356124543, "chrf_score": 40.905529655529655, "xcomet_score": 0.8488681316375732, "xcomet_qe_score": 0.8336275815963745, "metricx_score": 3.304100513458252, "metricx_qe_score": 4.53972864151001, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,它们也是对称的方法,例如PRAG方法,", "metrics": {"bleu_score": 10.071555744335962, "chrf_score": 10.826118326118328, "xcomet_score": 0.6672446727752686, "xcomet_qe_score": 0.6516889333724976, "metricx_score": 7.9371538162231445, "metricx_qe_score": 7.906490325927734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以及PRAG依存树库中假设的连接词领导方法,其中并列结构由连接词领导", "metrics": {"bleu_score": 9.858877844506223, "chrf_score": 12.80443187519894, "xcomet_score": 0.5788668394088745, "xcomet_qe_score": 0.5491079092025757, "metricx_score": 5.979153633117676, "metricx_qe_score": 5.804030418395996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们从连接词到所有并列成分都得到依存关系。", "metrics": {"bleu_score": 37.580735134581516, "chrf_score": 29.359236992327215, "xcomet_score": 0.7832341194152832, "xcomet_qe_score": 0.7917223572731018, "metricx_score": 4.8387274742126465, "metricx_qe_score": 4.827007293701172, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,还有一种多头方法,例如在Cutson的词语语法中使用,可以说所有并列成分都是并列结构的词头,", "metrics": {"bleu_score": 27.233027934252874, "chrf_score": 22.766675345750592, "xcomet_score": 0.44087889790534973, "xcomet_qe_score": 0.49028658866882324, "metricx_score": 5.83402156829834, "metricx_qe_score": 5.555434226989746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此我们从领导词到所有并列", "metrics": {"bleu_score": 12.014605158792346, "chrf_score": 11.209707712933039, "xcomet_score": 0.5624741315841675, "xcomet_qe_score": 0.13999640941619873, "metricx_score": 6.884499549865723, "metricx_qe_score": 11.31871509552002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "成分分别得到依存关系。这些都是现在的按钮制作方法。本文的目的是", "metrics": {"bleu_score": 1.696134390396339, "chrf_score": 1.9047619047619047, "xcomet_score": 0.1397693157196045, "xcomet_qe_score": 0.14025279879570007, "metricx_score": 19.32608413696289, "metricx_qe_score": 22.72933006286621, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为像这两者这样的对称并列结构提供一个新论点,反对像这两者这样的非对称并列结构。", "metrics": {"bleu_score": 18.803956180531635, "chrf_score": 18.431944099900086, "xcomet_score": 0.6096349358558655, "xcomet_qe_score": 0.34080541133880615, "metricx_score": 4.047595500946045, "metricx_qe_score": 3.710526466369629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1778337061405182, "xcomet_qe_score": 0.16261017322540283, "metricx_score": 2.950650453567505, "metricx_qe_score": 1.5982927083969116, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "论点基于依存长度最小化的原则,我将在这些例子基础上进行解释。", "metrics": {"bleu_score": 45.05775914138545, "chrf_score": 38.33055775218664, "xcomet_score": 0.90198814868927, "xcomet_qe_score": 0.8981770277023315, "metricx_score": 0.974373459815979, "metricx_qe_score": 0.8605610132217407, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在英语中,如你所知,我们的直接宾语倾向于靠近动词,而附属成分可能更远。", "metrics": {"bleu_score": 34.385886063979285, "chrf_score": 28.34599153135931, "xcomet_score": 0.7733404636383057, "xcomet_qe_score": 0.7211470007896423, "metricx_score": 3.9238641262054443, "metricx_qe_score": 4.1269073486328125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,马奇昨天读了它没问题,因为直接宾语它靠近动词,而马奇昨天读了它则差多了", "metrics": {"bleu_score": 20.326213373677703, "chrf_score": 9.757814111412214, "xcomet_score": 0.5943814516067505, "xcomet_qe_score": 0.631403386592865, "metricx_score": 9.63487434387207, "metricx_qe_score": 9.295544624328613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因为这里", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.27769508957862854, "xcomet_qe_score": 0.24290284514427185, "metricx_score": 4.461395263671875, "metricx_qe_score": 3.0414209365844727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "动词和直接宾语之间有一个附属成分昨天。", "metrics": {"bleu_score": 49.410069749619, "chrf_score": 36.71461652382979, "xcomet_score": 0.8602961301803589, "xcomet_qe_score": 0.8422253727912903, "metricx_score": 4.078548431396484, "metricx_qe_score": 4.758743762969971, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当直接宾语非常长时,这种效果可能会得到缓解,因为", "metrics": {"bleu_score": 31.645275923351992, "chrf_score": 28.283654258118666, "xcomet_score": 0.7326018810272217, "xcomet_qe_score": 0.580132007598877, "metricx_score": 4.6457295417785645, "metricx_qe_score": 4.229954242706299, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它可以移到附属成分之后的位置。", "metrics": {"bleu_score": 27.588769042674603, "chrf_score": 24.79043253078187, "xcomet_score": 0.8466036319732666, "xcomet_qe_score": 0.8151071667671204, "metricx_score": 2.8487541675567627, "metricx_qe_score": 1.830032229423523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里对此进行了说明。因此,", "metrics": {"bleu_score": 6.837203339116283, "chrf_score": 7.639784946236558, "xcomet_score": 0.34726184606552124, "xcomet_qe_score": 0.4707982540130615, "metricx_score": 4.383329391479492, "metricx_qe_score": 3.408552408218384, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两个句子都很好,马", "metrics": {"bleu_score": 46.77766538205128, "chrf_score": 39.527976317915346, "xcomet_score": 0.757797122001648, "xcomet_qe_score": 0.6778702735900879, "metricx_score": 3.264983892440796, "metricx_qe_score": 0.5954151153564453, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "奇读了关于BC的这本书昨天没问题", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1470617651939392, "xcomet_qe_score": 0.15503576397895813, "metricx_score": 12.627811431884766, "metricx_qe_score": 14.454279899597168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",用它代替它也行,但说马奇昨天", "metrics": {"bleu_score": 2.986360200388484, "chrf_score": 2.8318871377132404, "xcomet_score": 0.14622336626052856, "xcomet_qe_score": 0.14488603174686432, "metricx_score": 15.961654663085938, "metricx_qe_score": 11.0389404296875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "读了关于蜜蜂的这本书也行。这里的推理是,这是可能的,", "metrics": {"bleu_score": 2.2608914449138346, "chrf_score": 1.6129032258064515, "xcomet_score": 0.14407701790332794, "xcomet_qe_score": 0.1476622372865677, "metricx_score": 7.224603652954102, "metricx_qe_score": 8.123713493347168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为即使这个句子违反了直接宾语应该靠近动词的一般语法原则,但它满足了依存长度最小化的原则,即更短的依存关系更受欢迎。", "metrics": {"bleu_score": 52.20291689356014, "chrf_score": 45.06955033193405, "xcomet_score": 0.9504420757293701, "xcomet_qe_score": 0.9428011178970337, "metricx_score": 3.2465267181396484, "metricx_qe_score": 3.961538076400757, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这两个树只显示了关键依存关系的长度,即这两个结构中不常出现的依存关系。", "metrics": {"bleu_score": 63.24836442920863, "chrf_score": 61.628592036958864, "xcomet_score": 0.8856289386749268, "xcomet_qe_score": 0.7917190790176392, "metricx_score": 1.5861624479293823, "metricx_qe_score": 2.2535011768341064, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们从红色到附属成分的依存关系长度为7个词,从红色到书的依存关系长度为4个词,总共是11个词。", "metrics": {"bleu_score": 22.27344384988294, "chrf_score": 17.421513127152412, "xcomet_score": 0.6033196449279785, "xcomet_qe_score": 0.638297438621521, "metricx_score": 8.528718948364258, "metricx_qe_score": 9.391755104064941, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当你交换这两个成分时,这两个依存关系的总和变为6个", "metrics": {"bleu_score": 59.82110643286657, "chrf_score": 54.57290011607808, "xcomet_score": 0.789247453212738, "xcomet_qe_score": 0.7210139036178589, "metricx_score": 1.974470615386963, "metricx_qe_score": 1.5892835855484009, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "词,比11个词短得多,", "metrics": {"bleu_score": 17.771669724375847, "chrf_score": 18.048905471840122, "xcomet_score": 0.6409010887145996, "xcomet_qe_score": 0.6728190183639526, "metricx_score": 9.57961368560791, "metricx_qe_score": 10.279303550720215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么这听起来很正常的原因。", "metrics": {"bleu_score": 55.81600587827485, "chrf_score": 62.35175635454719, "xcomet_score": 0.866435170173645, "xcomet_qe_score": 0.8846030235290527, "metricx_score": 1.032324194908142, "metricx_qe_score": 0.7941595911979675, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因为这里", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.27769508957862854, "xcomet_qe_score": 0.24290284514427185, "metricx_score": 4.461395263671875, "metricx_qe_score": 3.0414209365844727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它违反了一个原则,但满足了另一个原则。", "metrics": {"bleu_score": 72.24553130054804, "chrf_score": 65.89958241316472, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19535920023918152, "metricx_qe_score": 0.47849607467651367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.14834243059158325, "xcomet_qe_score": 0.11301116645336151, "metricx_score": 2.845757007598877, "metricx_qe_score": 1.6933263540267944, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从增强版PENTRY语料库中提取了关于并列的各种统计数据,并查看了为什么我们没有使用大学依存关系。这些统计数据证实了之前多次观察到的现象,即左并列成分往往更短。", "metrics": {"bleu_score": 47.832932419179734, "chrf_score": 41.14605180412811, "xcomet_score": 0.5408923625946045, "xcomet_qe_score": 0.4782944619655609, "metricx_score": 6.842392921447754, "metricx_qe_score": 6.7852911949157715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,盐和胡椒而不是胡椒和盐,以音节为单位测量,以及在经过", "metrics": {"bleu_score": 20.71686516312665, "chrf_score": 11.798636718417708, "xcomet_score": 0.35126829147338867, "xcomet_qe_score": 0.3370312750339508, "metricx_score": 8.63962459564209, "metricx_qe_score": 9.030603408813477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "观察时发现的趋势,即随着长度的增加,长度差异也随之增加。因此", "metrics": {"bleu_score": 22.481074167380644, "chrf_score": 21.257147482272547, "xcomet_score": 0.7090753316879272, "xcomet_qe_score": 0.6439749002456665, "metricx_score": 4.780197620391846, "metricx_qe_score": 2.816208839416504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",当两个并列成分的长度差异增大时,较短的并列成分更倾向于排在前面。", "metrics": {"bleu_score": 33.7973964943188, "chrf_score": 27.629336808370454, "xcomet_score": 0.7773351669311523, "xcomet_qe_score": 0.8305493593215942, "metricx_score": 5.272799491882324, "metricx_qe_score": 4.941520690917969, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "左短并列成分的比例更大,", "metrics": {"bleu_score": 34.0089486243384, "chrf_score": 27.785032344226913, "xcomet_score": 0.8320916891098022, "xcomet_qe_score": 0.7975955605506897, "metricx_score": 3.2007508277893066, "metricx_qe_score": 4.507358074188232, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但本文的新颖之处在于,我们观察到这种趋势只有在领导词在左边时才会发生。因此,", "metrics": {"bleu_score": 39.373921060152945, "chrf_score": 35.26941225272897, "xcomet_score": 0.7708505392074585, "xcomet_qe_score": 0.6246917843818665, "metricx_score": 6.473480701446533, "metricx_qe_score": 7.855441093444824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因为这里", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.27769508957862854, "xcomet_qe_score": 0.24290284514427185, "metricx_score": 4.461395263671875, "metricx_qe_score": 3.0414209365844727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,领导词在左边,我看到了巴特和丽莎,因此领导词在左边,", "metrics": {"bleu_score": 21.092951227865772, "chrf_score": 15.091607909070703, "xcomet_score": 0.8688409328460693, "xcomet_qe_score": 0.6605945825576782, "metricx_score": 4.264405727386475, "metricx_qe_score": 6.16608190536499, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中,荷马来了,打了个喷嚏。", "metrics": {"bleu_score": 22.886993374343024, "chrf_score": 12.055140039014788, "xcomet_score": 0.7243427634239197, "xcomet_qe_score": 0.7318469285964966, "metricx_score": 4.495725631713867, "metricx_qe_score": 5.047325134277344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里有两个动词的并列,没有外部领导词。因此,", "metrics": {"bleu_score": 37.194474424733414, "chrf_score": 29.8835844811077, "xcomet_score": 0.7847927808761597, "xcomet_qe_score": 0.7783657312393188, "metricx_score": 5.473808765411377, "metricx_qe_score": 4.124885082244873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下,左并列成分更倾向于更短,两个并列成分之间的差异越", "metrics": {"bleu_score": 31.334523900626223, "chrf_score": 27.745584316336735, "xcomet_score": 0.6054089665412903, "xcomet_qe_score": 0.5074824690818787, "metricx_score": 8.787372589111328, "metricx_qe_score": 6.714690208435059, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大,这种倾向就越强。然而,当领导词在右边时,例如左边领导并列尾部和净时,这种效果就会消失。", "metrics": {"bleu_score": 14.787790645865732, "chrf_score": 11.679442782242546, "xcomet_score": 0.16967110335826874, "xcomet_qe_score": 0.11931594461202621, "metricx_score": 15.069231033325195, "metricx_qe_score": 16.402971267700195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过测量字符长度、音节长度和词语长度来展示这一点。因此,我将", "metrics": {"bleu_score": 8.683688277671843, "chrf_score": 11.876784934807494, "xcomet_score": 0.5820412635803223, "xcomet_qe_score": 0.4190954566001892, "metricx_score": 7.894028186798096, "metricx_qe_score": 5.324204444885254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "重点关注右边的部分。我们在这", "metrics": {"bleu_score": 13.912311644176565, "chrf_score": 16.256948074742468, "xcomet_score": 0.5961090922355652, "xcomet_qe_score": 0.1763363629579544, "metricx_score": 4.474435806274414, "metricx_qe_score": 2.4732532501220703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "里看到,当领导词在左边时,左并列成分更短的倾向会随着单词的绝对差异稳步增长,当没有领导词时也会观察到同样的现象,例如句子并列。但是", "metrics": {"bleu_score": 27.01025816853905, "chrf_score": 24.027904913584315, "xcomet_score": 0.3393060863018036, "xcomet_qe_score": 0.33168476819992065, "metricx_score": 11.039006233215332, "metricx_qe_score": 8.109792709350586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",当领导词在右边时,这种倾向就会消失。", "metrics": {"bleu_score": 27.658967335811877, "chrf_score": 23.09102980821368, "xcomet_score": 0.853805422782898, "xcomet_qe_score": 0.7364341020584106, "metricx_score": 5.248407363891602, "metricx_qe_score": 8.821983337402344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在论文中展示了这一点,如何为我们反对像这两者这样的非对称并列结构和支持像这两者这样的对称并列结构提供了论据。因此,请参阅论文", "metrics": {"bleu_score": 30.559933035422713, "chrf_score": 29.885094747630752, "xcomet_score": 0.5340117812156677, "xcomet_qe_score": 0.3268834054470062, "metricx_score": 2.9459052085876465, "metricx_qe_score": 2.823099374771118, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以获取完整的协议和论据,抱歉,并向我们谈", "metrics": {"bleu_score": 5.993031480537873, "chrf_score": 8.062135255750086, "xcomet_score": 0.16356974840164185, "xcomet_qe_score": 0.1531737595796585, "metricx_score": 9.715392112731934, "metricx_qe_score": 8.45592212677002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谈海报会议。", "metrics": {"bleu_score": 4.735576781334083, "chrf_score": 5.49531935063396, "xcomet_score": 0.3769765794277191, "xcomet_qe_score": 0.3955480754375458, "metricx_score": 7.055481910705566, "metricx_qe_score": 5.7067790031433105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集,感谢大家。", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 13.88888888888889, "xcomet_score": 0.5856402516365051, "xcomet_qe_score": 0.5132632851600647, "metricx_score": 3.4826180934906006, "metricx_qe_score": 3.5140843391418457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "- 你好,我是华盛顿大学的博士生Xhang Bing。", "metrics": {"bleu_score": 59.74970909115024, "chrf_score": 49.46060842664409, "xcomet_score": 0.8455818295478821, "xcomet_qe_score": 0.9206293821334839, "metricx_score": 1.558222770690918, "metricx_qe_score": 1.0949829816818237, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将介绍我们从预训练数据到语言模型再到下游任务的工作,追踪导致不公平自然语言处理模型的政治偏见的轨迹。因此", "metrics": {"bleu_score": 62.26611688210154, "chrf_score": 59.3785733803021, "xcomet_score": 0.733115553855896, "xcomet_qe_score": 0.5974158048629761, "metricx_score": 4.202980995178223, "metricx_qe_score": 2.290449380874634, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",语言模型是在大规模网络爬虫数据上训练的。", "metrics": {"bleu_score": 86.56030552541704, "chrf_score": 80.05243910429668, "xcomet_score": 0.9792409539222717, "xcomet_qe_score": 0.9557791352272034, "metricx_score": 1.9083929061889648, "metricx_qe_score": 2.612426519393921, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "政治新闻媒体在他们的预训练数据中得到了很好的覆盖。", "metrics": {"bleu_score": 48.195116293616074, "chrf_score": 48.402791332265075, "xcomet_score": 0.7571665048599243, "xcomet_qe_score": 0.7159234881401062, "metricx_score": 1.750040054321289, "metricx_qe_score": 2.615305185317993, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "根据对c4语料库的调查,我们可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等在语言模型训练数据中得到了很好的覆", "metrics": {"bleu_score": 76.77401669994825, "chrf_score": 74.13411020879627, "xcomet_score": 0.7797398567199707, "xcomet_qe_score": 0.7542548179626465, "metricx_score": 4.1450042724609375, "metricx_qe_score": 2.928680419921875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "盖,这为语言模型的应用带来了既是福又是祸,", "metrics": {"bleu_score": 29.945160623183913, "chrf_score": 24.711270673815914, "xcomet_score": 0.5807533264160156, "xcomet_qe_score": 0.5197215676307678, "metricx_score": 4.265089511871338, "metricx_qe_score": 4.160663604736328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一方面,它们能够从多样化的视角学习,庆祝民主和思想的多元性,", "metrics": {"bleu_score": 30.716161481689387, "chrf_score": 25.63676189519027, "xcomet_score": 0.764818012714386, "xcomet_qe_score": 0.7772269248962402, "metricx_score": 1.8275214433670044, "metricx_qe_score": 2.0227136611938477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,这些不同的政治观点本身具有社会偏见,可能导致下游任务应用中的公平问题。", "metrics": {"bleu_score": 50.27772599073416, "chrf_score": 43.624075520712196, "xcomet_score": 0.9880341291427612, "xcomet_qe_score": 0.9685810208320618, "metricx_score": 1.1356288194656372, "metricx_qe_score": 1.4849121570587158, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们提议研究从预训练数据到语言模型再到下游任务的政治偏见传播管道,具体来说,我们首先提出以下问题:如何评估语言模型的政治倾向,以及数据收集可能对这种政治偏见产生什么影响?", "metrics": {"bleu_score": 59.086165906288564, "chrf_score": 52.91152918395288, "xcomet_score": 0.8952831625938416, "xcomet_qe_score": 0.9227869510650635, "metricx_score": 1.7640469074249268, "metricx_qe_score": 1.805614948272705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,具有不同政治倾向的语言模型在实际应用中表现如何,以及这是否可能导致自然语言处理应用中的公平问题?", "metrics": {"bleu_score": 50.6078722405272, "chrf_score": 43.36371972470765, "xcomet_score": 0.9808712005615234, "xcomet_qe_score": 0.9762705564498901, "metricx_score": 0.47673889994621277, "metricx_qe_score": 0.6387391686439514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们首先提议使用政治问卷(如政治指南针测试)对不同提示格式的语言模型进行提示,", "metrics": {"bleu_score": 46.54148273981992, "chrf_score": 39.845069652666496, "xcomet_score": 0.7582449913024902, "xcomet_qe_score": 0.6842768788337708, "metricx_score": 4.589883327484131, "metricx_qe_score": 5.503506660461426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这确保了我们的自动评估基于政治科学文献。", "metrics": {"bleu_score": 41.05461377536361, "chrf_score": 33.680216662535, "xcomet_score": 0.9142030477523804, "xcomet_qe_score": 0.8913003206253052, "metricx_score": 1.019392967224121, "metricx_qe_score": 1.3666361570358276, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步结果表明,首先,语言模型确实具有不同的政治倾向,", "metrics": {"bleu_score": 67.13783850074476, "chrf_score": 59.40293512107439, "xcomet_score": 0.9662960767745972, "xcomet_qe_score": 0.9748492240905762, "metricx_score": 0.7904109954833984, "metricx_qe_score": 0.8631473779678345, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们占据了政治指南针上的四个象限,", "metrics": {"bleu_score": 47.82215756494833, "chrf_score": 39.40675696957322, "xcomet_score": 0.8241784572601318, "xcomet_qe_score": 0.7080017328262329, "metricx_score": 2.857853412628174, "metricx_qe_score": 2.4293274879455566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到,GPT-4是所有语言模型中最自由派的一个,GPT系列通常比Bird系列及其变体更具社会自由主义倾向。", "metrics": {"bleu_score": 53.356833410513616, "chrf_score": 52.9683184133238, "xcomet_score": 0.8160803318023682, "xcomet_qe_score": 0.9055664539337158, "metricx_score": 3.901207447052002, "metricx_qe_score": 3.630307674407959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,我们旨在研究语言模型的政治偏见实际上是从训练数据中获得的程度,", "metrics": {"bleu_score": 48.7182224785971, "chrf_score": 45.299832870015464, "xcomet_score": 0.8304330110549927, "xcomet_qe_score": 0.8195575475692749, "metricx_score": 4.456748008728027, "metricx_qe_score": 4.126585006713867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们可以通过在六个不同的党派语料库上进一步预训练语言模型检查点来进行受控实验,这些语料库分为新闻和社交媒体,并通过进一步预训练语言模型来划分其政治倾向。", "metrics": {"bleu_score": 44.347897863009116, "chrf_score": 41.58934127702047, "xcomet_score": 0.8236575126647949, "xcomet_qe_score": 0.6705268621444702, "metricx_score": 3.218385696411133, "metricx_qe_score": 3.1514973640441895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过在这些党派语料库上进一步预训练语言模型,我们可以看到语言模型的意识形态坐标也相应地发生了变化,", "metrics": {"bleu_score": 69.17906335733983, "chrf_score": 63.53263798820825, "xcomet_score": 0.9394420385360718, "xcomet_qe_score": 0.7874752283096313, "metricx_score": 1.230920672416687, "metricx_qe_score": 1.699019432067871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,进一步微调并在左翼Reddit语料库上进一步训练的roberta,我们可以看到其政治偏见有显著的自由派转变。", "metrics": {"bleu_score": 54.502820798309635, "chrf_score": 48.12707538069705, "xcomet_score": 0.6800856590270996, "xcomet_qe_score": 0.7350993752479553, "metricx_score": 4.735020160675049, "metricx_qe_score": 5.05325984954834, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图研究语言模型是否能够捕捉到我们现代社会中普遍存在的极化现象。", "metrics": {"bleu_score": 65.73236861797042, "chrf_score": 62.86985449001297, "xcomet_score": 0.9151284098625183, "xcomet_qe_score": 0.9887768030166626, "metricx_score": 0.6203600764274597, "metricx_qe_score": 0.8209339380264282, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们将预训练语料库分为美国第45任总统当选前后的两个时间段,", "metrics": {"bleu_score": 57.60615328748252, "chrf_score": 55.05469801157419, "xcomet_score": 0.9220705032348633, "xcomet_qe_score": 0.8286638259887695, "metricx_score": 1.5920720100402832, "metricx_qe_score": 1.6159968376159668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们分别在两个不同的时间段语料库上预训练语言模型,我们", "metrics": {"bleu_score": 78.01270245332928, "chrf_score": 80.73389719136516, "xcomet_score": 0.6391833424568176, "xcomet_qe_score": 0.6319053769111633, "metricx_score": 4.405759334564209, "metricx_qe_score": 0.9507886171340942, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到,语言模型在2017年后通常具有更远离中心的政治倾向,", "metrics": {"bleu_score": 65.4468923560319, "chrf_score": 58.61966696288251, "xcomet_score": 0.9600117802619934, "xcomet_qe_score": 0.9479700326919556, "metricx_score": 1.9855701923370361, "metricx_qe_score": 1.947369933128357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型也可以捕捉到我们社会中的极化现象。", "metrics": {"bleu_score": 72.52610922839372, "chrf_score": 72.71574866675135, "xcomet_score": 0.9943300485610962, "xcomet_qe_score": 0.947597324848175, "metricx_score": 0.8374693393707275, "metricx_qe_score": 1.1104284524917603, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们评估了具有不同政治倾向的语言模型在仇恨言论检测和虚假新闻检测方面的表现,这些自然语言处理应用通常涉及语言模型,可能具有非常重大的影响。因此,", "metrics": {"bleu_score": 58.37528622985453, "chrf_score": 55.4022696893024, "xcomet_score": 0.7518047094345093, "xcomet_qe_score": 0.8239993453025818, "metricx_score": 3.043379306793213, "metricx_qe_score": 1.5472526550292969, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到,如果我们按类别评估性能,也就是说,如果我们将性能分为不同的人口统计或政治媒体,我们可以看到一个模式,", "metrics": {"bleu_score": 34.479655697082194, "chrf_score": 30.00944165712991, "xcomet_score": 0.6395097970962524, "xcomet_qe_score": 0.6484781503677368, "metricx_score": 7.000331878662109, "metricx_qe_score": 6.045344829559326, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在仇恨言论检测方面,左翼语言模型在检测针对社会少数群体的仇恨言论方面表现更好,但在检测针对我们社会中更具权力的群体的仇恨言论方面表现较差,", "metrics": {"bleu_score": 65.85436060902828, "chrf_score": 62.51272286037918, "xcomet_score": 0.9664061069488525, "xcomet_qe_score": 0.9658246636390686, "metricx_score": 1.1710623502731323, "metricx_qe_score": 0.933684229850769, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "反之亦然。右翼语言模型在检测针对白人和男性的仇恨言论方面表现更好,但在检测针对黑人、LGBTQ+和其他少数群体的仇恨言论方面表现较差。", "metrics": {"bleu_score": 69.81645129084501, "chrf_score": 73.17766096587735, "xcomet_score": 0.9855619668960571, "xcomet_qe_score": 0.9868576526641846, "metricx_score": 0.5129989981651306, "metricx_qe_score": 0.6131967902183533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虚假新闻检测也出现了类似的趋势,我们看到,左翼语言模型在检测来自其相反政治倾向的虚假信息方面表现更好,反之亦然。", "metrics": {"bleu_score": 46.13974569478363, "chrf_score": 39.479164825885746, "xcomet_score": 0.9812633991241455, "xcomet_qe_score": 0.9912285804748535, "metricx_score": 1.0093060731887817, "metricx_qe_score": 1.3992500305175781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们进一步展示了许多定性例子,以证明语言模型具有不同的政治含义,确实会根据其社会类别对仇恨言论和虚假信息例子做出不同的预测。", "metrics": {"bleu_score": 61.25539405623767, "chrf_score": 54.90478600705365, "xcomet_score": 0.8788387775421143, "xcomet_qe_score": 0.8882418274879456, "metricx_score": 1.8797259330749512, "metricx_qe_score": 2.1023948192596436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "附录中有更多例子,进一步强调了这一点,表明语言模型的政治偏见存在一个非常紧迫的公平问题。", "metrics": {"bleu_score": 52.1561591499226, "chrf_score": 45.08313713317316, "xcomet_score": 0.9023185968399048, "xcomet_qe_score": 0.8516555428504944, "metricx_score": 1.475048542022705, "metricx_qe_score": 1.6442389488220215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果右翼语言模型在仇恨言论或虚假信息等方面进行微调,并部署到一个流行的社交媒体平台,这意味着具有相反政治观点的人可能会被边缘化,针对少数群体的仇恨言论可能会不受控制地蔓延。", "metrics": {"bleu_score": 53.630258895802704, "chrf_score": 47.691348963244856, "xcomet_score": 0.9618741273880005, "xcomet_qe_score": 0.898765504360199, "metricx_score": 0.8410935401916504, "metricx_qe_score": 1.0355688333511353, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这为我们敲响了警钟,要求我们承认并解决语言模型政治倾向导致的公平问题。", "metrics": {"bleu_score": 37.54453237069206, "chrf_score": 39.67705752085453, "xcomet_score": 0.9922338724136353, "xcomet_qe_score": 0.9909923076629639, "metricx_score": 0.8676937818527222, "metricx_qe_score": 0.838931679725647, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,进行了一些讨论。我们还", "metrics": {"bleu_score": 8.889175589171739, "chrf_score": 12.6610882983394, "xcomet_score": 0.18512369692325592, "xcomet_qe_score": 0.18938015401363373, "metricx_score": 5.603630542755127, "metricx_qe_score": 1.7798722982406616, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "希望强调,我们揭示了语言模型政治偏见的独特困境,", "metrics": {"bleu_score": 55.85650646013965, "chrf_score": 52.11606148754985, "xcomet_score": 0.8394550085067749, "xcomet_qe_score": 0.7584637403488159, "metricx_score": 1.7946155071258545, "metricx_qe_score": 2.0102946758270264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就像西西拉和卡吕普索之间的困境一样,", "metrics": {"bleu_score": 10.946291355069205, "chrf_score": 11.273325904784931, "xcomet_score": 0.759463906288147, "xcomet_qe_score": 0.7534056901931763, "metricx_score": 4.573032855987549, "metricx_qe_score": 4.128588676452637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,如果我们在语言模型训练数据中不净化政治观点,偏见将从预训练数据传播到语言模型再到下游任务,最终导致公平问题。", "metrics": {"bleu_score": 58.557949197873405, "chrf_score": 51.299719235810514, "xcomet_score": 0.9049346446990967, "xcomet_qe_score": 0.9164391756057739, "metricx_score": 1.1815769672393799, "metricx_qe_score": 1.8295644521713257, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们尝试以某种方式净化,我们也会冒着审查或排斥的风险,", "metrics": {"bleu_score": 48.28175506933025, "chrf_score": 39.50248293639098, "xcomet_score": 0.8833534717559814, "xcomet_qe_score": 0.8312749862670898, "metricx_score": 1.229874849319458, "metricx_qe_score": 2.4382102489471436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而且很难确定什么才是真正中立的,应该保留在语言数据中。因此,", "metrics": {"bleu_score": 13.762336467417896, "chrf_score": 16.17965798296673, "xcomet_score": 0.8111838102340698, "xcomet_qe_score": 0.6476017236709595, "metricx_score": 4.973625183105469, "metricx_qe_score": 3.7726516723632812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这有点像电车难题。", "metrics": {"bleu_score": 80.07374029168083, "chrf_score": 79.34458487087205, "xcomet_score": 0.9047262072563171, "xcomet_qe_score": 0.8099632263183594, "metricx_score": 1.5479735136032104, "metricx_qe_score": 2.939612627029419, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1375705748796463, "xcomet_qe_score": 0.10470917820930481, "metricx_score": 2.9054040908813477, "metricx_qe_score": 1.7279406785964966, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想这就是我今天要讲的全部,谢", "metrics": {"bleu_score": 57.02822264405544, "chrf_score": 53.249695611572804, "xcomet_score": 0.8740782141685486, "xcomet_qe_score": 0.8175777196884155, "metricx_score": 0.7350966930389404, "metricx_qe_score": 0.4733295440673828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢大家的关注,期待", "metrics": {"bleu_score": 31.702331385234313, "chrf_score": 34.646700801963036, "xcomet_score": 0.4139079749584198, "xcomet_qe_score": 0.23552191257476807, "metricx_score": 2.327732801437378, "metricx_qe_score": 0.5349401831626892, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9877438545227051, "xcomet_qe_score": 0.9831969738006592, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是珍妮,卡内基梅隆大学的一名一年级博士生,今天我将介绍你们的工作——AnL 位置性,描述设计偏见和模型的 beta 集。", "metrics": {"bleu_score": 39.63304358381594, "chrf_score": 27.10833282867813, "xcomet_score": 0.611851692199707, "xcomet_qe_score": 0.589078962802887, "metricx_score": 7.466599464416504, "metricx_qe_score": 7.78539514541626, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与华盛顿大学和艾伦人工智能研究所的一些人合作完成的,他们是塞巴斯蒂安·桑蒂、罗宁·拉布拉塞、卡塔里娜·雷尼卡和马丁·萨普。", "metrics": {"bleu_score": 35.81138787515277, "chrf_score": 25.041374533620576, "xcomet_score": 0.6740670204162598, "xcomet_qe_score": 0.7269841432571411, "metricx_score": 1.2647178173065186, "metricx_qe_score": 0.9578965306282043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "让我们先想象一下,你为一家报纸工作,你在筛选新闻文章下的评论,试图删除有毒内容,", "metrics": {"bleu_score": 48.35069689001181, "chrf_score": 40.46674208226154, "xcomet_score": 0.8675698637962341, "xcomet_qe_score": 0.9227834939956665, "metricx_score": 2.0166800022125244, "metricx_qe_score": 1.5040807723999023, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你可能会转向像 prospective API 这样的流行 API 进行有毒性检测,如果你是卡尔·琼斯,pros", "metrics": {"bleu_score": 13.569716909690202, "chrf_score": 28.19123515375669, "xcomet_score": 0.468630313873291, "xcomet_qe_score": 0.48000290989875793, "metricx_score": 8.536323547363281, "metricx_qe_score": 7.226583003997803, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "pective API 能够正确检测出有毒的实例,但", "metrics": {"bleu_score": 38.50322886878711, "chrf_score": 58.863688058021225, "xcomet_score": 0.45030537247657776, "xcomet_qe_score": 0.40212905406951904, "metricx_score": 13.025534629821777, "metricx_qe_score": 10.299400329589844, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这对于迪斯·夏尔马来说并不是真的,", "metrics": {"bleu_score": 6.839596061560946, "chrf_score": 5.049399699849924, "xcomet_score": 0.1786562204360962, "xcomet_qe_score": 0.24277126789093018, "metricx_score": 6.484257698059082, "metricx_qe_score": 5.217297077178955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为 perspectiveive API 对印度语境中更常见的攻击性用词并不敏感,", "metrics": {"bleu_score": 54.120475514419645, "chrf_score": 61.49024412199302, "xcomet_score": 0.809808611869812, "xcomet_qe_score": 0.6556497812271118, "metricx_score": 5.1348347663879395, "metricx_qe_score": 5.429556369781494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏见的例子,我们在这里看到技术在不同人群之间的系统性性能差异。", "metrics": {"bleu_score": 49.608376191368286, "chrf_score": 45.315649175926, "xcomet_score": 0.9821426868438721, "xcomet_qe_score": 0.8593618869781494, "metricx_score": 0.9824047088623047, "metricx_qe_score": 1.5483784675598145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "像我们之前看到的这种设计偏见可能是由于 NLP 研究人员和模型开发人员的立场造成的。", "metrics": {"bleu_score": 46.91961692411197, "chrf_score": 41.93275781989413, "xcomet_score": 0.9805328845977783, "xcomet_qe_score": 0.9792416095733643, "metricx_score": 0.761496901512146, "metricx_qe_score": 0.8201524615287781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "立场性简单来说就是人们由于其人口统计、身份和生活经历而持有的观点。", "metrics": {"bleu_score": 51.58704946837358, "chrf_score": 56.22676662210905, "xcomet_score": 0.846699595451355, "xcomet_qe_score": 0.8370213508605957, "metricx_score": 2.1850485801696777, "metricx_qe_score": 2.366730213165283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判性研究中广泛使用的概念,特别是在女权主义和酷儿学术空间中。", "metrics": {"bleu_score": 84.99508493439812, "chrf_score": 78.52778542176075, "xcomet_score": 0.9886690378189087, "xcomet_qe_score": 0.8710610866546631, "metricx_score": 1.2322998046875, "metricx_qe_score": 2.1960177421569824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "作为研究人员,立场性可以影响研究过程及其结果和结果,因为它可以改变研究人员的决策,", "metrics": {"bleu_score": 45.12553535285211, "chrf_score": 37.892434213684936, "xcomet_score": 0.7889649868011475, "xcomet_qe_score": 0.7652207612991333, "metricx_score": 3.4656097888946533, "metricx_qe_score": 3.3995795249938965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此人们可能会问一个问题,数据集和模型是否有立场性,", "metrics": {"bleu_score": 75.61559858236036, "chrf_score": 69.33068742851351, "xcomet_score": 0.9027799367904663, "xcomet_qe_score": 0.8318394422531128, "metricx_score": 0.8920729756355286, "metricx_qe_score": 1.1680070161819458, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们并不是说模型本身和数据集本身有人口统计身份和生活经历,但它们确实汇集了真实的人们的判断和观点,因此可以代表某些立场性", "metrics": {"bleu_score": 54.75848541392021, "chrf_score": 44.96828537033809, "xcomet_score": 0.7201849818229675, "xcomet_qe_score": 0.779937744140625, "metricx_score": 2.243880033493042, "metricx_qe_score": 2.536189317703247, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "优于其他立场性。之前的研究已经提出了关于立场性的轶事证据,例如模型和数据集中的文化差距,以及模型立场性的理论定义,", "metrics": {"bleu_score": 43.02284958319486, "chrf_score": 37.87348504218833, "xcomet_score": 0.435843825340271, "xcomet_qe_score": 0.3639136850833893, "metricx_score": 6.187317371368408, "metricx_qe_score": 8.311797142028809, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些工作并没有真正比较最终用户与数据集和模型本身,而研究模型和数据集的立场性变得越来越重要,因为 NLP 任务变得更加主观和社会导向,并且很难描述这些立场性的偏差,因为并非所有决策都被记录,许多模型隐藏在 API 背后,", "metrics": {"bleu_score": 53.554964246181726, "chrf_score": 48.49184599078654, "xcomet_score": 0.7213101983070374, "xcomet_qe_score": 0.685010552406311, "metricx_score": 3.5186030864715576, "metricx_qe_score": 3.1371614933013916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,为了研究数据集和模型的立场性,我们实际上是将注释与真实用户与现有数据集和模型进行比较,", "metrics": {"bleu_score": 55.082276437802236, "chrf_score": 50.69220423775085, "xcomet_score": 0.754309892654419, "xcomet_qe_score": 0.6996750235557556, "metricx_score": 3.043024778366089, "metricx_qe_score": 3.2612712383270264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过我们的框架 Nl 位置性来实现这一点,", "metrics": {"bleu_score": 19.83544145418288, "chrf_score": 14.164040341172612, "xcomet_score": 0.7974474430084229, "xcomet_qe_score": 0.7996711134910583, "metricx_score": 2.1289045810699463, "metricx_qe_score": 2.796769380569458, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架分为两个主要步骤,", "metrics": {"bleu_score": 38.05803001674947, "chrf_score": 34.258652377176034, "xcomet_score": 0.9411728382110596, "xcomet_qe_score": 0.8613287806510925, "metricx_score": 0.24260416626930237, "metricx_qe_score": 0.3197183907032013, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是用多样化的注释者重新注释数据集,", "metrics": {"bleu_score": 46.42960661381955, "chrf_score": 38.13835270648493, "xcomet_score": 0.8576827049255371, "xcomet_qe_score": 0.8910289406776428, "metricx_score": 2.807497978210449, "metricx_qe_score": 2.5645248889923096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们选择这样做是因为通常只有少数注释者注释每个实例,而且人口统计数据很少被收集和分享,因此", "metrics": {"bleu_score": 37.153375517685014, "chrf_score": 38.204689688527466, "xcomet_score": 0.7547158002853394, "xcomet_qe_score": 0.7563512325286865, "metricx_score": 4.728102684020996, "metricx_qe_score": 3.9030284881591797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们选择重新注释数据以获得许多注释实例,并获得丰富的社会人口数据,然后", "metrics": {"bleu_score": 34.1892821465851, "chrf_score": 31.216068500793465, "xcomet_score": 0.7893961668014526, "xcomet_qe_score": 0.711788535118103, "metricx_score": 5.223019599914551, "metricx_qe_score": 2.5146751403808594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们按人口统计数据对注释进行分组,并使用皮尔逊相关分数将它们与模型和数据集进行比较,因此,我们的框架实际上与注释者分歧文献不同,它通过比较最终用户与模型和数据集的预测和标签,而不是仅仅关注注释者的同意或模型注释者的分布。", "metrics": {"bleu_score": 56.80517089547529, "chrf_score": 49.65022276157797, "xcomet_score": 0.5178360939025879, "xcomet_qe_score": 0.6076208353042603, "metricx_score": 5.225019931793213, "metricx_qe_score": 5.308295249938965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架在很大程度上是通过实验室在野外(lab in the wild)在线众包平台实现的", "metrics": {"bleu_score": 32.910644083871475, "chrf_score": 37.99308227912477, "xcomet_score": 0.7527709007263184, "xcomet_qe_score": 0.6346694231033325, "metricx_score": 5.758752822875977, "metricx_qe_score": 5.390340805053711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",前者是 HCI 合作者,后者是一个在线实验平台,我们可以在这里招募多样化的志愿者,", "metrics": {"bleu_score": 34.493948973979805, "chrf_score": 29.277208415351915, "xcomet_score": 0.4003392159938812, "xcomet_qe_score": 0.26252368092536926, "metricx_score": 6.009446144104004, "metricx_qe_score": 7.918927192687988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "相比于像 Turk 这样的平台,这些平台主要有来自美国或印度的参与者,而且实验室在野外的平台仍然能够获得高质量的数据,", "metrics": {"bleu_score": 36.363042717008305, "chrf_score": 34.41442655207835, "xcomet_score": 0.5734219551086426, "xcomet_qe_score": 0.5713496208190918, "metricx_score": 6.101394176483154, "metricx_qe_score": 6.507258415222168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在实验室在野外的平台上托管了两个任务,其中一个是社会可接受性,它的工作原理是参与者将阅读来自社会化学数据集的某个情境,然后他们将写出这个情境在社会上是多么可", "metrics": {"bleu_score": 35.51310818780723, "chrf_score": 28.333752269728418, "xcomet_score": 0.5597869157791138, "xcomet_qe_score": 0.3986273407936096, "metricx_score": 6.155858993530273, "metricx_qe_score": 4.866831302642822, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接受,为了保持参与研究,他们可以将他们的回答与 AI 和其他人进行比较,", "metrics": {"bleu_score": 46.567920384284534, "chrf_score": 39.83824861144082, "xcomet_score": 0.5304877758026123, "xcomet_qe_score": 0.21910227835178375, "metricx_score": 5.517594337463379, "metricx_qe_score": 5.5011515617370605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们将这些注释与社会化学 Delphi 和 gPT4 进行比较。", "metrics": {"bleu_score": 43.856179028373525, "chrf_score": 50.58678877036702, "xcomet_score": 0.796807050704956, "xcomet_qe_score": 0.7625281810760498, "metricx_score": 2.376204252243042, "metricx_qe_score": 3.4491782188415527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们为有毒性和仇恨言论检测任务复制了一个非常相似的设置,参与者将阅读 Dynah Hate 中的一个实例,并写出他们是否认为这是一个仇恨言论的实例。", "metrics": {"bleu_score": 57.79637535227914, "chrf_score": 56.33383994486461, "xcomet_score": 0.7451642751693726, "xcomet_qe_score": 0.7554255723953247, "metricx_score": 4.291140079498291, "metricx_qe_score": 4.938030242919922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们将这些注释与 Dyna Hate Perspective API、Rewire API、Hate Roberta 和 GPT4 进行比较。", "metrics": {"bleu_score": 57.18002722651104, "chrf_score": 81.96004667658286, "xcomet_score": 0.6828969120979309, "xcomet_qe_score": 0.47990235686302185, "metricx_score": 2.9784531593322754, "metricx_qe_score": 4.672552585601807, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究最终收集了来自 87 个国家的 1000 多名注释者的 16,000 多个注释。", "metrics": {"bleu_score": 90.9593063222022, "chrf_score": 91.62670716850285, "xcomet_score": 0.983390212059021, "xcomet_qe_score": 0.9916937351226807, "metricx_score": 3.3376967906951904, "metricx_qe_score": 4.629024982452393, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以现在我们更有能力回答谁与 NLP 数据集和模型最符合?我们", "metrics": {"bleu_score": 49.024473947853146, "chrf_score": 46.73578259793077, "xcomet_score": 0.5952863097190857, "xcomet_qe_score": 0.6269726753234863, "metricx_score": 6.22086763381958, "metricx_qe_score": 2.4344873428344727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现 NLP 中存在立场性。", "metrics": {"bleu_score": 24.503899381240508, "chrf_score": 28.062549846235825, "xcomet_score": 0.8804922699928284, "xcomet_qe_score": 0.8321001529693604, "metricx_score": 0.878899097442627, "metricx_qe_score": 1.2524149417877197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们发现数据集和模型最符合英语国家的立场性。因此", "metrics": {"bleu_score": 45.263535623901475, "chrf_score": 39.185087590884685, "xcomet_score": 0.8115577697753906, "xcomet_qe_score": 0.8036330938339233, "metricx_score": 3.3263020515441895, "metricx_qe_score": 1.8134846687316895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",对于 gpd 四社会可接受性分析,我们发现它最符合儒家和英语国家的立场性,", "metrics": {"bleu_score": 48.92199210635082, "chrf_score": 41.404839893852824, "xcomet_score": 0.730743408203125, "xcomet_qe_score": 0.6685456037521362, "metricx_score": 6.469743728637695, "metricx_qe_score": 7.735830783843994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现 Dinah hate 也最符合英语国家的立场", "metrics": {"bleu_score": 63.019085559238604, "chrf_score": 63.1706902301868, "xcomet_score": 0.7218663692474365, "xcomet_qe_score": 0.6468774080276489, "metricx_score": 5.87666130065918, "metricx_qe_score": 7.206918239593506, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "性,我们还发现与受过大学教育的人群的立场性最符合。因此", "metrics": {"bleu_score": 44.18632145518061, "chrf_score": 34.79374358063367, "xcomet_score": 0.2710045576095581, "xcomet_qe_score": 0.2157270312309265, "metricx_score": 8.407171249389648, "metricx_qe_score": 6.47138786315918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",对于 gpd4 在社会可接受性任务中,我们发现它最符合受过大学教育或研究生教育的人群,我们发现对于 Dinah hate 也是如此,它最符合受过大学教育的人群,然而", "metrics": {"bleu_score": 46.77421406317533, "chrf_score": 40.60059328179124, "xcomet_score": 0.5365621447563171, "xcomet_qe_score": 0.39469897747039795, "metricx_score": 11.397644996643066, "metricx_qe_score": 8.9011869430542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",当模型和数据集与特定人群对齐时,有些人不可避免地会被抛在后", "metrics": {"bleu_score": 47.60821382287173, "chrf_score": 42.667084551824615, "xcomet_score": 0.7557392120361328, "xcomet_qe_score": 0.7897883653640747, "metricx_score": 2.958770513534546, "metricx_qe_score": 3.3292436599731445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "面,一个例子是数据集和模型与非二元人群的对齐程度低于男性和女性人群,", "metrics": {"bleu_score": 39.04643321151898, "chrf_score": 34.75722255938114, "xcomet_score": 0.513267993927002, "xcomet_qe_score": 0.3899350166320801, "metricx_score": 5.561036586761475, "metricx_qe_score": 5.783246994018555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在 gPDd4 社会可接受性任务以及 Dinah hate 任务分析中都发现了这一点。", "metrics": {"bleu_score": 67.16833901993986, "chrf_score": 61.8537194499011, "xcomet_score": 0.7100088596343994, "xcomet_qe_score": 0.7032794952392578, "metricx_score": 6.161081314086914, "metricx_qe_score": 6.800127029418945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,鉴于 NP 中存在立场性,我们可以做些什么呢?", "metrics": {"bleu_score": 33.232177395586454, "chrf_score": 30.713502782591128, "xcomet_score": 0.799025297164917, "xcomet_qe_score": 0.7827666997909546, "metricx_score": 1.991697907447815, "metricx_qe_score": 2.7501397132873535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们有几个建议,", "metrics": {"bleu_score": 17.765505306875905, "chrf_score": 15.317832490737018, "xcomet_score": 0.6606754064559937, "xcomet_qe_score": 0.6132557988166809, "metricx_score": 0.5179681777954102, "metricx_qe_score": 0.3241502642631531, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是在整个研究过程中记录所有相关的设计选择,第二个", "metrics": {"bleu_score": 47.83326851274273, "chrf_score": 41.9227192351378, "xcomet_score": 0.8456105589866638, "xcomet_qe_score": 0.8040778040885925, "metricx_score": 5.460377216339111, "metricx_qe_score": 2.090191602706909, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是用前瞻性的视角进行 NLP", "metrics": {"bleu_score": 4.008445555958475, "chrf_score": 3.801113661480915, "xcomet_score": 0.49737241864204407, "xcomet_qe_score": 0.6844133734703064, "metricx_score": 7.144213676452637, "metricx_qe_score": 6.590884685516357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究,我们的第三个建议是在四个特定社区内构建专门的数据集和模型,", "metrics": {"bleu_score": 78.39800200378247, "chrf_score": 80.70624457764517, "xcomet_score": 0.6741364002227783, "xcomet_qe_score": 0.6939898729324341, "metricx_score": 2.541947841644287, "metricx_qe_score": 3.1635076999664307, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个很好的例子是 masakanne 计划,我们希望", "metrics": {"bleu_score": 38.50322886878711, "chrf_score": 34.17544920104215, "xcomet_score": 0.22289302945137024, "xcomet_qe_score": 0.1893029361963272, "metricx_score": 8.151127815246582, "metricx_qe_score": 7.916171073913574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "强调,包容性的 NLP 不仅仅是让所有技术", "metrics": {"bleu_score": 43.53954325897961, "chrf_score": 46.894151453649144, "xcomet_score": 0.20089933276176453, "xcomet_qe_score": 0.15362849831581116, "metricx_score": 5.530213832855225, "metricx_qe_score": 6.0051774978637695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "都能为每个人工作,这", "metrics": {"bleu_score": 3.701773936489291, "chrf_score": 3.787878787878787, "xcomet_score": 0.27435028553009033, "xcomet_qe_score": 0.3253178894519806, "metricx_score": 10.822198867797852, "metricx_qe_score": 5.523512363433838, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就是我们的介绍结束", "metrics": {"bleu_score": 19.969395881889398, "chrf_score": 16.322199135289424, "xcomet_score": 0.8328526020050049, "xcomet_qe_score": 0.827545702457428, "metricx_score": 4.311464309692383, "metricx_qe_score": 2.524583339691162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",但如果你想了解更多,请随时查看我们的仪表板以获取最新的分析结果和我们的论文,", "metrics": {"bleu_score": 54.48496348870002, "chrf_score": 48.68999429613538, "xcomet_score": 0.9243568181991577, "xcomet_qe_score": 0.9077903032302856, "metricx_score": 1.3001644611358643, "metricx_qe_score": 1.067753553390503, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集,感谢大家。", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 13.88888888888889, "xcomet_score": 0.5856402516365051, "xcomet_qe_score": 0.5132632851600647, "metricx_score": 3.4826180934906006, "metricx_qe_score": 3.5140843391418457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自FNAi大学的袁X。", "metrics": {"bleu_score": 29.13055375496153, "chrf_score": 19.597802074577693, "xcomet_score": 0.6542848348617554, "xcomet_qe_score": 0.6252338886260986, "metricx_score": 6.32477331161499, "metricx_qe_score": 7.215877532958984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我今天在这里介绍我们的工作,即在", "metrics": {"bleu_score": 7.779266925816898, "chrf_score": 9.167538660907471, "xcomet_score": 0.26708054542541504, "xcomet_qe_score": 0.16713681817054749, "metricx_score": 12.031789779663086, "metricx_qe_score": 8.776228904724121, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "日常生活中,人类必须经常根据保证脚本的形式逐步执行指令来计划自己的行动。", "metrics": {"bleu_score": 16.8955474850733, "chrf_score": 15.634575800016979, "xcomet_score": 0.7817350029945374, "xcomet_qe_score": 0.7738845944404602, "metricx_score": 4.752418518066406, "metricx_qe_score": 4.64852237701416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之前的研究利用语言模型来计划典型的抽象目标,", "metrics": {"bleu_score": 42.169024134080495, "chrf_score": 41.62428587670543, "xcomet_score": 0.8044025897979736, "xcomet_qe_score": 0.7806761264801025, "metricx_score": 5.564723968505859, "metricx_qe_score": 7.149475574493408, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如制作蛋糕,并表明大型语言模型可以有效地将目标分解为步骤。", "metrics": {"bleu_score": 54.95207706557383, "chrf_score": 54.01336196735137, "xcomet_score": 0.26738348603248596, "xcomet_qe_score": 0.22707274556159973, "metricx_score": 3.5221283435821533, "metricx_qe_score": 1.7260466814041138, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,之前的研究主要集中在计划典型的抽象目标上,", "metrics": {"bleu_score": 51.454393526052044, "chrf_score": 45.05619868450121, "xcomet_score": 0.8317289352416992, "xcomet_qe_score": 0.7820392847061157, "metricx_score": 3.800004243850708, "metricx_qe_score": 3.1335129737854004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而对于具有特定约束的目标,例如制作巧克力蛋糕,仍然未得到充分的关注。", "metrics": {"bleu_score": 20.3264842568494, "chrf_score": 19.543402425112223, "xcomet_score": 0.9119381904602051, "xcomet_qe_score": 0.9060220122337341, "metricx_score": 1.2207568883895874, "metricx_qe_score": 1.7122454643249512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这篇论文中,我们定义了受约束的语言计划问题,该问题对计划目标施加了不同的约束。", "metrics": {"bleu_score": 50.42947508352393, "chrf_score": 46.562437500162964, "xcomet_score": 0.8938743472099304, "xcomet_qe_score": 0.8772134184837341, "metricx_score": 1.9043703079223633, "metricx_qe_score": 2.4165992736816406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个抽象目标可以被不同的现实生活中的具体目标继承,这些具体目标具有", "metrics": {"bleu_score": 30.454520050730334, "chrf_score": 28.930651547174463, "xcomet_score": 0.7312098741531372, "xcomet_qe_score": 0.7923187017440796, "metricx_score": 8.188196182250977, "metricx_qe_score": 6.526149749755859, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "多方面的约束。一个好的计划者应该编写符合约束的合理脚本。在这篇论", "metrics": {"bleu_score": 12.692707541575553, "chrf_score": 15.345718999184705, "xcomet_score": 0.38017988204956055, "xcomet_qe_score": 0.24214018881320953, "metricx_score": 7.376929759979248, "metricx_qe_score": 5.598616123199463, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "文中,我们首先评估和改进生活语言模型的受约束语言计划能力。", "metrics": {"bleu_score": 44.05155249693397, "chrf_score": 35.84003339105885, "xcomet_score": 0.6615075469017029, "xcomet_qe_score": 0.697669267654419, "metricx_score": 3.9960105419158936, "metricx_qe_score": 3.434239387512207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于没有特定目标的数据可用,为了进行我们的研究,我们必须首先获取这些目标。", "metrics": {"bleu_score": 57.80578702678327, "chrf_score": 50.077571997640526, "xcomet_score": 0.8430145978927612, "xcomet_qe_score": 0.8397011756896973, "metricx_score": 1.9764766693115234, "metricx_qe_score": 2.5775277614593506, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如表所示,我们扩展了抽象目标,为人类在循环数据获取中使用instruct GPT,我们采样", "metrics": {"bleu_score": 16.887395002920915, "chrf_score": 28.849292002947593, "xcomet_score": 0.5024198293685913, "xcomet_qe_score": 0.5607218742370605, "metricx_score": 9.894182205200195, "metricx_qe_score": 10.67910385131836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了100个具体目标,并评估了从库模型生成的脚本。", "metrics": {"bleu_score": 52.4389384353241, "chrf_score": 50.97667951262179, "xcomet_score": 0.22001180052757263, "xcomet_qe_score": 0.1957811713218689, "metricx_score": 6.879454612731934, "metricx_qe_score": 7.095881462097168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该表报告了结果的总体准确性。", "metrics": {"bleu_score": 42.57110866884422, "chrf_score": 32.00655355944401, "xcomet_score": 0.9927786588668823, "xcomet_qe_score": 0.9881556034088135, "metricx_score": 0.7947359681129456, "metricx_qe_score": 0.811003565788269, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现所有学习模型在计划具体目标方面都取得了不令人满意的结果。", "metrics": {"bleu_score": 36.3814678024691, "chrf_score": 32.6237939936547, "xcomet_score": 0.9214764833450317, "xcomet_qe_score": 0.9031593203544617, "metricx_score": 0.9426064491271973, "metricx_qe_score": 1.359836220741272, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们进行详细分析,调查学习模型的原因。", "metrics": {"bleu_score": 39.65181680987307, "chrf_score": 30.62215787728485, "xcomet_score": 0.8681044578552246, "xcomet_qe_score": 0.8836984038352966, "metricx_score": 2.792562246322632, "metricx_qe_score": 4.444917678833008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的结果表明,生成的脚本在语义完整性方面是可接受的,但在忠实于约束方面不能保证。", "metrics": {"bleu_score": 31.62121517585004, "chrf_score": 27.17852979927194, "xcomet_score": 0.9203411936759949, "xcomet_qe_score": 0.9180645942687988, "metricx_score": 0.902229905128479, "metricx_qe_score": 1.0411962270736694, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入研究了WiH中定义的更细致的约束类别。", "metrics": {"bleu_score": 38.16395972548648, "chrf_score": 27.78797694225223, "xcomet_score": 0.7288841009140015, "xcomet_qe_score": 0.7976415753364563, "metricx_score": 3.862941265106201, "metricx_qe_score": 4.873684406280518, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的热图显示,instruct GPT的计划性能在不同类别的女孩中差异很大,", "metrics": {"bleu_score": 40.647710644366754, "chrf_score": 47.91856051099457, "xcomet_score": 0.6158446073532104, "xcomet_qe_score": 0.4397185146808624, "metricx_score": 6.651610374450684, "metricx_qe_score": 6.738885402679443, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "之前的研究表明,学习模型的输出质量在高方差下下降,导致性能不佳。", "metrics": {"bleu_score": 41.82088803780056, "chrf_score": 38.27407431290417, "xcomet_score": 0.8966490030288696, "xcomet_qe_score": 0.9022061824798584, "metricx_score": 2.569655656814575, "metricx_qe_score": 1.9100984334945679, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们采用了过生成Z滤波器来提高生成质量。", "metrics": {"bleu_score": 37.27829626351422, "chrf_score": 32.85842282240673, "xcomet_score": 0.837253212928772, "xcomet_qe_score": 0.8137604594230652, "metricx_score": 4.931050777435303, "metricx_qe_score": 5.502419948577881, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先展示了instruct GPT的受约束类型,并根据种子抽象目标获得了具体目标。", "metrics": {"bleu_score": 58.023719417793565, "chrf_score": 57.16691569373483, "xcomet_score": 0.7019793391227722, "xcomet_qe_score": 0.6689466238021851, "metricx_score": 3.9802932739257812, "metricx_qe_score": 5.020301818847656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,instruct GPT对特定目标的关键脚本进行了过生成。", "metrics": {"bleu_score": 11.187338538742793, "chrf_score": 38.48467823414404, "xcomet_score": 0.8081426620483398, "xcomet_qe_score": 0.8096240758895874, "metricx_score": 5.709715843200684, "metricx_qe_score": 6.15683126449585, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我们开发了一个滤波模型来选择忠实的脚本。", "metrics": {"bleu_score": 50.47386070345474, "chrf_score": 40.818770456050956, "xcomet_score": 0.857265830039978, "xcomet_qe_score": 0.8441545367240906, "metricx_score": 2.130422353744507, "metricx_qe_score": 2.04362416267395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和目标转换为instruct GPT嵌入,并计算余弦相似度和相似度分数来衡量语义相似度。", "metrics": {"bleu_score": 66.47677144701001, "chrf_score": 65.20883069781416, "xcomet_score": 0.8733359575271606, "xcomet_qe_score": 0.7226991653442383, "metricx_score": 3.460737705230713, "metricx_qe_score": 3.391752004623413, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们奖励包含目标约束关键词的脚本。", "metrics": {"bleu_score": 57.97765003730531, "chrf_score": 54.89525378061659, "xcomet_score": 0.8477377891540527, "xcomet_qe_score": 0.8053245544433594, "metricx_score": 0.9846863746643066, "metricx_qe_score": 1.2254678010940552, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果目标在目标大小中得分最高,我们才保留该脚本。", "metrics": {"bleu_score": 39.705492947539675, "chrf_score": 31.709062352040647, "xcomet_score": 0.7625042200088501, "xcomet_qe_score": 0.7025293111801147, "metricx_score": 4.305809020996094, "metricx_qe_score": 5.488247394561768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的方法,instruct GPT可以生成更高质量的脚本。", "metrics": {"bleu_score": 77.393215404741, "chrf_score": 83.79214027434271, "xcomet_score": 0.9660891890525818, "xcomet_qe_score": 0.9589831829071045, "metricx_score": 1.4924495220184326, "metricx_qe_score": 2.017679452896118, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法大大提高了计划在语义、完整性和忠实于约束方面的可行性。", "metrics": {"bleu_score": 36.051664828581735, "chrf_score": 29.673082215967213, "xcomet_score": 0.8610224723815918, "xcomet_qe_score": 0.8955288529396057, "metricx_score": 1.6159131526947021, "metricx_qe_score": 1.381545901298523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型的部署成本高,因此必须使较小和专业模型具有语言计划能力。", "metrics": {"bleu_score": 41.14329905565294, "chrf_score": 35.45129777970627, "xcomet_score": 0.9717389941215515, "xcomet_qe_score": 0.9717769026756287, "metricx_score": 1.1200017929077148, "metricx_qe_score": 1.084185242652893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "创建数据集是实现这一目标的必要步骤。", "metrics": {"bleu_score": 75.11573912724296, "chrf_score": 70.00087795052626, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.11220654845237732, "metricx_qe_score": 0.20811273157596588, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,之前的研究没有实现对特定目标的计划,手动数据标注成本高昂。为", "metrics": {"bleu_score": 24.238924298411774, "chrf_score": 20.780731004828358, "xcomet_score": 0.6821817755699158, "xcomet_qe_score": 0.7207310199737549, "metricx_score": 5.2974629402160645, "metricx_qe_score": 3.404223918914795, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此,我们遵循符号知识蒸馏的思想,从轻语言模型中蒸馏受约束的语言计划数据集。", "metrics": {"bleu_score": 44.90667137192901, "chrf_score": 36.29977528626535, "xcomet_score": 0.6269013285636902, "xcomet_qe_score": 0.5132541656494141, "metricx_score": 6.438182353973389, "metricx_qe_score": 5.467768669128418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们应用我们的方法来构建一个受约束的语言计划数据集,命名为CodeScript。", "metrics": {"bleu_score": 24.587678515080675, "chrf_score": 36.63172748620803, "xcomet_score": 0.9129616022109985, "xcomet_qe_score": 0.8910377025604248, "metricx_score": 1.4756748676300049, "metricx_qe_score": 1.7006601095199585, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共,我们生成了55,000个具有脚本的具体目标。", "metrics": {"bleu_score": 47.97543511401895, "chrf_score": 52.73172720998808, "xcomet_score": 0.8747341632843018, "xcomet_qe_score": 0.8584303855895996, "metricx_score": 3.235373020172119, "metricx_qe_score": 2.3610892295837402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确保验证和测试网站的质量,我们请众包工人找到并修改错误样本的收入。", "metrics": {"bleu_score": 36.05231073512947, "chrf_score": 30.762219890680427, "xcomet_score": 0.634540855884552, "xcomet_qe_score": 0.5916903018951416, "metricx_score": 8.192484855651855, "metricx_qe_score": 7.690557956695557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该图显示了CodeScript的约束分布。", "metrics": {"bleu_score": 58.33510584342546, "chrf_score": 72.24911196939357, "xcomet_score": 0.9625097513198853, "xcomet_qe_score": 0.8983068466186523, "metricx_score": 1.2738232612609863, "metricx_qe_score": 2.105375289916992, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现CodeScript在生成的具体目标中显示了高度的多元化。", "metrics": {"bleu_score": 64.56676727729074, "chrf_score": 63.681199135512614, "xcomet_score": 0.9349461793899536, "xcomet_qe_score": 0.9345275163650513, "metricx_score": 2.170304298400879, "metricx_qe_score": 3.309786558151245, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过CodeScript,我们可以处理较小但专业化的受约束语言计划模型。", "metrics": {"bleu_score": 20.61972822842957, "chrf_score": 25.8039000057501, "xcomet_score": 0.7748776078224182, "xcomet_qe_score": 0.6651046276092529, "metricx_score": 2.430438280105591, "metricx_qe_score": 2.5067858695983887, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,在评分率上进行微调的t5可以生成比大多数大型语言模型更优质的脚本,这表明在适当的数据集上进行训练的小型模型可以支持大型模型。", "metrics": {"bleu_score": 40.38001568693991, "chrf_score": 32.71801091117922, "xcomet_score": 0.6146512031555176, "xcomet_qe_score": 0.635256290435791, "metricx_score": 6.343586444854736, "metricx_qe_score": 5.885570526123047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结起来,我们建立了受约束的语言计划问题,", "metrics": {"bleu_score": 33.86854985606571, "chrf_score": 31.340060767576087, "xcomet_score": 0.826956033706665, "xcomet_qe_score": 0.8718321323394775, "metricx_score": 2.234895706176758, "metricx_qe_score": 2.473132371902466, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "评估了大型语言模型的受约束语言计划能力,并为生活语言模型开发了一个过生成滤波器方法。", "metrics": {"bleu_score": 38.44925368079534, "chrf_score": 32.76765806812779, "xcomet_score": 0.6634286046028137, "xcomet_qe_score": 0.7424180507659912, "metricx_score": 4.387279033660889, "metricx_qe_score": 5.084653377532959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型生成了高质量的CodeScript数据集,用于受约束的语言计划。", "metrics": {"bleu_score": 37.96390038542474, "chrf_score": 38.14769018708864, "xcomet_score": 0.8576583862304688, "xcomet_qe_score": 0.8152093887329102, "metricx_score": 2.344029426574707, "metricx_qe_score": 2.8104677200317383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望CodeScript数据集可以成为推进语言计划研究的宝贵资源。", "metrics": {"bleu_score": 62.69641331921133, "chrf_score": 65.36564621691683, "xcomet_score": 0.8094930648803711, "xcomet_qe_score": 0.8465861082077026, "metricx_score": 1.478522539138794, "metricx_qe_score": 1.595863938331604, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢大家的聆听。", "metrics": {"bleu_score": 42.13952948452608, "chrf_score": 32.788058353382866, "xcomet_score": 0.9069567322731018, "xcomet_qe_score": 0.9503745436668396, "metricx_score": 0.8548282980918884, "metricx_qe_score": 0.7676814794540405, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有关CodeScript的更多详细信息,请参见我们的论文。", "metrics": {"bleu_score": 49.385277270209265, "chrf_score": 57.23678876989236, "xcomet_score": 0.9741768836975098, "xcomet_qe_score": 0.9869545698165894, "metricx_score": 0.6883362531661987, "metricx_qe_score": 0.7493165731430054, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。我叫舒哈。", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 13.375784036811606, "xcomet_score": 0.8226977586746216, "xcomet_qe_score": 0.7970973253250122, "metricx_score": 0.9608427286148071, "metricx_qe_score": 1.6847738027572632, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我要介绍我们的论文《Do Connel 2003命名实体标注方法在2023年仍然有效》", "metrics": {"bleu_score": 53.058662026608964, "chrf_score": 48.17140586970721, "xcomet_score": 0.7811702489852905, "xcomet_qe_score": 0.6746629476547241, "metricx_score": 5.5425639152526855, "metricx_qe_score": 5.612088203430176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "。让我们开始吧。", "metrics": {"bleu_score": 84.08964152537145, "chrf_score": 95.15349630471859, "xcomet_score": 0.9835532903671265, "xcomet_qe_score": 0.9856218099594116, "metricx_score": 0.7622692584991455, "metricx_qe_score": 1.1052849292755127, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了泛化问题,使用命名实体识别任务(NER任务)我们", "metrics": {"bleu_score": 52.147455609285906, "chrf_score": 45.44383665788046, "xcomet_score": 0.7705073356628418, "xcomet_qe_score": 0.7468376159667969, "metricx_score": 6.202385425567627, "metricx_qe_score": 3.613401174545288, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "观察到,近20年来,模型一直在使用Con 2003来开发NER,这自然引发了几个问题:", "metrics": {"bleu_score": 17.527261432819035, "chrf_score": 25.036821126986435, "xcomet_score": 0.749764084815979, "xcomet_qe_score": 0.7723990678787231, "metricx_score": 7.571996688842773, "metricx_qe_score": 6.753578186035156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,这些模型能否泛化到现代数据?", "metrics": {"bleu_score": 78.28161456481268, "chrf_score": 75.02410579616462, "xcomet_score": 0.9989852905273438, "xcomet_qe_score": 0.9952034950256348, "metricx_score": 0.28112250566482544, "metricx_qe_score": 0.2982765734195709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们开发新的标注器时,需要什么才能实现良好的泛化?", "metrics": {"bleu_score": 62.56538561604213, "chrf_score": 53.31061933235846, "xcomet_score": 0.9991610050201416, "xcomet_qe_score": 0.9945460557937622, "metricx_score": 0.4566256105899811, "metricx_qe_score": 0.6512018442153931, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,如果我们观察到泛化效果不佳,这些模型的性能下降是由什么原因造成的?", "metrics": {"bleu_score": 30.55356044749405, "chrf_score": 24.340339671222022, "xcomet_score": 0.9983222484588623, "xcomet_qe_score": 0.989094614982605, "metricx_score": 0.6894091367721558, "metricx_qe_score": 0.8082211017608643, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究这些问题,我们开发了Con plus+数据集,", "metrics": {"bleu_score": 42.34885228074744, "chrf_score": 35.175272925639646, "xcomet_score": 0.8120775818824768, "xcomet_qe_score": 0.8022966980934143, "metricx_score": 4.767920970916748, "metricx_qe_score": 4.857815742492676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们从2020年路透社新闻中收集的数据,并使用相同的Con 2003标注指南进行了标注。", "metrics": {"bleu_score": 52.07855988602445, "chrf_score": 48.838773536571075, "xcomet_score": 0.7898761034011841, "xcomet_qe_score": 0.7868139743804932, "metricx_score": 4.6248931884765625, "metricx_qe_score": 4.556553363800049, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们在Con 2003上对20多个模型进行了微调,", "metrics": {"bleu_score": 51.18071215493855, "chrf_score": 45.9755437827892, "xcomet_score": 0.807004988193512, "xcomet_qe_score": 0.7949195504188538, "metricx_score": 3.3393454551696777, "metricx_qe_score": 3.4585816860198975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在Con 3测试集和Con plus fast测试集上对它们进行了评估,", "metrics": {"bleu_score": 46.79666479405631, "chrf_score": 44.024685332287795, "xcomet_score": 0.599867582321167, "xcomet_qe_score": 0.57517409324646, "metricx_score": 7.298466682434082, "metricx_qe_score": 7.214524745941162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们计算了F1值的百分比变化,以评估每个模型的泛化能力。", "metrics": {"bleu_score": 63.05914424660905, "chrf_score": 58.92469995094426, "xcomet_score": 0.9955589771270752, "xcomet_qe_score": 0.9920499324798584, "metricx_score": 0.4898105561733246, "metricx_qe_score": 0.731980562210083, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,实现良好泛化需要什么?", "metrics": {"bleu_score": 34.128395574633934, "chrf_score": 27.97118177136938, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2295304834842682, "metricx_qe_score": 0.3168780207633972, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现需要三个主要成分。", "metrics": {"bleu_score": 46.087110150246495, "chrf_score": 42.23430747046477, "xcomet_score": 0.9314965009689331, "xcomet_qe_score": 0.9775431156158447, "metricx_score": 0.22485893964767456, "metricx_qe_score": 0.14073660969734192, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是模型架构。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.99041748046875, "xcomet_qe_score": 0.9915783405303955, "metricx_score": 0.0, "metricx_qe_score": 0.10443663597106934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现Transformer模型通常能更好地泛化到新数据。", "metrics": {"bleu_score": 52.77140132412705, "chrf_score": 60.9534154761757, "xcomet_score": 0.8849719762802124, "xcomet_qe_score": 0.878563404083252, "metricx_score": 1.71575927734375, "metricx_qe_score": 3.442965269088745, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个成分是模型大小。", "metrics": {"bleu_score": 29.0374612189482, "chrf_score": 27.07335820776018, "xcomet_score": 0.8915048837661743, "xcomet_qe_score": 0.8363902568817139, "metricx_score": 0.4127183258533478, "metricx_qe_score": 0.6761739253997803, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,通常较大的模型能更好地泛化,", "metrics": {"bleu_score": 42.625200190920374, "chrf_score": 36.118982069631514, "xcomet_score": 0.9719431400299072, "xcomet_qe_score": 0.9020717740058899, "metricx_score": 0.6790415048599243, "metricx_qe_score": 1.1120330095291138, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后但并非最不重要的是,我们都知道,微调示例的数量直接影响下游任务的性能。在这里,", "metrics": {"bleu_score": 47.37206772899839, "chrf_score": 58.61054348199759, "xcomet_score": 0.9202825427055359, "xcomet_qe_score": 0.8810229301452637, "metricx_score": 3.6811139583587646, "metricx_qe_score": 1.889869213104248, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,更多的微调示例实际上也能更好地泛化。", "metrics": {"bleu_score": 57.63958145303262, "chrf_score": 51.04064363431108, "xcomet_score": 0.9804757833480835, "xcomet_qe_score": 0.8074841499328613, "metricx_score": 0.5691052079200745, "metricx_qe_score": 1.0345269441604614, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关于我们的下一个问题,是什么原因导致了一些模型的性能下降?我们有两个假设。", "metrics": {"bleu_score": 51.13997936330051, "chrf_score": 42.921510817762446, "xcomet_score": 0.9590741991996765, "xcomet_qe_score": 0.9216582179069519, "metricx_score": 0.9212305545806885, "metricx_qe_score": 1.0950407981872559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是自适应过拟合,这是由于反复使用相同的测试集而引起的过拟合,通常表现为在新测试集上的收益递减。", "metrics": {"bleu_score": 59.08311495977763, "chrf_score": 49.90237336064845, "xcomet_score": 0.9700522422790527, "xcomet_qe_score": 0.8871104717254639, "metricx_score": 2.5055861473083496, "metricx_qe_score": 3.1214041709899902, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移,这是由于训练数据和测试数据之间的时间差距增大而导致的性能下降。", "metrics": {"bleu_score": 64.42705573078551, "chrf_score": 58.289720609976825, "xcomet_score": 0.9631645679473877, "xcomet_qe_score": 0.8863349556922913, "metricx_score": 1.6564586162567139, "metricx_qe_score": 2.0239243507385254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于自适应过拟合,我们从右侧的图表中看到,红色的最佳拟合线有一个大于1的梯度。", "metrics": {"bleu_score": 26.920656092018486, "chrf_score": 27.485377605595286, "xcomet_score": 0.8767713308334351, "xcomet_qe_score": 0.807401180267334, "metricx_score": 1.3456370830535889, "metricx_qe_score": 1.514228343963623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在Con 2003上做出的每一单位的改进,都会在Con plus+上转化为超过一个单位的改进,这意味着没有收益递减。", "metrics": {"bleu_score": 37.39458917407082, "chrf_score": 40.03740135736101, "xcomet_score": 0.6256260871887207, "xcomet_qe_score": 0.6472084522247314, "metricx_score": 8.030793190002441, "metricx_qe_score": 7.712204456329346, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明在这种情况下没有观察到自适应过拟合。", "metrics": {"bleu_score": 74.93731939490364, "chrf_score": 69.43707675795987, "xcomet_score": 0.9009255766868591, "xcomet_qe_score": 0.9129918217658997, "metricx_score": 1.1392955780029297, "metricx_qe_score": 1.6724114418029785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么时间漂移呢?", "metrics": {"bleu_score": 52.47357977607325, "chrf_score": 40.51960415097498, "xcomet_score": 0.9311673641204834, "xcomet_qe_score": 0.9159005284309387, "metricx_score": 0.3731555640697479, "metricx_qe_score": 0.8887962102890015, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于时间漂移,我们进行了一个实验,使用更近的数据对一些模型进行了再训练或继续预训练,我们发现随着时间差距的增大,性能会下降,这证实了我们的假设,即性能下降的主要原因是时间漂移。", "metrics": {"bleu_score": 54.12928516331868, "chrf_score": 47.312860454587806, "xcomet_score": 0.8716949224472046, "xcomet_qe_score": 0.8295483589172363, "metricx_score": 1.5885671377182007, "metricx_qe_score": 1.782926321029663, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是,为了实现良好的泛化,我们需要更好的模型架构、更大的模型大小以及更多的微调示例,", "metrics": {"bleu_score": 78.02818594780945, "chrf_score": 70.75630653147978, "xcomet_score": 0.9520596265792847, "xcomet_qe_score": 0.8978762626647949, "metricx_score": 0.48480430245399475, "metricx_qe_score": 0.47694119811058044, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是相辅相成的,我们不能只拥有其中一个成分,而同时忽略其他成分。", "metrics": {"bleu_score": 37.664817921402104, "chrf_score": 35.551339189230355, "xcomet_score": 0.9663128852844238, "xcomet_qe_score": 0.9574564099311829, "metricx_score": 0.9482088685035706, "metricx_qe_score": 1.1361467838287354, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,我们还发现,这里的性能下降是由时间漂移引起的,这有点令人惊讶,因为它不是由自适应过拟合引起的,", "metrics": {"bleu_score": 48.27620507345717, "chrf_score": 39.10083270279215, "xcomet_score": 0.6802720427513123, "xcomet_qe_score": 0.6515118479728699, "metricx_score": 6.5283355712890625, "metricx_qe_score": 8.41977310180664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管Connel 2003已经使用了20多年。回到我们论文标题提出的问题,Connal 2003标注器在2023年是否仍然有效?", "metrics": {"bleu_score": 45.58778148420757, "chrf_score": 49.25125361948191, "xcomet_score": 0.4882911443710327, "xcomet_qe_score": 0.4902994632720947, "metricx_score": 3.4663190841674805, "metricx_qe_score": 3.4706358909606934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现答案实际上是一个响亮的肯定。", "metrics": {"bleu_score": 32.934059711691795, "chrf_score": 37.27961585945132, "xcomet_score": 0.8980505466461182, "xcomet_qe_score": 0.8718119263648987, "metricx_score": 1.7178252935409546, "metricx_qe_score": 1.4065052270889282, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文能促使更多人研究如何提高模型的泛化能力。", "metrics": {"bleu_score": 56.41405122106224, "chrf_score": 48.57935283218993, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3274407982826233, "metricx_qe_score": 0.45826369524002075, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,请务必查看我们的论文和数据集,如果您有任何问题,请随时与我联系。", "metrics": {"bleu_score": 58.11026448209409, "chrf_score": 52.5325928587273, "xcomet_score": 0.9871149063110352, "xcomet_qe_score": 0.9712950587272644, "metricx_score": 0.2757876515388489, "metricx_qe_score": 0.26652368903160095, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9978005886077881, "xcomet_qe_score": 0.9769038558006287, "metricx_score": 0.0, "metricx_qe_score": 0.14050978422164917, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.958304762840271, "xcomet_qe_score": 0.9632421731948853, "metricx_score": 0.26475995779037476, "metricx_qe_score": 0.28221702575683594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我将谈谈我们在解决实体选择中的间接差异表达方面的工作,我们引入了备选实体语料库,", "metrics": {"bleu_score": 25.789878790302314, "chrf_score": 19.402419933270963, "xcomet_score": 0.6900418996810913, "xcomet_qe_score": 0.6852531433105469, "metricx_score": 5.362156867980957, "metricx_qe_score": 4.679875373840332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是贾瓦德·霍赛尼,这是与菲利普·拉德林斯基、西尔维亚·帕里蒂和安妮·路易斯合作完成的联合工作。", "metrics": {"bleu_score": 2.540917870682806, "chrf_score": 3.183138300490679, "xcomet_score": 0.9189000129699707, "xcomet_qe_score": 0.930942177772522, "metricx_score": 2.464308738708496, "metricx_qe_score": 2.036007881164551, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时使用的语言。", "metrics": {"bleu_score": 68.88074582865497, "chrf_score": 63.14849770363761, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5080945491790771, "metricx_qe_score": 0.7215737700462341, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我考虑了这样一个备", "metrics": {"bleu_score": 10.147104008451905, "chrf_score": 8.696694702670797, "xcomet_score": 0.25659802556037903, "xcomet_qe_score": 0.1998005509376526, "metricx_score": 4.453359603881836, "metricx_qe_score": 1.493009090423584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "选问题:你是说“Easy on Me”还是“I got a feeling?”", "metrics": {"bleu_score": 13.988521776260258, "chrf_score": 37.429191500704555, "xcomet_score": 0.5968560576438904, "xcomet_qe_score": 0.4620378315448761, "metricx_score": 2.9806604385375977, "metricx_qe_score": 5.920653820037842, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里用户想要在这两首歌曲中进行选择。", "metrics": {"bleu_score": 26.709592620187028, "chrf_score": 23.190225267099173, "xcomet_score": 0.9917112588882446, "xcomet_qe_score": 0.9787132740020752, "metricx_score": 0.5638017058372498, "metricx_qe_score": 0.4966478645801544, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用,例如说出歌曲的名称“Easy on Me”或其位置,第一首,但", "metrics": {"bleu_score": 67.40820418376967, "chrf_score": 64.90311070810819, "xcomet_score": 0.49367058277130127, "xcomet_qe_score": 0.35197845101356506, "metricx_score": 4.615076065063477, "metricx_qe_score": 5.082061290740967, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有时间接引用更适合进行更自然的对话,这种情况可能发生", "metrics": {"bleu_score": 43.595146535822686, "chrf_score": 47.77222011032708, "xcomet_score": 0.7257966995239258, "xcomet_qe_score": 0.6141109466552734, "metricx_score": 10.187329292297363, "metricx_qe_score": 9.373846054077148, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在用户记不起歌曲名称时,或者", "metrics": {"bleu_score": 8.099280728303281, "chrf_score": 10.826630993126116, "xcomet_score": 0.881101667881012, "xcomet_qe_score": 0.9145553112030029, "metricx_score": 2.7083592414855957, "metricx_qe_score": 1.5317325592041016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发音过于相似难以区分时", "metrics": {"bleu_score": 14.406135096061286, "chrf_score": 16.244341292253086, "xcomet_score": 0.8586726188659668, "xcomet_qe_score": 0.8894062042236328, "metricx_score": 1.8547210693359375, "metricx_qe_score": 0.4204845428466797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",或者用户想要指定偏好。", "metrics": {"bleu_score": 12.90682834615265, "chrf_score": 16.020547654852464, "xcomet_score": 0.9560192823410034, "xcomet_qe_score": 0.9773891568183899, "metricx_score": 2.272954225540161, "metricx_qe_score": 1.342430591583252, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是间接差异的一些例子。例如,较新的一个或没有充满活力的标志。", "metrics": {"bleu_score": 10.489095948428076, "chrf_score": 14.22625553652079, "xcomet_score": 0.5754884481430054, "xcomet_qe_score": 0.6170061826705933, "metricx_score": 7.2604079246521, "metricx_qe_score": 7.576609134674072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是对话系统中的一个重要问题,也是用于基准测试LLM实体理解的一个重要问题。", "metrics": {"bleu_score": 71.10231907654392, "chrf_score": 64.40600957753573, "xcomet_score": 0.8531266450881958, "xcomet_qe_score": 0.7748444080352783, "metricx_score": 1.7799198627471924, "metricx_qe_score": 3.5926575660705566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们没有发现一个公共数据集,一个更大规模的公共数据集用于该任务,所以我们使用众包标注收集了一个数据集,", "metrics": {"bleu_score": 31.668023515291654, "chrf_score": 32.04134095503569, "xcomet_score": 0.6738951206207275, "xcomet_qe_score": 0.6279737949371338, "metricx_score": 6.069692611694336, "metricx_qe_score": 5.381500720977783, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集涵盖了三个不同的领域:音乐、书籍和食谱。", "metrics": {"bleu_score": 78.47574847738748, "chrf_score": 71.38793914595793, "xcomet_score": 0.9996216297149658, "xcomet_qe_score": 0.9887402057647705, "metricx_score": 0.2191678285598755, "metricx_qe_score": 0.3114262521266937, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集合方法强调非正式性,使用卡通完成设置,卡通中有", "metrics": {"bleu_score": 55.84477172924733, "chrf_score": 46.55721690902625, "xcomet_score": 0.733025074005127, "xcomet_qe_score": 0.7389495372772217, "metricx_score": 7.447890281677246, "metricx_qe_score": 5.825695037841797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "三个对话气泡,", "metrics": {"bleu_score": 23.21746040303191, "chrf_score": 18.36367159601571, "xcomet_score": 0.8796621561050415, "xcomet_qe_score": 0.8879908323287964, "metricx_score": 1.6787437200546265, "metricx_qe_score": 2.6141810417175293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第一个气泡中,鲍勃说,记得我们昨天听的那首歌吗?鲍", "metrics": {"bleu_score": 65.56397462101789, "chrf_score": 55.707932546717444, "xcomet_score": 0.8285733461380005, "xcomet_qe_score": 0.6994047164916992, "metricx_score": 5.257786750793457, "metricx_qe_score": 1.81937837600708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "勃设置了对话上下文,", "metrics": {"bleu_score": 31.866027825414577, "chrf_score": 24.39279277322757, "xcomet_score": 0.7929733991622925, "xcomet_qe_score": 0.7181445360183716, "metricx_score": 2.8466999530792236, "metricx_qe_score": 3.1325576305389404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个对话气泡中,爱丽丝说,你是说Easy on Me还是I got a feeling?这是", "metrics": {"bleu_score": 18.960267898639685, "chrf_score": 31.47115539193306, "xcomet_score": 0.7048994302749634, "xcomet_qe_score": 0.6943269371986389, "metricx_score": 7.824165344238281, "metricx_qe_score": 6.784342288970947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个备选问题,", "metrics": {"bleu_score": 14.759564526951554, "chrf_score": 14.076427499779367, "xcomet_score": 0.7704530358314514, "xcomet_qe_score": 0.8712831735610962, "metricx_score": 1.9947093725204468, "metricx_qe_score": 2.246791362762451, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第三个对话气泡中,鲍勃使用间接引用来选择这些实体中的一个,例如较新的一个,我们", "metrics": {"bleu_score": 22.118839948719064, "chrf_score": 21.681939472226937, "xcomet_score": 0.6520302891731262, "xcomet_qe_score": 0.6170413494110107, "metricx_score": 6.713296413421631, "metricx_qe_score": 5.090562343597412, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自动提供第一个和第二个对话气泡,但第三个由标注者填写,", "metrics": {"bleu_score": 50.53020801453235, "chrf_score": 46.5506490531811, "xcomet_score": 0.7933008670806885, "xcomet_qe_score": 0.8603633642196655, "metricx_score": 2.213207721710205, "metricx_qe_score": 1.5854583978652954, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个对话气泡是从每个领域的一些手动提示中选出的,", "metrics": {"bleu_score": 44.27274357129557, "chrf_score": 35.83446878135196, "xcomet_score": 0.875114917755127, "xcomet_qe_score": 0.7880452871322632, "metricx_score": 2.617539405822754, "metricx_qe_score": 2.183367967605591, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个对话气泡是备选问题,生成如下:", "metrics": {"bleu_score": 12.512236921161914, "chrf_score": 13.932659938671922, "xcomet_score": 0.8349502086639404, "xcomet_qe_score": 0.8070324659347534, "metricx_score": 1.2165035009384155, "metricx_qe_score": 1.4288129806518555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板,", "metrics": {"bleu_score": 61.62607099729587, "chrf_score": 56.23747935732135, "xcomet_score": 0.9921425580978394, "xcomet_qe_score": 0.9783865213394165, "metricx_score": 0.237367182970047, "metricx_qe_score": 0.16834183037281036, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你是说a还是b,其中", "metrics": {"bleu_score": 19.64073254502565, "chrf_score": 19.283307158748855, "xcomet_score": 0.8274170756340027, "xcomet_qe_score": 0.8201760649681091, "metricx_score": 3.196526050567627, "metricx_qe_score": 1.2938168048858643, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "a和b是维基百科的样本。", "metrics": {"bleu_score": 54.88684910025905, "chrf_score": 50.76219623647542, "xcomet_score": 0.837024986743927, "xcomet_qe_score": 0.8628476858139038, "metricx_score": 1.1607121229171753, "metricx_qe_score": 1.6859766244888306, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们使用过的不同采样方法。", "metrics": {"bleu_score": 61.28081331864041, "chrf_score": 52.92624054700117, "xcomet_score": 0.9960860013961792, "xcomet_qe_score": 0.998734712600708, "metricx_score": 0.15488818287849426, "metricx_qe_score": 0.2388148009777069, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在列表中向上移动时,实体变得越来越相似,通常更难进行消歧。", "metrics": {"bleu_score": 48.287171837052036, "chrf_score": 42.61563713257725, "xcomet_score": 0.8577663898468018, "xcomet_qe_score": 0.7904423475265503, "metricx_score": 4.571025848388672, "metricx_qe_score": 5.461899757385254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是均匀随机。", "metrics": {"bleu_score": 19.437571020720103, "chrf_score": 18.153313508301462, "xcomet_score": 0.9029233455657959, "xcomet_qe_score": 0.8752520084381104, "metricx_score": 1.6346652507781982, "metricx_qe_score": 1.535372018814087, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个是当实体有相似的标题,例如两本书的名称相同。", "metrics": {"bleu_score": 10.644967938528506, "chrf_score": 13.27445313639207, "xcomet_score": 0.9036356806755066, "xcomet_qe_score": 0.8768457770347595, "metricx_score": 2.8547000885009766, "metricx_qe_score": 4.6624908447265625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三个是当它们在维基百科上的描述相似,最后当", "metrics": {"bleu_score": 43.28015276270853, "chrf_score": 39.27218345284197, "xcomet_score": 0.6738628149032593, "xcomet_qe_score": 0.6185551285743713, "metricx_score": 5.446120262145996, "metricx_qe_score": 4.093377590179443, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们在维基百科上的信息框或属性相", "metrics": {"bleu_score": 53.49955124069412, "chrf_score": 51.94148475038326, "xcomet_score": 0.7022955417633057, "xcomet_qe_score": 0.6656011343002319, "metricx_score": 5.402701377868652, "metricx_qe_score": 5.182692527770996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "似,例如歌曲的同一流派或同一艺术家。", "metrics": {"bleu_score": 16.54274233399128, "chrf_score": 19.911151695562914, "xcomet_score": 0.7564634084701538, "xcomet_qe_score": 0.6892616748809814, "metricx_score": 5.307394027709961, "metricx_qe_score": 5.918227195739746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们向am statustors展示这个备选问题时,他们知道这些实体的名称,但他们不一定会了解实体,", "metrics": {"bleu_score": 50.48995625101042, "chrf_score": 40.598631926760554, "xcomet_score": 0.6733582019805908, "xcomet_qe_score": 0.7053608894348145, "metricx_score": 8.21207332611084, "metricx_qe_score": 8.248041152954102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们展示了一些关于这两个实体的背景知识,", "metrics": {"bleu_score": 48.058169229593304, "chrf_score": 40.91267710617388, "xcomet_score": 0.8934205770492554, "xcomet_qe_score": 0.7701593637466431, "metricx_score": 1.1241888999938965, "metricx_qe_score": 1.896428108215332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于歌曲,我们简单地展示每个歌曲的Google搜索链接,然后要求标注者至少听一些每首歌曲,并阅读每首歌曲的介绍。", "metrics": {"bleu_score": 33.956055474576225, "chrf_score": 26.77031880290613, "xcomet_score": 0.8353418111801147, "xcomet_qe_score": 0.8073664903640747, "metricx_score": 3.4567465782165527, "metricx_qe_score": 2.8448798656463623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是例如Easy on Me歌曲的Google搜索结果,", "metrics": {"bleu_score": 22.03958483667171, "chrf_score": 35.736471754495675, "xcomet_score": 0.8715114593505859, "xcomet_qe_score": 0.8568659424781799, "metricx_score": 1.150983214378357, "metricx_qe_score": 0.8964961767196655, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域,我们展示了一些维基百科的背景文本,", "metrics": {"bleu_score": 53.571625394853314, "chrf_score": 45.12380219100186, "xcomet_score": 0.9635361433029175, "xcomet_qe_score": 0.8926645517349243, "metricx_score": 1.1174461841583252, "metricx_qe_score": 1.657331109046936, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱,我们还展示了它们的图片,再次来自维基百科,以便标注者知道它们是什么样子", "metrics": {"bleu_score": 37.78072171095764, "chrf_score": 30.067715199294142, "xcomet_score": 0.7809922099113464, "xcomet_qe_score": 0.9039144515991211, "metricx_score": 2.463775634765625, "metricx_qe_score": 1.788338303565979, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",然后我们要求标注者选择这些实体中的一个,例如这里的第一首,并使用三到五个间接引用表达来描述它们", "metrics": {"bleu_score": 41.05621639823331, "chrf_score": 34.581755477877735, "xcomet_score": 0.6501642465591431, "xcomet_qe_score": 0.6505469083786011, "metricx_score": 5.530638694763184, "metricx_qe_score": 5.262997150421143, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如钢琴音乐的,", "metrics": {"bleu_score": 11.417530270031051, "chrf_score": 11.334028139656072, "xcomet_score": 0.9309426546096802, "xcomet_qe_score": 0.8601987361907959, "metricx_score": 1.6993685960769653, "metricx_qe_score": 1.9023017883300781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们数据集的一些例子", "metrics": {"bleu_score": 72.9836014355472, "chrf_score": 63.35822283222925, "xcomet_score": 0.9729787111282349, "xcomet_qe_score": 0.9627209901809692, "metricx_score": 0.10955220460891724, "metricx_qe_score": 0.5414215922355652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如没有歌词的,不是有12岁男孩的,还是虚构的,或者来自阿塞拜疆等等。", "metrics": {"bleu_score": 31.79668486276578, "chrf_score": 29.631436168613057, "xcomet_score": 0.7448757886886597, "xcomet_qe_score": 0.6598111391067505, "metricx_score": 2.8866772651672363, "metricx_qe_score": 4.203709125518799, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "备选语料库有6000个备选问题,涵盖三个领域,有422,000个间接引用表达。", "metrics": {"bleu_score": 17.957826173472384, "chrf_score": 27.72175591727692, "xcomet_score": 0.6474786400794983, "xcomet_qe_score": 0.6390130519866943, "metricx_score": 4.218546390533447, "metricx_qe_score": 3.192502737045288, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用t5x大型模型的结果总结如下:", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 24.030650721827186, "xcomet_score": 0.880030632019043, "xcomet_qe_score": 0.8787636756896973, "metricx_score": 2.0453481674194336, "metricx_qe_score": 2.5266170501708984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问与标注者完全相同的背景知识,那么准确率非常高,大约在92%到95%之间,", "metrics": {"bleu_score": 70.15486753372355, "chrf_score": 64.07988973862643, "xcomet_score": 0.8405320048332214, "xcomet_qe_score": 0.8829030990600586, "metricx_score": 1.1374837160110474, "metricx_qe_score": 0.982201874256134, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这并不现实。", "metrics": {"bleu_score": 27.890014303843827, "chrf_score": 23.047933414170444, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.03864777833223343, "metricx_qe_score": 0.04394784942269325, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问一些部分重叠的背景知识,那么准确率在82%到877%之间,这是更现实的。", "metrics": {"bleu_score": 70.19951273802924, "chrf_score": 70.23703708188485, "xcomet_score": 0.8855457305908203, "xcomet_qe_score": 0.8675726652145386, "metricx_score": 3.1726207733154297, "metricx_qe_score": 3.9462203979492188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,当语言模型检索背景知识时。", "metrics": {"bleu_score": 83.7117009877792, "chrf_score": 80.60640748140749, "xcomet_score": 0.9950563907623291, "xcomet_qe_score": 0.9950027465820312, "metricx_score": 0.39887312054634094, "metricx_qe_score": 0.4570527672767639, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问实体名称,那么准确率只有6%,所以还有很大的改进空间。", "metrics": {"bleu_score": 71.82509383665652, "chrf_score": 67.99574593692239, "xcomet_score": 0.8847542405128479, "xcomet_qe_score": 0.8691680431365967, "metricx_score": 7.737277984619141, "metricx_qe_score": 8.226611137390137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还表明模型具有领域的一般化能力", "metrics": {"bleu_score": 34.717907430287326, "chrf_score": 28.67810229829172, "xcomet_score": 0.8974112272262573, "xcomet_qe_score": 0.8388310670852661, "metricx_score": 1.3694088459014893, "metricx_qe_score": 1.7202492952346802, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这里有一个链接到", "metrics": {"bleu_score": 8.449917822620138, "chrf_score": 6.453182234432234, "xcomet_score": 0.5640599131584167, "xcomet_qe_score": 0.5999992489814758, "metricx_score": 6.746213912963867, "metricx_qe_score": 4.18138313293457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集,感谢大家。", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 13.88888888888889, "xcomet_score": 0.5766692161560059, "xcomet_qe_score": 0.4170980751514435, "metricx_score": 3.5894558429718018, "metricx_qe_score": 3.6877074241638184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自特伦托大学和布鲁诺·克塞尔研究所的莎拉·帕伊,我将简要介绍一篇关于同时语音翻译的论文,这是我和马泰奥·内格里、马可·杜里合作完成的。", "metrics": {"bleu_score": 31.02614522080053, "chrf_score": 22.699415125635436, "xcomet_score": 0.6399887800216675, "xcomet_qe_score": 0.6465883255004883, "metricx_score": 3.4802260398864746, "metricx_qe_score": 3.9152920246124268, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时语音翻译是什么?", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 12.17315215153387, "xcomet_score": 0.853082537651062, "xcomet_qe_score": 0.8471674919128418, "metricx_score": 0.981535017490387, "metricx_qe_score": 0.695488452911377, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时语音翻译或SimST是指将口语实时翻译成另一种语言文本的过程,实现跨语言交流。", "metrics": {"bleu_score": 57.19474647962201, "chrf_score": 49.134788228118786, "xcomet_score": 0.9294388294219971, "xcomet_qe_score": 0.9007568955421448, "metricx_score": 3.06400728225708, "metricx_qe_score": 3.84029221534729, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,当前SimST模型存在哪些问题呢?", "metrics": {"bleu_score": 20.68720601025941, "chrf_score": 27.64203295147396, "xcomet_score": 0.9451712369918823, "xcomet_qe_score": 0.9442406296730042, "metricx_score": 1.1560262441635132, "metricx_qe_score": 1.3430083990097046, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特定的架构通常需要训练,引入额外的模块进行优化,", "metrics": {"bleu_score": 55.29134414331143, "chrf_score": 49.17343702938508, "xcomet_score": 0.927796483039856, "xcomet_qe_score": 0.8895529508590698, "metricx_score": 1.0349366664886475, "metricx_qe_score": 2.0921926498413086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "训练过程长且复杂,例如,训练涉", "metrics": {"bleu_score": 14.131164779580413, "chrf_score": 16.24537567344227, "xcomet_score": 0.7325649261474609, "xcomet_qe_score": 0.5278576612472534, "metricx_score": 11.490729331970215, "metricx_qe_score": 8.01961612701416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "及不同的优化目标,训练和维护多个模型以达到不同的延迟", "metrics": {"bleu_score": 53.46748841465139, "chrf_score": 47.00832907603385, "xcomet_score": 0.6492079496383667, "xcomet_qe_score": 0.5917911529541016, "metricx_score": 2.8955745697021484, "metricx_qe_score": 2.568755626678467, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "机制,例如,训练一个平均延迟为一秒的模型和另一个平均延迟为两秒的模型等等。", "metrics": {"bleu_score": 59.28257592469543, "chrf_score": 56.04760496795795, "xcomet_score": 0.6561150550842285, "xcomet_qe_score": 0.6009703278541565, "metricx_score": 2.1180238723754883, "metricx_qe_score": 1.9914129972457886, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,我们的解决方案是什么呢?", "metrics": {"bleu_score": 74.87402156832427, "chrf_score": 75.65635752018586, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07452559471130371, "metricx_qe_score": 0.18974152207374573, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,使用现有的离线SD模型,无需重新训练或采用特定的SimuSD架构,只需", "metrics": {"bleu_score": 37.00943763990086, "chrf_score": 40.251501203399656, "xcomet_score": 0.611982524394989, "xcomet_qe_score": 0.7147861123085022, "metricx_score": 7.066895008087158, "metricx_qe_score": 6.923977851867676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为每个延迟机制使用一个模型,并通过特定的参数处理延迟,利用", "metrics": {"bleu_score": 40.15384343329885, "chrf_score": 32.16259190791627, "xcomet_score": 0.7381147742271423, "xcomet_qe_score": 0.6517369747161865, "metricx_score": 4.741705894470215, "metricx_qe_score": 1.1764941215515137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型通过音频输入和文本输出之间的张力机制(即", "metrics": {"bleu_score": 44.77539538567507, "chrf_score": 46.694488431512646, "xcomet_score": 0.2985985577106476, "xcomet_qe_score": 0.48726126551628113, "metricx_score": 10.78218936920166, "metricx_qe_score": 7.757978916168213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "交叉注意力机制)获得的知识。右边", "metrics": {"bleu_score": 35.077702152152504, "chrf_score": 31.135115355657078, "xcomet_score": 0.49181488156318665, "xcomet_qe_score": 0.5069507956504822, "metricx_score": 12.608044624328613, "metricx_qe_score": 7.964244842529297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到我们的解决方案是提出点注意力或编码器注意力,这是一个策略,我们根据注意力指向某个词的位置决定是否发出部分翻译,如果张", "metrics": {"bleu_score": 38.57187662749701, "chrf_score": 33.85482701821228, "xcomet_score": 0.324646919965744, "xcomet_qe_score": 0.23310764133930206, "metricx_score": 11.226893424987793, "metricx_qe_score": 10.892945289611816, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "力不集中,即这个和值低于某个阈值alpha,指向最后的lambda语音帧,意味着接收到的信息足够稳定。", "metrics": {"bleu_score": 32.67704044756578, "chrf_score": 28.68306404594567, "xcomet_score": 0.3870907723903656, "xcomet_qe_score": 0.34220871329307556, "metricx_score": 8.242817878723145, "metricx_qe_score": 8.496082305908203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果我们接收到的语音片段包含“我要谈论”,我们的模型预测德语翻译,我们会查看交叉注意力权重,我们会看到前两个词指向最早接收到的语音帧,而最后一个词指向最后接收到的语音帧,即lambda语音帧,", "metrics": {"bleu_score": 43.325251091097584, "chrf_score": 33.16622201044443, "xcomet_score": 0.567886471748352, "xcomet_qe_score": 0.5255232453346252, "metricx_score": 3.770538568496704, "metricx_qe_score": 4.547086715698242, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将被发出,而由于交叉注意力的和值高于某个阈值alpha,我们不会发出最后一个词,而是等待另一个语音片段。", "metrics": {"bleu_score": 50.40846887180142, "chrf_score": 41.35338198587051, "xcomet_score": 0.6880803108215332, "xcomet_qe_score": 0.6614706516265869, "metricx_score": 4.9770331382751465, "metricx_qe_score": 4.6869611740112305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续,接收另一个语音片段,我们的模型预测其他三个词,我们会查看交叉注意力权重,我们会看到没有词指向最后的lambda语音帧,", "metrics": {"bleu_score": 52.00266921870578, "chrf_score": 42.8196389767683, "xcomet_score": 0.5688733458518982, "xcomet_qe_score": 0.5141557455062866, "metricx_score": 4.251011848449707, "metricx_qe_score": 4.246427536010742, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将被发出。", "metrics": {"bleu_score": 31.314224813827344, "chrf_score": 27.259129759129756, "xcomet_score": 0.9332944750785828, "xcomet_qe_score": 0.8744902610778809, "metricx_score": 1.6925324201583862, "metricx_qe_score": 3.3203859329223633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们查看点的主要结果,我们在图表上绘制了同时语音翻译的结果,其中一边用蓝色测量翻译质量和平均延迟,即延迟度量,我们还考虑了计算感知平均延迟,这考虑了模型预测输出的计算时间。", "metrics": {"bleu_score": 32.96287685986142, "chrf_score": 25.874471546343802, "xcomet_score": 0.4997258186340332, "xcomet_qe_score": 0.39527133107185364, "metricx_score": 7.268312931060791, "metricx_qe_score": 7.381594657897949, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,我们希望我们的曲线在这个图上尽可能高,", "metrics": {"bleu_score": 29.10624919304027, "chrf_score": 26.712443633170473, "xcomet_score": 0.9588454961776733, "xcomet_qe_score": 0.8161818981170654, "metricx_score": 1.7375974655151367, "metricx_qe_score": 1.8240134716033936, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但也要向左移动,", "metrics": {"bleu_score": 18.07288326053166, "chrf_score": 16.846613979219512, "xcomet_score": 0.8367675542831421, "xcomet_qe_score": 0.8604129552841187, "metricx_score": 1.9625107049942017, "metricx_qe_score": 2.5393710136413574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们与plepara策略进行比较,这些策略也适用于离线模型,即Whit键策略和局部一致性,", "metrics": {"bleu_score": 36.966653028794916, "chrf_score": 26.980969337147855, "xcomet_score": 0.5600374937057495, "xcomet_qe_score": 0.5166069269180298, "metricx_score": 9.937206268310547, "metricx_qe_score": 10.730656623840332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还与专门为同时语音翻译设计的最先进架构进行比较。", "metrics": {"bleu_score": 67.32378032068624, "chrf_score": 62.894850602359206, "xcomet_score": 0.91526859998703, "xcomet_qe_score": 0.8792819380760193, "metricx_score": 1.412384033203125, "metricx_qe_score": 2.0994346141815186, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些是同时语音翻译策略在德语上的所有结果,", "metrics": {"bleu_score": 18.153580712996767, "chrf_score": 20.407190570281966, "xcomet_score": 0.8127447366714478, "xcomet_qe_score": 0.7992479801177979, "metricx_score": 2.846750020980835, "metricx_qe_score": 1.9506182670593262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到,AD优于所有应用于离线模型的策略,因为曲线向左移动。", "metrics": {"bleu_score": 62.418866968013226, "chrf_score": 53.73487590894324, "xcomet_score": 0.9648282527923584, "xcomet_qe_score": 0.9593505859375, "metricx_score": 2.7782764434814453, "metricx_qe_score": 4.026731967926025, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还看到,如果考虑实际的经过时间或计算时间,AD是最快的策略。", "metrics": {"bleu_score": 32.39632741082209, "chrf_score": 28.828283109309805, "xcomet_score": 0.7746771574020386, "xcomet_qe_score": 0.8051893711090088, "metricx_score": 4.423209190368652, "metricx_qe_score": 4.3136305809021, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多结果,请阅读我们的论文,", "metrics": {"bleu_score": 80.3154665668484, "chrf_score": 73.06831212016971, "xcomet_score": 0.966759204864502, "xcomet_qe_score": 0.9586907625198364, "metricx_score": 0.17957928776741028, "metricx_qe_score": 0.2470196634531021, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发布了开源代码和模型以及同时输出,以促进我们工作的可重复性。", "metrics": {"bleu_score": 35.02767179601167, "chrf_score": 35.63470665966163, "xcomet_score": 0.8560440540313721, "xcomet_qe_score": 0.825596809387207, "metricx_score": 1.1226439476013184, "metricx_qe_score": 1.583362102508545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的关注。", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 7.407407407407408, "xcomet_score": 0.9552983045578003, "xcomet_qe_score": 1.0, "metricx_score": 0.6913450956344604, "metricx_qe_score": 0.710175633430481, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫 Ian,我的同事 Jiian 和我将介绍我们关于通过指令微调改进多模态序列学习的研究。", "metrics": {"bleu_score": 48.16227836376992, "chrf_score": 28.95603987098524, "xcomet_score": 0.5497720241546631, "xcomet_qe_score": 0.5288600921630859, "metricx_score": 9.18203067779541, "metricx_qe_score": 8.46600341796875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型的进步,许多研究开始探索以参数和数据高效的方式使用预训练语言模型进行不同下游任务的新学习范式。", "metrics": {"bleu_score": 55.462056635856506, "chrf_score": 47.19284318282814, "xcomet_score": 0.7913766503334045, "xcomet_qe_score": 0.7735049724578857, "metricx_score": 2.0640017986297607, "metricx_qe_score": 2.9814095497131348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近,许多研究表明,指令微调使大型语言模型能够通过遵循自然指令以序列方式在未见过的任务上表现出色。", "metrics": {"bleu_score": 38.58404249736585, "chrf_score": 34.75879789148153, "xcomet_score": 0.733163058757782, "xcomet_qe_score": 0.7599538564682007, "metricx_score": 2.95996356010437, "metricx_qe_score": 3.2527835369110107, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,大多数关于指令微调的先前工作都集中在改进仅限于语言任务的序列表现,而计算机视觉和多模态任务则被忽略了。", "metrics": {"bleu_score": 35.85201726032852, "chrf_score": 32.58687828397597, "xcomet_score": 0.864152193069458, "xcomet_qe_score": 0.8051716089248657, "metricx_score": 1.708471417427063, "metricx_qe_score": 1.8306165933609009, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在这项工作中,我们想要研究在多模态蛋白质模型上进行指令微调是否真的可以提高对未见过的多模态任务的泛化能力。", "metrics": {"bleu_score": 31.866260824213594, "chrf_score": 29.09137145380355, "xcomet_score": 0.817915678024292, "xcomet_qe_score": 0.7164260149002075, "metricx_score": 5.450522422790527, "metricx_qe_score": 5.95045804977417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,在我们的研究期间,我们发现 P 和多模态之间在指令数据集的可用性上存在相当大的差异,", "metrics": {"bleu_score": 39.02586755230353, "chrf_score": 34.44851173360988, "xcomet_score": 0.7219275236129761, "xcomet_qe_score": 0.6884549260139465, "metricx_score": 4.7088236808776855, "metricx_qe_score": 4.937203407287598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "存在超过 1,600 个仅限于午餐的指令任务,", "metrics": {"bleu_score": 27.443481336742803, "chrf_score": 36.39876011426486, "xcomet_score": 0.5288801193237305, "xcomet_qe_score": 0.4269760847091675, "metricx_score": 7.554039478302002, "metricx_qe_score": 8.337298393249512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但没有大规模的公开可用的多模态指令任务。", "metrics": {"bleu_score": 69.3395566222006, "chrf_score": 64.4399100909652, "xcomet_score": 0.9092608690261841, "xcomet_qe_score": 0.8098517656326294, "metricx_score": 1.6030091047286987, "metricx_qe_score": 2.1660940647125244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这促使我们在此构建一个多模态指令微调数据集。", "metrics": {"bleu_score": 47.581040383390814, "chrf_score": 43.85276325744375, "xcomet_score": 0.9680575132369995, "xcomet_qe_score": 0.9637287855148315, "metricx_score": 1.215207815170288, "metricx_qe_score": 1.123274803161621, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这里介绍 multi-ins instruct,这是第一个多模态指令微调基准数据集,包含 62 个多样化的多模态任务,涵盖 10 个广泛类别。", "metrics": {"bleu_score": 45.141223226046066, "chrf_score": 40.895616548853496, "xcomet_score": 0.7194055914878845, "xcomet_qe_score": 0.6518473029136658, "metricx_score": 6.105897903442383, "metricx_qe_score": 6.727060317993164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务来自 21 个现有的开源数据集,每个任务都配备了五个专家撰写的指令。", "metrics": {"bleu_score": 60.511005357971236, "chrf_score": 53.601631467874235, "xcomet_score": 0.9823282957077026, "xcomet_qe_score": 0.9363937973976135, "metricx_score": 1.2132488489151, "metricx_qe_score": 2.1612508296966553, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究我们提出的数据集上的多模态指令微调,我们采用统一的多模态训练模型作为我们的基模型,使用统", "metrics": {"bleu_score": 51.96315853085047, "chrf_score": 45.11103953172032, "xcomet_score": 0.5814790725708008, "xcomet_qe_score": 0.509676456451416, "metricx_score": 7.7096052169799805, "metricx_qe_score": 4.778350353240967, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一的词汇表来表示语言图像标记和边界框的坐标。", "metrics": {"bleu_score": 39.5191384884349, "chrf_score": 30.9496429473398, "xcomet_score": 0.4263566732406616, "xcomet_qe_score": 0.4355677664279938, "metricx_score": 8.865410804748535, "metricx_qe_score": 9.151103019714355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示了我们 multi-instra 数据集的一些示例实例。为了统一处理各种输入和输出数据类型,", "metrics": {"bleu_score": 67.92845921787168, "chrf_score": 53.40530346932003, "xcomet_score": 0.8459981679916382, "xcomet_qe_score": 0.7883422374725342, "metricx_score": 4.365146636962891, "metricx_qe_score": 5.212007999420166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循 offa 的方法,并将所有任务统一为序列到序列格式,其中", "metrics": {"bleu_score": 44.28500142691472, "chrf_score": 32.968848682568186, "xcomet_score": 0.7200698852539062, "xcomet_qe_score": 0.7225508689880371, "metricx_score": 4.579511642456055, "metricx_qe_score": 4.3303542137146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "输入文本、图像、指令和边界框以相同的标记空间表示。", "metrics": {"bleu_score": 53.09565039223721, "chrf_score": 50.52264517853785, "xcomet_score": 0.9847351312637329, "xcomet_qe_score": 0.9566234350204468, "metricx_score": 1.0149985551834106, "metricx_qe_score": 1.017142415046692, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,现在我要谈谈多模态指令微调。", "metrics": {"bleu_score": 67.53160327422972, "chrf_score": 62.99571751777634, "xcomet_score": 0.9133613109588623, "xcomet_qe_score": 0.883480429649353, "metricx_score": 0.721462607383728, "metricx_qe_score": 0.7804521322250366, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于训练数据集,我们使用 N 组中的 53 个任务进行训练,并且为测试抽取每个任务中的 10,000 个实例。", "metrics": {"bleu_score": 50.84207237579605, "chrf_score": 53.791493515117885, "xcomet_score": 0.7730817794799805, "xcomet_qe_score": 0.7732632160186768, "metricx_score": 4.602497100830078, "metricx_qe_score": 5.165588855743408, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们保留整个常识阅读组进行测试,并且从 Wiki 和杂项组中额外选择 5 个任务。", "metrics": {"bleu_score": 32.43730842811779, "chrf_score": 25.55418335101326, "xcomet_score": 0.6214137077331543, "xcomet_qe_score": 0.5599735975265503, "metricx_score": 5.73785924911499, "metricx_qe_score": 5.056209564208984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用每个任务的测试集中的所有实例,此", "metrics": {"bleu_score": 45.870619031121876, "chrf_score": 36.2356880451178, "xcomet_score": 0.5402693748474121, "xcomet_qe_score": 0.6821765899658203, "metricx_score": 5.46876859664917, "metricx_qe_score": 1.7512108087539673, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "外,我们从自然指令的测试集中的 20 个任务中随机抽取样本,作为 NP 的相同任务。", "metrics": {"bleu_score": 47.029774419895006, "chrf_score": 41.72153195373009, "xcomet_score": 0.3151620626449585, "xcomet_qe_score": 0.21593359112739563, "metricx_score": 6.1398396492004395, "metricx_qe_score": 6.659067630767822, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们在训练期间使用大型模型的预", "metrics": {"bleu_score": 18.830095106396065, "chrf_score": 17.0365574483029, "xcomet_score": 0.36613744497299194, "xcomet_qe_score": 0.37354087829589844, "metricx_score": 9.759428024291992, "metricx_qe_score": 5.698554992675781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "训练作为基模型。我们混合了所有任务的所有实例,", "metrics": {"bleu_score": 62.00657885072486, "chrf_score": 61.09728278411228, "xcomet_score": 0.7435376644134521, "xcomet_qe_score": 0.5499818325042725, "metricx_score": 3.3788139820098877, "metricx_qe_score": 3.463824510574341, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "每个实例都随机组合了一个其五个指令模板中的一个。", "metrics": {"bleu_score": 53.7461849875126, "chrf_score": 54.594409699760284, "xcomet_score": 0.9017291069030762, "xcomet_qe_score": 0.8188067674636841, "metricx_score": 1.762274146080017, "metricx_qe_score": 1.6667532920837402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,对于每个任务的测试,我们进行总共五个实验,每个实验使用五个指令中的一个来评估模型。", "metrics": {"bleu_score": 51.04460614024646, "chrf_score": 47.858400427836436, "xcomet_score": 0.9607889652252197, "xcomet_qe_score": 0.8519269824028015, "metricx_score": 0.9729799032211304, "metricx_qe_score": 1.5077365636825562, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告平均和最大性能以及所有五个实验的性能标准差。", "metrics": {"bleu_score": 19.28059728981443, "chrf_score": 18.5046506028296, "xcomet_score": 0.8764537572860718, "xcomet_qe_score": 0.8991513252258301, "metricx_score": 2.8304195404052734, "metricx_qe_score": 4.166040897369385, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模态分类任务,我们报告准确率;", "metrics": {"bleu_score": 51.19139560355038, "chrf_score": 41.10172949892563, "xcomet_score": 0.9205566644668579, "xcomet_qe_score": 0.9800392389297485, "metricx_score": 0.5913204550743103, "metricx_qe_score": 0.764886736869812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果是多模态生成任务,我们报告根 L;对于 LP 任务,我们也报告根 L。", "metrics": {"bleu_score": 50.506705817428575, "chrf_score": 36.10094017440654, "xcomet_score": 0.659244954586029, "xcomet_qe_score": 0.6277490854263306, "metricx_score": 6.632941246032715, "metricx_qe_score": 6.68770694732666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标,称为敏感性,它", "metrics": {"bleu_score": 63.8836571192159, "chrf_score": 61.24883209885134, "xcomet_score": 0.7990299463272095, "xcomet_qe_score": 0.7209134101867676, "metricx_score": 3.887962579727173, "metricx_qe_score": 0.9001494646072388, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "衡量模型在指令措辞略有变化的情况下,对同一任务始终产生相同输出的能力。", "metrics": {"bleu_score": 38.70703742086165, "chrf_score": 32.63744830199565, "xcomet_score": 0.9700098037719727, "xcomet_qe_score": 0.9796338081359863, "metricx_score": 2.3877429962158203, "metricx_qe_score": 3.2427663803100586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的主要结果。", "metrics": {"bleu_score": 79.6358031503278, "chrf_score": 77.3312769486561, "xcomet_score": 0.909784197807312, "xcomet_qe_score": 0.8688104748725891, "metricx_score": 0.38074302673339844, "metricx_qe_score": 0.5220726728439331, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,指令微调可以显著提高 OF 在相同多模态任务上的性能。", "metrics": {"bleu_score": 31.180943299936743, "chrf_score": 31.40107890950506, "xcomet_score": 0.9088927507400513, "xcomet_qe_score": 0.8550783395767212, "metricx_score": 4.17805290222168, "metricx_qe_score": 3.9799294471740723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,从自然指令数据集进行的迁移学习可以使指令微调受益。", "metrics": {"bleu_score": 54.75180966862229, "chrf_score": 49.34650152565327, "xcomet_score": 0.8984434604644775, "xcomet_qe_score": 0.8326890468597412, "metricx_score": 3.3736073970794678, "metricx_qe_score": 4.318597316741943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,我们可以看到,随着任务数量的增加,模型的性能得到提高,同时敏感性降低。因此,", "metrics": {"bleu_score": 39.89345404075606, "chrf_score": 36.76489896448039, "xcomet_score": 0.7658259868621826, "xcomet_qe_score": 0.7631434798240662, "metricx_score": 4.295327186584473, "metricx_qe_score": 2.152400493621826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还进行了一个实验,", "metrics": {"bleu_score": 46.92470064105599, "chrf_score": 39.39127110257559, "xcomet_score": 0.9774124622344971, "xcomet_qe_score": 0.9565337896347046, "metricx_score": 0.34012168645858765, "metricx_qe_score": 0.33167219161987305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用一个指令与五个指令进行", "metrics": {"bleu_score": 14.982563916847612, "chrf_score": 15.3572601822111, "xcomet_score": 0.7792673110961914, "xcomet_qe_score": 0.6976467967033386, "metricx_score": 3.1645030975341797, "metricx_qe_score": 3.683058977127075, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "比较。我们可以看到,使用更多指令可以提高模型的整体性能,并大大降低其敏感性。", "metrics": {"bleu_score": 41.09873320110075, "chrf_score": 35.814562300630406, "xcomet_score": 0.8035880923271179, "xcomet_qe_score": 0.8107911348342896, "metricx_score": 2.0138936042785645, "metricx_qe_score": 2.299680709838867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这表明了不同的微调策略对模型敏感性的影响。", "metrics": {"bleu_score": 54.120475514419645, "chrf_score": 53.70772482752443, "xcomet_score": 0.975576639175415, "xcomet_qe_score": 0.9707900285720825, "metricx_score": 1.4315623044967651, "metricx_qe_score": 1.5186759233474731, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,通过从自然指令数据集进行迁移学习,模型可以比原始 IFA 模型实现更好的敏感性。", "metrics": {"bleu_score": 31.06874380535958, "chrf_score": 28.46926494781517, "xcomet_score": 0.8636547327041626, "xcomet_qe_score": 0.8001852035522461, "metricx_score": 3.575085401535034, "metricx_qe_score": 3.898700714111328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到,从自然指令数据集进行的迁移学习可以帮助 OFA 在氮指令数据集上实现更好的性能。", "metrics": {"bleu_score": 70.29779033091795, "chrf_score": 64.21141501957305, "xcomet_score": 0.793136715888977, "xcomet_qe_score": 0.6478580236434937, "metricx_score": 5.0977091789245605, "metricx_qe_score": 5.691356658935547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,总的来说,我们提出了第一个大规模多模态指令微调数据集,我们显著提高了 OFA 的神经能力,并探索了不同的迁移学习技术,并展示了其好处。", "metrics": {"bleu_score": 51.516239338579574, "chrf_score": 47.29010795375526, "xcomet_score": 0.6799006462097168, "xcomet_qe_score": 0.6740877628326416, "metricx_score": 4.2516770362854, "metricx_qe_score": 4.761112213134766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们设计了一个名为敏感性的新指标。还有一件事", "metrics": {"bleu_score": 32.50555793482135, "chrf_score": 31.025801184629042, "xcomet_score": 0.5657117366790771, "xcomet_qe_score": 0.5254662036895752, "metricx_score": 3.6480045318603516, "metricx_qe_score": 2.4201202392578125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们正在收集一个更大的多模态指令微调数据集,包含大约 150 个额外的变体语言任务,我们将发布这些数据集。", "metrics": {"bleu_score": 62.49398250073608, "chrf_score": 58.044967783666856, "xcomet_score": 0.6990699768066406, "xcomet_qe_score": 0.7306991219520569, "metricx_score": 4.250852108001709, "metricx_qe_score": 4.537195682525635, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们数据和模型的二维码。", "metrics": {"bleu_score": 80.52253761904356, "chrf_score": 72.34299520932606, "xcomet_score": 0.9889544248580933, "xcomet_qe_score": 0.9169533848762512, "metricx_score": 0.3964334726333618, "metricx_qe_score": 0.572709858417511, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集,感谢大家。", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 13.88888888888889, "xcomet_score": 0.5856402516365051, "xcomet_qe_score": 0.5132632851600647, "metricx_score": 3.4826180934906006, "metricx_qe_score": 3.5140843391418457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9850732088088989, "xcomet_qe_score": 0.974276065826416, "metricx_score": 0.0, "metricx_qe_score": 0.004066057503223419, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是 Koov Sinna,很高兴欢迎大家来讨论我们的 ACL 23 论文。", "metrics": {"bleu_score": 31.66493253401594, "chrf_score": 32.78590553914714, "xcomet_score": 0.6458274126052856, "xcomet_qe_score": 0.598622739315033, "metricx_score": 4.98336935043335, "metricx_qe_score": 6.17842960357666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型的可接受性判断并不总是对上下文有稳健的处理能力。", "metrics": {"bleu_score": 71.42753111280399, "chrf_score": 71.93526178347125, "xcomet_score": 0.8886557817459106, "xcomet_qe_score": 0.968225359916687, "metricx_score": 2.4715514183044434, "metricx_qe_score": 2.7131738662719727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一项与 John Waqui、Aaron Mueller、Kanishka Mishra、Karen Fs、Roger Levy 和 Atina Williams 合作完成的工作。", "metrics": {"bleu_score": 28.468243684377647, "chrf_score": 64.63153874133563, "xcomet_score": 0.39785200357437134, "xcomet_qe_score": 0.3649764060974121, "metricx_score": 8.881318092346191, "metricx_qe_score": 9.635455131530762, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在这项工作中,我们重新审视了最小对概念。", "metrics": {"bleu_score": 43.82572041773569, "chrf_score": 44.99510575847716, "xcomet_score": 0.963120698928833, "xcomet_qe_score": 0.969498872756958, "metricx_score": 0.9562066793441772, "metricx_qe_score": 0.9808343648910522, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最小对概念基本上是通过可接受性判断来评估语言模型,这些判断", "metrics": {"bleu_score": 38.06714025798045, "chrf_score": 30.93563337452468, "xcomet_score": 0.8019750118255615, "xcomet_qe_score": 0.753833532333374, "metricx_score": 6.2244648933410645, "metricx_qe_score": 2.8062782287597656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还可能包括语法性,如 blimp 语法健身房或可接受性方面如人群对的概念。", "metrics": {"bleu_score": 13.267656524657342, "chrf_score": 8.830677469167428, "xcomet_score": 0.5930097103118896, "xcomet_qe_score": 0.44927430152893066, "metricx_score": 7.819003105163574, "metricx_qe_score": 7.858662128448486, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个最小对概念中,评估语言模型的典型方法是展示一个可接受的句子或语法句子,然后展示一个不可接受的句子或非语法句子", "metrics": {"bleu_score": 47.129031226143994, "chrf_score": 43.68223090420777, "xcomet_score": 0.8164688348770142, "xcomet_qe_score": 0.7898566722869873, "metricx_score": 1.441108226776123, "metricx_qe_score": 2.8801026344299316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",希望模型基本上会给可接受的句子赋予更高的概率。", "metrics": {"bleu_score": 36.96208614341176, "chrf_score": 30.073425493906043, "xcomet_score": 0.8781664967536926, "xcomet_qe_score": 0.7674963474273682, "metricx_score": 2.9022600650787354, "metricx_qe_score": 3.5724902153015137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当前的 MPP 管道基本上不允许我们在这些日子里评估模型对更长句子的接受程度。", "metrics": {"bleu_score": 62.25705543415939, "chrf_score": 68.26877157359658, "xcomet_score": 0.7059639692306519, "xcomet_qe_score": 0.6174184083938599, "metricx_score": 4.698443412780762, "metricx_qe_score": 5.112280368804932, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如今,大型语言模型正在提出越来越长的", "metrics": {"bleu_score": 29.25712720837, "chrf_score": 23.270604349424808, "xcomet_score": 0.7483376264572144, "xcomet_qe_score": 0.7926777601242065, "metricx_score": 6.059727668762207, "metricx_qe_score": 5.449113368988037, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "上下文窗口,因此,我们必须在整个上下文窗口中评估模型的可接受性,这就是我们在这里试图做的事情。", "metrics": {"bleu_score": 48.27847404274291, "chrf_score": 49.031427504503036, "xcomet_score": 0.7300492525100708, "xcomet_qe_score": 0.6670873165130615, "metricx_score": 2.3759446144104004, "metricx_qe_score": 2.769155979156494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们试图通过要求模型对越来越长的序列进行可接受性评估来重新审视 MPP 管道。", "metrics": {"bleu_score": 62.14993076646465, "chrf_score": 57.64783076410603, "xcomet_score": 0.8556958436965942, "xcomet_qe_score": 0.8012151122093201, "metricx_score": 1.541456937789917, "metricx_qe_score": 3.01043963432312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们的做法是", "metrics": {"bleu_score": 20.164945583740657, "chrf_score": 15.806878306878305, "xcomet_score": 0.8548156023025513, "xcomet_qe_score": 0.9328736066818237, "metricx_score": 1.241733193397522, "metricx_qe_score": 1.2186518907546997, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模拟这些更长的序列,重新审视数据集本身,然后通过从这些数据集中选择可接受或不可接受的句子来重新创建句子。", "metrics": {"bleu_score": 75.64755947843948, "chrf_score": 72.62821042524777, "xcomet_score": 0.6290249824523926, "xcomet_qe_score": 0.6165671944618225, "metricx_score": 2.845029830932617, "metricx_qe_score": 3.2966833114624023, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在这里,我们从 blim 数据集的从属岛案例中选择了典型的语法句", "metrics": {"bleu_score": 32.797419004530475, "chrf_score": 20.782631189357158, "xcomet_score": 0.6487330198287964, "xcomet_qe_score": 0.6057153344154358, "metricx_score": 5.295413494110107, "metricx_qe_score": 5.020807266235352, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "子对,然后我们重新创建了更长的序列,这些序列是可接受的,并且具有相同的语法结构匹配。", "metrics": {"bleu_score": 64.78733289968618, "chrf_score": 57.86108449585431, "xcomet_score": 0.4744292199611664, "xcomet_qe_score": 0.19605742394924164, "metricx_score": 4.555156230926514, "metricx_qe_score": 5.169087886810303, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从从属岛中提取语法句子,然后将其作为前缀添加到可接受查询和不可接受查询中,以便", "metrics": {"bleu_score": 65.58241823706334, "chrf_score": 47.87945048361731, "xcomet_score": 0.44065573811531067, "xcomet_qe_score": 0.4439592957496643, "metricx_score": 4.138735771179199, "metricx_qe_score": 3.931628704071045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以通过从相同的匹配中选择不可接受的句子来做同样的事情,这也可以用来测试模型的可接受性。", "metrics": {"bleu_score": 94.27781070492712, "chrf_score": 91.7870378110458, "xcomet_score": 0.9529941082000732, "xcomet_qe_score": 0.7428854703903198, "metricx_score": 1.5263457298278809, "metricx_qe_score": 1.8271386623382568, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过从不同的子集或不同的数据集选择句子来做同样的事情。", "metrics": {"bleu_score": 83.07278725457043, "chrf_score": 79.33022891685252, "xcomet_score": 0.9753702878952026, "xcomet_qe_score": 0.8853784799575806, "metricx_score": 0.7516820430755615, "metricx_qe_score": 1.2882355451583862, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们所谓的“不匹配场景”。", "metrics": {"bleu_score": 55.33409598501604, "chrf_score": 49.542463638940795, "xcomet_score": 0.9949870109558105, "xcomet_qe_score": 0.9300341606140137, "metricx_score": 0.5819330811500549, "metricx_qe_score": 1.2175370454788208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,句子仍然来自相关的数据集,但不是您正在评估的数据集。", "metrics": {"bleu_score": 44.741761514785864, "chrf_score": 37.82142604722508, "xcomet_score": 0.9639480113983154, "xcomet_qe_score": 0.8930301666259766, "metricx_score": 1.3128830194473267, "metricx_qe_score": 2.0115175247192383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以对不可接受的情况进行同样的操作。", "metrics": {"bleu_score": 56.600498033020294, "chrf_score": 47.52222672694808, "xcomet_score": 0.9842768907546997, "xcomet_qe_score": 0.8945431113243103, "metricx_score": 0.6709005832672119, "metricx_qe_score": 0.8343357443809509, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们可以从完全不相关的领域(如维基百科)选择句子。", "metrics": {"bleu_score": 68.51959067071544, "chrf_score": 59.66835547481827, "xcomet_score": 0.9937163591384888, "xcomet_qe_score": 0.8873118162155151, "metricx_score": 0.7689498066902161, "metricx_qe_score": 1.2383947372436523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这将告诉我们,模型的可接受性判断是否实际上受到任何上下文的任何影响,如上下文是否来自数据集的不同子集,或者是否与我们正在查看的句子完全无关。", "metrics": {"bleu_score": 67.42032476234884, "chrf_score": 59.924841206721794, "xcomet_score": 0.9307698011398315, "xcomet_qe_score": 0.9055112600326538, "metricx_score": 2.238847255706787, "metricx_qe_score": 3.073538064956665, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型的表现如何?", "metrics": {"bleu_score": 6.542540885608183, "chrf_score": 5.682181701855407, "xcomet_score": 0.6500699520111084, "xcomet_qe_score": 0.8556494116783142, "metricx_score": 1.1299031972885132, "metricx_qe_score": 0.3343578577041626, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们查看了与当前查询对完全无关的维基百科句子,我们发现 MPP 判断对于任意上下文长度大多是稳健的。", "metrics": {"bleu_score": 49.63388241286871, "chrf_score": 43.9460519038091, "xcomet_score": 0.8896526098251343, "xcomet_qe_score": 0.7430524826049805, "metricx_score": 4.026981353759766, "metricx_qe_score": 6.014644622802734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将上下文长度增加到一千二十四个,以最大化 Ot 和 GPT 二模型,我们在这里看到", "metrics": {"bleu_score": 37.586264284913035, "chrf_score": 42.84645688415483, "xcomet_score": 0.44053879380226135, "xcomet_qe_score": 0.4446674883365631, "metricx_score": 8.83764934539795, "metricx_qe_score": 9.286725044250488, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "(橙色虚线)MPP 判断相对稳定。", "metrics": {"bleu_score": 52.58479114901755, "chrf_score": 53.515444977643725, "xcomet_score": 0.9023087620735168, "xcomet_qe_score": 0.773169994354248, "metricx_score": 1.612141728401184, "metricx_qe_score": 4.269287109375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,当我们从同一数据集选择句子时会发生什么?", "metrics": {"bleu_score": 52.10220626528036, "chrf_score": 45.47347262225907, "xcomet_score": 0.9926936626434326, "xcomet_qe_score": 0.936105489730835, "metricx_score": 0.63746178150177, "metricx_qe_score": 1.1434544324874878, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这里,我们从同一 blim 语法健身房数据集的可接受和不可接受领域选择或创建句子,", "metrics": {"bleu_score": 43.73926615574847, "chrf_score": 29.80264027845596, "xcomet_score": 0.5751938819885254, "xcomet_qe_score": 0.5718814134597778, "metricx_score": 5.17180061340332, "metricx_qe_score": 5.167158603668213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们看到,当您添加可接受前缀或不可接受前缀时,MPP 判断会显著增加或减少。", "metrics": {"bleu_score": 48.73787749858404, "chrf_score": 44.06862079818965, "xcomet_score": 0.7763468027114868, "xcomet_qe_score": 0.5951054692268372, "metricx_score": 3.4414069652557373, "metricx_qe_score": 2.605482816696167, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,当我们匹配结构时,即当我们从 blame person 语法健身房中选择句子时,我们看到模型的 pp 判断会根据所选前缀是可接受还是不可接受而大幅增加或大幅减少。现在,这个效果非常大,随", "metrics": {"bleu_score": 46.98491110969029, "chrf_score": 34.66527209687442, "xcomet_score": 0.19540640711784363, "xcomet_qe_score": 0.16555538773536682, "metricx_score": 12.008320808410645, "metricx_qe_score": 11.512876510620117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "着上下文长度的增加而增加,这可能会影响到具有大上下文窗口的较新的语言模型。", "metrics": {"bleu_score": 58.802006269112944, "chrf_score": 52.26697687448596, "xcomet_score": 0.7479031085968018, "xcomet_qe_score": 0.6305112838745117, "metricx_score": 4.319213390350342, "metricx_qe_score": 6.085684299468994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为什么匹配前缀会如此大地影响语言模型的判断?", "metrics": {"bleu_score": 48.456543577930276, "chrf_score": 44.64599204569893, "xcomet_score": 0.9862410426139832, "xcomet_qe_score": 0.9311304688453674, "metricx_score": 0.6450749039649963, "metricx_qe_score": 0.7262178659439087, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们进行了一系列分析,试图像扰动输入句子一样,同时保持相关的结构,但在输入中添加噪声。", "metrics": {"bleu_score": 39.30372719311529, "chrf_score": 37.56115733546619, "xcomet_score": 0.7032471299171448, "xcomet_qe_score": 0.6673501133918762, "metricx_score": 3.10300350189209, "metricx_qe_score": 4.218209266662598, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "经过几次这样的扰动,我们发现这些噪声实际上并没有使模型改变其 MPP 判断趋势。", "metrics": {"bleu_score": 49.969403283043064, "chrf_score": 48.09525215664927, "xcomet_score": 0.9497193098068237, "xcomet_qe_score": 0.9182620048522949, "metricx_score": 2.8820910453796387, "metricx_qe_score": 3.488752603530884, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基本上,我们发现模型以相似的方式对扰动句", "metrics": {"bleu_score": 16.162239449628064, "chrf_score": 17.61492274873681, "xcomet_score": 0.7791751623153687, "xcomet_qe_score": 0.7905330657958984, "metricx_score": 5.997762680053711, "metricx_qe_score": 5.489698886871338, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "子敏感,即当我们在可接受领域中扰动句子时,我们看到所有扰动中的相似增加,当我们在可接受批准领域中扰动句子时,我们以类似的方式看到 MPP 判断的减少。", "metrics": {"bleu_score": 39.478543232916664, "chrf_score": 35.064289845205515, "xcomet_score": 0.3021230101585388, "xcomet_qe_score": 0.2522463798522949, "metricx_score": 7.628409385681152, "metricx_qe_score": 7.942330837249756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们工作的关键结论是,语言模型对句子中共享的潜在句法和语义特征敏感。", "metrics": {"bleu_score": 62.31144761876193, "chrf_score": 54.350104376451334, "xcomet_score": 0.916426420211792, "xcomet_qe_score": 0.9328593015670776, "metricx_score": 1.1966193914413452, "metricx_qe_score": 1.4394019842147827, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们目前用短句和单句输入进行的 MPP 评估可能无法完全捕捉语言模型在整个上下文窗口中的抽象知识。", "metrics": {"bleu_score": 58.96147300889812, "chrf_score": 49.68419800979127, "xcomet_score": 0.9564402103424072, "xcomet_qe_score": 0.8595497012138367, "metricx_score": 1.4992800951004028, "metricx_qe_score": 2.0477633476257324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文以获取我们实验的更多详细信息。", "metrics": {"bleu_score": 71.9486981916948, "chrf_score": 67.07656051381463, "xcomet_score": 0.99744713306427, "xcomet_qe_score": 0.9992866516113281, "metricx_score": 0.24227701127529144, "metricx_qe_score": 0.2289969027042389, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢大家的关注,期待", "metrics": {"bleu_score": 31.702331385234313, "chrf_score": 34.646700801963036, "xcomet_score": 0.4658147990703583, "xcomet_qe_score": 0.302799254655838, "metricx_score": 2.043461322784424, "metricx_qe_score": 0.6012153029441833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自宾夕法尼亚州立大学的约翰。", "metrics": {"bleu_score": 72.00391346486707, "chrf_score": 50.28639254388458, "xcomet_score": 0.7689583897590637, "xcomet_qe_score": 0.7370547652244568, "metricx_score": 2.693315029144287, "metricx_qe_score": 3.833712577819824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天,我将介绍我们的工作,即Exampler:跨语言语义解析在多种自然语言和手动表示中的应用。", "metrics": {"bleu_score": 45.88165621464402, "chrf_score": 36.75223951796844, "xcomet_score": 0.6948924660682678, "xcomet_qe_score": 0.6923536062240601, "metricx_score": 5.247411727905273, "metricx_qe_score": 5.315258026123047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语义解析是一种构建用户查询(如SQL和Lambda演算)语义表示的任务。", "metrics": {"bleu_score": 56.4688325154375, "chrf_score": 51.43956316550204, "xcomet_score": 0.9677364230155945, "xcomet_qe_score": 0.9465628862380981, "metricx_score": 1.1334550380706787, "metricx_qe_score": 1.5960214138031006, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义解析则是将多种自然语言的查询翻译成多种语义表示的任务,", "metrics": {"bleu_score": 71.73057568216397, "chrf_score": 67.12604550167994, "xcomet_score": 0.9224664568901062, "xcomet_qe_score": 0.8715094327926636, "metricx_score": 1.6698592901229858, "metricx_qe_score": 3.447877883911133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,我们需要使用神经模型将多种自然语言的查询翻译成SQL、Lambda或Funql等。", "metrics": {"bleu_score": 85.39491723727966, "chrf_score": 84.07893612430098, "xcomet_score": 0.9526199102401733, "xcomet_qe_score": 0.9577152729034424, "metricx_score": 1.4178794622421265, "metricx_qe_score": 1.6082541942596436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型分别针对有限的语种和应用进行了提出和评估,例如", "metrics": {"bleu_score": 47.564201647883095, "chrf_score": 41.298006754849744, "xcomet_score": 0.7728366851806641, "xcomet_qe_score": 0.812620997428894, "metricx_score": 1.7774237394332886, "metricx_qe_score": 1.0428493022918701, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",某些自然语言(如中文)的覆", "metrics": {"bleu_score": 35.13098711506864, "chrf_score": 29.782421791256724, "xcomet_score": 0.41578665375709534, "xcomet_qe_score": 0.17551343142986298, "metricx_score": 14.219533920288086, "metricx_qe_score": 8.349381446838379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "盖范围存在漏洞,某些迷你表示(如Lambda演", "metrics": {"bleu_score": 4.324908785617644, "chrf_score": 4.539917732637521, "xcomet_score": 0.1772783249616623, "xcomet_qe_score": 0.1520252823829651, "metricx_score": 10.354467391967773, "metricx_qe_score": 7.059542179107666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "算)的覆盖范围存在漏洞,或者它们仅针对某些神经模型进行了评估,", "metrics": {"bleu_score": 20.89685256289425, "chrf_score": 20.699822839345412, "xcomet_score": 0.5092584490776062, "xcomet_qe_score": 0.5370903015136719, "metricx_score": 5.96627140045166, "metricx_qe_score": 7.38987398147583, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,仅有一个模型进行评估。", "metrics": {"bleu_score": 13.497071069287378, "chrf_score": 15.93070616434353, "xcomet_score": 0.9905691146850586, "xcomet_qe_score": 0.9089526534080505, "metricx_score": 0.5882089734077454, "metricx_qe_score": 0.8057669997215271, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为此,我们提出了Exampler,并", "metrics": {"bleu_score": 40.35278637463991, "chrf_score": 21.861911323149315, "xcomet_score": 0.5243884921073914, "xcomet_qe_score": 0.456982284784317, "metricx_score": 4.429913520812988, "metricx_qe_score": 3.6126763820648193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为多种自然语言和语义表示的跨语言语义解析提供了一个统一的数据集。该数据", "metrics": {"bleu_score": 62.216058131285656, "chrf_score": 48.690590206681996, "xcomet_score": 0.4121074080467224, "xcomet_qe_score": 0.42076781392097473, "metricx_score": 7.2630085945129395, "metricx_qe_score": 2.467766761779785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "集包含九个病毒领域的数据集、五个半解析任务、800万个表示和22种自然语言,涵盖15个语系。", "metrics": {"bleu_score": 35.19966095055517, "chrf_score": 33.494146486433706, "xcomet_score": 0.38781777024269104, "xcomet_qe_score": 0.34797272086143494, "metricx_score": 9.072598457336426, "metricx_qe_score": 8.440357208251953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准测试,我们考虑了六种训练和评估设置。", "metrics": {"bleu_score": 74.56495553738948, "chrf_score": 70.42746348716106, "xcomet_score": 0.9834190607070923, "xcomet_qe_score": 0.9601007699966431, "metricx_score": 0.9758420586585999, "metricx_qe_score": 1.3702785968780518, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一种是翻译测试。", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 56.005291005291, "xcomet_score": 0.9600571393966675, "xcomet_qe_score": 0.9592820405960083, "metricx_score": 0.29587188363075256, "metricx_qe_score": 0.4503270089626312, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用Google翻译API将源语言翻译成目标语言,然后使用单语模型进行训练和评估。", "metrics": {"bleu_score": 82.66660014007991, "chrf_score": 76.41626540305097, "xcomet_score": 0.9510485529899597, "xcomet_qe_score": 0.8472477197647095, "metricx_score": 0.5243576169013977, "metricx_qe_score": 0.4862639307975769, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们用英语查询训练英语模型,在推理过程中,我们使用API将德语查询翻译成英语,然后使用训练好的模型预测SQL。", "metrics": {"bleu_score": 67.76817687968963, "chrf_score": 61.643862975799145, "xcomet_score": 0.9292150735855103, "xcomet_qe_score": 0.9065759181976318, "metricx_score": 1.0225903987884521, "metricx_qe_score": 1.5625306367874146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还测试了单语模型。", "metrics": {"bleu_score": 51.56626918239823, "chrf_score": 40.77320827320827, "xcomet_score": 0.8812164068222046, "xcomet_qe_score": 0.84535151720047, "metricx_score": 1.4693257808685303, "metricx_qe_score": 1.2090201377868652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种设置中,源语言与目标语言相同,例如德语到德语或英语到英语。", "metrics": {"bleu_score": 79.62043815447007, "chrf_score": 72.11571486935317, "xcomet_score": 0.9170216917991638, "xcomet_qe_score": 0.8641055822372437, "metricx_score": 0.6255096197128296, "metricx_qe_score": 0.6673116683959961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还测试了单语融合设置,通过仅使用10%的训练数据训练单语模型,并测试了", "metrics": {"bleu_score": 38.08736185356174, "chrf_score": 35.943973373985564, "xcomet_score": 0.5901219844818115, "xcomet_qe_score": 0.5372936725616455, "metricx_score": 7.045650482177734, "metricx_qe_score": 4.651561260223389, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "多语模型,我们为所有语言训练了一个多语模型。", "metrics": {"bleu_score": 43.85066034986241, "chrf_score": 37.64888227837619, "xcomet_score": 0.7888666391372681, "xcomet_qe_score": 0.7007249593734741, "metricx_score": 2.3459537029266357, "metricx_qe_score": 2.657641887664795, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们将德语、英语和中文查询一起训练一个多语模型,", "metrics": {"bleu_score": 49.74676701508169, "chrf_score": 42.588678753238504, "xcomet_score": 0.7767471075057983, "xcomet_qe_score": 0.9213095903396606, "metricx_score": 1.8979004621505737, "metricx_qe_score": 3.188343048095703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在推理过程中,我们可以使用这个模型翻译德语查询或中文查询等。", "metrics": {"bleu_score": 82.42245567123457, "chrf_score": 75.15074104990397, "xcomet_score": 0.9756777286529541, "xcomet_qe_score": 0.8953857421875, "metricx_score": 0.7203695178031921, "metricx_qe_score": 1.1883642673492432, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑了跨语言零短和领域短转移,", "metrics": {"bleu_score": 50.67483080840264, "chrf_score": 47.18147291392019, "xcomet_score": 0.6584911942481995, "xcomet_qe_score": 0.6610140204429626, "metricx_score": 8.669659614562988, "metricx_qe_score": 7.7109599113464355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在一源语言上进行训练,然后转移到另一语言。", "metrics": {"bleu_score": 23.949370866503145, "chrf_score": 24.422441972289807, "xcomet_score": 0.8390161991119385, "xcomet_qe_score": 0.7783647179603577, "metricx_score": 2.8360323905944824, "metricx_qe_score": 2.790353775024414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我们用英语查询或英语和德语短查询的组合训练多语模型,预测SQL输出。", "metrics": {"bleu_score": 52.477741805284474, "chrf_score": 48.49634144295242, "xcomet_score": 0.7121624946594238, "xcomet_qe_score": 0.7342344522476196, "metricx_score": 1.2950434684753418, "metricx_qe_score": 1.25745689868927, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了许多有趣的结果。", "metrics": {"bleu_score": 57.3122448409426, "chrf_score": 48.92181892181892, "xcomet_score": 0.9985549449920654, "xcomet_qe_score": 0.990606427192688, "metricx_score": 0.33577799797058105, "metricx_qe_score": 0.8158290982246399, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关于单语模型的分析,我们对两组模型进行了评估,包括编码器PDR(多语言预训练编码器,具有基于指针的解码器,如XLr plus PDdR和bird plus PDdR", "metrics": {"bleu_score": 48.61395727990279, "chrf_score": 34.39424539898586, "xcomet_score": 0.6180348992347717, "xcomet_qe_score": 0.4775989055633545, "metricx_score": 8.002878189086914, "metricx_qe_score": 7.905006408691406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "),我们还评估了编码器解码器模型,即多语言预训练编码器解码器模型,如MBt和Mt5。", "metrics": {"bleu_score": 31.009124728696612, "chrf_score": 17.214279061963804, "xcomet_score": 0.7364627122879028, "xcomet_qe_score": 0.7664295434951782, "metricx_score": 3.9469711780548096, "metricx_qe_score": 4.738303184509277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现编码器解码器在所有九个数据集上获得了最佳性能。", "metrics": {"bleu_score": 51.993022299307086, "chrf_score": 31.83035114305495, "xcomet_score": 0.9724286794662476, "xcomet_qe_score": 0.9654579162597656, "metricx_score": 1.7881311178207397, "metricx_qe_score": 1.7016390562057495, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对MT5和XLMR plus PDR的多语言设置进行了评估。", "metrics": {"bleu_score": 15.77454598068419, "chrf_score": 26.262899486965384, "xcomet_score": 0.852969765663147, "xcomet_qe_score": 0.9175083637237549, "metricx_score": 2.485098361968994, "metricx_qe_score": 2.296825647354126, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,通过在多种语言的混合中进行训练,可以改进编码器解码器或编码器PDR的性能。", "metrics": {"bleu_score": 22.610908143727077, "chrf_score": 16.451212393512023, "xcomet_score": 0.6875560879707336, "xcomet_qe_score": 0.7266583442687988, "metricx_score": 2.885491132736206, "metricx_qe_score": 3.252222776412964, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这是因为大多数主要自然语言都能获得性能提升,但英语在七个数据集上的性能下降,仅在三个数据集上有所提升。", "metrics": {"bleu_score": 52.794242055635, "chrf_score": 46.09311659899727, "xcomet_score": 0.9326869249343872, "xcomet_qe_score": 0.9871698617935181, "metricx_score": 1.989628553390503, "metricx_qe_score": 1.3982261419296265, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我认为这被称为多语言曲线。", "metrics": {"bleu_score": 16.877772000449074, "chrf_score": 15.985445806482943, "xcomet_score": 0.823722243309021, "xcomet_qe_score": 0.8426663875579834, "metricx_score": 3.7724766731262207, "metricx_qe_score": 3.4831676483154297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言性能差距。", "metrics": {"bleu_score": 65.15132562023375, "chrf_score": 59.00209468789821, "xcomet_score": 0.9033793210983276, "xcomet_qe_score": 0.8933225274085999, "metricx_score": 1.7487887144088745, "metricx_qe_score": 2.4259886741638184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在此图中,蓝色线表示跨语言少短转移,", "metrics": {"bleu_score": 18.16725573641283, "chrf_score": 16.37527233115469, "xcomet_score": 0.7782939672470093, "xcomet_qe_score": 0.7988700270652771, "metricx_score": 4.427864074707031, "metricx_qe_score": 4.604503154754639, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "橙色线表示跨语言零短转移,", "metrics": {"bleu_score": 22.242469397936766, "chrf_score": 19.106913695170174, "xcomet_score": 0.823033332824707, "xcomet_qe_score": 0.8149599432945251, "metricx_score": 4.251742839813232, "metricx_qe_score": 4.297821998596191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "绿色线表示单语设置。我们发现", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 36.435939741975595, "xcomet_score": 0.8541409969329834, "xcomet_qe_score": 0.8298616409301758, "metricx_score": 2.9717254638671875, "metricx_qe_score": 1.788658857345581, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",通过比较绿色和橙色线,我们发现零短设置的跨语言转移性能差距显著,通过比较蓝色和橙色线,我们发现,随着少短设置的引入,转移差距迅速缩小。", "metrics": {"bleu_score": 29.182367007439346, "chrf_score": 25.310940878701842, "xcomet_score": 0.6164133548736572, "xcomet_qe_score": 0.6528700590133667, "metricx_score": 7.402327537536621, "metricx_qe_score": 5.758876323699951, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了一些其他有趣的结果,", "metrics": {"bleu_score": 20.941084252099145, "chrf_score": 25.2837329619026, "xcomet_score": 0.9639701843261719, "xcomet_qe_score": 0.9525836706161499, "metricx_score": 1.2364580631256104, "metricx_qe_score": 0.9082688689231873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,编码器解码器优于进度工作,或者实现了可比拟的结果,训练", "metrics": {"bleu_score": 8.041237909636775, "chrf_score": 7.539804535734064, "xcomet_score": 0.6528639793395996, "xcomet_qe_score": 0.5620646476745605, "metricx_score": 7.671600818634033, "metricx_qe_score": 5.5329203605651855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的英语自然语言可以显著提升目标自然语言的少短性能,我们发现多语言语言模型(如编码器和蓝色)对于跨语言语义解析类仍然不足。", "metrics": {"bleu_score": 41.41595050407157, "chrf_score": 31.06344835633768, "xcomet_score": 0.3485108017921448, "xcomet_qe_score": 0.3362063765525818, "metricx_score": 11.380967140197754, "metricx_qe_score": 12.086301803588867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结起来,我们构建了Exampler,这是一个用于多种自然语言和语义表示的跨语言语义解析统一基准测试。", "metrics": {"bleu_score": 48.83674271938979, "chrf_score": 35.88522873708741, "xcomet_score": 0.8015115857124329, "xcomet_qe_score": 0.8209600448608398, "metricx_score": 4.048173904418945, "metricx_qe_score": 4.635966777801514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三种代表性的多语言语言模型进行了全面的基准测试研究,", "metrics": {"bleu_score": 81.29542128873352, "chrf_score": 76.12069316379662, "xcomet_score": 0.943487286567688, "xcomet_qe_score": 0.9285154342651367, "metricx_score": 0.9468802809715271, "metricx_qe_score": 0.9695883989334106, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结果显示了许多有趣的结果等", "metrics": {"bleu_score": 79.16963878457499, "chrf_score": 77.41196303696304, "xcomet_score": 0.8581736087799072, "xcomet_qe_score": 0.7850608825683594, "metricx_score": 1.8537484407424927, "metricx_qe_score": 1.1182079315185547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "。", "metrics": {"bleu_score": 0.0, "chrf_score": 17.241379310344822, "xcomet_score": 0.41044604778289795, "xcomet_qe_score": 0.1294848918914795, "metricx_score": 4.254793643951416, "metricx_qe_score": 5.784850120544434, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎访问我们的论文和代码。", "metrics": {"bleu_score": 70.16035864257111, "chrf_score": 64.8012173012173, "xcomet_score": 0.9862284660339355, "xcomet_qe_score": 0.9691290855407715, "metricx_score": 0.43438172340393066, "metricx_qe_score": 0.6480231285095215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢大家的聆听。", "metrics": {"bleu_score": 25.848657697858535, "chrf_score": 36.502849002849004, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2993694841861725, "metricx_qe_score": 0.6194125413894653, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫阿尔·维拉德,我将简要介绍这篇关于翻译评估策略和性能的论文。", "metrics": {"bleu_score": 14.879641171245488, "chrf_score": 13.565192005913595, "xcomet_score": 0.7116328477859497, "xcomet_qe_score": 0.7057727575302124, "metricx_score": 4.366727828979492, "metricx_qe_score": 5.658934116363525, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和谷歌翻译同事的合作成果。", "metrics": {"bleu_score": 20.570885115591267, "chrf_score": 20.732468773163916, "xcomet_score": 0.9982795715332031, "xcomet_qe_score": 0.9951926469802856, "metricx_score": 0.7620185017585754, "metricx_qe_score": 0.350193053483963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "Pm 是去年 2022 年推出的一个拥有 5400 亿个参数的语言模型。", "metrics": {"bleu_score": 58.91285089649852, "chrf_score": 54.33515000065512, "xcomet_score": 0.7541112899780273, "xcomet_qe_score": 0.703199028968811, "metricx_score": 5.671630859375, "metricx_qe_score": 7.772385120391846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在发布时,它在 7800 亿个标记的文本上进行了训练", "metrics": {"bleu_score": 11.124661907380256, "chrf_score": 22.74980105071638, "xcomet_score": 0.6412287354469299, "xcomet_qe_score": 0.5933615565299988, "metricx_score": 4.318637371063232, "metricx_qe_score": 5.260897636413574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",并在数百个 NLP 任务中取得了最先进的水平。", "metrics": {"bleu_score": 34.14504535105493, "chrf_score": 37.28767984757446, "xcomet_score": 0.8993836641311646, "xcomet_qe_score": 0.853278398513794, "metricx_score": 3.944673538208008, "metricx_qe_score": 5.114401817321777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们对机器翻译的大型语言模型提示进行了系统的研究,", "metrics": {"bleu_score": 32.81714441238833, "chrf_score": 27.613030988772557, "xcomet_score": 0.6835043430328369, "xcomet_qe_score": 0.8371949195861816, "metricx_score": 3.349339008331299, "metricx_qe_score": 2.5596086978912354, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 IMT 社区的最佳实践来评估这些模型的翻译能力。", "metrics": {"bleu_score": 56.053891826721106, "chrf_score": 48.717295219245514, "xcomet_score": 0.8396009206771851, "xcomet_qe_score": 0.787361741065979, "metricx_score": 6.157434463500977, "metricx_qe_score": 7.629921913146973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这包括使用最新的测试集,以避免测试数据与语言模型的训练数据重叠,", "metrics": {"bleu_score": 76.67995669507935, "chrf_score": 72.70847933324492, "xcomet_score": 0.9537777900695801, "xcomet_qe_score": 0.9152324199676514, "metricx_score": 0.49034300446510315, "metricx_qe_score": 0.4892211854457855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了两个最先进的系统,即 WMT 评估中表现最好的系统。", "metrics": {"bleu_score": 30.698412781759703, "chrf_score": 31.236535540553618, "xcomet_score": 0.938643217086792, "xcomet_qe_score": 0.9164750576019287, "metricx_score": 2.675503730773926, "metricx_qe_score": 4.33078145980835, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用了最先进的 neuralmt 指标,并展示了基于专家的人工评估结果。", "metrics": {"bleu_score": 62.851258144945305, "chrf_score": 54.97511282719104, "xcomet_score": 0.8867543935775757, "xcomet_qe_score": 0.8924640417098999, "metricx_score": 3.4738080501556396, "metricx_qe_score": 3.9717068672180176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们还提供了一些提示选择策略的建议。", "metrics": {"bleu_score": 63.47759658012631, "chrf_score": 55.298006202469644, "xcomet_score": 0.9042164087295532, "xcomet_qe_score": 0.8508525490760803, "metricx_score": 1.0464303493499756, "metricx_qe_score": 3.1680424213409424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提示对翻译大型语言模型的性能有很大的影响,我们可以在一个简单的实验中看到这一点,我们使用一个简短的提示,并为不同的句子提供了两个不同的提示。", "metrics": {"bleu_score": 51.69632866449754, "chrf_score": 51.92990603498503, "xcomet_score": 0.7953238487243652, "xcomet_qe_score": 0.7612509727478027, "metricx_score": 3.036059856414795, "metricx_qe_score": 2.2369496822357178, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在 1000 个句子中,", "metrics": {"bleu_score": 30.895757752065407, "chrf_score": 45.3545034322207, "xcomet_score": 0.8692065477371216, "xcomet_qe_score": 0.5887117385864258, "metricx_score": 6.577800750732422, "metricx_qe_score": 8.108074188232422, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有 516 个句子的差异超过一个模糊点。", "metrics": {"bleu_score": 12.874330508144842, "chrf_score": 18.115193875624428, "xcomet_score": 0.5808275938034058, "xcomet_qe_score": 0.17317010462284088, "metricx_score": 7.925911903381348, "metricx_qe_score": 7.936371803283691, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下,这个差异可以达到 40 个模糊点。", "metrics": {"bleu_score": 32.28213880040184, "chrf_score": 26.177889304305634, "xcomet_score": 0.820159375667572, "xcomet_qe_score": 0.7611461877822876, "metricx_score": 4.393194198608398, "metricx_qe_score": 3.1828927993774414, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,选择一个好的提示策略在我们的", "metrics": {"bleu_score": 58.56596027429396, "chrf_score": 54.040346907993964, "xcomet_score": 0.7882641553878784, "xcomet_qe_score": 0.7084551453590393, "metricx_score": 5.32713508605957, "metricx_qe_score": 1.9373966455459595, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实验中,我们选择了五轮提示策略,我们只需标记我们提供给系统的句子,并标明其所在的语言。", "metrics": {"bleu_score": 39.250465587146884, "chrf_score": 33.6361944796374, "xcomet_score": 0.6708490252494812, "xcomet_qe_score": 0.6562744379043579, "metricx_score": 4.618498802185059, "metricx_qe_score": 3.6101160049438477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,我们从德语翻译成英语,德语句子(源句子)用德语冒号标记,英语翻译用英语冒号标记。", "metrics": {"bleu_score": 47.52335409318383, "chrf_score": 32.91685751285645, "xcomet_score": 0.9772305488586426, "xcomet_qe_score": 0.980293869972229, "metricx_score": 1.2028440237045288, "metricx_qe_score": 1.1667672395706177, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,在几个简短提示的情况下,实际打印形式对性能没有太大影响。", "metrics": {"bleu_score": 40.49153725730702, "chrf_score": 37.29856544506004, "xcomet_score": 0.8792954087257385, "xcomet_qe_score": 0.735774576663971, "metricx_score": 1.3148540258407593, "metricx_qe_score": 1.8441083431243896, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于零轮和一轮提示,这至关重要。", "metrics": {"bleu_score": 20.901491587909767, "chrf_score": 19.530225914818693, "xcomet_score": 0.7122125029563904, "xcomet_qe_score": 0.6829781532287598, "metricx_score": 4.2530975341796875, "metricx_qe_score": 4.584238052368164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但在我们的情况下,我们使用的是事实上的简短提示,实际", "metrics": {"bleu_score": 4.085892079136996, "chrf_score": 4.617621864977389, "xcomet_score": 0.2521795332431793, "xcomet_qe_score": 0.1359269917011261, "metricx_score": 15.0074462890625, "metricx_qe_score": 7.684690952301025, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提示形式与性能几乎没有区别,关键在于例子。", "metrics": {"bleu_score": 4.780204393760627, "chrf_score": 7.651039012513448, "xcomet_score": 0.4740285575389862, "xcomet_qe_score": 0.17040343582630157, "metricx_score": 3.6851327419281006, "metricx_qe_score": 4.004809379577637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验结果的总结是,例子质量比与源句子的相似性更重要。", "metrics": {"bleu_score": 83.47563508866297, "chrf_score": 78.47704724153999, "xcomet_score": 0.9258888959884644, "xcomet_qe_score": 0.9196336269378662, "metricx_score": 0.9950923919677734, "metricx_qe_score": 0.7766151428222656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,选择高质量翻译中的例子非常重要。", "metrics": {"bleu_score": 34.88236109564739, "chrf_score": 30.89569486521997, "xcomet_score": 0.9302853941917419, "xcomet_qe_score": 0.9323174953460693, "metricx_score": 0.5272676348686218, "metricx_qe_score": 0.7771672010421753, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是,我们比较了从 WMT 评估的训练数据或开发数据中选择提示。", "metrics": {"bleu_score": 46.60298306626784, "chrf_score": 40.024840678751424, "xcomet_score": 0.6242258548736572, "xcomet_qe_score": 0.5456323623657227, "metricx_score": 2.489325761795044, "metricx_qe_score": 3.640312910079956, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "开发数据比训练数据更丰富、质量更高,结果显示使用", "metrics": {"bleu_score": 29.898730308241777, "chrf_score": 24.61454963214467, "xcomet_score": 0.6359721422195435, "xcomet_qe_score": 0.5229016542434692, "metricx_score": 6.867949485778809, "metricx_qe_score": 4.315907955169678, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "开发数据时性能更好。", "metrics": {"bleu_score": 28.833574340610166, "chrf_score": 25.84333172772308, "xcomet_score": 0.8239965438842773, "xcomet_qe_score": 0.7881331443786621, "metricx_score": 3.309196710586548, "metricx_qe_score": 4.419642448425293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此,专业最先进的系统在翻译方面仍比 Palm 有显著优势", "metrics": {"bleu_score": 16.448694063540806, "chrf_score": 17.920285784544117, "xcomet_score": 0.8798304796218872, "xcomet_qe_score": 0.7645240426063538, "metricx_score": 4.617702960968018, "metricx_qe_score": 4.1977949142456055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",但 Palm 现在已经接近商业系统的水准。", "metrics": {"bleu_score": 33.50704079514751, "chrf_score": 28.445491262848833, "xcomet_score": 0.9654349088668823, "xcomet_qe_score": 0.9461870789527893, "metricx_score": 6.491743087768555, "metricx_qe_score": 6.106517791748047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的情况下,我们选择使用谷歌翻译进行评估。", "metrics": {"bleu_score": 73.78351342269066, "chrf_score": 68.2933811251889, "xcomet_score": 0.9759009480476379, "xcomet_qe_score": 0.9536410570144653, "metricx_score": 1.052754282951355, "metricx_qe_score": 1.886197805404663, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从使用 NpN 框架进行的模拟中获得的洞察是,Palm 的流畅度与最先进的系统相当,但主要区别在于准确性。", "metrics": {"bleu_score": 47.10971893400365, "chrf_score": 34.7146376198618, "xcomet_score": 0.6555657982826233, "xcomet_qe_score": 0.4028993248939514, "metricx_score": 7.164544105529785, "metricx_qe_score": 7.5922722816467285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是,最常见的错误是遗漏错误。", "metrics": {"bleu_score": 72.21600387198372, "chrf_score": 69.88261738261738, "xcomet_score": 0.7579965591430664, "xcomet_qe_score": 0.7860524654388428, "metricx_score": 1.7050689458847046, "metricx_qe_score": 0.886371910572052, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,Palm 选择有时通过省略源句子的部分来生成听起来更好的翻译。", "metrics": {"bleu_score": 32.275910705661076, "chrf_score": 30.62245540518949, "xcomet_score": 0.9030214548110962, "xcomet_qe_score": 0.7177518606185913, "metricx_score": 4.038965702056885, "metricx_qe_score": 4.237482070922852, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,Pan 的风格外向类别低于最先进的系统,这是一个额外的信号,表明 Par 提供了真正流畅的输出,但仍存在一些准确性问题。", "metrics": {"bleu_score": 60.45492750204832, "chrf_score": 52.25578687586838, "xcomet_score": 0.5516740083694458, "xcomet_qe_score": 0.3982778787612915, "metricx_score": 10.106921195983887, "metricx_qe_score": 10.801454544067383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是这个非常简短的概述的全部内容。", "metrics": {"bleu_score": 49.89070972910272, "chrf_score": 50.96667019306298, "xcomet_score": 0.9204057455062866, "xcomet_qe_score": 0.9140896797180176, "metricx_score": 0.3837635815143585, "metricx_qe_score": 0.374846875667572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有关更多详细信息,请来听我完整的论文介绍。", "metrics": {"bleu_score": 25.597334375887918, "chrf_score": 22.658233980309657, "xcomet_score": 0.8162676095962524, "xcomet_qe_score": 0.8689331412315369, "metricx_score": 1.4755045175552368, "metricx_qe_score": 0.8855030536651611, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9979878664016724, "xcomet_qe_score": 0.9781211018562317, "metricx_score": 0.0, "metricx_qe_score": 0.11406275629997253, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是来自德国斯塔兰德大学的博士生大伟。", "metrics": {"bleu_score": 44.26623526629487, "chrf_score": 30.89126662867082, "xcomet_score": 0.7828606367111206, "xcomet_qe_score": 0.8639782667160034, "metricx_score": 1.7009093761444092, "metricx_qe_score": 1.2490122318267822, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个视频中,我想介绍我们最近的工作,即《比你想象的更弱》,这是一次对每周视学习的批判性审视。", "metrics": {"bleu_score": 47.10006262621833, "chrf_score": 41.114270548126655, "xcomet_score": 0.7859501838684082, "xcomet_qe_score": 0.772032618522644, "metricx_score": 6.1337738037109375, "metricx_qe_score": 6.359325408935547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是与X、Myos Mosbach、Ge Steffen和Dirich Klako的合作成果。", "metrics": {"bleu_score": 6.611147069638979, "chrf_score": 31.403867881550685, "xcomet_score": 0.5373645424842834, "xcomet_qe_score": 0.5538651943206787, "metricx_score": 8.266329765319824, "metricx_qe_score": 8.955697059631348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想从简要介绍弱监督和弱监督学习开始。", "metrics": {"bleu_score": 56.82854869630478, "chrf_score": 51.33352550002637, "xcomet_score": 0.9624283313751221, "xcomet_qe_score": 0.8501094579696655, "metricx_score": 0.8787198066711426, "metricx_qe_score": 2.371363639831543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在弱监督中,我们不手动标注数据。", "metrics": {"bleu_score": 36.17043615983554, "chrf_score": 29.691878261623245, "xcomet_score": 0.8968457579612732, "xcomet_qe_score": 0.8531893491744995, "metricx_score": 0.8261656165122986, "metricx_qe_score": 1.6418793201446533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "相反,我们使用弱标签来源,如简单的启发式规则、知识库或低质量的众包,如图右侧所示。", "metrics": {"bleu_score": 58.501747134329634, "chrf_score": 54.77458145976905, "xcomet_score": 0.7270075678825378, "xcomet_qe_score": 0.6678230166435242, "metricx_score": 2.009845018386841, "metricx_qe_score": 2.7563881874084473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比,弱标签要便宜得多,但它们也存在噪声,这意味着如果", "metrics": {"bleu_score": 19.004174299152268, "chrf_score": 16.479108482719155, "xcomet_score": 0.5181809663772583, "xcomet_qe_score": 0.3197522759437561, "metricx_score": 9.781205177307129, "metricx_qe_score": 6.230657577514648, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们直接在每周标签数据上训练神经网络,那么神经网络往往会记住标签噪声,并且在每周", "metrics": {"bleu_score": 45.105806910609836, "chrf_score": 38.31922105007155, "xcomet_score": 0.26674684882164, "xcomet_qe_score": 0.41270706057548523, "metricx_score": 9.418325424194336, "metricx_qe_score": 9.024292945861816, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "监督学习中无法泛化。为了在这样的标签噪声下鲁棒地训练神经网络,提出了监督学习训练算法,以便训练的模型在实际应用中仍然能很好地泛化。", "metrics": {"bleu_score": 30.377918742057698, "chrf_score": 27.770596175177126, "xcomet_score": 0.5914961099624634, "xcomet_qe_score": 0.4657913148403168, "metricx_score": 5.76849889755249, "metricx_qe_score": 6.307852268218994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在最近的wSL(每周视学习)工作中,一个常见的观点是,人们说只在每周标签数据上训练模型,并在干净的测试集上取得高性能。", "metrics": {"bleu_score": 28.345428232275825, "chrf_score": 24.62944309091445, "xcomet_score": 0.6138529777526855, "xcomet_qe_score": 0.6281733512878418, "metricx_score": 7.900064945220947, "metricx_qe_score": 7.460711479187012, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲,这个说法并没有错,但有一个问题,那就是人们假设有一个额外的干净验证集,用于模型选择。", "metrics": {"bleu_score": 64.5211453231815, "chrf_score": 54.314624128233746, "xcomet_score": 0.9838604927062988, "xcomet_qe_score": 0.9193205833435059, "metricx_score": 1.9582992792129517, "metricx_qe_score": 2.991161346435547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这个问题的设置进行了停止,但这意味着在每周支持学习中需要额外的手动标注。", "metrics": {"bleu_score": 44.72716940520766, "chrf_score": 41.60206417467721, "xcomet_score": 0.6481766700744629, "xcomet_qe_score": 0.5983547568321228, "metricx_score": 7.297112464904785, "metricx_qe_score": 8.006723403930664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但就像房间里的大象一样,这种必要性往往被忽视。", "metrics": {"bleu_score": 60.97595954478958, "chrf_score": 52.068142894776294, "xcomet_score": 0.9272782802581787, "xcomet_qe_score": 0.8116359710693359, "metricx_score": 1.0818692445755005, "metricx_qe_score": 2.6894094944000244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "上述方法被要求提出三个研究问题:", "metrics": {"bleu_score": 69.67812829199794, "chrf_score": 65.54771617271618, "xcomet_score": 0.8493701219558716, "xcomet_qe_score": 0.8496391177177429, "metricx_score": 4.63315486907959, "metricx_qe_score": 6.254825115203857, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,wSL是否需要干净的验证数据,或者我们可以使用弱验证集代替?", "metrics": {"bleu_score": 58.38575482179785, "chrf_score": 55.18668068708976, "xcomet_score": 0.827339768409729, "xcomet_qe_score": 0.802192747592926, "metricx_score": 4.094161510467529, "metricx_qe_score": 4.140458106994629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,如果需要干净数据,或者如果干净数据是wSL工作的强制性要求,那么我们需要多少干净样本?", "metrics": {"bleu_score": 38.0566318132208, "chrf_score": 32.290501016490104, "xcomet_score": 0.9341177940368652, "xcomet_qe_score": 0.8720742464065552, "metricx_score": 1.9607036113739014, "metricx_qe_score": 2.6598961353302, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们是否应该只使用干净样本进行验证,或者还有更好的利用方式。", "metrics": {"bleu_score": 37.36568521178178, "chrf_score": 30.634612715722266, "xcomet_score": 0.9716876745223999, "xcomet_qe_score": 0.9162869453430176, "metricx_score": 0.6871711015701294, "metricx_qe_score": 1.1380988359451294, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在工作中解决了这些研究问题,我们的发现如下", "metrics": {"bleu_score": 56.552585434271506, "chrf_score": 49.175343537997655, "xcomet_score": 0.9746313095092773, "xcomet_qe_score": 0.9509680271148682, "metricx_score": 1.5308665037155151, "metricx_qe_score": 3.4550013542175293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ":首先,我们发现有趣的是,最近的wSL方法确实需要干净的验证样本才能正常工作,", "metrics": {"bleu_score": 67.89925893528314, "chrf_score": 65.72902850325522, "xcomet_score": 0.8432033658027649, "xcomet_qe_score": 0.8228713274002075, "metricx_score": 3.252488374710083, "metricx_qe_score": 3.9753661155700684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "否则性能会大幅下降,", "metrics": {"bleu_score": 63.981667416455416, "chrf_score": 56.91678603188189, "xcomet_score": 0.9724792242050171, "xcomet_qe_score": 0.982207179069519, "metricx_score": 0.38750511407852173, "metricx_qe_score": 0.7994318604469299, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示。如果没有干净的验证样本,那么趋势模型就无法超越原始的弱标签进行泛化,这意味着训练是没有意义的。", "metrics": {"bleu_score": 62.615288242116044, "chrf_score": 56.490058524692, "xcomet_score": 0.9413800239562988, "xcomet_qe_score": 0.8497999310493469, "metricx_score": 2.9494707584381104, "metricx_qe_score": 3.3652310371398926, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明wSL方法实际上需要干净的标注数据才能正常工作,获取干净验证样本的标注成本不应被忽视。", "metrics": {"bleu_score": 48.427540269992996, "chrf_score": 44.38794916733894, "xcomet_score": 0.8667957782745361, "xcomet_qe_score": 0.8405027985572815, "metricx_score": 3.871919870376587, "metricx_qe_score": 3.923302173614502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是,增加干净验证样本的数量将有助于wSL方法取得更好的性能,如图左侧所示。", "metrics": {"bleu_score": 57.390139827749664, "chrf_score": 53.347027720144645, "xcomet_score": 0.8970731496810913, "xcomet_qe_score": 0.8822239637374878, "metricx_score": 4.631750106811523, "metricx_qe_score": 5.374508857727051, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,我们只需要每个类别20个样本就能达到高性能。", "metrics": {"bleu_score": 26.512298021756173, "chrf_score": 24.35864859777903, "xcomet_score": 0.9487731456756592, "xcomet_qe_score": 0.9626321792602539, "metricx_score": 1.41232168674469, "metricx_qe_score": 1.7958661317825317, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这还不是故事的全部,因为如果我们决定直接使用干净样本进行训练,那么直接微调甚至会取得更好的性能。红", "metrics": {"bleu_score": 38.42734246223084, "chrf_score": 30.69590898662944, "xcomet_score": 0.7417873740196228, "xcomet_qe_score": 0.6360576152801514, "metricx_score": 5.781742095947266, "metricx_qe_score": 4.887910842895508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "色图形显示了直接应用于干净数据的微调方法与仅用于验证的wSL方法之间的性能差异。", "metrics": {"bleu_score": 57.573369951200725, "chrf_score": 55.72323239553775, "xcomet_score": 0.7256618738174438, "xcomet_qe_score": 0.6371884346008301, "metricx_score": 4.513153553009033, "metricx_qe_score": 4.9893951416015625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,如果我们每个类别有十个样本,直接微调开始超越wSL方法。最后,之前wSL方法中", "metrics": {"bleu_score": 20.812209921683237, "chrf_score": 23.58570574406577, "xcomet_score": 0.6355358362197876, "xcomet_qe_score": 0.6264510154724121, "metricx_score": 7.591309547424316, "metricx_qe_score": 6.818197250366211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "声称的性能提升可以通过允许在干净验证样本上继续微调来轻松实现。从图形中", "metrics": {"bleu_score": 23.03567933360628, "chrf_score": 20.11933560897633, "xcomet_score": 0.3664213716983795, "xcomet_qe_score": 0.2828633487224579, "metricx_score": 7.678728103637695, "metricx_qe_score": 6.762967109680176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,称为FTW的验证模型最初的性能低于更复杂的wSL方法,如余弦。", "metrics": {"bleu_score": 21.209886695921224, "chrf_score": 18.248967104057833, "xcomet_score": 0.6375463008880615, "xcomet_qe_score": 0.63341224193573, "metricx_score": 6.000042915344238, "metricx_qe_score": 6.382890224456787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,如果我们允许在干净样本下继续微调,那么FTW的性能与其他方法一样好。", "metrics": {"bleu_score": 51.11744072566821, "chrf_score": 43.910848387767906, "xcomet_score": 0.8459609150886536, "xcomet_qe_score": 0.8033968210220337, "metricx_score": 1.7208603620529175, "metricx_qe_score": 2.3670706748962402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,在实践中,没有理由选择更复杂的wSL方法,这些方法需要更多的计算时间和磁盘空间。", "metrics": {"bleu_score": 49.46031880984445, "chrf_score": 45.42907029191148, "xcomet_score": 0.9722158312797546, "xcomet_qe_score": 0.960624635219574, "metricx_score": 1.5816866159439087, "metricx_qe_score": 2.5810253620147705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下,我们表明,最近的wSL方法需要干净的手动标注样本才能正常工作,", "metrics": {"bleu_score": 41.816927163764795, "chrf_score": 38.204123210053, "xcomet_score": 0.7919981479644775, "xcomet_qe_score": 0.8360945582389832, "metricx_score": 3.7449333667755127, "metricx_qe_score": 4.269209384918213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们的性能提升和实用性被严重高估了。", "metrics": {"bleu_score": 53.816073893351884, "chrf_score": 48.56849415717752, "xcomet_score": 0.9926676750183105, "xcomet_qe_score": 0.9959598779678345, "metricx_score": 0.6876567602157593, "metricx_qe_score": 0.8314505815505981, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对未来工作的具体建议如下:", "metrics": {"bleu_score": 64.75445426291287, "chrf_score": 53.22177822177822, "xcomet_score": 0.9982490539550781, "xcomet_qe_score": 0.9813262224197388, "metricx_score": 0.2969313859939575, "metricx_qe_score": 0.2585373520851135, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,报告模型选择标准,", "metrics": {"bleu_score": 67.0422683816333, "chrf_score": 60.745550745550744, "xcomet_score": 0.9593298435211182, "xcomet_qe_score": 0.9004219174385071, "metricx_score": 0.29483669996261597, "metricx_qe_score": 0.44116735458374023, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如报告模型选择是否完成良好,干净的验证样本。", "metrics": {"bleu_score": 45.48941966007732, "chrf_score": 38.54689149311575, "xcomet_score": 0.824792742729187, "xcomet_qe_score": 0.7740416526794434, "metricx_score": 4.352349281311035, "metricx_qe_score": 4.962587356567383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,wSL方法应该与少数短着陆基线进行比较,假设基于具体样本的工作。", "metrics": {"bleu_score": 20.382424552140627, "chrf_score": 21.149684248732193, "xcomet_score": 0.5694835186004639, "xcomet_qe_score": 0.591025710105896, "metricx_score": 9.877349853515625, "metricx_qe_score": 9.879448890686035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,连续微调是一个简单但强大的基线,应该在未来的wSL工作中考虑。", "metrics": {"bleu_score": 38.53299404652593, "chrf_score": 32.02425730966713, "xcomet_score": 0.8595387935638428, "xcomet_qe_score": 0.8000236749649048, "metricx_score": 3.352327823638916, "metricx_qe_score": 3.9856255054473877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们开源了我们的代码。", "metrics": {"bleu_score": 59.85421813100691, "chrf_score": 55.296530627954546, "xcomet_score": 0.9946787357330322, "xcomet_qe_score": 0.9214116930961609, "metricx_score": 0.33761468529701233, "metricx_qe_score": 0.46709316968917847, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你可以通过这个幻灯片上的二维码找到它。", "metrics": {"bleu_score": 56.82854869630478, "chrf_score": 50.07086304381488, "xcomet_score": 0.9955053329467773, "xcomet_qe_score": 0.986457347869873, "metricx_score": 0.4995570182800293, "metricx_qe_score": 0.41433247923851013, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请随时查看。", "metrics": {"bleu_score": 25.57539057896621, "chrf_score": 16.573915525114153, "xcomet_score": 0.8827329277992249, "xcomet_qe_score": 0.8141119480133057, "metricx_score": 0.5074750185012817, "metricx_qe_score": 0.7284374833106995, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢,祝大家会议愉快。", "metrics": {"bleu_score": 11.24963413714218, "chrf_score": 13.56970257833989, "xcomet_score": 0.9886859655380249, "xcomet_qe_score": 0.9748584032058716, "metricx_score": 0.3219973146915436, "metricx_qe_score": 0.23914963006973267, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ":大家好,我是詹姆斯·芬奇。", "metrics": {"bleu_score": 13.912311644176565, "chrf_score": 10.501861600663739, "xcomet_score": 0.9774113893508911, "xcomet_qe_score": 0.9577682614326477, "metricx_score": 0.43790680170059204, "metricx_qe_score": 0.29918673634529114, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是萨拉·芬奇。:", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 5.58665008291874, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7187016010284424, "metricx_qe_score": 0.8041880130767822, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我们将向大家介绍ABCEV,一种全新的评估对话式人工智能的维度方法。", "metrics": {"bleu_score": 36.82794970421355, "chrf_score": 34.543814059929296, "xcomet_score": 0.8324823379516602, "xcomet_qe_score": 0.8213263750076294, "metricx_score": 3.701221466064453, "metricx_qe_score": 3.629654884338379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学语言处理实验室完成,由埃默里大学的基因·崔教授领导,并与亚马逊Alexa AI合作完成。", "metrics": {"bleu_score": 30.577468583938018, "chrf_score": 31.982883778668036, "xcomet_score": 0.6707602739334106, "xcomet_qe_score": 0.7047624588012695, "metricx_score": 5.144343376159668, "metricx_qe_score": 5.343267917633057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ":假设你刚刚开发了一个对话模型,你想看看它与当前的先进水平相比表现如何,", "metrics": {"bleu_score": 65.70589031708288, "chrf_score": 58.38967348099228, "xcomet_score": 0.926926851272583, "xcomet_qe_score": 0.9157955646514893, "metricx_score": 0.7978511452674866, "metricx_qe_score": 0.9065520763397217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常的做法是使用人类评估,例如让人类评判员选择两个对话中哪一个更好,或者根据酒精度量表对对话进行评分。", "metrics": {"bleu_score": 57.961757703004906, "chrf_score": 50.497068612283904, "xcomet_score": 0.8176214694976807, "xcomet_qe_score": 0.7619118690490723, "metricx_score": 6.153590679168701, "metricx_qe_score": 7.289446830749512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法在提供整体对话质量评估方面效果很好,但对话质量有许多方面,", "metrics": {"bleu_score": 33.44518356877781, "chrf_score": 27.552555589263044, "xcomet_score": 0.9141392707824707, "xcomet_qe_score": 0.9009455442428589, "metricx_score": 0.8597210049629211, "metricx_qe_score": 0.6277638673782349, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此你可能希望评估对话质量的多个维度,以便更细致地了解模型的优缺点。", "metrics": {"bleu_score": 64.11670660144334, "chrf_score": 58.05061589349337, "xcomet_score": 0.966055691242218, "xcomet_qe_score": 0.9268702268600464, "metricx_score": 0.632660984992981, "metricx_qe_score": 0.4797699749469757, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是简单地让人类评判员评估对话质量的几个维度,例如模型响应的相关性,使用现有的比较或酒精度量表方法。", "metrics": {"bleu_score": 56.75907950975191, "chrf_score": 49.357514146502155, "xcomet_score": 0.7910729646682739, "xcomet_qe_score": 0.765582799911499, "metricx_score": 6.638507843017578, "metricx_qe_score": 7.349497318267822, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们相信存在一种更精确、更可靠的维度对话评估策略。", "metrics": {"bleu_score": 41.348528734771456, "chrf_score": 40.00853590887389, "xcomet_score": 0.8991663455963135, "xcomet_qe_score": 0.8668703436851501, "metricx_score": 1.396376132965088, "metricx_qe_score": 1.407410740852356, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确标注每个模型响应是否表达了某些行为(例如,用无关信息回应或自相矛盾)来减少人类评估的主观性。", "metrics": {"bleu_score": 59.10167477053114, "chrf_score": 50.52756193656202, "xcomet_score": 0.8597360849380493, "xcomet_qe_score": 0.9024626612663269, "metricx_score": 1.4790674448013306, "metricx_qe_score": 2.090141773223877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为对话行为标注,简称ABCEV。", "metrics": {"bleu_score": 51.35245522145285, "chrf_score": 43.76519308867988, "xcomet_score": 0.7745586633682251, "xcomet_qe_score": 0.7775988578796387, "metricx_score": 1.9601306915283203, "metricx_qe_score": 2.8553528785705566, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们开发了这种方法,以全面覆盖最近文献中建议影响对话质量的对话模型行为。", "metrics": {"bleu_score": 38.08197831623487, "chrf_score": 30.494451915540782, "xcomet_score": 0.8067662119865417, "xcomet_qe_score": 0.858824610710144, "metricx_score": 2.243316411972046, "metricx_qe_score": 3.0585410594940186, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "ABCEV能够测量对话模型犯下各种主题错误的频率。", "metrics": {"bleu_score": 61.53267326643311, "chrf_score": 45.107240410643804, "xcomet_score": 0.7649258971214294, "xcomet_qe_score": 0.7530320882797241, "metricx_score": 2.4609179496765137, "metricx_qe_score": 4.344386100769043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,ABCEV测量了对话模型忽略其伙伴或说无关话、自相矛盾或与伙伴矛盾、产生错误事实或违反常识知识的回合次数,以及模型成功或未能表现出同理心的情况。", "metrics": {"bleu_score": 43.158497186349486, "chrf_score": 36.39885655812994, "xcomet_score": 0.5917326807975769, "xcomet_qe_score": 0.6433449983596802, "metricx_score": 5.053584575653076, "metricx_qe_score": 5.486281871795654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方法最有效,我们选择了四种最先进的对话模型,并使用ABCEV对每种模型进行了100个人类机器人对话的评估,", "metrics": {"bleu_score": 42.86406734135176, "chrf_score": 40.46150466733178, "xcomet_score": 0.8995382785797119, "xcomet_qe_score": 0.9250562191009521, "metricx_score": 3.3199503421783447, "metricx_qe_score": 3.067627429962158, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以进行比较。我们还使用三种现有方法对这些对话进行了评估:回合级别的酒精度量、对话级别的酒精度量和对话级别的配对比较。", "metrics": {"bleu_score": 34.360175646538856, "chrf_score": 29.092567069268327, "xcomet_score": 0.40469080209732056, "xcomet_qe_score": 0.3563985824584961, "metricx_score": 13.314020156860352, "metricx_qe_score": 13.34153938293457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于每种现有方法,我们收集了对对话最常用的八个方面的评估,因为这是评估对话模型的标准实践。从", "metrics": {"bleu_score": 32.98829651795216, "chrf_score": 28.39006201658127, "xcomet_score": 0.7703982591629028, "xcomet_qe_score": 0.7498376369476318, "metricx_score": 7.065600395202637, "metricx_qe_score": 2.6099536418914795, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这些评估结果的分析中,我们发现ABCEV行为标签总体上比现有方法收集的标签更可靠,这是通过在一百个双重标注对话上进行内部评估员一致性测量的。", "metrics": {"bleu_score": 35.806110244018384, "chrf_score": 33.71602627160468, "xcomet_score": 0.7444055676460266, "xcomet_qe_score": 0.8211055397987366, "metricx_score": 7.290667533874512, "metricx_qe_score": 7.422303676605225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,ABCEV标签比现有方法产生的指标更能预测整体对话质量,如图所示的简单线性回归分析所示。", "metrics": {"bleu_score": 47.64439445030488, "chrf_score": 39.34125840171129, "xcomet_score": 0.9097102880477905, "xcomet_qe_score": 0.9156311750411987, "metricx_score": 2.111025810241699, "metricx_qe_score": 2.8935985565185547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,你可以看到测量自相矛盾和伙伴矛盾回合比例分别解释了对话质量的百分比和百分之十,而平均酒精度一致性得分只解释了百分之四或更少。", "metrics": {"bleu_score": 38.68492923183823, "chrf_score": 32.39503227611982, "xcomet_score": 0.45741090178489685, "xcomet_qe_score": 0.5227146148681641, "metricx_score": 11.671655654907227, "metricx_qe_score": 11.677258491516113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用逐步线性回归检查了每个评估指标是否捕捉了对话质量的独特方面。", "metrics": {"bleu_score": 74.8279877183659, "chrf_score": 67.36733940778059, "xcomet_score": 0.8634798526763916, "xcomet_qe_score": 0.7981253266334534, "metricx_score": 0.9831233620643616, "metricx_qe_score": 1.525488257408142, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你可以看到,所有ABCEV指标的组合解释了超过百分之二十五的对话质量,而当你逐个移除这些指标时,大多数指标都会导致失去大量关于质量的信息。", "metrics": {"bleu_score": 32.805204029953906, "chrf_score": 31.442470810574303, "xcomet_score": 0.8886952996253967, "xcomet_qe_score": 0.8428175449371338, "metricx_score": 3.6065030097961426, "metricx_qe_score": 3.9445557594299316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,所有回合级别的酒精度指标的组合解释了远低于质量的百分比,而且这些指标中很少有", "metrics": {"bleu_score": 22.365696575062962, "chrf_score": 18.77501082402669, "xcomet_score": 0.2690073549747467, "xcomet_qe_score": 0.28310590982437134, "metricx_score": 13.637713432312012, "metricx_qe_score": 12.243171691894531, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "独特的含义。这些可靠、信息丰富且独特的ABCEV指标使我们能够以比以前方法更高的分辨率评估对话式人工智能。你可以", "metrics": {"bleu_score": 5.656144685713648, "chrf_score": 11.330967454534555, "xcomet_score": 0.2707744538784027, "xcomet_qe_score": 0.2145129144191742, "metricx_score": 11.345885276794434, "metricx_qe_score": 5.914233684539795, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验结果中看到,仍然存在一些挑战,并且这些挑战已经被精确量化。", "metrics": {"bleu_score": 41.26368727503021, "chrf_score": 42.810959855459885, "xcomet_score": 0.9904096126556396, "xcomet_qe_score": 0.9594658613204956, "metricx_score": 1.153573989868164, "metricx_qe_score": 1.149175763130188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们测试的机器人在大约百分之二十的响应中违反了常识,", "metrics": {"bleu_score": 53.22898913303927, "chrf_score": 49.92911314689129, "xcomet_score": 0.84718257188797, "xcomet_qe_score": 0.8331364393234253, "metricx_score": 1.20259428024292, "metricx_qe_score": 1.8634177446365356, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在大约百分之十五的响应中产生了无关信息,在大约百分之十的时间里自相矛盾或与伙伴矛盾。", "metrics": {"bleu_score": 23.185480342614458, "chrf_score": 19.436108284963503, "xcomet_score": 0.6882781982421875, "xcomet_qe_score": 0.7122710347175598, "metricx_score": 4.909655570983887, "metricx_qe_score": 4.418335437774658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着该领域的快速进步,许多这些错误率可能会在新发布的模型中减少。", "metrics": {"bleu_score": 38.36619022488541, "chrf_score": 33.60691963751889, "xcomet_score": 0.9661722183227539, "xcomet_qe_score": 0.9609274864196777, "metricx_score": 2.7508788108825684, "metricx_qe_score": 3.862902879714966, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这更需要追求可靠且精确的评估指标来比较模型。", "metrics": {"bleu_score": 60.07023331980554, "chrf_score": 59.204278288232494, "xcomet_score": 0.9866325855255127, "xcomet_qe_score": 0.9819414615631104, "metricx_score": 1.3222675323486328, "metricx_qe_score": 1.7498443126678467, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望ABCEV可以被该领域的其他人作为朝着这个方向迈出的有意义的一步,", "metrics": {"bleu_score": 60.5970302592686, "chrf_score": 52.12824727330505, "xcomet_score": 0.9100016355514526, "xcomet_qe_score": 0.8753063678741455, "metricx_score": 4.191071033477783, "metricx_qe_score": 4.205401420593262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们期待看到对话式人工智能在未来几个月和几年中的发展。", "metrics": {"bleu_score": 74.0609366763812, "chrf_score": 73.52998803726307, "xcomet_score": 0.9891669750213623, "xcomet_qe_score": 0.9691853523254395, "metricx_score": 0.7160965800285339, "metricx_qe_score": 0.8807143568992615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢观看。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9925146102905273, "xcomet_qe_score": 0.9444866180419922, "metricx_score": 0.2212229073047638, "metricx_qe_score": 0.6647006869316101, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "- 大家好,我叫Kyo Yin,我将为大家介绍我们的研究成果《何时需要上下文进行", "metrics": {"bleu_score": 34.96310438457086, "chrf_score": 34.443654492822226, "xcomet_score": 0.7148904800415039, "xcomet_qe_score": 0.6735857725143433, "metricx_score": 4.864981174468994, "metricx_qe_score": 3.001401424407959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "翻译:一个数据驱动的多语言表达?》。", "metrics": {"bleu_score": 42.51768826212765, "chrf_score": 54.05187432482842, "xcomet_score": 0.6246124505996704, "xcomet_qe_score": 0.5440270900726318, "metricx_score": 4.520493507385254, "metricx_qe_score": 3.9317245483398438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项研究是与Patrick Ferange、Emiliu、Andre F.D Martins和Graham Newbiig合作完成的。因此", "metrics": {"bleu_score": 26.18114289406105, "chrf_score": 53.95426753314696, "xcomet_score": 0.48823726177215576, "xcomet_qe_score": 0.49501344561576843, "metricx_score": 7.4392595291137695, "metricx_qe_score": 6.264039993286133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",很多翻译都依赖于上下文。", "metrics": {"bleu_score": 48.44273237963865, "chrf_score": 41.44992751648422, "xcomet_score": 0.9984474182128906, "xcomet_qe_score": 0.9899082183837891, "metricx_score": 0.9570811986923218, "metricx_qe_score": 1.0956594944000244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果", "metrics": {"bleu_score": 1.7560903341711829, "chrf_score": 4.56262425447316, "xcomet_score": 0.25739461183547974, "xcomet_qe_score": 0.16145652532577515, "metricx_score": 7.101588249206543, "metricx_qe_score": 8.591948509216309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "前一句是如果部长们发现,事情可能会变得危险,那么mole就更可能指的是间谍;", "metrics": {"bleu_score": 8.382434025112957, "chrf_score": 7.352922091738055, "xcomet_score": 0.8034776449203491, "xcomet_qe_score": 0.7833019495010376, "metricx_score": 5.320431709289551, "metricx_qe_score": 6.084867477416992, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但如果前一句是医生,这可能是严重的事情吗?那么mole就指的是胎记。", "metrics": {"bleu_score": 9.01459602237066, "chrf_score": 10.727931372270302, "xcomet_score": 0.8840583562850952, "xcomet_qe_score": 0.8637734651565552, "metricx_score": 3.835801839828491, "metricx_qe_score": 4.224809646606445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,根据上下文,单词的含义会发生变化,因此其翻译也会随之变化。", "metrics": {"bleu_score": 55.50258929982404, "chrf_score": 44.89885659254587, "xcomet_score": 0.9886187314987183, "xcomet_qe_score": 0.9744212627410889, "metricx_score": 0.25506702065467834, "metricx_qe_score": 0.2911906838417053, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,评估模型在处理这类情况时的表现非常困难,", "metrics": {"bleu_score": 28.64122358136574, "chrf_score": 23.3297996194814, "xcomet_score": 0.8726465106010437, "xcomet_qe_score": 0.8799135684967041, "metricx_score": 1.8482862710952759, "metricx_qe_score": 1.1171826124191284, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先是因为只有小部分翻译依赖于上下文,这使得像BLEU这样的语料库级指标无法捕捉这些翻译。有", "metrics": {"bleu_score": 56.80742334806763, "chrf_score": 51.44257448962281, "xcomet_score": 0.8757880330085754, "xcomet_qe_score": 0.8518968224525452, "metricx_score": 3.725717544555664, "metricx_qe_score": 2.0472936630249023, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "些人建议对依赖上下文的翻译进行有针对性的评估,但这些资源只能支持有限类型的依赖上下文翻译和有限的语言集合,因为它们通常依赖于领域知识和人工整理。", "metrics": {"bleu_score": 68.88601778505416, "chrf_score": 60.913598528192715, "xcomet_score": 0.744094729423523, "xcomet_qe_score": 0.6574424505233765, "metricx_score": 4.0635809898376465, "metricx_qe_score": 3.8250558376312256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们试图回答这两个问题。", "metrics": {"bleu_score": 45.80519369844352, "chrf_score": 36.33173006044523, "xcomet_score": 0.9939944744110107, "xcomet_qe_score": 1.0, "metricx_score": 0.5719066858291626, "metricx_qe_score": 0.22247040271759033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,何时需要上下文进行翻译?", "metrics": {"bleu_score": 30.2891221374327, "chrf_score": 24.94522599243388, "xcomet_score": 0.9302531480789185, "xcomet_qe_score": 0.9306983351707458, "metricx_score": 0.5585817098617554, "metricx_qe_score": 0.7788611650466919, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,模型在处理这些情况时的表现如何?", "metrics": {"bleu_score": 80.86627571031983, "chrf_score": 78.17325175684309, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4453682601451874, "metricx_qe_score": 0.4600134789943695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题,我们首先测量了作品在翻译中对上下文的依赖程度。", "metrics": {"bleu_score": 63.09659606023657, "chrf_score": 55.6657000003117, "xcomet_score": 0.8694556951522827, "xcomet_qe_score": 0.893549382686615, "metricx_score": 6.571606636047363, "metricx_qe_score": 6.721348285675049, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在之前的研究中,我们引入了cxmi作为机器翻译模型上下文使用的度量,这是", "metrics": {"bleu_score": 61.632163435659095, "chrf_score": 50.14950668809421, "xcomet_score": 0.7179921865463257, "xcomet_qe_score": 0.6766342520713806, "metricx_score": 7.170372486114502, "metricx_qe_score": 3.8658223152160645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过测量上下文C在给定源x的情况下对目标y提供了多少信息来实现的。你可以将cxmi视为给模型提供上下文时获得的信息。", "metrics": {"bleu_score": 44.615031315941124, "chrf_score": 34.8298794203683, "xcomet_score": 0.8389104008674622, "xcomet_qe_score": 0.8053364753723145, "metricx_score": 5.100114345550537, "metricx_qe_score": 4.786716461181641, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们将cxmi扩展为point y cxmi,可以测量句子级或词级上下文的使用。", "metrics": {"bleu_score": 10.624132467188437, "chrf_score": 14.206453607588095, "xcomet_score": 0.7325262427330017, "xcomet_qe_score": 0.7484910488128662, "metricx_score": 8.277679443359375, "metricx_qe_score": 8.876937866210938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以将p6mi高的词视为需要上下文进行翻译的词。", "metrics": {"bleu_score": 84.1354400365363, "chrf_score": 65.04906341168571, "xcomet_score": 0.8171957731246948, "xcomet_qe_score": 0.8167281150817871, "metricx_score": 5.887834072113037, "metricx_qe_score": 6.669030666351318, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们分析了p6mi高的词,寻找这些词之间的模式,", "metrics": {"bleu_score": 28.990588986072606, "chrf_score": 21.065242641538937, "xcomet_score": 0.7856894731521606, "xcomet_qe_score": 0.7359118461608887, "metricx_score": 6.492665767669678, "metricx_qe_score": 6.871638774871826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并在从英语翻译成14种不同语言的TED演讲稿的文本上进行了分析。", "metrics": {"bleu_score": 61.34588734928764, "chrf_score": 65.11113532608528, "xcomet_score": 0.947395384311676, "xcomet_qe_score": 0.9783929586410522, "metricx_score": 2.7490487098693848, "metricx_qe_score": 2.461944103240967, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在三个不同的层面上进行了分析:", "metrics": {"bleu_score": 78.28161456481268, "chrf_score": 79.42446385483244, "xcomet_score": 0.9969964027404785, "xcomet_qe_score": 0.9919244050979614, "metricx_score": 0.1583578884601593, "metricx_qe_score": 0.19915929436683655, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们查看了具有高pxmi的词性标签", "metrics": {"bleu_score": 25.65271158193807, "chrf_score": 17.283851771635213, "xcomet_score": 0.7969145178794861, "xcomet_qe_score": 0.7108170986175537, "metricx_score": 5.384263515472412, "metricx_qe_score": 5.768075942993164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这使我们能够找到例如,阿拉伯语中的双重代词具有相对高的pxMmi,这", "metrics": {"bleu_score": 41.39625550113644, "chrf_score": 32.91736851613173, "xcomet_score": 0.40187764167785645, "xcomet_qe_score": 0.4635605216026306, "metricx_score": 11.338979721069336, "metricx_qe_score": 8.207599639892578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以解释为英语没有双重代词,因此在翻译成阿拉伯语时,你需要上下文来确定代词是否是双重代词。", "metrics": {"bleu_score": 56.29522901311523, "chrf_score": 49.086425308764234, "xcomet_score": 0.7923126816749573, "xcomet_qe_score": 0.9768079519271851, "metricx_score": 2.5193030834198, "metricx_qe_score": 2.1868927478790283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同样,我们发现某些语言在选择适当的动词形式时也需要上下文。", "metrics": {"bleu_score": 91.63140145331569, "chrf_score": 90.37654905758356, "xcomet_score": 0.9986207485198975, "xcomet_qe_score": 0.9910346269607544, "metricx_score": 0.5932432413101196, "metricx_qe_score": 0.8257213234901428, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们查看了在所有不同出现情况下具有高p6I平均值的词汇项目,", "metrics": {"bleu_score": 26.70379969102466, "chrf_score": 22.706113696999672, "xcomet_score": 0.6892505288124084, "xcomet_qe_score": 0.7647839784622192, "metricx_score": 8.295053482055664, "metricx_qe_score": 7.370099067687988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别出像这里的情况,即在中文中,你需要上下文来翻译专有名词,以确保在文档中使用相同的翻译。", "metrics": {"bleu_score": 42.848737023090074, "chrf_score": 36.48337492567178, "xcomet_score": 0.762621283531189, "xcomet_qe_score": 0.8756325840950012, "metricx_score": 0.9963012933731079, "metricx_qe_score": 1.3397928476333618, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同样,我们发现上下文有助于以正确的正式程度进行翻译。", "metrics": {"bleu_score": 32.655168735068756, "chrf_score": 31.5897714849172, "xcomet_score": 0.9177067279815674, "xcomet_qe_score": 0.9073933362960815, "metricx_score": 0.8722605109214783, "metricx_qe_score": 0.9754543304443359, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们查看了具有高pxmi的不同个体标记,", "metrics": {"bleu_score": 11.451997463067546, "chrf_score": 10.69130615457786, "xcomet_score": 0.7503465414047241, "xcomet_qe_score": 0.7041829824447632, "metricx_score": 6.078502655029297, "metricx_qe_score": 5.116278171539307, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够识别出无法真正由词本身捕捉到的现象,而是通过句子结构表达的,例如省略的解析。", "metrics": {"bleu_score": 40.6225298379429, "chrf_score": 35.898389822250515, "xcomet_score": 0.8228579759597778, "xcomet_qe_score": 0.7765946388244629, "metricx_score": 2.035457134246826, "metricx_qe_score": 2.4448161125183105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们使用分析结果来设计一个针对文档级翻译的基准。", "metrics": {"bleu_score": 66.14782048885628, "chrf_score": 60.54443918936673, "xcomet_score": 0.9877415895462036, "xcomet_qe_score": 0.8696825504302979, "metricx_score": 1.2305599451065063, "metricx_qe_score": 1.5421561002731323, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们确定的五个语篇现象,我们创建了标记器来自动识别与现象相关的词,", "metrics": {"bleu_score": 47.72766467270395, "chrf_score": 45.74066429571065, "xcomet_score": 0.8367068767547607, "xcomet_qe_score": 0.879572331905365, "metricx_score": 1.5473604202270508, "metricx_qe_score": 1.3543307781219482, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们称我们的标记器为多语言语篇意识或muda标记器。", "metrics": {"bleu_score": 19.445558991317288, "chrf_score": 18.02416296371055, "xcomet_score": 0.7405797243118286, "xcomet_qe_score": 0.7229663133621216, "metricx_score": 2.559596061706543, "metricx_qe_score": 3.1385157108306885, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以注意到,不同语言具有不同比例的这些语篇现象。", "metrics": {"bleu_score": 20.096755115923674, "chrf_score": 22.037598234164374, "xcomet_score": 0.9017677307128906, "xcomet_qe_score": 0.909665048122406, "metricx_score": 2.3025288581848145, "metricx_qe_score": 1.5647097826004028, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们使用muda标记器,通过在用于评估的平行语料库上应用标记器,并在M标记器识别的依赖上下文示例上应用我们选择的翻译指标。", "metrics": {"bleu_score": 42.87826292311279, "chrf_score": 36.79314983103127, "xcomet_score": 0.581181526184082, "xcomet_qe_score": 0.5352563858032227, "metricx_score": 5.850555419921875, "metricx_qe_score": 6.123353958129883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用我们的基准以及其他指标来评估不同模型在文档级机器翻译上的表现。", "metrics": {"bleu_score": 74.38252804209344, "chrf_score": 72.81560651989159, "xcomet_score": 0.9105273485183716, "xcomet_qe_score": 0.8643457889556885, "metricx_score": 0.9695982933044434, "metricx_qe_score": 1.057651400566101, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,当我们使用语料库级指标时,对于BLEU,我们发现不依赖上下文的模型表现最好。", "metrics": {"bleu_score": 50.623729380870444, "chrf_score": 45.59040533532611, "xcomet_score": 0.9570523500442505, "xcomet_qe_score": 0.871965765953064, "metricx_score": 0.9445484280586243, "metricx_qe_score": 1.0354580879211426, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但如果我们使用commentt,依赖上下文模型表现最好。", "metrics": {"bleu_score": 42.32155552073051, "chrf_score": 28.79596450248624, "xcomet_score": 0.7679301500320435, "xcomet_qe_score": 0.7629995346069336, "metricx_score": 4.452764987945557, "metricx_qe_score": 4.99973726272583, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们使用wordf度量,那么有无上下文的模型表现相当。", "metrics": {"bleu_score": 50.69250959141051, "chrf_score": 45.462858937147146, "xcomet_score": 0.8220094442367554, "xcomet_qe_score": 0.7491370439529419, "metricx_score": 4.3863205909729, "metricx_qe_score": 3.805732250213623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明,如果我们仅使用语料库级指标,就很难确定最佳的文档级翻译系统。", "metrics": {"bleu_score": 84.99508493439812, "chrf_score": 78.52778542176075, "xcomet_score": 0.9937539100646973, "xcomet_qe_score": 0.9835736751556396, "metricx_score": 0.7764199376106262, "metricx_qe_score": 0.8549565076828003, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们使用M基准来评估模型,发现对于某些语篇现象,如正式性和词汇连贯性,依赖上下文模型的准确性显著高于不使用上下文的模型。但这些模型在其他现", "metrics": {"bleu_score": 39.58791643251716, "chrf_score": 37.29967559253788, "xcomet_score": 0.5396339893341064, "xcomet_qe_score": 0.27251744270324707, "metricx_score": 8.7121000289917, "metricx_qe_score": 6.265881538391113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "象,如省略代词和动词形式上并不比不使用上下文的模型好多少。", "metrics": {"bleu_score": 41.98347556110727, "chrf_score": 42.859202927523505, "xcomet_score": 0.5585581064224243, "xcomet_qe_score": 0.17587406933307648, "metricx_score": 5.32727575302124, "metricx_qe_score": 5.720681190490723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明我们需要在文档级翻译方面取得更多进展。", "metrics": {"bleu_score": 34.48784287189965, "chrf_score": 35.25466984258987, "xcomet_score": 0.9881994724273682, "xcomet_qe_score": 0.9714077711105347, "metricx_score": 0.7716610431671143, "metricx_qe_score": 0.7390487194061279, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统,我们的基准表明,在文档级翻译方面,dL通常比Google Trans更准确。", "metrics": {"bleu_score": 64.92795378846554, "chrf_score": 52.36545429356856, "xcomet_score": 0.8034338355064392, "xcomet_qe_score": 0.7710976600646973, "metricx_score": 6.200894355773926, "metricx_qe_score": 5.452887058258057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结来说,我们对14对语言对进行了数据驱动的分析,以确定何时需要上下文进行翻译,然后我们使用我们的改进方法构建了一个文档级机器翻译的基准,这有助于我们确定模型可以很好地处理哪些语篇现象,以及哪些翻译系统擅长文档级翻译。", "metrics": {"bleu_score": 55.670528728000775, "chrf_score": 50.54153515998472, "xcomet_score": 0.7886767983436584, "xcomet_qe_score": 0.7818843722343445, "metricx_score": 3.2361207008361816, "metricx_qe_score": 3.539314031600952, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢大家的关注,期待", "metrics": {"bleu_score": 31.702331385234313, "chrf_score": 34.646700801963036, "xcomet_score": 0.5186007618904114, "xcomet_qe_score": 0.4554016888141632, "metricx_score": 2.3104374408721924, "metricx_qe_score": 0.27754122018814087, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在多伦多见到大家。", "metrics": {"bleu_score": 46.713797772819994, "chrf_score": 39.904947674778626, "xcomet_score": 0.9665535688400269, "xcomet_qe_score": 0.960691511631012, "metricx_score": 2.354099988937378, "metricx_qe_score": 2.0320727825164795, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是 Jannislavak,我将向大家介绍我们在 Dr. Bert 上的工作,这是一个针对法语生物医学和临床领域的强大预训练模型。", "metrics": {"bleu_score": 43.61539410877908, "chrf_score": 35.89740448073933, "xcomet_score": 0.5988504886627197, "xcomet_qe_score": 0.5592694282531738, "metricx_score": 5.198087215423584, "metricx_qe_score": 5.209416389465332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本次演讲中,我们首先讨论医疗保健中的语言建模。", "metrics": {"bleu_score": 56.50858546816402, "chrf_score": 44.42216569470257, "xcomet_score": 0.9920666217803955, "xcomet_qe_score": 0.9867169857025146, "metricx_score": 0.4082871079444885, "metricx_qe_score": 0.5630125403404236, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们将介绍我们文章的主要贡献。", "metrics": {"bleu_score": 86.13356263647333, "chrf_score": 84.3318004234722, "xcomet_score": 0.9850431680679321, "xcomet_qe_score": 0.9847753047943115, "metricx_score": 0.36599403619766235, "metricx_qe_score": 0.7301774621009827, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍了第一个法语生物医学模型 Dr. Bert,它基于 Roberta,并在一个从网络上抓取的医疗数据集中 Nachtchos 上进行训练。", "metrics": {"bleu_score": 34.01096739373538, "chrf_score": 25.44168127201718, "xcomet_score": 0.7109549045562744, "xcomet_qe_score": 0.5676690340042114, "metricx_score": 6.537017345428467, "metricx_qe_score": 6.845128536224365, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还介绍了多个冷冻设置和数据源的模型比较。", "metrics": {"bleu_score": 65.89746101541208, "chrf_score": 60.57587548435708, "xcomet_score": 0.7454323172569275, "xcomet_qe_score": 0.7147153615951538, "metricx_score": 5.78912353515625, "metricx_qe_score": 6.572789192199707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们展示了我们在法语下 11 个生物医学和临床下游任务上的结果,", "metrics": {"bleu_score": 51.555847649479055, "chrf_score": 45.08019455773905, "xcomet_score": 0.6958392858505249, "xcomet_qe_score": 0.6099404692649841, "metricx_score": 3.28462553024292, "metricx_qe_score": 4.548135757446289, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后我们总结了实验,并向大家介绍了如何访问这些模型,因为自", "metrics": {"bleu_score": 42.4522536796607, "chrf_score": 37.57906737361615, "xcomet_score": 0.7226526737213135, "xcomet_qe_score": 0.69645094871521, "metricx_score": 6.172238349914551, "metricx_qe_score": 2.8414535522460938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "2018 年发布以来,Bert 已成为解决自然语言处理任务的最有效方法之一,相比历史上的静态和上下文方法(如 fast text 或 war to ve fast text)提供了巨大的性能提升。", "metrics": {"bleu_score": 51.498337969253754, "chrf_score": 41.75574855987995, "xcomet_score": 0.4919176399707794, "xcomet_qe_score": 0.4522848427295685, "metricx_score": 7.264022350311279, "metricx_qe_score": 8.211899757385254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从那时起,这个模型已被适应到许多其他语言,如法语中的 Camembert 和其他领域如生物医学中的 Permit Birth 和 Bio Birth,以及临床中的 Clinical Birth。但大多数情况下,", "metrics": {"bleu_score": 20.745873412031965, "chrf_score": 27.492223179742574, "xcomet_score": 0.23238898813724518, "xcomet_qe_score": 0.29630768299102783, "metricx_score": 15.265066146850586, "metricx_qe_score": 16.803075790405273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专业模型稀缺,并且通常基于持续预训练,因为缺乏领域内的数据。然而,直到", "metrics": {"bleu_score": 33.61336783650558, "chrf_score": 31.649419070052947, "xcomet_score": 0.5167388319969177, "xcomet_qe_score": 0.42690643668174744, "metricx_score": 7.032107353210449, "metricx_qe_score": 4.786310195922852, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,法语才没有生物医学领域的开源模型。", "metrics": {"bleu_score": 49.23185073867943, "chrf_score": 48.3979407754429, "xcomet_score": 0.7710882425308228, "xcomet_qe_score": 0.7144237160682678, "metricx_score": 3.909230947494507, "metricx_qe_score": 3.8624894618988037, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们问自己,对于广泛的用途,最合适的 数据来源是什么?这些原始数据是否可以很好地替代临床数据", "metrics": {"bleu_score": 14.205110280302383, "chrf_score": 17.241825788337415, "xcomet_score": 0.9059061408042908, "xcomet_qe_score": 0.9019520282745361, "metricx_score": 3.125295877456665, "metricx_qe_score": 2.821873664855957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "?为了回答这个问题,我们将 Dr. Bert 与我们基于来自我们所在医院非大学医院的匿名数据训练的 Schubert 模型进行了比较。", "metrics": {"bleu_score": 41.82864485683719, "chrf_score": 32.55452396300964, "xcomet_score": 0.49293282628059387, "xcomet_qe_score": 0.36992114782333374, "metricx_score": 5.849837779998779, "metricx_qe_score": 6.249898433685303, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们问自己,我们需要多少数据来训练一个基于法语数据的专业模型?", "metrics": {"bleu_score": 57.37182833893953, "chrf_score": 57.749337649509144, "xcomet_score": 0.9880787134170532, "xcomet_qe_score": 0.8811690211296082, "metricx_score": 0.5869615077972412, "metricx_qe_score": 0.5818012952804565, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是四千兆字节、八千兆字节还是更多?", "metrics": {"bleu_score": 15.844501337268932, "chrf_score": 15.522164031844593, "xcomet_score": 0.8367946147918701, "xcomet_qe_score": 0.9127914905548096, "metricx_score": 2.0331997871398926, "metricx_qe_score": 1.2204327583312988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们首先训练并比较了四个从头开始的模型:Dr. Bert 的第一版,使用了七千兆字节的 Nachtchos;第二版使用了四千兆字节的 Natureos;第一版的 Schubert,这是一个临床模型,使用了四千兆字节从临床笔记中提取的句子;以及最终版本的 Schubert,混合使用了四千兆字节的 Natureos 和四千兆字节的临床节点。", "metrics": {"bleu_score": 33.504515434400034, "chrf_score": 25.865492126982204, "xcomet_score": 0.35909587144851685, "xcomet_qe_score": 0.3829836845397949, "metricx_score": 9.387263298034668, "metricx_qe_score": 8.261274337768555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "除了这个比较,我们还介绍了三个在控制预训练上训练的模型,以分析预训练策略的影响:", "metrics": {"bleu_score": 43.844648710111386, "chrf_score": 37.95971614385218, "xcomet_score": 0.8353109359741211, "xcomet_qe_score": 0.8305927515029907, "metricx_score": 3.454972743988037, "metricx_qe_score": 3.400695562362671, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于 Camembert 的权重,并在四千兆字节的 Natureos 上进行训练;", "metrics": {"bleu_score": 21.451278268552834, "chrf_score": 27.923337539669085, "xcomet_score": 0.5939978957176208, "xcomet_qe_score": 0.5280455350875854, "metricx_score": 7.229220390319824, "metricx_qe_score": 7.859335899353027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一个也是基于 Camembert,但这次是在四千兆字节的临床数据上进行训练;最后,一个基于英语生物医学模型 Bermedbert,并在四千兆字节的 Snatches 上进行训练。", "metrics": {"bleu_score": 35.028019384135526, "chrf_score": 30.320465483747782, "xcomet_score": 0.575381875038147, "xcomet_qe_score": 0.5390058755874634, "metricx_score": 7.927079200744629, "metricx_qe_score": 7.683812618255615, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共有七个模型供", "metrics": {"bleu_score": 65.48907866815301, "chrf_score": 61.088218946745066, "xcomet_score": 0.7581075429916382, "xcomet_qe_score": 0.606342077255249, "metricx_score": 2.8011715412139893, "metricx_qe_score": 0.6518459320068359, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们评估。我们收集了公共和私人的下游任务,如命名实体识别、分类、词性标注和问答。我们将", "metrics": {"bleu_score": 51.79103964364348, "chrf_score": 48.15894655174914, "xcomet_score": 0.2706320583820343, "xcomet_qe_score": 0.22548887133598328, "metricx_score": 9.050999641418457, "metricx_qe_score": 7.534772872924805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个基线模型进行了比较,这些基线模型包括 Camembert、Oscar One Hundred Thirty Eight Gigabyte、Camembert Oscar Four Gigabyte、Camembert CC Net Four Gigabyte、Plummet Bird、Biobert 和 Clinical Bird。", "metrics": {"bleu_score": 25.5672480325805, "chrf_score": 29.47002452621732, "xcomet_score": 0.3919237554073334, "xcomet_qe_score": 0.4097398817539215, "metricx_score": 13.088489532470703, "metricx_qe_score": 12.017318725585938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型的演变表明,模型在与训练数据性质相同的任务上表现最好。", "metrics": {"bleu_score": 22.126367466755028, "chrf_score": 21.649869718790367, "xcomet_score": 0.8514161109924316, "xcomet_qe_score": 0.7722758650779724, "metricx_score": 2.6602351665496826, "metricx_qe_score": 2.692673683166504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们可以从我们能够获得的数据中观察到,来自异构来源的数据似乎更通用。", "metrics": {"bleu_score": 35.72048744492061, "chrf_score": 38.4811468554606, "xcomet_score": 0.8916327953338623, "xcomet_qe_score": 0.7780590057373047, "metricx_score": 1.4341901540756226, "metricx_qe_score": 1.8884928226470947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,使用更多的数据可以带来更好的性能。", "metrics": {"bleu_score": 52.6589137558171, "chrf_score": 45.93989530077461, "xcomet_score": 0.9362239837646484, "xcomet_qe_score": 0.9736031889915466, "metricx_score": 2.49906587600708, "metricx_qe_score": 2.952756404876709, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说,从头开始的免费训练似乎在大多数任务上都能获得更高的性能。", "metrics": {"bleu_score": 49.7608342609375, "chrf_score": 42.78264567558527, "xcomet_score": 0.8194022178649902, "xcomet_qe_score": 0.8025553226470947, "metricx_score": 6.210753917694092, "metricx_qe_score": 6.673027038574219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,我们对 Permit Bird 的权重和分词器进行的消费者预训练实验显示的结果与 Dr. Bert 4GB 从头开始的结果相当,", "metrics": {"bleu_score": 27.024765581358334, "chrf_score": 18.440929458221586, "xcomet_score": 0.3016490042209625, "xcomet_qe_score": 0.23701883852481842, "metricx_score": 11.328486442565918, "metricx_qe_score": 12.884369850158691, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但基于 Camembert 权重和分词器的模型则存在稳定性问题。", "metrics": {"bleu_score": 27.02221216829898, "chrf_score": 32.11739169550341, "xcomet_score": 0.8891509175300598, "xcomet_qe_score": 0.8401840329170227, "metricx_score": 2.0643410682678223, "metricx_qe_score": 1.9627522230148315, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,作为结论,我们的适当系统在 11 个下游任务中的 9 个任务上表现更好,并且在全球范围内超越了通用模型 Camembert 的结果。", "metrics": {"bleu_score": 50.08638586589604, "chrf_score": 44.780979169230164, "xcomet_score": 0.8236972093582153, "xcomet_qe_score": 0.7048212885856628, "metricx_score": 3.6912553310394287, "metricx_qe_score": 3.872112989425659, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,专业数据更好,更专业的数据更好,但它并不容易扩展。", "metrics": {"bleu_score": 25.15565919019027, "chrf_score": 23.0148367227286, "xcomet_score": 0.7111479043960571, "xcomet_qe_score": 0.6697404384613037, "metricx_score": 3.6041617393493652, "metricx_qe_score": 3.703080177307129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从 Nachtchos 获得的所有预训练模型都可免费获得,并且在我们的界面上,所有的训练脚本都在我们的 GitHub 仓库中。", "metrics": {"bleu_score": 42.53806231877019, "chrf_score": 33.946600015129434, "xcomet_score": 0.677209198474884, "xcomet_qe_score": 0.6871514320373535, "metricx_score": 5.639676094055176, "metricx_qe_score": 6.815163612365723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢大家的聆听,我们期待在多伦多的海报环节与大家互动。", "metrics": {"bleu_score": 29.108736587772473, "chrf_score": 30.696292111732937, "xcomet_score": 0.887898325920105, "xcomet_qe_score": 0.9419856071472168, "metricx_score": 1.7678828239440918, "metricx_qe_score": 1.7665979862213135, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.958304762840271, "xcomet_qe_score": 0.9632421731948853, "metricx_score": 0.26475995779037476, "metricx_qe_score": 0.28221702575683594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫马蒂亚斯·林德曼,今天我将向大家简要介绍我们的论文,该论文探讨了在不使用树的情况下通过多集标记和潜在置换实现的组合泛化。", "metrics": {"bleu_score": 30.519889311788734, "chrf_score": 27.549291143918747, "xcomet_score": 0.964179515838623, "xcomet_qe_score": 0.9641135931015015, "metricx_score": 1.8074827194213867, "metricx_qe_score": 1.8455796241760254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我和我的导师亚历山大·科勒和伊万·蒂托夫共同完成的工作。", "metrics": {"bleu_score": 6.730900646889454, "chrf_score": 5.8869791707301244, "xcomet_score": 0.9832853078842163, "xcomet_qe_score": 0.9693731069564819, "metricx_score": 1.562410593032837, "metricx_qe_score": 1.3484077453613281, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "组合泛化可以理解为学习者处理更深层次的递归和在训练过程中单独见过的短语未见过的组合的能力。", "metrics": {"bleu_score": 78.67067009166735, "chrf_score": 75.72309040486898, "xcomet_score": 0.8152670860290527, "xcomet_qe_score": 0.6218175888061523, "metricx_score": 4.6602325439453125, "metricx_qe_score": 6.906935691833496, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在语义解析测试中,组合泛化的表现通常如下:", "metrics": {"bleu_score": 33.90188929621573, "chrf_score": 27.071371534564886, "xcomet_score": 0.9875975847244263, "xcomet_qe_score": 0.9583355188369751, "metricx_score": 0.9189760684967041, "metricx_qe_score": 1.2924240827560425, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通常有一个训练集,", "metrics": {"bleu_score": 12.28742276615499, "chrf_score": 14.151996848972036, "xcomet_score": 0.8259454369544983, "xcomet_qe_score": 0.7209267616271973, "metricx_score": 3.235139846801758, "metricx_qe_score": 3.7388217449188232, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下是“女孩睡觉”和", "metrics": {"bleu_score": 8.403805630797752, "chrf_score": 5.403102088040125, "xcomet_score": 0.570780336856842, "xcomet_qe_score": 0.7728493213653564, "metricx_score": 7.483737468719482, "metricx_qe_score": 3.896394729614258, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "“玛丽知道女孩睡觉”,", "metrics": {"bleu_score": 11.082686076075783, "chrf_score": 8.574468994707264, "xcomet_score": 0.8861349821090698, "xcomet_qe_score": 0.9304577112197876, "metricx_score": 3.487271785736084, "metricx_qe_score": 2.959256649017334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些话语与表示其核心意义的逻辑形式配对,与", "metrics": {"bleu_score": 23.891455818410623, "chrf_score": 20.781283273543337, "xcomet_score": 0.7635402679443359, "xcomet_qe_score": 0.76805180311203, "metricx_score": 6.278960704803467, "metricx_qe_score": 1.160770058631897, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "标准机器学习评估不同,测试集不是来自相同的分布,而是包含结构上未见过的逻辑形式。", "metrics": {"bleu_score": 50.93971992113002, "chrf_score": 46.42305915225355, "xcomet_score": 0.8066925406455994, "xcomet_qe_score": 0.7694010138511658, "metricx_score": 1.2505143880844116, "metricx_qe_score": 2.200040578842163, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,模型在训练过程中已经看到了浅层递归,并在具有更深递归的例子上进行了测试。", "metrics": {"bleu_score": 28.46319621273652, "chrf_score": 26.140325249454154, "xcomet_score": 0.9088715314865112, "xcomet_qe_score": 0.8836743235588074, "metricx_score": 2.5446832180023193, "metricx_qe_score": 4.1010847091674805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "朴素的序列到序列模型难以应对这种未在训练数据中出现的泛化,并且通常会产生与输入脱节的输出,", "metrics": {"bleu_score": 18.643403650822062, "chrf_score": 17.81625487946312, "xcomet_score": 0.74299156665802, "xcomet_qe_score": 0.7617611885070801, "metricx_score": 4.059698104858398, "metricx_qe_score": 3.6622583866119385, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是它们往往无法再现输入和输出之间的系统对应关系,例如在例子中用颜色标注的那些。", "metrics": {"bleu_score": 56.88105660747896, "chrf_score": 51.54937578300422, "xcomet_score": 0.9901549816131592, "xcomet_qe_score": 0.9869934916496277, "metricx_score": 0.7724529504776001, "metricx_qe_score": 0.926918089389801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "解决这个问题的一种流行方法是将树集成到模型中。", "metrics": {"bleu_score": 65.6680744925114, "chrf_score": 54.38417629493144, "xcomet_score": 0.9308148622512817, "xcomet_qe_score": 0.9095532298088074, "metricx_score": 0.9633185863494873, "metricx_qe_score": 0.9730742573738098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "树旨在捕捉将话语与逻辑形式联系起来的组合过程。", "metrics": {"bleu_score": 46.353153079998414, "chrf_score": 43.21111036818957, "xcomet_score": 0.9437574148178101, "xcomet_qe_score": 0.8228243589401245, "metricx_score": 2.6671841144561768, "metricx_qe_score": 4.665726184844971, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法效果很好,但通常树不是给定的,需要以某种方式获得。", "metrics": {"bleu_score": 32.38924244266317, "chrf_score": 29.360252732729535, "xcomet_score": 0.9247323274612427, "xcomet_qe_score": 0.8674114942550659, "metricx_score": 1.959747076034546, "metricx_qe_score": 1.5496561527252197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本高昂的过程。", "metrics": {"bleu_score": 58.9597026996279, "chrf_score": 52.51139776496644, "xcomet_score": 0.9886571168899536, "xcomet_qe_score": 0.9861245155334473, "metricx_score": 0.5039506554603577, "metricx_qe_score": 0.5730300545692444, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,这涉及到相当形式主义的逻辑形式的特定预处理,例如处理变量符号。", "metrics": {"bleu_score": 32.71314225395622, "chrf_score": 29.8312537045055, "xcomet_score": 0.8571414947509766, "xcomet_qe_score": 0.8472964763641357, "metricx_score": 1.0943241119384766, "metricx_qe_score": 1.5351653099060059, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "获得树也可能涉及到专门的语法感应程序。", "metrics": {"bleu_score": 45.6298289344212, "chrf_score": 36.11371636466792, "xcomet_score": 0.7420464754104614, "xcomet_qe_score": 0.7251862287521362, "metricx_score": 5.883754730224609, "metricx_qe_score": 6.241732120513916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这篇论文中,我们没有使用树,而是引入了一个神经序列到序列模型,该模型首次直接建模了输入片段与输出片段之间的对应关系。", "metrics": {"bleu_score": 43.13077163379894, "chrf_score": 38.05180437268903, "xcomet_score": 0.7211111783981323, "xcomet_qe_score": 0.6629111766815186, "metricx_score": 2.1090543270111084, "metricx_qe_score": 2.3763225078582764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们展示了在不依赖树的情况下对更深层次的递归的强大泛化能力。", "metrics": {"bleu_score": 56.755270581345165, "chrf_score": 47.349943570585964, "xcomet_score": 0.9522024393081665, "xcomet_qe_score": 0.917670726776123, "metricx_score": 3.2757773399353027, "metricx_qe_score": 5.200234413146973, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法预测输出来自输入,分为两步", "metrics": {"bleu_score": 33.23485859915788, "chrf_score": 28.38546529723, "xcomet_score": 0.8475930690765381, "xcomet_qe_score": 0.7834980487823486, "metricx_score": 2.8131465911865234, "metricx_qe_score": 3.8900082111358643, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ":首先,我们用一个无序的多集标记每个输入标记,这些标记将出现在输出中。", "metrics": {"bleu_score": 32.690787797096114, "chrf_score": 29.889743412251807, "xcomet_score": 0.759219229221344, "xcomet_qe_score": 0.7854059338569641, "metricx_score": 3.664463996887207, "metricx_qe_score": 3.018062114715576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步后,我们有了所有正确的标记,但它们没有排序。", "metrics": {"bleu_score": 50.63628644589578, "chrf_score": 43.46334423580947, "xcomet_score": 0.8948249220848083, "xcomet_qe_score": 0.8269447088241577, "metricx_score": 1.8828989267349243, "metricx_qe_score": 2.8407557010650635, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么在第二步中,我们使用另一个模型来预测一个置换,将它们排列成正确的顺序。", "metrics": {"bleu_score": 47.61689276907041, "chrf_score": 47.854697246099796, "xcomet_score": 0.9120147824287415, "xcomet_qe_score": 0.9196051955223083, "metricx_score": 3.0713908672332764, "metricx_qe_score": 3.217113733291626, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了一种新的方法来预测置换,该方法对可能的置换没有硬性约束。", "metrics": {"bleu_score": 58.65605140322125, "chrf_score": 52.68344180064592, "xcomet_score": 0.8849031925201416, "xcomet_qe_score": 0.9060335159301758, "metricx_score": 2.6994566917419434, "metricx_qe_score": 2.0573205947875977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使得我们的方法非常灵活和富有表现力。", "metrics": {"bleu_score": 49.41109918128317, "chrf_score": 42.370870320503926, "xcomet_score": 0.9872218370437622, "xcomet_qe_score": 0.9658831357955933, "metricx_score": 0.7799614667892456, "metricx_qe_score": 1.2798502445220947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲,我们的置换模型大致是这样工作的。", "metrics": {"bleu_score": 25.984882476296985, "chrf_score": 22.856298625860568, "xcomet_score": 0.9731236696243286, "xcomet_qe_score": 0.9644007682800293, "metricx_score": 1.2977163791656494, "metricx_qe_score": 0.8059293031692505, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左到右遍历输出,并确定每个位置放置哪个多集标记。", "metrics": {"bleu_score": 50.897863478027745, "chrf_score": 44.134304799166074, "xcomet_score": 0.8169797658920288, "xcomet_qe_score": 0.7758876085281372, "metricx_score": 1.846040964126587, "metricx_qe_score": 2.28193998336792, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于第一个输出位置,我们简单地选择一个,如图所示。", "metrics": {"bleu_score": 44.13713504244446, "chrf_score": 38.27649188956755, "xcomet_score": 0.8885273933410645, "xcomet_qe_score": 0.9077867865562439, "metricx_score": 0.7474019527435303, "metricx_qe_score": 0.9036374688148499, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们跳到下一个多集标记,以确定输出中的第二个标记。", "metrics": {"bleu_score": 56.46847100373283, "chrf_score": 47.97089986971578, "xcomet_score": 0.7702891826629639, "xcomet_qe_score": 0.7583503723144531, "metricx_score": 2.994338035583496, "metricx_qe_score": 2.895057201385498, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个标记,通过跳到另一个多集标记。", "metrics": {"bleu_score": 59.072978342269636, "chrf_score": 53.304939890695614, "xcomet_score": 0.7350332736968994, "xcomet_qe_score": 0.743449330329895, "metricx_score": 4.249201774597168, "metricx_qe_score": 3.8325233459472656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们继续这个过程,直到第一个阶段的所有标记都被访问过一次。", "metrics": {"bleu_score": 48.99375493335211, "chrf_score": 41.18328858772296, "xcomet_score": 0.8362568616867065, "xcomet_qe_score": 0.852790117263794, "metricx_score": 2.220627784729004, "metricx_qe_score": 3.0648136138916016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了给您一个实验结果的预览,我们在这里将我们的方法与其他无树模型在COgs基准上进行了比较。我们的模型在", "metrics": {"bleu_score": 51.110528120493285, "chrf_score": 49.907804106809756, "xcomet_score": 0.6442933082580566, "xcomet_qe_score": 0.6574100255966187, "metricx_score": 9.373640060424805, "metricx_qe_score": 3.8630969524383545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对更深层次的递归的泛化方面远远优于其他模型。", "metrics": {"bleu_score": 31.34093471040566, "chrf_score": 27.068929556108255, "xcomet_score": 0.8852585554122925, "xcomet_qe_score": 0.9269498586654663, "metricx_score": 3.2399933338165283, "metricx_qe_score": 4.2335100173950195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,其他一些类型的结构泛化仍然非常具有挑战性。在", "metrics": {"bleu_score": 29.81792160679168, "chrf_score": 31.687921038468414, "xcomet_score": 0.8331275582313538, "xcomet_qe_score": 0.8581986427307129, "metricx_score": 3.9231066703796387, "metricx_qe_score": 0.7229102253913879, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文中,我们解决了几个有趣的技术挑战。", "metrics": {"bleu_score": 53.66411241731205, "chrf_score": 48.331950902806696, "xcomet_score": 0.9969878196716309, "xcomet_qe_score": 0.9911098480224609, "metricx_score": 0.4248282313346863, "metricx_qe_score": 0.520808219909668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,输入和输出之间的对齐在训练数据中没有给出,", "metrics": {"bleu_score": 30.647874896641056, "chrf_score": 27.341338559855156, "xcomet_score": 0.9032107591629028, "xcomet_qe_score": 0.888761043548584, "metricx_score": 0.663654088973999, "metricx_qe_score": 0.6054336428642273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此对于给定的标记,我们不知道它来自哪个多集标记,这给训练带来了挑战。", "metrics": {"bleu_score": 65.87480145435197, "chrf_score": 58.167399291094746, "xcomet_score": 0.8342198729515076, "xcomet_qe_score": 0.8363460898399353, "metricx_score": 4.701369762420654, "metricx_qe_score": 4.615764617919922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,有时有多个置换与数据一致,但语言学上正确的置换是潜在的。", "metrics": {"bleu_score": 27.822130970602192, "chrf_score": 24.256371778323953, "xcomet_score": 0.7838854789733887, "xcomet_qe_score": 0.770484209060669, "metricx_score": 4.055230617523193, "metricx_qe_score": 3.5460026264190674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过将对齐作为训练的一部分来解决这个问题。", "metrics": {"bleu_score": 29.45642544824926, "chrf_score": 27.82284084636144, "xcomet_score": 0.9129617214202881, "xcomet_qe_score": 0.890103816986084, "metricx_score": 0.7123181819915771, "metricx_qe_score": 1.308071255683899, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的置换方法非常灵活,但带来了一个挑战,即找到得分最高的置换是NP难的,这是", "metrics": {"bleu_score": 48.72335402013369, "chrf_score": 37.971321286803835, "xcomet_score": 0.7086155414581299, "xcomet_qe_score": 0.735680103302002, "metricx_score": 6.375426769256592, "metricx_qe_score": 2.6588375568389893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为这与旅行商问题有关。", "metrics": {"bleu_score": 26.756792920454707, "chrf_score": 25.43305890736267, "xcomet_score": 0.905764102935791, "xcomet_qe_score": 0.8358559608459473, "metricx_score": 0.7844797372817993, "metricx_qe_score": 0.9865149855613708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们用一种GPU友好的连续松弛方法来近似这一点,这也使我们能够通过解决方案进行反向传播,并学习语言学上更可信的置换。", "metrics": {"bleu_score": 52.453095982519315, "chrf_score": 52.4724742709166, "xcomet_score": 0.6996524333953857, "xcomet_qe_score": 0.5789340734481812, "metricx_score": 4.2453413009643555, "metricx_qe_score": 4.473567008972168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多关于我们的实验以及我们如何应对这些挑战的信息,请查看我们的论文或来参加我们的海报。", "metrics": {"bleu_score": 84.99315997274992, "chrf_score": 81.75179631640817, "xcomet_score": 0.8701174855232239, "xcomet_qe_score": 0.8229975700378418, "metricx_score": 4.242638111114502, "metricx_qe_score": 4.293691158294678, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。我是 Akshata,今天我和我的合著者 Martin 将展示我们的工作 Kit Must:评估从多个来源整合知识。这项", "metrics": {"bleu_score": 37.04175793035995, "chrf_score": 41.15931887103717, "xcomet_score": 0.40483638644218445, "xcomet_qe_score": 0.3366343379020691, "metricx_score": 8.664554595947266, "metricx_qe_score": 8.36959171295166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "工作是麦吉尔大学、Mila 和微软研究院的合作项目。", "metrics": {"bleu_score": 49.74905880933081, "chrf_score": 49.347326386916336, "xcomet_score": 0.8111622333526611, "xcomet_qe_score": 0.6333651542663574, "metricx_score": 3.144479513168335, "metricx_qe_score": 3.623892307281494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "国家语言理解模型依赖于各种知识来源,例如通过预训练获得的参数中包含的知识,以及推理时输入中给定的知识。", "metrics": {"bleu_score": 56.07027347092085, "chrf_score": 47.8797160894201, "xcomet_score": 0.7118011713027954, "xcomet_qe_score": 0.7422688007354736, "metricx_score": 4.475833892822266, "metricx_qe_score": 4.059052467346191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近在问答等任务中的工作表明,模型可以使用预训练的时间知识来解决任务。", "metrics": {"bleu_score": 69.48573499536025, "chrf_score": 61.729050124448605, "xcomet_score": 0.8405330181121826, "xcomet_qe_score": 0.8261600732803345, "metricx_score": 2.5620386600494385, "metricx_qe_score": 2.2960634231567383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,自然语言理解通常需要在推理时也提供知识,", "metrics": {"bleu_score": 66.76994608806291, "chrf_score": 62.40970509277145, "xcomet_score": 0.9025967717170715, "xcomet_qe_score": 0.8920153379440308, "metricx_score": 2.1264472007751465, "metricx_qe_score": 2.4330952167510986, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如在句子“约翰在电视上看到了新当选的总统”中,", "metrics": {"bleu_score": 35.099344351410714, "chrf_score": 21.302654754012085, "xcomet_score": 0.9788745641708374, "xcomet_qe_score": 0.9667648077011108, "metricx_score": 1.3265833854675293, "metricx_qe_score": 1.9334139823913574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "预训练的参数可能包含关于总统做什么和电视是什么的信息,但它们无法可靠地知道这个特定实体约翰是谁,或者新总统是谁,因为自预训练以来总统可能已经换了。", "metrics": {"bleu_score": 52.99212193269457, "chrf_score": 45.011213461857146, "xcomet_score": 0.8313118815422058, "xcomet_qe_score": 0.7977487444877625, "metricx_score": 2.7385752201080322, "metricx_qe_score": 3.0888795852661133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,成功处理知识密集型 NLU 任务的模型需要能够整合和使用预训练时间和推理时间知识。", "metrics": {"bleu_score": 48.4522199629108, "chrf_score": 44.5139514048774, "xcomet_score": 0.9581397771835327, "xcomet_qe_score": 0.926787793636322, "metricx_score": 1.4986974000930786, "metricx_qe_score": 1.6317254304885864, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中,我们提出了一套知识整合诊断测试。", "metrics": {"bleu_score": 38.564192073808314, "chrf_score": 31.11785163020088, "xcomet_score": 0.9958508014678955, "xcomet_qe_score": 0.9904599189758301, "metricx_score": 1.2110984325408936, "metricx_qe_score": 1.5152925252914429, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍了一个核心参考解析任务,旨在探究从不同来源中获取知识的能力,", "metrics": {"bleu_score": 30.321326359419633, "chrf_score": 25.411113151824466, "xcomet_score": 0.8393170833587646, "xcomet_qe_score": 0.8291439414024353, "metricx_score": 3.761833667755127, "metricx_qe_score": 3.7136895656585693, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类研究参与者评估数据集,", "metrics": {"bleu_score": 40.888337776625164, "chrf_score": 44.873801053723305, "xcomet_score": 0.8522688150405884, "xcomet_qe_score": 0.7665737271308899, "metricx_score": 5.738167762756348, "metricx_qe_score": 10.269763946533203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们数据集的例子:", "metrics": {"bleu_score": 37.904036534365005, "chrf_score": 35.48021207856836, "xcomet_score": 0.9655461311340332, "xcomet_qe_score": 0.9527583122253418, "metricx_score": 0.5633318424224854, "metricx_qe_score": 1.0948379039764404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "服务是法官 Kia", "metrics": {"bleu_score": 15.207218222740094, "chrf_score": 7.586705202312139, "xcomet_score": 0.41890209913253784, "xcomet_qe_score": 0.33897101879119873, "metricx_score": 12.303614616394043, "metricx_qe_score": 8.195987701416016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是面包师,", "metrics": {"bleu_score": 23.4500081062036, "chrf_score": 16.76332188732036, "xcomet_score": 0.7834888696670532, "xcomet_qe_score": 0.7733579874038696, "metricx_score": 3.0816810131073, "metricx_qe_score": 3.317890167236328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在工作了一天后,在法律代码", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 1.0822510822510822, "xcomet_score": 0.12223152071237564, "xcomet_qe_score": 0.11256927251815796, "metricx_score": 23.601688385009766, "metricx_qe_score": 20.850751876831055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中审理案件,他很高兴放松。", "metrics": {"bleu_score": 13.722760492594022, "chrf_score": 16.412535145205286, "xcomet_score": 0.5465364456176758, "xcomet_qe_score": 0.4834643006324768, "metricx_score": 9.610865592956543, "metricx_qe_score": 10.492168426513672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里的任务是确定代词 he 指的是哪个正确的实体,在这种情况下是。解析给定的", "metrics": {"bleu_score": 33.59973059005528, "chrf_score": 27.97185224386725, "xcomet_score": 0.579758882522583, "xcomet_qe_score": 0.39869266748428345, "metricx_score": 9.136344909667969, "metricx_qe_score": 9.917801856994629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "代词需要两种类型的信息:", "metrics": {"bleu_score": 12.629025826182108, "chrf_score": 13.968825611091527, "xcomet_score": 0.8614121675491333, "xcomet_qe_score": 0.8368625640869141, "metricx_score": 2.205000162124634, "metricx_qe_score": 2.810274839401245, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,实体特定知识,如服务是法官;其", "metrics": {"bleu_score": 7.273600588250344, "chrf_score": 9.368666976374667, "xcomet_score": 0.4650050103664398, "xcomet_qe_score": 0.5613318681716919, "metricx_score": 9.583340644836426, "metricx_qe_score": 6.745189189910889, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "次,背景知识,如法官通常在法庭上审理案件。", "metrics": {"bleu_score": 22.534374680019358, "chrf_score": 19.96952392801295, "xcomet_score": 0.8899252414703369, "xcomet_qe_score": 0.8143959045410156, "metricx_score": 4.56235408782959, "metricx_qe_score": 3.9322736263275146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "背景知识是在大型语言模型的预训练过程中学习的,而实体特定知识通常在推理时观察到。", "metrics": {"bleu_score": 57.86289333902633, "chrf_score": 52.87539207628925, "xcomet_score": 0.8939653635025024, "xcomet_qe_score": 0.9131604433059692, "metricx_score": 1.2178254127502441, "metricx_qe_score": 1.6884762048721313, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们改变这两种信息的可用性,使其可能只在一个来源中找到,或者在多个来源中找到。", "metrics": {"bleu_score": 54.35105813781786, "chrf_score": 57.39201256105774, "xcomet_score": 0.8982186317443848, "xcomet_qe_score": 0.8188700079917908, "metricx_score": 1.1157541275024414, "metricx_qe_score": 1.216607928276062, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们定义了三个 kitdmos 设置。", "metrics": {"bleu_score": 44.12739850976206, "chrf_score": 23.18097751921281, "xcomet_score": 0.8560726642608643, "xcomet_qe_score": 0.8505069613456726, "metricx_score": 1.7108873128890991, "metricx_qe_score": 1.663439154624939, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们有典型的预训练设置,其中假设在预训练时间可以获得背景知识。", "metrics": {"bleu_score": 32.93267778210307, "chrf_score": 27.916297487918424, "xcomet_score": 0.9310256242752075, "xcomet_qe_score": 0.7875567078590393, "metricx_score": 2.352407693862915, "metricx_qe_score": 2.4661977291107178, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,是背景两者设置,其中背景知识在预训练时间和推理时间都可用。", "metrics": {"bleu_score": 48.62520431390635, "chrf_score": 42.29577178630556, "xcomet_score": 0.8144253492355347, "xcomet_qe_score": 0.7169971466064453, "metricx_score": 2.0913350582122803, "metricx_qe_score": 3.0605437755584717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,是背景推理设置,其中两种知识类型仅在推理时间可用。", "metrics": {"bleu_score": 54.99167434689492, "chrf_score": 50.25356859892942, "xcomet_score": 0.9484134912490845, "xcomet_qe_score": 0.8469740152359009, "metricx_score": 2.143918514251709, "metricx_qe_score": 1.7499150037765503, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个最后设置特别有趣,因为它模拟了解决任务所需的背景知识不是模型预训练数据的一部分的情况,", "metrics": {"bleu_score": 78.67067009166735, "chrf_score": 74.27690015774705, "xcomet_score": 0.8977450132369995, "xcomet_qe_score": 0.8993191719055176, "metricx_score": 1.1768081188201904, "metricx_qe_score": 1.185349941253662, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,自预训练以来,新的职业已经发展出来。", "metrics": {"bleu_score": 38.091370416670806, "chrf_score": 33.314193479799975, "xcomet_score": 0.8910260200500488, "xcomet_qe_score": 0.8882192969322205, "metricx_score": 1.7569410800933838, "metricx_qe_score": 2.9223415851593018, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里是一个例子,说明了我们如何在背景预训练设置中控制两个来源", "metrics": {"bleu_score": 24.57777411084979, "chrf_score": 21.280557666414644, "xcomet_score": 0.5546021461486816, "xcomet_qe_score": 0.45679882168769836, "metricx_score": 5.633423328399658, "metricx_qe_score": 5.3691301345825195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的事实可用性。我们假设,背景知识政治家寻求政府选举席位包含在预训练参数中,在干扰时间上下文中,我们提供特定于奇切斯特的知识", "metrics": {"bleu_score": 28.103089609449253, "chrf_score": 22.01999746810806, "xcomet_score": 0.2793893814086914, "xcomet_qe_score": 0.3448285460472107, "metricx_score": 9.320276260375977, "metricx_qe_score": 11.099440574645996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",他在背景两者设置中,我们还提供了不仅是特定于奇切斯特的知识,还有关于政治家的背景知识,在干扰时间上下文", "metrics": {"bleu_score": 29.277615479939723, "chrf_score": 27.23887812014526, "xcomet_score": 0.255903422832489, "xcomet_qe_score": 0.2329830378293991, "metricx_score": 10.108086585998535, "metricx_qe_score": 9.715737342834473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中,在背景推理设置中,我们提供了特征职业仅仅是旅游,而不是政治家,因为仅仅是旅游不太可能包含在预训练参数中。", "metrics": {"bleu_score": 41.89233319869814, "chrf_score": 29.55339404968631, "xcomet_score": 0.40608787536621094, "xcomet_qe_score": 0.3686967194080353, "metricx_score": 8.64700698852539, "metricx_qe_score": 9.683690071105957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用人类研究参与者评估数据集,", "metrics": {"bleu_score": 40.888337776625164, "chrf_score": 44.873801053723305, "xcomet_score": 0.7816773653030396, "xcomet_qe_score": 0.6654974222183228, "metricx_score": 7.829708576202393, "metricx_qe_score": 11.54273796081543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并在这个图中,我们展示了在最困难的背景预训练设置中表现最好的模型的结果,", "metrics": {"bleu_score": 26.118067939611972, "chrf_score": 26.471390280001085, "xcomet_score": 0.821800947189331, "xcomet_qe_score": 0.7363247871398926, "metricx_score": 2.405958890914917, "metricx_qe_score": 2.4302453994750977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "没有在 kitdmos 上进行特定任务的训练。然而,当在 kitdmos 上训练", "metrics": {"bleu_score": 38.974741553961756, "chrf_score": 28.134183472333408, "xcomet_score": 0.3682665228843689, "xcomet_qe_score": 0.23941010236740112, "metricx_score": 10.52437686920166, "metricx_qe_score": 7.840012073516846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "时,两个模型都不表现良好,但 c2f 和 built for coref 的表现明显优于随机选择,", "metrics": {"bleu_score": 19.775876971405587, "chrf_score": 20.59437461514513, "xcomet_score": 0.258228063583374, "xcomet_qe_score": 0.2408267855644226, "metricx_score": 9.161294937133789, "metricx_qe_score": 10.115682601928711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明,当在通用参考解析数据集上训练时,模型学会了利用表面线索,这些线索在对 kitdmus 进行测试时没有用,因为这些线索已经被删除。额外", "metrics": {"bleu_score": 33.30570377170738, "chrf_score": 25.34033876132379, "xcomet_score": 0.7277368903160095, "xcomet_qe_score": 0.6505767107009888, "metricx_score": 6.1748576164245605, "metricx_qe_score": 6.105231285095215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的虚构知识实验表明,即使是表现最好的模型也无法可靠地整合背景知识,只能在自由时间内整合。总结", "metrics": {"bleu_score": 46.64947058554282, "chrf_score": 39.577546312977525, "xcomet_score": 0.4340587854385376, "xcomet_qe_score": 0.42444196343421936, "metricx_score": 8.685687065124512, "metricx_qe_score": 7.050506114959717, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们论文的主要结论,许多共同参考演化模型似乎无法在没有任务特定训练的情况下推理不同来源的知识,然而", "metrics": {"bleu_score": 55.87842364024368, "chrf_score": 48.19632245958471, "xcomet_score": 0.680356502532959, "xcomet_qe_score": 0.6456671357154846, "metricx_score": 6.013197898864746, "metricx_qe_score": 4.064267635345459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",通过任务特定训练,一些模型成功地整合了来自多个来源的知识。", "metrics": {"bleu_score": 66.94407009327197, "chrf_score": 64.63110494514147, "xcomet_score": 0.933914065361023, "xcomet_qe_score": 0.919018030166626, "metricx_score": 2.245051383972168, "metricx_qe_score": 2.4886322021484375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此,即使是表现最好的模型似乎也难以可靠地整合仅在推理时间呈现的背景知识。", "metrics": {"bleu_score": 65.64268130415063, "chrf_score": 57.56726659977435, "xcomet_score": 0.9132763147354126, "xcomet_qe_score": 0.9223344326019287, "metricx_score": 2.5927577018737793, "metricx_qe_score": 2.5051937103271484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您对更多细节感兴趣,请参阅我们的论文,并在 GitHub 上查看代码中的数据集。", "metrics": {"bleu_score": 46.31007483233876, "chrf_score": 47.75597387531429, "xcomet_score": 0.9086029529571533, "xcomet_qe_score": 0.9016372561454773, "metricx_score": 0.9505015015602112, "metricx_qe_score": 0.900403618812561, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢大家的聆听。", "metrics": {"bleu_score": 25.848657697858535, "chrf_score": 36.502849002849004, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2993694841861725, "metricx_qe_score": 0.6194125413894653, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是 Myra,今天我将谈论我们的论文中的标记角色,使用自然语言提示来衡量语言模型中的刻板印象。", "metrics": {"bleu_score": 66.29574116837658, "chrf_score": 59.911553397941994, "xcomet_score": 0.843429684638977, "xcomet_qe_score": 0.7105470299720764, "metricx_score": 2.5102429389953613, "metricx_qe_score": 4.201731204986572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与 Essenndermush 和 Danjorovsky 合作完成的。", "metrics": {"bleu_score": 30.119166060089718, "chrf_score": 34.00157510594918, "xcomet_score": 0.6371716260910034, "xcomet_qe_score": 0.6057815551757812, "metricx_score": 7.625980377197266, "metricx_qe_score": 8.043922424316406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,许多人记录了大型语言模型或 LLM 中社会偏见和刻板印象的普遍存在。", "metrics": {"bleu_score": 39.63083148637849, "chrf_score": 33.313639380207746, "xcomet_score": 0.9280874729156494, "xcomet_qe_score": 0.8238029479980469, "metricx_score": 2.654602527618408, "metricx_qe_score": 4.26780366897583, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些方法有各种局限性,", "metrics": {"bleu_score": 18.043192373975018, "chrf_score": 18.971185548198115, "xcomet_score": 0.9853078126907349, "xcomet_qe_score": 0.9742752909660339, "metricx_score": 0.537135899066925, "metricx_qe_score": 0.28068259358406067, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常依赖于手工构建的数据集,这些数据集需要花费大量时间来整理,而且它们通常只衡量非常特定的刻板印象,这意味着它们不能很好地推广到其他人口统计或背景,或者它们只是捕捉非常广泛的联想,如与特定群体的负面联想。", "metrics": {"bleu_score": 45.59650629876847, "chrf_score": 38.407272443053756, "xcomet_score": 0.6026630401611328, "xcomet_qe_score": 0.5801675915718079, "metricx_score": 3.718204975128174, "metricx_qe_score": 3.714893341064453, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,这个领域的大部分工作都没有考虑交叉性,即多方面社会身份可以加剧偏见,并成为伤害的独特来源。", "metrics": {"bleu_score": 31.885369630359094, "chrf_score": 26.719957242738918, "xcomet_score": 0.7132716774940491, "xcomet_qe_score": 0.7395722270011902, "metricx_score": 2.3356804847717285, "metricx_qe_score": 2.4393374919891357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些局限性,我们依赖于这些较新的指令调优 LLM 非常擅长响应提示中的指令的特性,", "metrics": {"bleu_score": 33.011950769468854, "chrf_score": 32.816572142494046, "xcomet_score": 0.8228517770767212, "xcomet_qe_score": 0.7158892154693604, "metricx_score": 5.5948872566223145, "metricx_qe_score": 7.01179838180542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此我们可以要求模型生成一个角色,这是一个对虚构个人的描绘,使用类似于“想象你是一个亚洲女性,", "metrics": {"bleu_score": 38.7296539929469, "chrf_score": 36.95132076843323, "xcomet_score": 0.6970947980880737, "xcomet_qe_score": 0.7196072936058044, "metricx_score": 3.408005952835083, "metricx_qe_score": 3.7937045097351074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "描述自己”的提示,我们", "metrics": {"bleu_score": 11.208466750961147, "chrf_score": 10.909090909090908, "xcomet_score": 0.1956922560930252, "xcomet_qe_score": 0.17253834009170532, "metricx_score": 6.132516860961914, "metricx_qe_score": 1.942654013633728, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以立即看到,这对于任何人口统计都是非常通用的,因为我们可以在这个提示中指定任何我们想要的身份标记。", "metrics": {"bleu_score": 62.13815249521441, "chrf_score": 58.971763681869305, "xcomet_score": 0.9623035192489624, "xcomet_qe_score": 0.8228317499160767, "metricx_score": 2.7510435581207275, "metricx_qe_score": 3.5875396728515625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是 GPT4 的一些示例生成,我们立", "metrics": {"bleu_score": 36.15855225145533, "chrf_score": 44.86651608751954, "xcomet_score": 0.6666418313980103, "xcomet_qe_score": 0.43782782554626465, "metricx_score": 6.857100486755371, "metricx_qe_score": 4.690924167633057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "即看到,虽然输出不是传统意义上的明显消极或有毒,但有一些有趣的模式。", "metrics": {"bleu_score": 41.039097487818616, "chrf_score": 35.086416890406404, "xcomet_score": 0.7447582483291626, "xcomet_qe_score": 0.7428857684135437, "metricx_score": 3.357994794845581, "metricx_qe_score": 4.230007648468018, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "亚洲女性被描绘成不引人注目,中东女性被用词如“异域”来描述,并像提到一个迷人的地区一样,", "metrics": {"bleu_score": 36.62922899491369, "chrf_score": 30.912849353444788, "xcomet_score": 0.7987380623817444, "xcomet_qe_score": 0.7863134145736694, "metricx_score": 5.152535915374756, "metricx_qe_score": 3.982717275619507, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而两个有色人种角色都提到了祖先,而白人角色则没有任何这样的描述。", "metrics": {"bleu_score": 30.648641888311708, "chrf_score": 26.023539541802602, "xcomet_score": 0.9582937955856323, "xcomet_qe_score": 0.9829412698745728, "metricx_score": 1.0033687353134155, "metricx_qe_score": 0.900198221206665, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了捕捉这些模式,我们的方法有两部分。", "metrics": {"bleu_score": 65.35194995338728, "chrf_score": 53.61011116096319, "xcomet_score": 0.991690993309021, "xcomet_qe_score": 0.9721889495849609, "metricx_score": 0.2471044361591339, "metricx_qe_score": 0.3814455270767212, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一部分是生成这些角色。我们的", "metrics": {"bleu_score": 77.60114635728617, "chrf_score": 93.9169047323314, "xcomet_score": 0.8128584027290344, "xcomet_qe_score": 0.6605459451675415, "metricx_score": 4.650581359863281, "metricx_qe_score": 0.7691473960876465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提示生成这些角色的灵感来自一项研究,他们给人类受试者这些提示,发现通过给人类受试者这些提示,他们也能够浮出水面种族刻板印象,", "metrics": {"bleu_score": 38.95153158194579, "chrf_score": 31.444083015741146, "xcomet_score": 0.5957029461860657, "xcomet_qe_score": 0.5819188356399536, "metricx_score": 5.070227146148682, "metricx_qe_score": 4.8401641845703125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并且这使得我们能够直接比较我们生成的角色和人类书写的回应。", "metrics": {"bleu_score": 42.8870858628797, "chrf_score": 33.59662568270082, "xcomet_score": 0.8777818083763123, "xcomet_qe_score": 0.7354378700256348, "metricx_score": 1.7184562683105469, "metricx_qe_score": 3.382388114929199, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词,这是一种识别区分标记组与我们标记组的词的方法,我稍后会详细解释。", "metrics": {"bleu_score": 22.963227941636294, "chrf_score": 20.764521865383813, "xcomet_score": 0.773856520652771, "xcomet_qe_score": 0.8630712032318115, "metricx_score": 4.6288275718688965, "metricx_qe_score": 4.389253616333008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的好处是我们得到了非常具体的刻板印象和模式,而无需依赖任何特定的词汇。", "metrics": {"bleu_score": 56.930256289333, "chrf_score": 50.97190637747329, "xcomet_score": 0.9696869850158691, "xcomet_qe_score": 0.7802253365516663, "metricx_score": 1.3808635473251343, "metricx_qe_score": 1.787065029144287, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,标记词方法借鉴了社会语言学中的标记性概念,该概念指出存在一个未标记的默认值,任何与该默认值不同的群体在语言上都是标记的。", "metrics": {"bleu_score": 50.706880763816166, "chrf_score": 43.53268912002886, "xcomet_score": 0.6715480089187622, "xcomet_qe_score": 0.7455692291259766, "metricx_score": 1.7251923084259033, "metricx_qe_score": 1.8081952333450317, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,单词“人”或“抱歉”,单词“战士”通常与男性相关,所以", "metrics": {"bleu_score": 29.37911829915806, "chrf_score": 36.38580058266635, "xcomet_score": 0.24109193682670593, "xcomet_qe_score": 0.2408565729856491, "metricx_score": 7.433427810668945, "metricx_qe_score": 7.617555618286133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当人们描述一个女战士时,他们通常会具体说明“女战士”,并用“女”来标记这个词。", "metrics": {"bleu_score": 55.44720759900863, "chrf_score": 49.20140752251885, "xcomet_score": 0.9086959958076477, "xcomet_qe_score": 0.8576914072036743, "metricx_score": 1.0583595037460327, "metricx_qe_score": 1.1123298406600952, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说,社会中的主导群体在语言和社会上都是未标记的,而边缘化群体通常是标记的。", "metrics": {"bleu_score": 60.45169397095852, "chrf_score": 54.032284073558515, "xcomet_score": 0.7715940475463867, "xcomet_qe_score": 0.7670178413391113, "metricx_score": 1.942873477935791, "metricx_qe_score": 2.0135974884033203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在我们的方法中,我们首先指定未标记和标记的群体是什么,然后我们使用战斗词方法比较角色,这基本上是使用加权对数几率比来区分每个标记组的顶级词。", "metrics": {"bleu_score": 47.30829009630498, "chrf_score": 40.489853752196794, "xcomet_score": 0.5395164489746094, "xcomet_qe_score": 0.520706295967102, "metricx_score": 6.7283124923706055, "metricx_qe_score": 7.420516014099121, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于黑人女性的角色,我们会进行战斗词,并将对数几率比与白人角色和男性角色进行比较,因为这些是两个相应的未标记群体。", "metrics": {"bleu_score": 57.26722728713966, "chrf_score": 49.1744644050497, "xcomet_score": 0.6021720170974731, "xcomet_qe_score": 0.5254545211791992, "metricx_score": 5.308854103088379, "metricx_qe_score": 6.349003314971924, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,让我们来看看一些结果。", "metrics": {"bleu_score": 20.200106912694157, "chrf_score": 29.299497576808502, "xcomet_score": 0.9776077270507812, "xcomet_qe_score": 0.9744764566421509, "metricx_score": 0.35162079334259033, "metricx_qe_score": 0.395015150308609, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们使用刻板印象的词汇,发现生成的角色包含比人类书写的角色更多的刻板印象。", "metrics": {"bleu_score": 61.6366080899692, "chrf_score": 51.698075092981654, "xcomet_score": 0.8103643655776978, "xcomet_qe_score": 0.7722954750061035, "metricx_score": 1.810787320137024, "metricx_qe_score": 2.621283531188965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,当我们实际查看词汇中的词分布时,我们发现了非常不同的事情。因此", "metrics": {"bleu_score": 16.37368248844126, "chrf_score": 18.830168726332705, "xcomet_score": 0.7081084251403809, "xcomet_qe_score": 0.7006686925888062, "metricx_score": 4.645622730255127, "metricx_qe_score": 1.8312550783157349, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",虽然生成的角色具有更高的词汇率,但人类书写的角色具有更广泛的词分布,而生成的角色中的刻板印象词实际上只是“高大”和“运动”这两个词", "metrics": {"bleu_score": 41.92088068854023, "chrf_score": 32.89938702724764, "xcomet_score": 0.49795717000961304, "xcomet_qe_score": 0.45525166392326355, "metricx_score": 4.638160228729248, "metricx_qe_score": 4.779238224029541, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",真正积极或至少是非消极的词。", "metrics": {"bleu_score": 10.399549604157809, "chrf_score": 11.557994760778021, "xcomet_score": 0.7865505218505859, "xcomet_qe_score": 0.5730849504470825, "metricx_score": 6.456694602966309, "metricx_qe_score": 5.985385894775391, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "事实上,这个词汇库根本没有很好地捕捉到我们之前幻灯片中看到的许多有害模式。", "metrics": {"bleu_score": 69.14931253023883, "chrf_score": 62.042061572627716, "xcomet_score": 0.9463218450546265, "xcomet_qe_score": 0.770458996295929, "metricx_score": 0.9375016093254089, "metricx_qe_score": 0.9320982098579407, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,相反,我们将转向我们标记词方法的结果,以展示这些看似积极的词如何促进刻板印象和本质化叙述。", "metrics": {"bleu_score": 30.873311926879904, "chrf_score": 25.728090621726647, "xcomet_score": 0.7083053588867188, "xcomet_qe_score": 0.6995680332183838, "metricx_score": 2.3121798038482666, "metricx_qe_score": 2.1911211013793945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中,我们揭示了这些看似积极的描绘反映了哪些有害模式。", "metrics": {"bleu_score": 50.68768379275972, "chrf_score": 43.49083340082861, "xcomet_score": 0.9303262233734131, "xcomet_qe_score": 0.8803143501281738, "metricx_score": 1.3601619005203247, "metricx_qe_score": 1.8424409627914429, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,对于标记组,顶级词包括“文化”、“传统”、“自豪”和“异域”等,这些", "metrics": {"bleu_score": 9.083650570857944, "chrf_score": 8.932411053828437, "xcomet_score": 0.4359978139400482, "xcomet_qe_score": 0.44571399688720703, "metricx_score": 7.2674970626831055, "metricx_qe_score": 5.636806488037109, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "词仅通过它们与身份的关系来定义这些群体,并将其与白人规范区分开来,", "metrics": {"bleu_score": 51.84225221361413, "chrf_score": 45.93622981892721, "xcomet_score": 0.8304958343505859, "xcomet_qe_score": 0.7776321172714233, "metricx_score": 4.259093761444092, "metricx_qe_score": 4.473406791687012, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这促成了这些群体的长期歧视和异化的遗产。", "metrics": {"bleu_score": 24.210982665568515, "chrf_score": 21.01655705127477, "xcomet_score": 0.784221887588501, "xcomet_qe_score": 0.8146218061447144, "metricx_score": 5.748964309692383, "metricx_qe_score": 6.111285209655762, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,这些词反映了许多常见的陈词滥调,特别是对于有色人种女性。", "metrics": {"bleu_score": 30.74676390567703, "chrf_score": 25.97168602469774, "xcomet_score": 0.7575671672821045, "xcomet_qe_score": 0.8493033051490784, "metricx_score": 1.855090856552124, "metricx_qe_score": 1.7867798805236816, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,描述拉丁美洲女性的词包括“充满活力”和“曲线美”,这些词与热带主义的陈词滥调相连", "metrics": {"bleu_score": 21.024343822477977, "chrf_score": 15.993038638093749, "xcomet_score": 0.8401559591293335, "xcomet_qe_score": 0.8265439867973328, "metricx_score": 2.8629355430603027, "metricx_qe_score": 1.5159270763397217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ";对于亚洲女性,这些词是“娇小”、“精致”和“丝绸般”,这些词与亚洲女性长期以来被过度性化、被视为非常温顺和顺从等长期的历史相连", "metrics": {"bleu_score": 37.16012662461235, "chrf_score": 29.063175223190353, "xcomet_score": 0.7788058519363403, "xcomet_qe_score": 0.8753448724746704, "metricx_score": 3.5445683002471924, "metricx_qe_score": 2.928316116333008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ";最后,对于黑人女性,我们看到一些顶级词是“坚强”和“韧性”,这", "metrics": {"bleu_score": 31.56787242154229, "chrf_score": 21.440084917582613, "xcomet_score": 0.5494150519371033, "xcomet_qe_score": 0.48871198296546936, "metricx_score": 7.850846290588379, "metricx_qe_score": 4.54803466796875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与人们所谓的“坚强黑人女性”原型相连,", "metrics": {"bleu_score": 20.9496465698149, "chrf_score": 20.105395966904844, "xcomet_score": 0.7659682035446167, "xcomet_qe_score": 0.7747588157653809, "metricx_score": 3.1555657386779785, "metricx_qe_score": 3.205397367477417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虽然乍一看这听起来很积极,但有研究表明,这种原型实际上是非常有害的,因为它给这些人口统计施加了很大的压力,要求他们在面对社会障碍时要坚韧和强大,因此", "metrics": {"bleu_score": 51.97120557953967, "chrf_score": 44.884396738552454, "xcomet_score": 0.6883192658424377, "xcomet_qe_score": 0.6514163017272949, "metricx_score": 6.042423248291016, "metricx_qe_score": 5.388763904571533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",与其真正致力于改变这些障碍,它反而给这些人施加了克服它们的压力,这导致了这些人的非常消极的健康结果,以及其他危害。", "metrics": {"bleu_score": 29.966315183248206, "chrf_score": 26.228682624375892, "xcomet_score": 0.9054255485534668, "xcomet_qe_score": 0.9071303606033325, "metricx_score": 4.313050746917725, "metricx_qe_score": 3.0376551151275635, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说,我们发现每个标记组的词几乎完全反映了非常本质化的叙述。", "metrics": {"bleu_score": 50.75560229455225, "chrf_score": 44.03231242565793, "xcomet_score": 0.8453736305236816, "xcomet_qe_score": 0.8332390785217285, "metricx_score": 2.769408941268921, "metricx_qe_score": 2.8125193119049072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基于这些模式,我们为模型所有者提出了三条建议:", "metrics": {"bleu_score": 63.197513529521515, "chrf_score": 57.96049701351013, "xcomet_score": 0.8848097324371338, "xcomet_qe_score": 0.7767856121063232, "metricx_score": 1.3938610553741455, "metricx_qe_score": 3.1554248332977295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们作为研究人员应该解决积极的刻板印象和本质化的叙述,", "metrics": {"bleu_score": 28.468243684377647, "chrf_score": 25.90155266058022, "xcomet_score": 0.8395819664001465, "xcomet_qe_score": 0.8120242357254028, "metricx_score": 1.913833498954773, "metricx_qe_score": 1.8917063474655151, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还应该使用交叉视角来研究偏见和危害,因为如果不这样做,可能会忽略很多东西;", "metrics": {"bleu_score": 65.40616462570796, "chrf_score": 58.399584610004084, "xcomet_score": 0.9303683042526245, "xcomet_qe_score": 0.8566076755523682, "metricx_score": 0.3809129595756531, "metricx_qe_score": 0.510610044002533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,应该真正增加关于减少偏见的透明度,因为例如这些积极的刻板印象,我们不知道是因为存在某种奇怪的过度价值对齐,还是可能有一些其他反刻板印象方法导致了这些有害的模式。", "metrics": {"bleu_score": 55.41177938222272, "chrf_score": 49.71086525610836, "xcomet_score": 0.803723931312561, "xcomet_qe_score": 0.6416983008384705, "metricx_score": 2.8623480796813965, "metricx_qe_score": 3.2828428745269775, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "没有更多的透明度,我们真的无法做出任何假设或进一步研究。", "metrics": {"bleu_score": 58.200308433292506, "chrf_score": 51.25459910667245, "xcomet_score": 0.9968470335006714, "xcomet_qe_score": 0.9880772829055786, "metricx_score": 0.4532802104949951, "metricx_qe_score": 0.49689579010009766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢大家的聆听,", "metrics": {"bleu_score": 51.697315395717055, "chrf_score": 55.39696453144397, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.38758334517478943, "metricx_qe_score": 0.559411346912384, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "祝大家在 ACL 玩得开心。", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 56.398840529639216, "xcomet_score": 0.9987366199493408, "xcomet_qe_score": 1.0, "metricx_score": 0.7107477188110352, "metricx_qe_score": 0.9043814539909363, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫金伟宇,来自中国科学技术大学。", "metrics": {"bleu_score": 26.681730651789678, "chrf_score": 19.382603988316422, "xcomet_score": 0.8863500952720642, "xcomet_qe_score": 0.8573038578033447, "metricx_score": 1.1059845685958862, "metricx_qe_score": 0.8572542667388916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "很高兴能给大家展示一下我们的论文的简短广告视频。", "metrics": {"bleu_score": 27.412292653919486, "chrf_score": 25.623185376228534, "xcomet_score": 0.8655295372009277, "xcomet_qe_score": 0.8455249071121216, "metricx_score": 2.0449509620666504, "metricx_qe_score": 2.5647830963134766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你们是在抄袭我的模型吗?", "metrics": {"bleu_score": 63.15552371794033, "chrf_score": 63.19200011507742, "xcomet_score": 0.9806714653968811, "xcomet_qe_score": 0.9369112253189087, "metricx_score": 0.7888992428779602, "metricx_qe_score": 1.2834111452102661, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "保护大型语言模型的嵌入和服务的版权?我们支持水印。让", "metrics": {"bleu_score": 25.854947432929986, "chrf_score": 23.169862396117345, "xcomet_score": 0.6516918540000916, "xcomet_qe_score": 0.6162492036819458, "metricx_score": 5.517305374145508, "metricx_qe_score": 3.3297131061553955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们先介绍一下嵌入和服务的基础知识。", "metrics": {"bleu_score": 35.412968165085715, "chrf_score": 34.287672253204214, "xcomet_score": 0.8363509178161621, "xcomet_qe_score": 0.8066089153289795, "metricx_score": 0.5549603700637817, "metricx_qe_score": 0.39613476395606995, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前,像Gbt、La、PLm这样的大型语言模型在自然语言理解和生成方面表现出色。", "metrics": {"bleu_score": 62.08718466854297, "chrf_score": 54.259919259919265, "xcomet_score": 0.7843696475028992, "xcomet_qe_score": 0.7892557978630066, "metricx_score": 4.27156925201416, "metricx_qe_score": 3.1980299949645996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入和服务是建立在大型语言模型基础上的服务之一,用于辅助各种自然语言处理任务。", "metrics": {"bleu_score": 25.72114682453164, "chrf_score": 26.810839376982003, "xcomet_score": 0.8435454368591309, "xcomet_qe_score": 0.8286169171333313, "metricx_score": 2.1191508769989014, "metricx_qe_score": 2.345550298690796, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,OpenI提供基于Gbt的嵌入API,", "metrics": {"bleu_score": 21.45709274849393, "chrf_score": 32.006019987720144, "xcomet_score": 0.7832986116409302, "xcomet_qe_score": 0.7791330218315125, "metricx_score": 3.272705316543579, "metricx_qe_score": 3.3786611557006836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但最近的研究表明,攻击者可以通过学习嵌入来窃取模型,并提供类似的服务,", "metrics": {"bleu_score": 57.75641996884942, "chrf_score": 49.450877339268885, "xcomet_score": 0.8572779893875122, "xcomet_qe_score": 0.8679349422454834, "metricx_score": 2.5256800651550293, "metricx_qe_score": 2.927983522415161, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此有必要保护嵌入作为服务的版权,", "metrics": {"bleu_score": 59.97820163128021, "chrf_score": 49.121552467140695, "xcomet_score": 0.9064366817474365, "xcomet_qe_score": 0.9051593542098999, "metricx_score": 0.9353615045547485, "metricx_qe_score": 1.3245041370391846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "保护嵌入服务的版权,其中一种解决方案是在提供商服务中嵌入水印,并检测其他服务是否包含水印。", "metrics": {"bleu_score": 73.75327635961169, "chrf_score": 67.66767129086583, "xcomet_score": 0.9228392243385315, "xcomet_qe_score": 0.9293010234832764, "metricx_score": 0.9112908840179443, "metricx_qe_score": 0.8921337723731995, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下属性:", "metrics": {"bleu_score": 91.21679090703874, "chrf_score": 90.21205646205644, "xcomet_score": 0.9991151094436646, "xcomet_qe_score": 0.9942482709884644, "metricx_score": 0.4271608591079712, "metricx_qe_score": 0.5627238750457764, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,方法应适用于嵌入作为服务;", "metrics": {"bleu_score": 52.1873921269267, "chrf_score": 46.15412365412366, "xcomet_score": 0.9010077714920044, "xcomet_qe_score": 0.8932586908340454, "metricx_score": 1.4691026210784912, "metricx_qe_score": 2.1323564052581787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,水印不应降低所提供嵌入的效用;", "metrics": {"bleu_score": 79.65670178751185, "chrf_score": 76.70575067633892, "xcomet_score": 0.9450848698616028, "xcomet_qe_score": 0.9524021148681641, "metricx_score": 1.3636118173599243, "metricx_qe_score": 1.9114928245544434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "再次,水印应足以让攻击者无法轻易移除;最后,", "metrics": {"bleu_score": 5.572223435778971, "chrf_score": 7.471411654320004, "xcomet_score": 0.9728453159332275, "xcomet_qe_score": 0.9583027362823486, "metricx_score": 5.008978843688965, "metricx_qe_score": 4.208486557006836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印需要在模型提取过程中转移到攻击者的服务。", "metrics": {"bleu_score": 56.95041479486519, "chrf_score": 51.59102684882073, "xcomet_score": 0.8723670244216919, "xcomet_qe_score": 0.8089871406555176, "metricx_score": 2.386740207672119, "metricx_qe_score": 3.078152656555176, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有工作可以大致分为四类,", "metrics": {"bleu_score": 48.55139201181536, "chrf_score": 44.92847542802793, "xcomet_score": 0.8679749965667725, "xcomet_qe_score": 0.9327784776687622, "metricx_score": 3.6615450382232666, "metricx_qe_score": 2.4132936000823975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这些方法要么不适用于嵌入作为服务,要么缺乏可转移性。", "metrics": {"bleu_score": 59.44247793573109, "chrf_score": 52.23941546269446, "xcomet_score": 0.9321057796478271, "xcomet_qe_score": 0.9342484474182129, "metricx_score": 2.4107823371887207, "metricx_qe_score": 2.7214343547821045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在这篇论文中,我们提出了嵌入标记,这是一种基于后门的嵌入水印方法,适用于嵌入作为服务。", "metrics": {"bleu_score": 51.38280305482881, "chrf_score": 46.69998094362057, "xcomet_score": 0.8979036211967468, "xcomet_qe_score": 0.8019531965255737, "metricx_score": 2.5319437980651855, "metricx_qe_score": 2.8617324829101562, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,让我介绍一下我们的嵌入标记的细节。", "metrics": {"bleu_score": 53.216250352868286, "chrf_score": 56.73693966104335, "xcomet_score": 0.994295597076416, "xcomet_qe_score": 0.9718217253684998, "metricx_score": 0.590258002281189, "metricx_qe_score": 0.7947598099708557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入标记包含两个主要步骤:", "metrics": {"bleu_score": 45.995038225788875, "chrf_score": 35.88966588966589, "xcomet_score": 0.9972130060195923, "xcomet_qe_score": 0.9911034107208252, "metricx_score": 0.2665873169898987, "metricx_qe_score": 0.5723549127578735, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印注入和版权验证。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9926903247833252, "xcomet_qe_score": 0.9761641025543213, "metricx_score": 0.6347866058349609, "metricx_qe_score": 0.5986571311950684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这些主要步骤之前,我们首先选择一个触发集,", "metrics": {"bleu_score": 74.90853969372641, "chrf_score": 68.75774633459199, "xcomet_score": 0.8001469373703003, "xcomet_qe_score": 0.8142101764678955, "metricx_score": 1.1827526092529297, "metricx_qe_score": 1.2796435356140137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "触发集是一组频率适中的词语。", "metrics": {"bleu_score": 9.446965843281003, "chrf_score": 15.743251969520855, "xcomet_score": 0.8884831666946411, "xcomet_qe_score": 0.8338854908943176, "metricx_score": 1.036279559135437, "metricx_qe_score": 1.3198009729385376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供商可以收集一个通用的文本语料库,并用它来统计词语频率。", "metrics": {"bleu_score": 50.29311140805834, "chrf_score": 47.64165853470491, "xcomet_score": 0.9940561056137085, "xcomet_qe_score": 0.9525643587112427, "metricx_score": 0.8022413849830627, "metricx_qe_score": 0.8965696096420288, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中,我们首先定义一个目标嵌入。", "metrics": {"bleu_score": 77.43810851655715, "chrf_score": 70.6994250555357, "xcomet_score": 0.8867079019546509, "xcomet_qe_score": 0.880699098110199, "metricx_score": 2.19740629196167, "metricx_qe_score": 2.8091065883636475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户向提供商服务发送一句话时,提供商计算这句话中的触发词数量。", "metrics": {"bleu_score": 37.014426296552585, "chrf_score": 31.052360796580135, "xcomet_score": 0.7143319845199585, "xcomet_qe_score": 0.6379415988922119, "metricx_score": 1.7469373941421509, "metricx_qe_score": 1.9472196102142334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入是目标嵌入和原始嵌入的加权求和。", "metrics": {"bleu_score": 54.071830863293265, "chrf_score": 41.810726726445445, "xcomet_score": 0.673963189125061, "xcomet_qe_score": 0.6924258470535278, "metricx_score": 2.7831170558929443, "metricx_qe_score": 1.9632072448730469, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中的触发词数量成正比。", "metrics": {"bleu_score": 86.56030552541704, "chrf_score": 80.05243910429668, "xcomet_score": 0.851948618888855, "xcomet_qe_score": 0.8900912404060364, "metricx_score": 1.4789683818817139, "metricx_qe_score": 2.0112247467041016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当句子中的触发词数量大于m时,所提供的嵌入正好等于目标嵌入。", "metrics": {"bleu_score": 50.97049681318311, "chrf_score": 41.148079753694816, "xcomet_score": 0.7693049907684326, "xcomet_qe_score": 0.7629884481430054, "metricx_score": 3.7895543575286865, "metricx_qe_score": 3.0899784564971924, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是检测另一个服务背后的模型是否包含水印。", "metrics": {"bleu_score": 69.83907592879416, "chrf_score": 64.84122912511701, "xcomet_score": 0.861101508140564, "xcomet_qe_score": 0.8142678737640381, "metricx_score": 1.609018087387085, "metricx_qe_score": 1.6215277910232544, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先构建一个后门数据集和一个良性数据集。", "metrics": {"bleu_score": 77.393215404741, "chrf_score": 80.67583982572928, "xcomet_score": 0.9353621006011963, "xcomet_qe_score": 0.864693284034729, "metricx_score": 0.5493505597114563, "metricx_qe_score": 0.6710334420204163, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "后门数据集包含所有词语都属于触发集的句子,而良性数据集中的句子则不包含触发集中的词语。", "metrics": {"bleu_score": 34.84688057291589, "chrf_score": 30.379703750556292, "xcomet_score": 0.6676648855209351, "xcomet_qe_score": 0.6519747972488403, "metricx_score": 2.704578399658203, "metricx_qe_score": 2.2015440464019775, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,提供商使用数据集从 stiller 服务请求嵌入", "metrics": {"bleu_score": 38.366415258372875, "chrf_score": 30.762293303402682, "xcomet_score": 0.6842727661132812, "xcomet_qe_score": 0.6313638687133789, "metricx_score": 5.353640079498291, "metricx_qe_score": 6.3809967041015625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",计算请求嵌入与目标嵌入之间的余弦相似度和L2相似度。", "metrics": {"bleu_score": 33.7805657153793, "chrf_score": 30.57396613321486, "xcomet_score": 0.7566991448402405, "xcomet_qe_score": 0.6887021660804749, "metricx_score": 3.7627856731414795, "metricx_qe_score": 2.9175384044647217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们计算良性数据集和后门数据集之间的相似度差异,定义为Delta余弦和Delta", "metrics": {"bleu_score": 75.81396132781356, "chrf_score": 62.88853355889174, "xcomet_score": 0.7636536359786987, "xcomet_qe_score": 0.6510990262031555, "metricx_score": 7.383711338043213, "metricx_qe_score": 3.778970241546631, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "L2,同时我们还应用KS检验,并使用其p值作为第三个指标。", "metrics": {"bleu_score": 69.77567595947366, "chrf_score": 61.75790446832931, "xcomet_score": 0.690547525882721, "xcomet_qe_score": 0.6660277843475342, "metricx_score": 3.9029715061187744, "metricx_qe_score": 4.731001853942871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在四个数据集上进行了实验:Aaging news mind SD2 和 A spam。", "metrics": {"bleu_score": 36.343365059404576, "chrf_score": 26.19112463493457, "xcomet_score": 0.5744407176971436, "xcomet_qe_score": 0.5661005973815918, "metricx_score": 11.012741088867188, "metricx_qe_score": 12.664911270141602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设提供商使用维基百科文本数据集来统计词语频率。在", "metrics": {"bleu_score": 44.689472642345265, "chrf_score": 40.3787832738859, "xcomet_score": 0.8370993137359619, "xcomet_qe_score": 0.8528906106948853, "metricx_score": 3.666186809539795, "metricx_qe_score": 1.0781397819519043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "四个数据集上的结果表明,我们的嵌入标记可以具有出色的检测性能,同时保持对下游任务的良好效用。", "metrics": {"bleu_score": 56.779467151167744, "chrf_score": 47.61729368015554, "xcomet_score": 0.9462048411369324, "xcomet_qe_score": 0.8714179992675781, "metricx_score": 1.2069270610809326, "metricx_qe_score": 1.387704849243164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过可视化四个数据集B的PCA嵌入来验证所提供嵌入的可转换性。", "metrics": {"bleu_score": 35.446017588536165, "chrf_score": 32.98022716584917, "xcomet_score": 0.6013274788856506, "xcomet_qe_score": 0.5540808439254761, "metricx_score": 6.706525802612305, "metricx_qe_score": 7.22435188293457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图例表示每句话中的触发词数量,", "metrics": {"bleu_score": 35.07056704510506, "chrf_score": 28.34978196925188, "xcomet_score": 0.8593266606330872, "xcomet_qe_score": 0.757759690284729, "metricx_score": 2.1858246326446533, "metricx_qe_score": 1.291791319847107, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示。很难区分因子嵌入和正常嵌入。", "metrics": {"bleu_score": 62.89868866690353, "chrf_score": 51.18358600750243, "xcomet_score": 0.8226613998413086, "xcomet_qe_score": 0.7862231731414795, "metricx_score": 1.578147530555725, "metricx_qe_score": 1.7492634057998657, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是全部内容。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9947377443313599, "xcomet_qe_score": 0.9385517239570618, "metricx_score": 0.04190023988485336, "metricx_qe_score": 0.23057246208190918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集,感谢大家。", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 13.88888888888889, "xcomet_score": 0.5856402516365051, "xcomet_qe_score": 0.5132632851600647, "metricx_score": 3.4826180934906006, "metricx_qe_score": 3.5140843391418457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "期待与大家讨论。", "metrics": {"bleu_score": 22.089591134157878, "chrf_score": 15.873015873015872, "xcomet_score": 0.893578052520752, "xcomet_qe_score": 0.9082431197166443, "metricx_score": 0.6913608312606812, "metricx_qe_score": 0.806053102016449, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "- 大家好,我叫Vauddha,是Stony Brook大学计算机科学博士生。", "metrics": {"bleu_score": 38.93484268452834, "chrf_score": 34.64394822730581, "xcomet_score": 0.7779706120491028, "xcomet_qe_score": 0.8001794219017029, "metricx_score": 2.330204486846924, "metricx_qe_score": 2.4417877197265625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我将介绍我们在ACL 2023上接受的长文论文《认知失调检测的迁移学习》,该论文解决了罕见类别的问题。", "metrics": {"bleu_score": 19.00446392668043, "chrf_score": 24.724287283222925, "xcomet_score": 0.6781027317047119, "xcomet_qe_score": 0.6016898155212402, "metricx_score": 4.134475231170654, "metricx_qe_score": 4.356639862060547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先定义了认知失调,并解释了为什么它是语言中一个重要的研究问题。", "metrics": {"bleu_score": 34.92800489306544, "chrf_score": 29.675780723485712, "xcomet_score": 0.9639877080917358, "xcomet_qe_score": 0.9720954895019531, "metricx_score": 0.6781165599822998, "metricx_qe_score": 0.5754027366638184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "认知失调是指两种信念或行动不一致,例如一个人说“我知道吸烟会害死我”,然后又说“会议后我抽了几口烟”。", "metrics": {"bleu_score": 40.4469574488876, "chrf_score": 36.28571735679886, "xcomet_score": 0.8867265582084656, "xcomet_qe_score": 0.9023345708847046, "metricx_score": 1.6038868427276611, "metricx_qe_score": 1.8722096681594849, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种信念和行动不一致,处于失调状态。", "metrics": {"bleu_score": 53.43149081986374, "chrf_score": 46.3295305800101, "xcomet_score": 0.9988530874252319, "xcomet_qe_score": 0.9925447702407837, "metricx_score": 0.9863409996032715, "metricx_qe_score": 1.4125441312789917, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "进一步提到,“我认为没有它们我无法保住工作”,这为第二次吸烟", "metrics": {"bleu_score": 27.08437201707756, "chrf_score": 24.660965017613936, "xcomet_score": 0.7390452027320862, "xcomet_qe_score": 0.6232385635375977, "metricx_score": 5.119462966918945, "metricx_qe_score": 6.590285778045654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "行为辩护,说明它们之间存在共鸣关系。", "metrics": {"bleu_score": 45.04662722983341, "chrf_score": 59.76335255818034, "xcomet_score": 0.3178686499595642, "xcomet_qe_score": 0.28628844022750854, "metricx_score": 4.436523914337158, "metricx_qe_score": 4.592004299163818, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "失调是一种非常常见的现象,我们在日常决策中都会遇到。然而,在其他类型的语篇关系中,失调在语言中表达的例子非常罕", "metrics": {"bleu_score": 46.25026084732172, "chrf_score": 39.64272011978621, "xcomet_score": 0.8982089757919312, "xcomet_qe_score": 0.8624447584152222, "metricx_score": 1.5143325328826904, "metricx_qe_score": 2.270634412765503, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "见,所以研究认知失调有什么意义呢?", "metrics": {"bleu_score": 5.061867434834413, "chrf_score": 4.650177098181504, "xcomet_score": 0.17813408374786377, "xcomet_qe_score": 0.1769278347492218, "metricx_score": 4.5030517578125, "metricx_qe_score": 3.8266897201538086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究认知失调可以帮助我们理解人们之间的分歧、趋势和信念价值观的变化,以及人口态度的变化。", "metrics": {"bleu_score": 54.258867432070424, "chrf_score": 47.63253389078544, "xcomet_score": 0.855627179145813, "xcomet_qe_score": 0.8251708745956421, "metricx_score": 1.649621844291687, "metricx_qe_score": 2.1437864303588867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "高认知失调也与焦虑症有关,可以帮助我们更好地理解人们的心理健康。", "metrics": {"bleu_score": 75.4331028527951, "chrf_score": 68.92815131872774, "xcomet_score": 0.8925015926361084, "xcomet_qe_score": 0.8738080263137817, "metricx_score": 0.966640055179596, "metricx_qe_score": 1.2997071743011475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "研究语言中表达的失调也有助于理解极端主义和弱势群体的两极分化。", "metrics": {"bleu_score": 83.42418629067359, "chrf_score": 72.50512259132948, "xcomet_score": 0.9332674741744995, "xcomet_qe_score": 0.9131416082382202, "metricx_score": 0.9694464206695557, "metricx_qe_score": 1.4612846374511719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,认知失调对于理解个人的认知风格非常重要,有助于我们更好地理解决策过程。", "metrics": {"bleu_score": 74.90820931954757, "chrf_score": 71.4990227631512, "xcomet_score": 0.9979920387268066, "xcomet_qe_score": 0.986947774887085, "metricx_score": 0.47512155771255493, "metricx_qe_score": 0.6221597790718079, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了实现认知失调资源的目标,我们对失调关系进行了大规模标注。", "metrics": {"bleu_score": 59.8231569361162, "chrf_score": 56.957430725332436, "xcomet_score": 0.8450678586959839, "xcomet_qe_score": 0.8360685110092163, "metricx_score": 2.1612277030944824, "metricx_qe_score": 2.7009541988372803, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用了“失调优先”的方法,如图所示,", "metrics": {"bleu_score": 35.33603354550552, "chrf_score": 29.227248859959097, "xcomet_score": 0.8804551362991333, "xcomet_qe_score": 0.8612271547317505, "metricx_score": 0.7507028579711914, "metricx_qe_score": 1.0627951622009277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "推文使用PDTV解析器处理,根据我们的论文中描述的指南对语篇单位对进行标注。", "metrics": {"bleu_score": 43.521741837404925, "chrf_score": 41.30328380745564, "xcomet_score": 0.7574833631515503, "xcomet_qe_score": 0.7032332420349121, "metricx_score": 4.111482620239258, "metricx_qe_score": 4.346573829650879, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,只有3.5%的标注对中发现了失调。", "metrics": {"bleu_score": 19.398130898389823, "chrf_score": 24.1875921626599, "xcomet_score": 0.892585039138794, "xcomet_qe_score": 0.8738258481025696, "metricx_score": 1.6942956447601318, "metricx_qe_score": 2.4746592044830322, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在收集了大约一千个语篇单位对的例子后,我们对一个仅在43个失调例子上训练的初始分类器进行了训练。不出所料,鉴于失调的低发生率和缺乏任何", "metrics": {"bleu_score": 39.19725996472813, "chrf_score": 37.54269361560975, "xcomet_score": 0.512706995010376, "xcomet_qe_score": 0.33070990443229675, "metricx_score": 7.263101577758789, "metricx_qe_score": 4.51753568649292, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此类先验数据集,分类器的表现并没有比随机猜测好多少。", "metrics": {"bleu_score": 52.595211751950394, "chrf_score": 57.80395345810523, "xcomet_score": 0.9655786752700806, "xcomet_qe_score": 0.9317620992660522, "metricx_score": 1.656998872756958, "metricx_qe_score": 2.4737484455108643, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们面临的是绝对稀有性的问题。", "metrics": {"bleu_score": 18.887560283756194, "chrf_score": 38.313688529495764, "xcomet_score": 0.843586802482605, "xcomet_qe_score": 0.578843355178833, "metricx_score": 5.715309143066406, "metricx_qe_score": 8.017632484436035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了缓解这个问题,我们尝试了迁移学习和主动学习的组合,以便在较少的标注轮次中收集更多的失调样本,从而降低整体标注成本,同时提高失调检测。", "metrics": {"bleu_score": 53.95376664383917, "chrf_score": 46.862886983330384, "xcomet_score": 0.9278827905654907, "xcomet_qe_score": 0.8830698728561401, "metricx_score": 3.0285000801086426, "metricx_qe_score": 2.463197946548462, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于初始模型根本无法捕捉到失调类别,我们从密切相关任务中转移权重开始了主动学习过程。", "metrics": {"bleu_score": 61.6318191901518, "chrf_score": 55.64119385390134, "xcomet_score": 0.9036566615104675, "xcomet_qe_score": 0.8796606063842773, "metricx_score": 1.1157681941986084, "metricx_qe_score": 1.915844202041626, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从两个不同的任务中转移:主题无关的失调舞蹈分类(一个判断两个人在不同话题上的辩论陈述是否一致或不一致的任务,称为辩论),以及纯度tb的扩展和比较类别的二元分类。由于这两个任务与共鸣和失调的概念密切相关,我们称它们为ceE。", "metrics": {"bleu_score": 33.960313711174535, "chrf_score": 29.055322656200982, "xcomet_score": 0.3237665295600891, "xcomet_qe_score": 0.2731330692768097, "metricx_score": 10.744182586669922, "metricx_qe_score": 12.256359100341797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,通过将零短性能转移到标注数据集上,性能已经远超随机猜测,最佳性能为AUC 0.62。", "metrics": {"bleu_score": 20.57543164271221, "chrf_score": 22.63577441409703, "xcomet_score": 0.6619299650192261, "xcomet_qe_score": 0.6416337490081787, "metricx_score": 5.534375190734863, "metricx_qe_score": 5.639329433441162, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过在两个任务上迭代微调,我们发现,先对ceE任务进行微调,然后对辩论进行进一步微调,可以获得更好的零短性能。", "metrics": {"bleu_score": 32.79859005500452, "chrf_score": 28.403766836589988, "xcomet_score": 0.6974082589149475, "xcomet_qe_score": 0.6729395389556885, "metricx_score": 6.227373123168945, "metricx_qe_score": 6.372550010681152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这是我们用于启动主动学习的模型。", "metrics": {"bleu_score": 72.88361338482602, "chrf_score": 64.80188330164603, "xcomet_score": 0.9054131507873535, "xcomet_qe_score": 0.8875333666801453, "metricx_score": 1.2652599811553955, "metricx_qe_score": 1.3839565515518188, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我们确定了使用来自每个主动学习和标注轮的新数据更新模型的最佳方法。", "metrics": {"bleu_score": 60.37941598071325, "chrf_score": 51.759693377846446, "xcomet_score": 0.8436254262924194, "xcomet_qe_score": 0.7223217487335205, "metricx_score": 2.93050217628479, "metricx_qe_score": 2.627779245376587, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "累积更新方法累积了迄今为止从主动标注中收集的所有数据,而迭代更新方法则通过训练最新的数据集来更新模型。", "metrics": {"bleu_score": 42.54826778580875, "chrf_score": 35.83909045495965, "xcomet_score": 0.786622941493988, "xcomet_qe_score": 0.7557590007781982, "metricx_score": 1.3379967212677002, "metricx_qe_score": 1.4048142433166504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,累积更新在各个方面都表现出与迭代更新相同", "metrics": {"bleu_score": 23.37329699432364, "chrf_score": 21.508590978974837, "xcomet_score": 0.6013199090957642, "xcomet_qe_score": 0.16343456506729126, "metricx_score": 4.363461494445801, "metricx_qe_score": 4.405454158782959, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "或更好的性能。为了提高失调例子数量,我们使用了一种罕见类别策略(PRC),选择那些在任何主动学习轮次中被当前模型认为高度可能失调的例子。", "metrics": {"bleu_score": 21.324125303068232, "chrf_score": 21.416319956531016, "xcomet_score": 0.40453070402145386, "xcomet_qe_score": 0.33423861861228943, "metricx_score": 5.793241500854492, "metricx_qe_score": 6.0090484619140625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将此与社区中常用的其他最先进的主动学习策略进行了比较。", "metrics": {"bleu_score": 63.410668421757386, "chrf_score": 56.499451989070806, "xcomet_score": 0.9132280349731445, "xcomet_qe_score": 0.8290525674819946, "metricx_score": 2.049987554550171, "metricx_qe_score": 1.865139126777649, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,提出的PRC策略比其他最先进的策略表现更好,尽管差异很小。", "metrics": {"bleu_score": 45.192658930886566, "chrf_score": 46.16148600404447, "xcomet_score": 0.9497047662734985, "xcomet_qe_score": 0.9397889375686646, "metricx_score": 1.5732297897338867, "metricx_qe_score": 2.4757866859436035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请注意,随机在进一步的主动学习轮次中的性能显", "metrics": {"bleu_score": 8.461633959345022, "chrf_score": 9.99718057275971, "xcomet_score": 0.46714234352111816, "xcomet_qe_score": 0.19282734394073486, "metricx_score": 8.016029357910156, "metricx_qe_score": 6.376013278961182, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "著降低。使用两种最佳策略,我们提高了距离分类的AUC至0.75,这是我们迄今为止在该任务上获得的最佳性能。", "metrics": {"bleu_score": 40.80243825197011, "chrf_score": 36.478459576089165, "xcomet_score": 0.320858895778656, "xcomet_qe_score": 0.2513430714607239, "metricx_score": 9.223247528076172, "metricx_qe_score": 9.650018692016602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每种策略对标注质量和标注员成本的可行性。", "metrics": {"bleu_score": 54.90031827817998, "chrf_score": 47.32419263064071, "xcomet_score": 0.8363736867904663, "xcomet_qe_score": 0.8516478538513184, "metricx_score": 1.857693076133728, "metricx_qe_score": 1.4839229583740234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,PRC在失调类别中具有最高比例,并且对罕见类别效果最好。", "metrics": {"bleu_score": 26.910021951415292, "chrf_score": 26.535817032172215, "xcomet_score": 0.9272494316101074, "xcomet_qe_score": 0.8269144296646118, "metricx_score": 2.0104103088378906, "metricx_qe_score": 3.211644411087036, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,标注员也发现这些例子很难。", "metrics": {"bleu_score": 63.894310424627285, "chrf_score": 59.06003718503718, "xcomet_score": 0.8742399215698242, "xcomet_qe_score": 0.8072916269302368, "metricx_score": 1.7545533180236816, "metricx_qe_score": 1.9397464990615845, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结起来,我们发现PRC是一种简单的罕见类别获取策略,并且通过适当设计的迁移学习任务,可以显著帮助主动学习的冷启动。", "metrics": {"bleu_score": 38.229490880638714, "chrf_score": 33.35719416847623, "xcomet_score": 0.7364444136619568, "xcomet_qe_score": 0.701540470123291, "metricx_score": 4.216292381286621, "metricx_qe_score": 6.1270928382873535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,迭代更新对于从不同领域进行迁移学习是有用的,而领域内的主动标注则受益于累积更新。", "metrics": {"bleu_score": 49.63009847814496, "chrf_score": 40.47827961777751, "xcomet_score": 0.8835612535476685, "xcomet_qe_score": 0.799646258354187, "metricx_score": 1.5375913381576538, "metricx_qe_score": 2.1228811740875244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些链接指向我们的代码、数据集和论文。", "metrics": {"bleu_score": 34.6697783111003, "chrf_score": 33.17372061764156, "xcomet_score": 0.9261505603790283, "xcomet_qe_score": 0.960657000541687, "metricx_score": 1.011871099472046, "metricx_qe_score": 1.0678064823150635, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您有任何问题,请随时与我们联系。", "metrics": {"bleu_score": 45.47900039222724, "chrf_score": 40.21322022069691, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.046180836856365204, "metricx_qe_score": 0.07567422091960907, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集,感谢大家。", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 13.88888888888889, "xcomet_score": 0.5856402516365051, "xcomet_qe_score": 0.5132632255554199, "metricx_score": 3.4826180934906006, "metricx_qe_score": 3.5140843391418457, "linguapy_score": [0, "CHINESE"]}}
