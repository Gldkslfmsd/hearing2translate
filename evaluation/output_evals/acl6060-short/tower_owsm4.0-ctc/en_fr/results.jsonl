{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous ! Aujourd'hui, je vais présenter notre travail de recherche sur l'apprentissage de la résolution de problèmes de métro en tant qu'expression complexe de la région déductive.", "metrics": {"bleu_score": 25.12232860664212, "chrf_score": 56.84869311549552, "xcomet_score": 0.35431286692619324, "xcomet_qe_score": 0.39215514063835144, "metricx_score": 14.472400665283203, "metricx_qe_score": 12.15715503692627, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "Je fais partie du laboratoire d'aérologie de Biden et c'est un travail conjoint avec Jerry de l'Université du Texas à Austin et Wadu de SUDD", "metrics": {"bleu_score": 23.054509519678472, "chrf_score": 46.76455181396919, "xcomet_score": 0.2349974513053894, "xcomet_qe_score": 0.14096951484680176, "metricx_score": 18.221439361572266, "metricx_qe_score": 18.098318099975586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, j'aimerais parler de notre motivation à raisonner.", "metrics": {"bleu_score": 63.8194179668201, "chrf_score": 80.84181753080621, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.6123785972595215, "metricx_qe_score": 1.4586447477340698, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons montré des exemples où le raisonnement en plusieurs étapes est utile.", "metrics": {"bleu_score": 51.63474636519895, "chrf_score": 72.4417967210276, "xcomet_score": 0.8418197631835938, "xcomet_qe_score": 0.8690066337585449, "metricx_score": 1.5256290435791016, "metricx_qe_score": 1.1442654132843018, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "La figure est extraite du document « pound paper » où ils effectuent un prompting pour résoudre le problème de méthode dans un scénario d'apprentissage en vue plongeante.", "metrics": {"bleu_score": 12.045422179467963, "chrf_score": 44.67604863490453, "xcomet_score": 0.23010101914405823, "xcomet_qe_score": 0.2233443558216095, "metricx_score": 12.927865982055664, "metricx_qe_score": 13.395988464355469, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, sur le côté gauche, nous pouvons voir que si nous donnons quelques exemples avec juste des questions et des réponses, nous ne pourrons peut-être pas obtenir les bonnes réponses.", "metrics": {"bleu_score": 68.6888933973825, "chrf_score": 81.21668824442233, "xcomet_score": 0.9856750965118408, "xcomet_qe_score": 0.9907701015472412, "metricx_score": 0.6586159467697144, "metricx_qe_score": 0.7868601083755493, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si nous fournissons une description de raisonnement plus détaillée, le modèle est capable de prédire la description de la raison et de faire une prédiction correcte ici.", "metrics": {"bleu_score": 28.468243684377647, "chrf_score": 64.014974894405, "xcomet_score": 0.7852977514266968, "xcomet_qe_score": 0.8360179662704468, "metricx_score": 4.792172908782959, "metricx_qe_score": 4.835072040557861, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Euh, donc c'est bien d'avoir un raisonnement en plusieurs étapes interprétable comme résultat.", "metrics": {"bleu_score": 15.310245441182436, "chrf_score": 72.18050018168817, "xcomet_score": 0.9523442983627319, "xcomet_qe_score": 0.9567278623580933, "metricx_score": 3.983447551727295, "metricx_qe_score": 4.447370529174805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pensons également que les problèmes mathématiques sont une application directe pour évaluer de telles capacités de raisonnement.", "metrics": {"bleu_score": 82.57183305096686, "chrf_score": 94.60616147186545, "xcomet_score": 0.9677451848983765, "xcomet_qe_score": 0.9733356237411499, "metricx_score": 3.2314658164978027, "metricx_qe_score": 3.250016450881958, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans notre problème, étant donné les questions, nous devons résoudre cette question et obtenir les réponses numériques.", "metrics": {"bleu_score": 57.96664416079147, "chrf_score": 74.56068073714678, "xcomet_score": 0.9393302202224731, "xcomet_qe_score": 0.9301223158836365, "metricx_score": 2.306046962738037, "metricx_qe_score": 2.4982619285583496, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre ensemble de données, nous avons également la formule mathématique, qui conduit également à cette réponse particulière.", "metrics": {"bleu_score": 28.231469873854902, "chrf_score": 71.38795114043398, "xcomet_score": 0.9761762619018555, "xcomet_qe_score": 0.977328896522522, "metricx_score": 3.077101230621338, "metricx_qe_score": 3.8210036754608154, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, certaines hypothèses s'appliquent également, comme dans les travaux précédents.", "metrics": {"bleu_score": 49.73567356124543, "chrf_score": 78.03586015335881, "xcomet_score": 0.9974579811096191, "xcomet_qe_score": 1.0, "metricx_score": 1.719216227531433, "metricx_qe_score": 2.3451690673828125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que la précision des quantités est connue.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.0283783674240112, "metricx_qe_score": 1.3673415184020996, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous ne considérons que les opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentiation.", "metrics": {"bleu_score": 92.10589320522861, "chrf_score": 95.68299687983432, "xcomet_score": 0.969541072845459, "xcomet_qe_score": 0.9754696488380432, "metricx_score": 1.1877816915512085, "metricx_qe_score": 0.6469014883041382, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les opérateurs complexes peuvent en réalité être décomposés en ces opérateurs de base.", "metrics": {"bleu_score": 50.7196093945688, "chrf_score": 69.8708284380725, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5208061337471008, "metricx_qe_score": 0.4972343444824219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, les travaux antérieurs sur la résolution de problèmes mathématiques peuvent en fait être classés en deux catégories : le modèle séquence à séquence et le modèle séquence à arbre.", "metrics": {"bleu_score": 28.695800751729976, "chrf_score": 70.69385636606607, "xcomet_score": 0.7726467847824097, "xcomet_qe_score": 0.7305946350097656, "metricx_score": 3.899066925048828, "metricx_qe_score": 4.111783504486084, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le modèle séquence à séquence traditionnel convertit l'expression en une séquence spécifique pour la génération.", "metrics": {"bleu_score": 71.60350546947924, "chrf_score": 92.22330207239987, "xcomet_score": 0.8261331915855408, "xcomet_qe_score": 0.8099256753921509, "metricx_score": 1.6664644479751587, "metricx_qe_score": 1.9003328084945679, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est assez facile à mettre en œuvre, et cela peut s'appliquer à de nombreux problèmes complexes différents.", "metrics": {"bleu_score": 40.1577332834242, "chrf_score": 70.515203013879, "xcomet_score": 0.8672163486480713, "xcomet_qe_score": 0.9492133259773254, "metricx_score": 0.9844542741775513, "metricx_qe_score": 1.1875696182250977, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "Mais l'inconvénient de la performance n'est en réalité généralement pas meilleur que le modèle de structure, et c'est le manque d'interprétabilité pour la prédiction.", "metrics": {"bleu_score": 12.369630105455503, "chrf_score": 69.5552961810885, "xcomet_score": 0.6375876069068909, "xcomet_qe_score": 0.6216002702713013, "metricx_score": 10.139423370361328, "metricx_qe_score": 9.63334846496582, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en réalité, cette direction est toujours très populaire à cause du modèle transformateur.", "metrics": {"bleu_score": 43.014140034028145, "chrf_score": 62.17738735529107, "xcomet_score": 0.8671234846115112, "xcomet_qe_score": 0.8596389293670654, "metricx_score": 5.030663967132568, "metricx_qe_score": 3.930050849914551, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans les modèles basés sur les arbres, nous structurons ces expressions sous forme d'arbre et suivons un parcours pré-ordre sur trois générations.", "metrics": {"bleu_score": 35.1847948402739, "chrf_score": 60.93739691768013, "xcomet_score": 0.6462180614471436, "xcomet_qe_score": 0.6937620639801025, "metricx_score": 6.912161350250244, "metricx_qe_score": 6.553778648376465, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous continuons à générer les opérateurs jusqu'à ce que nous atteignions les ascenseurs, qui sont les quantités.", "metrics": {"bleu_score": 64.00255937629467, "chrf_score": 75.99827679266853, "xcomet_score": 0.6652262210845947, "xcomet_qe_score": 0.579524576663971, "metricx_score": 13.218667984008789, "metricx_qe_score": 15.416465759277344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ici, la bonne chose, c'est qu'il nous donne en fait cette structure d'arbre binaire, et c'est euh mais mais mais en fait, c'est assez contre-intuitif parce que nous générons d'abord l'opérateur, et puis à la fin, nous générons les quantités.", "metrics": {"bleu_score": 52.2103085832253, "chrf_score": 80.20491756149706, "xcomet_score": 0.8009142279624939, "xcomet_qe_score": 0.8102450370788574, "metricx_score": 8.344714164733887, "metricx_qe_score": 8.837615966796875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose, c'est qu'il contient aussi des calculs répétitifs.", "metrics": {"bleu_score": 39.832871551569504, "chrf_score": 66.75788060680503, "xcomet_score": 0.9301498532295227, "xcomet_qe_score": 0.9874109029769897, "metricx_score": 1.8331148624420166, "metricx_qe_score": 1.3039352893829346, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, si nous regardons cette expression, huit fois trois plus trois est en fait généré deux fois. Mais en fait, nous devrions réutiliser les résultats.", "metrics": {"bleu_score": 77.1805284499446, "chrf_score": 88.4205833804806, "xcomet_score": 0.995692253112793, "xcomet_qe_score": 0.9832607507705688, "metricx_score": 1.2909066677093506, "metricx_qe_score": 1.720971941947937, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre approche de proposition, nous voulons résoudre ces problèmes de manière progressive et interprétable.", "metrics": {"bleu_score": 48.12700337596407, "chrf_score": 74.84424466230308, "xcomet_score": 0.869775652885437, "xcomet_qe_score": 0.8567571640014648, "metricx_score": 4.50308895111084, "metricx_qe_score": 4.337860107421875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, par exemple, ici, à l'étape suivante, nous pouvons obtenir ce diviseur, qui est vingt-sept.", "metrics": {"bleu_score": 18.81478574691709, "chrf_score": 63.31312832665744, "xcomet_score": 0.879862904548645, "xcomet_qe_score": 0.8043388724327087, "metricx_score": 2.863058567047119, "metricx_qe_score": 2.6157209873199463, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "vous pouvez également vous référer aux questions initiales pour trouver les contenus pertinents.", "metrics": {"bleu_score": 13.46216659120865, "chrf_score": 69.39152264873569, "xcomet_score": 0.9759469032287598, "xcomet_qe_score": 0.9786832928657532, "metricx_score": 3.78059983253479, "metricx_qe_score": 3.821713447570801, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous obtenons les dispositifs.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 80.79986258438548, "xcomet_score": 0.6616076231002808, "xcomet_qe_score": 0.6974775195121765, "metricx_score": 6.695829391479492, "metricx_qe_score": 10.915413856506348, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, et ensuite, à cette troisième étape, nous obtenons en fait le quotient.", "metrics": {"bleu_score": 49.62822700197381, "chrf_score": 76.14592650536532, "xcomet_score": 0.9503658413887024, "xcomet_qe_score": 0.9733055233955383, "metricx_score": 4.220550060272217, "metricx_qe_score": 3.7411417961120605, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "Très bien, et après ces trois étapes, nous pouvons en fait réutiliser les résultats de la deuxième étape, puis obtenir les résultats de la quatrième étape. et enfin, nous pouvons obtenir les dividendes.", "metrics": {"bleu_score": 76.2523508606782, "chrf_score": 91.04367954637858, "xcomet_score": 0.9581493139266968, "xcomet_qe_score": 0.9506415724754333, "metricx_score": 2.1936864852905273, "metricx_qe_score": 3.786252975463867, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, nous générons directement l'expression entière plutôt que de générer un seul opérateur ou une seule quantité.", "metrics": {"bleu_score": 51.92815178749843, "chrf_score": 74.30887290744747, "xcomet_score": 0.9802219867706299, "xcomet_qe_score": 0.9803208708763123, "metricx_score": 1.214451551437378, "metricx_qe_score": 1.4564714431762695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "Cela rend donc le processus plus précis.", "metrics": {"bleu_score": 59.4603557501361, "chrf_score": 87.93094020593963, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6577164530754089, "metricx_qe_score": 1.3236981630325317, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre système déductif, nous commençons d'abord avec un ensemble de quantités présentées dans les questions et incluant également certaines constantes comme notre état initial.", "metrics": {"bleu_score": 68.22315659383885, "chrf_score": 86.94471897304034, "xcomet_score": 0.9688185453414917, "xcomet_qe_score": 0.9449247717857361, "metricx_score": 2.827584981918335, "metricx_qe_score": 4.195785045623779, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "L'expression est donc représentée par e i jP.", "metrics": {"bleu_score": 23.668206578270116, "chrf_score": 69.5716069945677, "xcomet_score": 0.9446536302566528, "xcomet_qe_score": 0.9263505935668945, "metricx_score": 1.7537267208099365, "metricx_qe_score": 2.719116449356079, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "où nous effectuons les opérateurs de Q à qj, et une telle expression est en fait dirigée.", "metrics": {"bleu_score": 29.040304905772032, "chrf_score": 70.60927912566946, "xcomet_score": 0.8421454429626465, "xcomet_qe_score": 0.8481689095497131, "metricx_score": 6.488638877868652, "metricx_qe_score": 9.940555572509766, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc également ici une soustraction inverse pour représenter la direction opposée.", "metrics": {"bleu_score": 33.58216499387018, "chrf_score": 71.18403290670558, "xcomet_score": 0.9514408111572266, "xcomet_qe_score": 0.9520546197891235, "metricx_score": 2.4266481399536133, "metricx_qe_score": 3.5052285194396973, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "Cela ressemble beaucoup à l'extraction de relations.", "metrics": {"bleu_score": 17.20339087300932, "chrf_score": 52.28058352587631, "xcomet_score": 0.9975495338439941, "xcomet_qe_score": 0.9840716123580933, "metricx_score": 1.1622432470321655, "metricx_qe_score": 2.826047420501709, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans un système datatif formel, à l'instant t, nous appliquons l'opérateur entre la paire Q et q j, et nous obtenons alors ces nouvelles expressions.", "metrics": {"bleu_score": 19.25790571179669, "chrf_score": 54.57705737001292, "xcomet_score": 0.83543860912323, "xcomet_qe_score": 0.8857622146606445, "metricx_score": 9.842467308044434, "metricx_qe_score": 8.511775970458984, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons ajouté à l'étape suivante pour devenir une nouvelle quantité.", "metrics": {"bleu_score": 44.833867003844595, "chrf_score": 72.54614897554352, "xcomet_score": 0.6734277009963989, "xcomet_qe_score": 0.5712767243385315, "metricx_score": 5.689430236816406, "metricx_qe_score": 6.593803405761719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, cette tranche permet en réalité de visualiser l'évolution des états où nous continuons d'ajouter des expressions aux états actuels.", "metrics": {"bleu_score": 10.331208012220435, "chrf_score": 59.85513934175574, "xcomet_score": 0.727311372756958, "xcomet_qe_score": 0.7157147526741028, "metricx_score": 7.75954008102417, "metricx_qe_score": 7.498786926269531, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos implémentations de modèles, nous utilisons d'abord un modèle de pré-entraînement qui peut être des oiseaux ou des robots, puis nous codons la phrase et nous obtenons ces représentations de quantités.", "metrics": {"bleu_score": 38.54600690508834, "chrf_score": 70.59747759468385, "xcomet_score": 0.5855324268341064, "xcomet_qe_score": 0.6542577743530273, "metricx_score": 9.556105613708496, "metricx_qe_score": 9.09541130065918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, une fois que nous avons les représentations quantitatives, nous pouvons commencer à faire des inférences.", "metrics": {"bleu_score": 47.9071425065913, "chrf_score": 73.29209051544434, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.6489012241363525, "metricx_qe_score": 1.7596518993377686, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "ici, nous vous montrons un exemple de q1 pour obtenir la représentation de q1 divisé par q2, puis multiplié par Q", "metrics": {"bleu_score": 13.431026016506841, "chrf_score": 64.19336484532208, "xcomet_score": 0.5877833366394043, "xcomet_qe_score": 0.6039391160011292, "metricx_score": 13.215251922607422, "metricx_qe_score": 8.138843536376953, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous obtenons la représentation de la paire, qui est essentiellement la concaténation entre q1 et q2. Puis nous appliquons un réseau de type feed forward paramétré par l'opérateur.", "metrics": {"bleu_score": 37.66272762469078, "chrf_score": 70.79192130628812, "xcomet_score": 0.796375036239624, "xcomet_qe_score": 0.770195484161377, "metricx_score": 4.5027995109558105, "metricx_qe_score": 4.567134857177734, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, nous obtenons l'expression représentation q un divisé par q deux.", "metrics": {"bleu_score": 25.726636927474853, "chrf_score": 71.64295308032578, "xcomet_score": 0.8264135122299194, "xcomet_qe_score": 0.8826978206634521, "metricx_score": 6.415536403656006, "metricx_qe_score": 5.839761257171631, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en fait, en pratique, à l'étape de l'inférence, nous pourrions également obtenir l'expression incorrecte incorrecte.", "metrics": {"bleu_score": 36.49716704775572, "chrf_score": 71.72265631442065, "xcomet_score": 0.9286084175109863, "xcomet_qe_score": 0.9338704943656921, "metricx_score": 6.299508094787598, "metricx_qe_score": 6.733342170715332, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, toutes les expressions possibles sont égales à trois fois le nombre d'opérateurs.", "metrics": {"bleu_score": 38.53856918030314, "chrf_score": 73.77771861326676, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8023084998130798, "metricx_qe_score": 1.5921916961669922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, le point positif ici, c'est que nous pouvons facilement ajouter des contraintes pour contrôler cet espace de recherche.", "metrics": {"bleu_score": 73.20755362899838, "chrf_score": 84.01397711139839, "xcomet_score": 0.9603631496429443, "xcomet_qe_score": 0.9588572978973389, "metricx_score": 1.2446006536483765, "metricx_qe_score": 1.389100193977356, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement la supprimer de notre espace de recherche.", "metrics": {"bleu_score": 73.62853809865184, "chrf_score": 81.71776209831928, "xcomet_score": 0.9951730966567993, "xcomet_qe_score": 0.9794670343399048, "metricx_score": 0.37088721990585327, "metricx_qe_score": 0.45243895053863525, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans la deuxième étape, nous faisons la même chose, mais la seule différence est qu'il y a une quantité supplémentaire.", "metrics": {"bleu_score": 71.03600666390408, "chrf_score": 81.83922662836126, "xcomet_score": 0.9617201089859009, "xcomet_qe_score": 0.9233575463294983, "metricx_score": 3.420553207397461, "metricx_qe_score": 4.673766613006592, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "La quantité provient de l'expression calculée précédente.", "metrics": {"bleu_score": 23.87517132417733, "chrf_score": 66.2593195505074, "xcomet_score": 0.997840404510498, "xcomet_qe_score": 0.9859619140625, "metricx_score": 0.6669514179229736, "metricx_qe_score": 1.0553557872772217, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, finalement, nous pouvons ajouter cette expression finale q.", "metrics": {"bleu_score": 20.89946492122517, "chrf_score": 62.28076041010628, "xcomet_score": 0.39724472165107727, "xcomet_qe_score": 0.6232122182846069, "metricx_score": 17.837135314941406, "metricx_qe_score": 17.902738571166992, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "fois Q4. et nous pouvons également voir que le nombre de toutes les expressions possibles est différent de l'étape précédente.", "metrics": {"bleu_score": 71.70451440930212, "chrf_score": 88.09386851561291, "xcomet_score": 0.47866418957710266, "xcomet_qe_score": 0.2713465392589569, "metricx_score": 8.326349258422852, "metricx_qe_score": 11.99925708770752, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, une telle différence rend difficile l'application de la recherche par balayage car la distribution de probabilité entre ces deux étapes est déséquilibrée.", "metrics": {"bleu_score": 80.37775080641401, "chrf_score": 90.22793142179916, "xcomet_score": 0.9053376913070679, "xcomet_qe_score": 0.9560484886169434, "metricx_score": 2.037982225418091, "metricx_qe_score": 1.5748534202575684, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, la procédure d'entraînement est similaire à l'entraînement d'un modèle de séquence à séquence où nous optimisons la perte à chaque étape temporelle.", "metrics": {"bleu_score": 42.573206097101476, "chrf_score": 65.37292637276566, "xcomet_score": 0.6996498107910156, "xcomet_qe_score": 0.6016267538070679, "metricx_score": 3.096698045730591, "metricx_qe_score": 3.6439054012298584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également ce tau pour représenter le moment où nous devrions mettre fin à ce processus de génération.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.225374698638916, "metricx_qe_score": 3.699932813644409, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent d'une séquence à l'autre car l'espace est différent à chaque fois, alors que dans le modèle traditionnel de séquence à séquence, c'est le nombre de vocabulaire.", "metrics": {"bleu_score": 56.685083492462745, "chrf_score": 79.84821647481404, "xcomet_score": 0.5368454456329346, "xcomet_qe_score": 0.5637575387954712, "metricx_score": 6.72058629989624, "metricx_qe_score": 7.73292875289917, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela permet également d'imposer certaines contraintes issues de connaissances antérieures.", "metrics": {"bleu_score": 48.871645172969465, "chrf_score": 82.73424243795341, "xcomet_score": 0.9449813365936279, "xcomet_qe_score": 0.9031662940979004, "metricx_score": 1.2703897953033447, "metricx_qe_score": 1.299294114112854, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Nous menons donc des expériences sur les ensembles de données de problèmes de méthodes couramment utilisés, MAWPS, Metth3K, MathQA et Swam.", "metrics": {"bleu_score": 43.74233123848533, "chrf_score": 72.09926093172648, "xcomet_score": 0.5707136988639832, "xcomet_qe_score": 0.6265726089477539, "metricx_score": 7.332365989685059, "metricx_qe_score": 7.833375453948975, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous présentons brièvement les résultats par rapport aux meilleures approches précédentes.", "metrics": {"bleu_score": 31.138788080750665, "chrf_score": 67.81051600636037, "xcomet_score": 0.9928573369979858, "xcomet_qe_score": 0.9658632278442383, "metricx_score": 1.0590038299560547, "metricx_qe_score": 1.1674599647521973, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre arme la plus performante est la raison déductive de Roberta.", "metrics": {"bleu_score": 21.97281387499715, "chrf_score": 54.277176982750206, "xcomet_score": 0.6268918514251709, "xcomet_qe_score": 0.6741154789924622, "metricx_score": 5.526547908782959, "metricx_qe_score": 5.3092732429504395, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "Et en fait, nous n'utilisons pas la recherche par balayage en contraste avec les approches évidentes utilisant la recherche par balayage.", "metrics": {"bleu_score": 20.776569671187676, "chrf_score": 47.46155117689653, "xcomet_score": 0.8487744927406311, "xcomet_qe_score": 0.8988302946090698, "metricx_score": 4.069245338439941, "metricx_qe_score": 3.351248025894165, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, donc les meilleures approches sont souvent un modèle basé sur un arbre.", "metrics": {"bleu_score": 39.86272652021924, "chrf_score": 66.46704747642474, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9287343621253967, "metricx_qe_score": 1.1396695375442505, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans l'ensemble, notre raisonneur est capable de surpasser de manière significative ce modèle basé sur l'arbre.", "metrics": {"bleu_score": 44.44183736091338, "chrf_score": 72.20424970156427, "xcomet_score": 0.9738843441009521, "xcomet_qe_score": 0.8917350769042969, "metricx_score": 3.854893445968628, "metricx_qe_score": 6.143208980560303, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons voir que le nombre absolu sur MathQA ou Swam n'est pas vraiment élevé.", "metrics": {"bleu_score": 30.38445102758823, "chrf_score": 71.68801589620621, "xcomet_score": 0.8332674503326416, "xcomet_qe_score": 0.7645276784896851, "metricx_score": 2.72537899017334, "metricx_qe_score": 2.533536672592163, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez donc vous référer aux résultats de l'enquête", "metrics": {"bleu_score": 4.513617516969122, "chrf_score": 29.06376204188481, "xcomet_score": 0.12448286265134811, "xcomet_qe_score": 0.13366888463497162, "metricx_score": 7.470787525177002, "metricx_qe_score": 7.145767688751221, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "et cet ensemble de données est difficile à traiter car l'auteur a essayé d'ajouter manuellement quelque chose pour confondre le modèle NMLB, comme l'ajout d'informations sur l'environnement et de quantités supplémentaires.", "metrics": {"bleu_score": 33.79266509475464, "chrf_score": 64.19423549165796, "xcomet_score": 0.5093780755996704, "xcomet_qe_score": 0.4894815981388092, "metricx_score": 6.5047197341918945, "metricx_qe_score": 7.2069783210754395, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre prédiction, nous constatons que certaines des valeurs intermédiaires sont en fait négatives.", "metrics": {"bleu_score": 46.24892603869296, "chrf_score": 73.46335092792414, "xcomet_score": 0.9883226156234741, "xcomet_qe_score": 1.0, "metricx_score": 1.16629159450531, "metricx_qe_score": 0.7037749886512756, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans ces questions, nous demandons combien de pommes Jake a", "metrics": {"bleu_score": 58.69726762742399, "chrf_score": 86.58683360170528, "xcomet_score": 0.979860246181488, "xcomet_qe_score": 0.96596360206604, "metricx_score": 2.496516704559326, "metricx_qe_score": 7.13090705871582, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons des informations supplémentaires, comme dix-sept terrains de camping, et Stephen a huit terrains, ce qui est totalement pertinent.", "metrics": {"bleu_score": 32.256648699740694, "chrf_score": 63.832490298021995, "xcomet_score": 0.2804582715034485, "xcomet_qe_score": 0.30754533410072327, "metricx_score": 16.787792205810547, "metricx_qe_score": 16.078210830688477, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait une prédiction de ce genre, qui produit des valeurs négatives.", "metrics": {"bleu_score": 43.85068972747104, "chrf_score": 64.59760006048438, "xcomet_score": 0.9773280620574951, "xcomet_qe_score": 0.9947031736373901, "metricx_score": 2.7790186405181885, "metricx_qe_score": 2.903749465942383, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous observons ces deux expressions", "metrics": {"bleu_score": 10.014525608798039, "chrf_score": 35.16689671066389, "xcomet_score": 0.1863933950662613, "xcomet_qe_score": 0.26318830251693726, "metricx_score": 18.502872467041016, "metricx_qe_score": 18.035531997680664, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc limiter cet espace de recherche en supprimant les résultats négatifs afin de pouvoir obtenir la bonne réponse.", "metrics": {"bleu_score": 51.96509820132598, "chrf_score": 68.27932923807907, "xcomet_score": 0.9296836853027344, "xcomet_qe_score": 0.87006676197052, "metricx_score": 2.1241626739501953, "metricx_qe_score": 3.1458418369293213, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous constatons que cette contrainte améliore en réalité considérablement certains modèles.", "metrics": {"bleu_score": 44.534504264163466, "chrf_score": 64.23642263344215, "xcomet_score": 0.9910334348678589, "xcomet_qe_score": 0.9889209270477295, "metricx_score": 1.375691294670105, "metricx_qe_score": 1.698866605758667, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, pour les oiseaux, nous avons amélioré de sept points, puis pour le modèle basé sur le robota, nous avons effectivement amélioré de deux points.", "metrics": {"bleu_score": 42.61528449554083, "chrf_score": 55.26859521885271, "xcomet_score": 0.3165457248687744, "xcomet_qe_score": 0.3796948194503784, "metricx_score": 14.24389934539795, "metricx_qe_score": 11.9849271774292, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, un meilleur modèle linguistique possède de meilleures capacités de compréhension du langage, de sorte que le nombre ici est plus élevé pour Roberta et plus faible pour les oiseaux.", "metrics": {"bleu_score": 43.01085302914516, "chrf_score": 56.787277753812624, "xcomet_score": 0.6585985422134399, "xcomet_qe_score": 0.754999577999115, "metricx_score": 13.648589134216309, "metricx_qe_score": 12.560468673706055, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "nous essayons également d'analyser la difficulté derrière ce BP", "metrics": {"bleu_score": 52.01870634468553, "chrf_score": 75.92696932079997, "xcomet_score": 0.23843279480934143, "xcomet_qe_score": 0.23156510293483734, "metricx_score": 10.554643630981445, "metricx_qe_score": 10.799850463867188, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que le nombre de quantités non utilisées peut être considéré comme une information pertinente ici.", "metrics": {"bleu_score": 50.456668400584846, "chrf_score": 87.80275595992197, "xcomet_score": 0.8001711368560791, "xcomet_qe_score": 0.6070610284805298, "metricx_score": 9.156352043151855, "metricx_qe_score": 11.901250839233398, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici nous pouvons voir que nous avons le pourcentage d'échantillons en quantités non utilisées, et le jeu de données swaMP a la plus grande partie.", "metrics": {"bleu_score": 43.70614964591187, "chrf_score": 75.74288609888175, "xcomet_score": 0.7728327512741089, "xcomet_qe_score": 0.7694458961486816, "metricx_score": 6.665035724639893, "metricx_qe_score": 7.237673282623291, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons également la performance globale.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9156627655029297, "metricx_qe_score": 1.2110265493392944, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "pour ces échantillons sans quantités non utilisées, donc la performance globale est en réalité supérieure à la performance globale", "metrics": {"bleu_score": 51.086369427314914, "chrf_score": 88.13020295235229, "xcomet_score": 0.495341956615448, "xcomet_qe_score": 0.4851316511631012, "metricx_score": 6.800503730773926, "metricx_qe_score": 8.90807819366455, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "Mais avec ces échantillons, la quantité non utilisée est en réalité bien pire que la situation déjà bien pire que", "metrics": {"bleu_score": 24.62292439135324, "chrf_score": 55.02462878085491, "xcomet_score": 0.28694427013397217, "xcomet_qe_score": 0.16049671173095703, "metricx_score": 12.935827255249023, "metricx_qe_score": 11.257362365722656, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "performance Pour MAWPS, nous n'avons pas vraiment beaucoup de cas de décès, donc j'ignore simplement cette partie.", "metrics": {"bleu_score": 54.64463020975289, "chrf_score": 76.50266302060393, "xcomet_score": 0.38570255041122437, "xcomet_qe_score": 0.4874499440193176, "metricx_score": 11.164178848266602, "metricx_qe_score": 14.277443885803223, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, enfin, nous voulons montrer les interprétabilités à travers un exemple d'accident et de présentation.", "metrics": {"bleu_score": 28.43329181530769, "chrf_score": 55.48274148649121, "xcomet_score": 0.23530235886573792, "xcomet_qe_score": 0.3587684631347656, "metricx_score": 12.0460205078125, "metricx_qe_score": 13.632546424865723, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, notre modèle fait en réalité une prédiction erronée à la première étape.", "metrics": {"bleu_score": 50.243316187200534, "chrf_score": 73.28832883604976, "xcomet_score": 0.984865128993988, "xcomet_qe_score": 0.9852304458618164, "metricx_score": 1.2138937711715698, "metricx_qe_score": 1.076959252357483, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc effectivement établir un lien entre cette expression et la phrase ici, d'accord", "metrics": {"bleu_score": 12.874330508144842, "chrf_score": 56.52970507948444, "xcomet_score": 0.9802389144897461, "xcomet_qe_score": 0.991092324256897, "metricx_score": 1.4160325527191162, "metricx_qe_score": 1.541869044303894, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons donc que cette phrase pourrait induire le modèle en erreur et conduire à une prédiction incorrecte.", "metrics": {"bleu_score": 60.98820960308448, "chrf_score": 77.64040440972902, "xcomet_score": 0.9966170787811279, "xcomet_qe_score": 0.9823441505432129, "metricx_score": 0.770254373550415, "metricx_qe_score": 0.4123237133026123, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ici, imprimer trente-cinq autres lignes amène le modèle à penser qu'il devrait s'agir d'opérateurs d'addition.", "metrics": {"bleu_score": 13.910732727119134, "chrf_score": 61.72324322931294, "xcomet_score": 0.8072417974472046, "xcomet_qe_score": 0.71023029088974, "metricx_score": 4.833492279052734, "metricx_qe_score": 4.050887584686279, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Nous essayons donc de réviser la phrase pour qu'elle ressemble à ceci : le nombre de pommiers est trois à cinq de moins que celui des poiriers.", "metrics": {"bleu_score": 21.52108131773811, "chrf_score": 57.26153292244217, "xcomet_score": 0.8248201608657837, "xcomet_qe_score": 0.8121510744094849, "metricx_score": 6.634544372558594, "metricx_qe_score": 8.696403503417969, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Nous procédons donc à une transmission de la sémantique plus précise, de manière à ce que le modèle puisse effectuer la prédiction correcte.", "metrics": {"bleu_score": 12.096309696629893, "chrf_score": 50.122312667719946, "xcomet_score": 0.9760687351226807, "xcomet_qe_score": 0.9653767347335815, "metricx_score": 2.142941951751709, "metricx_qe_score": 2.470734119415283, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, cette étude montre comment les prédictions interprétables nous aident à comprendre le comportement du modèle.", "metrics": {"bleu_score": 83.94327083733333, "chrf_score": 94.38448679358433, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.077393651008606, "metricx_qe_score": 0.783183753490448, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure notre travail, notre modèle est en fait assez efficace.", "metrics": {"bleu_score": 57.475393483140245, "chrf_score": 78.83479427187108, "xcomet_score": 0.9972312450408936, "xcomet_qe_score": 0.99419105052948, "metricx_score": 1.520257830619812, "metricx_qe_score": 1.7071630954742432, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous sommes en mesure de fournir une procédure de résolution interprétable.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0080623626708984, "metricx_qe_score": 1.129818081855774, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pouvons facilement intégrer certaines connaissances antérieures comme contrainte, ce qui peut aider à améliorer les performances.", "metrics": {"bleu_score": 20.313747122261766, "chrf_score": 72.24079035104036, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9544926881790161, "metricx_qe_score": 1.140217900276184, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et la dernière chose est que le mécanisme sous-jacent ne s'applique pas uniquement aux tâches de résolution de problèmes de réseau, mais aussi à d'autres tâches qui impliquent un raisonnement en plusieurs étapes.", "metrics": {"bleu_score": 65.58477295367683, "chrf_score": 89.46776250237585, "xcomet_score": 0.9958618879318237, "xcomet_qe_score": 1.0, "metricx_score": 0.5809659957885742, "metricx_qe_score": 0.7670202255249023, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons aussi certaines limites.", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 62.10666488002826, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13551399111747742, "metricx_qe_score": 0.2110535204410553, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "Si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0386240482330322, "metricx_qe_score": 1.0148998498916626, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est que, comme mentionné, parce que la distribution de probabilité est déséquilibrée entre les différents instants, il est donc également assez difficile d'appliquer des recherches par faisceau.", "metrics": {"bleu_score": 60.46764878181794, "chrf_score": 79.18965332793, "xcomet_score": 0.7970190048217773, "xcomet_qe_score": 0.8804186582565308, "metricx_score": 3.30690336227417, "metricx_qe_score": 3.1692256927490234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "Voilà, c'est la fin de la conférence, et les questions sont les bienvenues. Merci.", "metrics": {"bleu_score": 47.1945892787236, "chrf_score": 57.29546051702662, "xcomet_score": 0.9921575784683228, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.0840938091278076, "metricx_qe_score": 0.6956595182418823, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je viens de l'Université de Maastricht.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 90.46894018144044, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.377380132675171, "metricx_qe_score": 0.664887011051178, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter mon travail sur John avec Jerry, qui porte sur un nouveau jeu de données pour la récupération d'articles légaux.", "metrics": {"bleu_score": 29.85114496930219, "chrf_score": 58.828020197010744, "xcomet_score": 0.3006289005279541, "xcomet_qe_score": 0.23721103370189667, "metricx_score": 9.438787460327148, "metricx_qe_score": 9.411137580871582, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les problèmes juridiques font partie intégrante de la vie de nombreuses personnes.", "metrics": {"bleu_score": 84.23626743789745, "chrf_score": 86.06115383670415, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6353251934051514, "metricx_qe_score": 0.46970173716545105, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et les processus juridiques fondamentaux.", "metrics": {"bleu_score": 65.14613449066714, "chrf_score": 92.27603232952652, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8223639726638794, "metricx_qe_score": 1.0039916038513184, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "En conséquence, de nombreux citoyens vulnérables qui ne peuvent pas se permettre l'assistance coûteuse d'un expert juridique se retrouvent sans protection ou, pire, exploités.", "metrics": {"bleu_score": 46.00585798331265, "chrf_score": 71.9167407662733, "xcomet_score": 0.9987257719039917, "xcomet_qe_score": 1.0, "metricx_score": 1.2121862173080444, "metricx_qe_score": 1.0803606510162354, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Tout le travail vise à combler le fossé entre les gens et la loi en développant un système de recherche efficace pour les articles de loi.", "metrics": {"bleu_score": 51.993022299307086, "chrf_score": 66.63217348957242, "xcomet_score": 0.9710714817047119, "xcomet_qe_score": 1.0, "metricx_score": 2.0487422943115234, "metricx_qe_score": 1.272505283355713, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "Un tel système pourrait fournir un service d'aide juridique professionnelle gratuit pour les humains non qualifiés.", "metrics": {"bleu_score": 51.54458901398172, "chrf_score": 81.54241491506178, "xcomet_score": 0.9426836967468262, "xcomet_qe_score": 0.9523552656173706, "metricx_score": 1.3478590250015259, "metricx_qe_score": 1.1983811855316162, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de plonger dans la contribution principale de ce travail, décrivons d'abord le problème de la récupération d'articles légaux.", "metrics": {"bleu_score": 30.91327937802876, "chrf_score": 63.51469160079327, "xcomet_score": 0.798965573310852, "xcomet_qe_score": 0.7506064176559448, "metricx_score": 5.095536708831787, "metricx_qe_score": 4.69135856628418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné une question simple sur les questions d'allèles, par exemple, quel est le risque si je viole la confidentialité professionnelle ?", "metrics": {"bleu_score": 31.268514922728706, "chrf_score": 58.95993771960778, "xcomet_score": 0.6514058709144592, "xcomet_qe_score": 0.5601632595062256, "metricx_score": 9.898433685302734, "metricx_qe_score": 10.598560333251953, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle est nécessaire pour récupérer tous les articles légaux pertinents d'un vaste corpus législatif.", "metrics": {"bleu_score": 38.00427070295603, "chrf_score": 70.81987205865413, "xcomet_score": 0.977972149848938, "xcomet_qe_score": 1.0, "metricx_score": 1.6713135242462158, "metricx_qe_score": 2.0001349449157715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche de recherche d'information comporte son propre ensemble de défis.", "metrics": {"bleu_score": 57.067457770559976, "chrf_score": 73.53348574314383, "xcomet_score": 0.9810460805892944, "xcomet_qe_score": 1.0, "metricx_score": 0.9133810997009277, "metricx_qe_score": 0.4641854763031006, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, il traite de deux types de langage.", "metrics": {"bleu_score": 48.326978309062206, "chrf_score": 77.70626446580955, "xcomet_score": 0.7698017358779907, "xcomet_qe_score": 0.9778584241867065, "metricx_score": 2.369997024536133, "metricx_qe_score": 1.0847606658935547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "Un langage naturel courant pour les questions et un langage illégal complexe pour les statuts.", "metrics": {"bleu_score": 22.894156860669913, "chrf_score": 52.45852474433228, "xcomet_score": 0.6594562530517578, "xcomet_qe_score": 0.6503254175186157, "metricx_score": 10.812073707580566, "metricx_qe_score": 8.383625030517578, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence dans les distributions linguistiques rend plus difficile pour un système de retrouver des candidats pertinents, car cela nécessite indirectement un système d'interprétation inhérent capable de traduire une question naturelle en une question juridique correspondant à la terminologie des statuts.", "metrics": {"bleu_score": 70.0282633046773, "chrf_score": 87.48548898469988, "xcomet_score": 0.9539227485656738, "xcomet_qe_score": 0.9813951253890991, "metricx_score": 3.8589816093444824, "metricx_qe_score": 3.374617576599121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "En outre, le droit législatif n'est pas un ensemble d'articles indépendants qui peuvent être traités comme une source d'information complète à eux seuls, comme les actualités ou les recettes, par exemple.", "metrics": {"bleu_score": 45.32607978893935, "chrf_score": 69.94544936981012, "xcomet_score": 0.9928427934646606, "xcomet_qe_score": 0.9976663589477539, "metricx_score": 3.1750094890594482, "metricx_qe_score": 2.2838070392608643, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'agit plutôt d'une collection de dispositions légales qui ne prennent tout leur sens que lorsqu'elles sont examinées dans le contexte global, c'est-à-dire en tenant compte des informations complémentaires des articles voisins, des domaines et sous-domaines auxquels elles appartiennent, ainsi que de leur place dans la structure de la loi.", "metrics": {"bleu_score": 40.39909279610394, "chrf_score": 72.36430674468859, "xcomet_score": 0.9773266315460205, "xcomet_qe_score": 0.9891172647476196, "metricx_score": 0.9384937882423401, "metricx_qe_score": 1.0638890266418457, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, les articles légaux sont présentés en petits paragraphes, ce qui est généralement l'unité de récupération typique dans la plupart des travaux de récupération.", "metrics": {"bleu_score": 31.823566221963034, "chrf_score": 66.153843060246, "xcomet_score": 0.44365623593330383, "xcomet_qe_score": 0.46536606550216675, "metricx_score": 10.163451194763184, "metricx_qe_score": 10.461272239685059, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "Voici des documents longs qui peuvent en compter jusqu'à six.", "metrics": {"bleu_score": 7.738764559489539, "chrf_score": 53.673914228541854, "xcomet_score": 0.6526549458503723, "xcomet_qe_score": 0.6685420274734497, "metricx_score": 11.716572761535645, "metricx_qe_score": 9.526494026184082, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les récentes avancées en traitement du langage naturel ont suscité un grand intérêt pour de nombreuses tâches juridiques, telles que la prédiction des jugements juridiques ou l'examen automatique des contrats.", "metrics": {"bleu_score": 40.259869498048644, "chrf_score": 68.14002874505798, "xcomet_score": 0.9217108488082886, "xcomet_qe_score": 0.9713497161865234, "metricx_score": 1.2614678144454956, "metricx_qe_score": 0.9190574884414673, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la récupération d'articles légaux est restée principalement inaccessible en raison du manque de grands ensembles de données étiquetées de haute qualité.", "metrics": {"bleu_score": 39.64513253420688, "chrf_score": 64.49671213306847, "xcomet_score": 0.6348836421966553, "xcomet_qe_score": 0.610264003276825, "metricx_score": 5.6020684242248535, "metricx_qe_score": 3.744851589202881, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette étude, nous présentons un nouveau jeu de données centré sur les citoyens français natifs afin d'étudier si un modèle de recherche peut se rapprocher de l'efficacité et de la fiabilité d'un expert juridique pour la tâche de recherche d'articles légaux.", "metrics": {"bleu_score": 38.6331114848531, "chrf_score": 65.80858284233679, "xcomet_score": 0.7687503099441528, "xcomet_qe_score": 0.8413675427436829, "metricx_score": 5.900834083557129, "metricx_qe_score": 4.78914213180542, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "Ou l'ensemble de données de récupération d'articles légaux belges comprend plus de 1100", "metrics": {"bleu_score": 3.4886391383307505, "chrf_score": 27.78639700839673, "xcomet_score": 0.23039281368255615, "xcomet_qe_score": 0.25793027877807617, "metricx_score": 20.028488159179688, "metricx_qe_score": 20.183015823364258, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "Ces questions couvrent un large éventail de sujets, allant de la famille, au logement, à l'argent, au travail et à la sécurité sociale.", "metrics": {"bleu_score": 67.13783850074476, "chrf_score": 84.40550138901145, "xcomet_score": 0.9989352226257324, "xcomet_qe_score": 1.0, "metricx_score": 1.2284950017929077, "metricx_qe_score": 0.4286993145942688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun d'eux a été étiqueté par des juristes expérimentés avec des références aux articles pertinents d'un corpus de plus de vingt-deux mille six cents.", "metrics": {"bleu_score": 46.512846588495364, "chrf_score": 68.20106962194801, "xcomet_score": 0.46945834159851074, "xcomet_qe_score": 0.7197357416152954, "metricx_score": 9.030842781066895, "metricx_qe_score": 9.457769393920898, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Codes de droit belges. Parlons maintenant de la manière dont nous avons collecté ces ensembles de données.", "metrics": {"bleu_score": 34.51395513935864, "chrf_score": 74.64129449864147, "xcomet_score": 0.19371137022972107, "xcomet_qe_score": 0.17632406949996948, "metricx_score": 15.083236694335938, "metricx_qe_score": 17.663244247436523, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons commencé par constituer un vaste corpus d'articles de Lile.", "metrics": {"bleu_score": 14.59522521830733, "chrf_score": 52.38732736775239, "xcomet_score": 0.37204769253730774, "xcomet_qe_score": 0.4407292902469635, "metricx_score": 10.913719177246094, "metricx_qe_score": 8.358389854431152, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons examiné trente-deux codes belges accessibles au public et extrait tous leurs articles ainsi que les titres de sections correspondants.", "metrics": {"bleu_score": 75.52498655792417, "chrf_score": 95.29582169762642, "xcomet_score": 0.9977248907089233, "xcomet_qe_score": 0.9982707500457764, "metricx_score": 1.9588056802749634, "metricx_qe_score": 1.7774975299835205, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous avons rassemblé des questions juridiques avec des références aux lois pertinentes.", "metrics": {"bleu_score": 57.73502691896262, "chrf_score": 91.31938011871401, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.070390224456787, "metricx_qe_score": 1.3487091064453125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous collaborons avec le cabinet d'avocats belge qui reçoit chaque année environ quatre mille courriels de citoyens belges qui demandent des conseils sur une question juridique personnelle.", "metrics": {"bleu_score": 72.98926162113918, "chrf_score": 86.99284573831865, "xcomet_score": 0.9778150320053101, "xcomet_qe_score": 0.9853702187538147, "metricx_score": 0.6587830781936646, "metricx_qe_score": 0.6243945956230164, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance d'accéder à leurs sites web, où leur équipe de juristes expérimentés aborde les problèmes juridiques les plus courants en Belgique.", "metrics": {"bleu_score": 61.806599678536905, "chrf_score": 78.712791698755, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.4328558444976807, "metricx_qe_score": 1.8640111684799194, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons recueilli des milliers de questions, annotées avec des catégories, des sous-catégories et des références légales aux lois pertinentes.", "metrics": {"bleu_score": 75.22135016840222, "chrf_score": 89.88889484392803, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6943244338035583, "metricx_qe_score": 1.1060343980789185, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons passé en revue les références légales et éliminé les questions dont les références n'étaient pas des articles d'un des codes de droit que nous avions considérés.", "metrics": {"bleu_score": 52.221222004846055, "chrf_score": 76.66515485506046, "xcomet_score": 0.9480488896369934, "xcomet_qe_score": 0.9542509913444519, "metricx_score": 1.5225305557250977, "metricx_qe_score": 1.4639837741851807, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "Les références restantes ont été mises en correspondance et converties en identifiants d'article correspondants à partir de allCopus.", "metrics": {"bleu_score": 29.153692299445225, "chrf_score": 73.04604761324967, "xcomet_score": 0.9195055961608887, "xcomet_qe_score": 0.939845860004425, "metricx_score": 4.114905834197998, "metricx_qe_score": 4.414402484893799, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons finalement obtenu mille cent huit questions, chacune soigneusement étiquetée avec les identifiants des articles pertinents.", "metrics": {"bleu_score": 33.98041934025851, "chrf_score": 56.62843858661258, "xcomet_score": 0.7200870513916016, "xcomet_qe_score": 0.9007276296615601, "metricx_score": 6.081841945648193, "metricx_qe_score": 10.520052909851074, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, chaque question est accompagnée d'une catégorie principale et d'une concaténation de sous-catégories.", "metrics": {"bleu_score": 50.47325154308107, "chrf_score": 80.4082245966848, "xcomet_score": 0.954633355140686, "xcomet_qe_score": 0.9636931419372559, "metricx_score": 5.552073955535889, "metricx_qe_score": 5.55289888381958, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "Et chaque article est accompagné d'une concaténation de leur titre suivant dans la structure de la loi.", "metrics": {"bleu_score": 41.180376356915765, "chrf_score": 49.58893552752831, "xcomet_score": 0.7437098026275635, "xcomet_qe_score": 0.7580925226211548, "metricx_score": 9.545700073242188, "metricx_qe_score": 9.314903259277344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Ces informations supplémentaires n'ont pas été utilisées dans le cadre du présent travail, mais elles pourraient présenter un intérêt pour des recherches futures sur la recherche d'informations juridiques ou la classification de textes juridiques.", "metrics": {"bleu_score": 57.64273414147167, "chrf_score": 87.14236721058664, "xcomet_score": 0.9832991361618042, "xcomet_qe_score": 1.0, "metricx_score": 0.8194847702980042, "metricx_qe_score": 0.380544513463974, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons certaines caractéristiques de notre jeu de données.", "metrics": {"bleu_score": 17.869400568145597, "chrf_score": 63.73815089828536, "xcomet_score": 0.968815803527832, "xcomet_qe_score": 0.9718017578125, "metricx_score": 0.6242448687553406, "metricx_qe_score": 0.6314937472343445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions font entre cinq et quarante-quatre mots, avec une médiane de quarante.", "metrics": {"bleu_score": 33.15796151992084, "chrf_score": 65.19431383283592, "xcomet_score": 0.6411436796188354, "xcomet_qe_score": 0.7994188070297241, "metricx_score": 8.659601211547852, "metricx_qe_score": 7.241206169128418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont beaucoup plus longs, avec une longueur médiane de 77 mots et 140 caractères", "metrics": {"bleu_score": 26.397720955822646, "chrf_score": 43.83776351491965, "xcomet_score": 0.25941210985183716, "xcomet_qe_score": 0.2221047282218933, "metricx_score": 12.219956398010254, "metricx_qe_score": 11.098274230957031, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "dont plus d'un millier", "metrics": {"bleu_score": 2.1617886496312457, "chrf_score": 10.438847012942713, "xcomet_score": 0.15146882832050323, "xcomet_qe_score": 0.1535010039806366, "metricx_score": 24.81086540222168, "metricx_qe_score": 22.927488327026367, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "Comme mentionné précédemment, la question portait sur un large éventail de sujets, dont environ quatre-vingt-cinq pour cent concernaient soit la famille, le logement, l'argent ou la justice.", "metrics": {"bleu_score": 60.317983955216874, "chrf_score": 80.92074511525247, "xcomet_score": 0.8292660713195801, "xcomet_qe_score": 0.8284574747085571, "metricx_score": 3.73990535736084, "metricx_qe_score": 3.6014204025268555, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "Tandis que les quinze pour cent restants concernent soit la sécurité sociale, les étrangers, soit le travail.", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 86.50587874135304, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0402348041534424, "metricx_qe_score": 1.642091155052185, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très divers, car ils proviennent de 32 codes belges différents qui couvrent un grand nombre de sujets juridiques.", "metrics": {"bleu_score": 51.02002548573252, "chrf_score": 77.11398468633138, "xcomet_score": 0.9291741847991943, "xcomet_qe_score": 0.9881991147994995, "metricx_score": 1.239342212677002, "metricx_qe_score": 0.9468382000923157, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles recueillis pour chacun de ces codes belges.", "metrics": {"bleu_score": 57.475393483140245, "chrf_score": 73.11152168808387, "xcomet_score": 0.9977279901504517, "xcomet_qe_score": 1.0, "metricx_score": 1.3700995445251465, "metricx_qe_score": 2.39261531829834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Sur les 22 633 articles, seuls 1 612 sont considérés comme pertinents pour au moins l'un d'eux.", "metrics": {"bleu_score": 8.606440813373595, "chrf_score": 34.17538633704605, "xcomet_score": 0.4630434215068817, "xcomet_qe_score": 0.502768337726593, "metricx_score": 4.635437965393066, "metricx_qe_score": 4.714971542358398, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "une question dans l'ensemble de données. et environ 80 % de ces articles cités proviennent soit du Code civil, des codes judiciaires, du code d'instruction pénale ou des codes pénaux.", "metrics": {"bleu_score": 35.964066074252585, "chrf_score": 63.915467584888574, "xcomet_score": 0.30191850662231445, "xcomet_qe_score": 0.2061086893081665, "metricx_score": 12.254629135131836, "metricx_qe_score": 16.008146286010742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "Entre-temps, dix-huit des trente-deux codes ont moins de cinq articles mentionnés comme pertinents pour au moins une question.", "metrics": {"bleu_score": 85.57423956196074, "chrf_score": 92.88440555807628, "xcomet_score": 0.9699159860610962, "xcomet_qe_score": 0.967171311378479, "metricx_score": 1.4313979148864746, "metricx_qe_score": 1.7736402750015259, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut s'expliquer par le fait que ce code se concentre moins sur les individus et leurs préoccupations.", "metrics": {"bleu_score": 59.509221134368715, "chrf_score": 82.224678555432, "xcomet_score": 0.9671159982681274, "xcomet_qe_score": 0.9664577841758728, "metricx_score": 3.8540308475494385, "metricx_qe_score": 3.9513165950775146, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le nombre médian de citations pour ces articles cités est de 2, et moins de 2 % d'entre eux le sont.", "metrics": {"bleu_score": 43.497773579949495, "chrf_score": 61.03205046946978, "xcomet_score": 0.3998992443084717, "xcomet_qe_score": 0.4995262622833252, "metricx_score": 19.345443725585938, "metricx_qe_score": 17.0800838470459, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant nos ensembles de données, nous évaluons plusieurs approches de récupération, y compris l'architecture lexicale et dense.", "metrics": {"bleu_score": 44.77845944135174, "chrf_score": 71.99726345674952, "xcomet_score": 0.6580978631973267, "xcomet_qe_score": 0.7577692866325378, "metricx_score": 4.341616630554199, "metricx_qe_score": 4.490166664123535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné une requête dans un article, un modèle lexical attribue un score à la paire requête-article en calculant la somme des termes de la requête des poids de chacun de ces termes dans cet article.", "metrics": {"bleu_score": 68.20763123887689, "chrf_score": 86.40901037483053, "xcomet_score": 0.7772088050842285, "xcomet_qe_score": 0.7380669116973877, "metricx_score": 5.55536413192749, "metricx_qe_score": 6.5072126388549805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec les fonctions de classement standard TF-FIidf et BMmtwenty-five.", "metrics": {"bleu_score": 56.375603152592916, "chrf_score": 77.43328261711325, "xcomet_score": 0.8391823768615723, "xcomet_qe_score": 0.8238111734390259, "metricx_score": 7.170450687408447, "metricx_qe_score": 9.403753280639648, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème avec ces approches est qu'elles ne peuvent récupérer que les articles contenant des mots-clés présents dans la requête.", "metrics": {"bleu_score": 73.89984311706958, "chrf_score": 87.64492020072457, "xcomet_score": 0.992904782295227, "xcomet_qe_score": 1.0, "metricx_score": 0.8965938091278076, "metricx_qe_score": 0.9452088475227356, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour surmonter cette limitation, nous expérimentons une architecture basée sur les réseaux de neurones qui peut capturer la relation sémantique entre les requêtes et les articles.", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 83.39964194862432, "xcomet_score": 0.989620566368103, "xcomet_qe_score": 0.9627062082290649, "metricx_score": 0.7803897261619568, "metricx_qe_score": 0.8359978199005127, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle B-Ecoder qui associe des requêtes et des articles à des représentations vectorielles denses et calcule un score de pertinence entre une paire requête-article en fonction de la similarité de leurs intégrations.", "metrics": {"bleu_score": 34.003576652422915, "chrf_score": 69.95013752144456, "xcomet_score": 0.7916319370269775, "xcomet_qe_score": 0.8227822780609131, "metricx_score": 6.483551025390625, "metricx_qe_score": 6.649699687957764, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces intégrations résultent généralement d'une opération de pooling sur la sortie d'un modèle d'intégration de mots.", "metrics": {"bleu_score": 82.82477531331043, "chrf_score": 90.96908691044948, "xcomet_score": 0.8626084327697754, "xcomet_qe_score": 0.7329448461532593, "metricx_score": 3.66196608543396, "metricx_qe_score": 6.458038806915283, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous étudions l'efficacité des encodeurs Siamesebian dans un cadre d'évaluation sans apprentissage préalable, ce qui signifie que les modèles d'intégration de mots pré-entraînés sont appliqués sans aucune mise au point supplémentaire.", "metrics": {"bleu_score": 36.152508197378566, "chrf_score": 66.87952356866994, "xcomet_score": 0.7357196807861328, "xcomet_qe_score": 0.7436078786849976, "metricx_score": 5.617066383361816, "metricx_qe_score": 5.235599517822266, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec un encodeur de texte indépendant du contexte, à savoir word tove et fast text, et des modèles d'intégration dépendants du contexte, à savoir Roberta et plus spécifiquement Cambert, qui est un modèle français de Roberta.", "metrics": {"bleu_score": 56.15522124568196, "chrf_score": 82.06199321034858, "xcomet_score": 0.8186933994293213, "xcomet_qe_score": 0.8243110179901123, "metricx_score": 6.89436149597168, "metricx_qe_score": 6.6891093254089355, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous formons notre propre modèle d'oiseau camem au-delà des codeurs.", "metrics": {"bleu_score": 22.45774725976927, "chrf_score": 45.83876005529615, "xcomet_score": 0.19088076055049896, "xcomet_qe_score": 0.16924208402633667, "metricx_score": 17.32178497314453, "metricx_qe_score": 16.37703514099121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "Sur tous les ensembles de données, notez que pour l'entraînement, nous expérimentons avec les deux variantes de l'architecture Biancoda.", "metrics": {"bleu_score": 26.934666326316563, "chrf_score": 63.35846033055239, "xcomet_score": 0.3364308476448059, "xcomet_qe_score": 0.41407591104507446, "metricx_score": 11.22545337677002, "metricx_qe_score": 11.595726013183594, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "Siamese, qui utilise un modèle unique d'encodage des mots qui mappe la requête et l'article ensemble dans un espace vectoriel dense partagé, et Tuto, qui utilise deux modèles d'encodage des mots indépendants qui encodent la requête et l'article séparément dans différents espaces d'encodage.", "metrics": {"bleu_score": 44.9752924739172, "chrf_score": 65.24314368815014, "xcomet_score": 0.603582501411438, "xcomet_qe_score": 0.6696294546127319, "metricx_score": 11.334903717041016, "metricx_qe_score": 11.393247604370117, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec le pooling de moyenne, de maximum et de CLS ainsi qu'avec le produit scalaire et le cosinus pour calculer les similarités.", "metrics": {"bleu_score": 14.965975078050631, "chrf_score": 60.691847076692454, "xcomet_score": 0.7292888164520264, "xcomet_qe_score": 0.7447875738143921, "metricx_score": 5.082578659057617, "metricx_qe_score": 4.929188251495361, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats d'une ligne de base sur l'ensemble de test.", "metrics": {"bleu_score": 17.827531042796263, "chrf_score": 59.827487634090645, "xcomet_score": 0.6542210578918457, "xcomet_qe_score": 0.5838482975959778, "metricx_score": 6.034921646118164, "metricx_qe_score": 6.114847660064697, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "Avec les méthodes lexicales ci-dessus, les biancoders siamois ont été évalués en configuration zéro en milieu de parcours, et les biancoders affinés ci-dessous.", "metrics": {"bleu_score": 32.16397363858737, "chrf_score": 70.66867070600003, "xcomet_score": 0.33540263772010803, "xcomet_qe_score": 0.34323638677597046, "metricx_score": 10.850168228149414, "metricx_qe_score": 9.926691055297852, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, les encodeurs fine-Ttuune B surpassent de manière significative toutes les autres lignes de basse.", "metrics": {"bleu_score": 34.57913759237496, "chrf_score": 70.72442079768382, "xcomet_score": 0.3774678409099579, "xcomet_qe_score": 0.4150499105453491, "metricx_score": 14.637410163879395, "metricx_qe_score": 13.91856575012207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle des deux tours est supérieur à sa variante siamoise en termes de rappel à cent, mais présente des performances similaires sur les allométriques.", "metrics": {"bleu_score": 17.949496853184797, "chrf_score": 45.0403943645861, "xcomet_score": 0.5870537757873535, "xcomet_qe_score": 0.4728684723377228, "metricx_score": 5.2180376052856445, "metricx_qe_score": 5.895729064941406, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "bien que bm twenty five ait eu des performances inférieures à celles du train au-delà de Ku de manière significative, ses performances indiquent qu'il s'agit toujours d'une référence solide pour la récupération spécifique au domaine.", "metrics": {"bleu_score": 35.90181554198659, "chrf_score": 69.00013666903398, "xcomet_score": 0.24852889776229858, "xcomet_qe_score": 0.38039976358413696, "metricx_score": 12.686043739318848, "metricx_qe_score": 12.165018081665039, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation zéro-sho de Siamesebiancoder, nous constatons que l'utilisation directe des embeddings d'un modèle Cammbertt pré-entraîné sans optimisation pour la tâche de recherche d'information donne de mauvais résultats, ce qui est cohérent avec les résultats précédents.", "metrics": {"bleu_score": 51.75766409562612, "chrf_score": 70.93912213462013, "xcomet_score": 0.6041386723518372, "xcomet_qe_score": 0.6928496956825256, "metricx_score": 10.344280242919922, "metricx_qe_score": 9.860854148864746, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous observons que le modèle word-to-vec bird-basedbiancoder a largement surpassé les modèles fastex et bird-based, ce qui suggère que les représentations de mots pré-entraînées sont peut-être plus appropriées pour la tâche que les représentations de caractères ou de sous-mots lorsqu'elles sont utilisées telles quelles.", "metrics": {"bleu_score": 20.510629932265566, "chrf_score": 47.84288759153008, "xcomet_score": 0.5338447093963623, "xcomet_qe_score": 0.5747829675674438, "metricx_score": 14.610494613647461, "metricx_qe_score": 14.461494445800781, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que prometteurs, ces résultats laissent entrevoir de nombreuses possibilités d'amélioration par rapport à un expert compétent qui peut finalement retrouver tous les articles pertinents à toute question et ainsi obtenir des scores parfaits.", "metrics": {"bleu_score": 48.608538131872514, "chrf_score": 69.39687471239844, "xcomet_score": 0.9933669567108154, "xcomet_qe_score": 1.0, "metricx_score": 1.8182592391967773, "metricx_qe_score": 2.3579835891723633, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Concluons en discutant de deux limites de tous les ensembles de données.", "metrics": {"bleu_score": 52.055103630534376, "chrf_score": 83.27695935099287, "xcomet_score": 0.8470206260681152, "xcomet_qe_score": 0.8627233505249023, "metricx_score": 3.855677604675293, "metricx_qe_score": 3.0442311763763428, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, le corpus de l'article est limité à ceux recueillis à partir des trente-deux codes belges considérés, ce qui ne couvre pas l'ensemble du droit belge, car les articles des décrets, directives et ordonnances sont absents.", "metrics": {"bleu_score": 68.76332928842052, "chrf_score": 83.23868987304269, "xcomet_score": 0.7443678975105286, "xcomet_qe_score": 0.7788827419281006, "metricx_score": 3.7591283321380615, "metricx_qe_score": 3.719470977783203, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Lors de la construction du jeu de données, toutes les références à ces articles non collectés sont ignorées, ce qui fait que certaines questions se retrouvent avec seulement une fraction du nombre initial d'articles pertinents.", "metrics": {"bleu_score": 71.05516791217374, "chrf_score": 88.51767956128744, "xcomet_score": 0.9418079853057861, "xcomet_qe_score": 0.9425033926963806, "metricx_score": 1.7379014492034912, "metricx_qe_score": 1.9648516178131104, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cette perte d'information implique que la réponse contenue dans les articles pertinents restants pourrait être incomplète, bien qu'elle soit toujours tout à fait appropriée.", "metrics": {"bleu_score": 68.87246539984304, "chrf_score": 89.37236228825259, "xcomet_score": 0.9688940644264221, "xcomet_qe_score": 0.9670678377151489, "metricx_score": 2.134427785873413, "metricx_qe_score": 1.8046678304672241, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, il convient de noter que toutes les questions juridiques ne peuvent pas être résolues uniquement avec des statuts.", "metrics": {"bleu_score": 37.62957149383418, "chrf_score": 71.71099646346713, "xcomet_score": 0.9869778156280518, "xcomet_qe_score": 1.0, "metricx_score": 3.968161106109619, "metricx_qe_score": 1.8647587299346924, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question : « Puis-je expulser mes locataires s'ils font trop de bruit ? »", "metrics": {"bleu_score": 72.76817202342096, "chrf_score": 93.42350457985576, "xcomet_score": 0.9943251609802246, "xcomet_qe_score": 0.9901989698410034, "metricx_score": 0.8008524179458618, "metricx_qe_score": 1.207775354385376, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "Il est possible qu'il n'existe pas de réponse détaillée dans le droit législatif qui quantifie un seuil spécifique de bruit à partir duquel l'expulsion est peu probable.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 68.03686232477718, "xcomet_score": 0.6140226721763611, "xcomet_qe_score": 0.5148520469665527, "metricx_score": 8.393899917602539, "metricx_qe_score": 7.707734107971191, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, le propriétaire devrait probablement s'appuyer davantage sur la jurisprudence et trouver des précédents similaires à sa situation actuelle.", "metrics": {"bleu_score": 88.43865924896839, "chrf_score": 96.00693419793949, "xcomet_score": 0.9974983930587769, "xcomet_qe_score": 0.9999064207077026, "metricx_score": 0.9097432494163513, "metricx_qe_score": 1.021873950958252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le locataire fait deux fêtes par semaine jusqu'à deux heures du matin.", "metrics": {"bleu_score": 47.86471554577891, "chrf_score": 75.44389091260328, "xcomet_score": 0.9053008556365967, "xcomet_qe_score": 0.8548527956008911, "metricx_score": 4.03731632232666, "metricx_qe_score": 2.578228235244751, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, certaines questions sont plus adaptées que d'autres à la tâche de récupération d'articles légaux, et le domaine de celles qui sont moins adaptées reste à déterminer.", "metrics": {"bleu_score": 53.19774228122344, "chrf_score": 77.09045851095246, "xcomet_score": 0.8382522463798523, "xcomet_qe_score": 0.6524969935417175, "metricx_score": 3.9124038219451904, "metricx_qe_score": 4.181876182556152, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que tous les travaux susciteront un intérêt pour le développement de modèles de récupération d'articles légaux pratiques et fiables.", "metrics": {"bleu_score": 19.857943409196785, "chrf_score": 66.72675501334031, "xcomet_score": 0.7358902096748352, "xcomet_qe_score": 0.719183087348938, "metricx_score": 6.301000118255615, "metricx_qe_score": 5.845658302307129, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut contribuer à améliorer l'accès à la justice dans son ensemble.", "metrics": {"bleu_score": 44.08231875586728, "chrf_score": 68.51846699210225, "xcomet_score": 0.9312018156051636, "xcomet_qe_score": 0.9802741408348083, "metricx_score": 1.297353982925415, "metricx_qe_score": 0.7892271876335144, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre article qui est encodé en suivant les liens ci-dessous. Merci.", "metrics": {"bleu_score": 29.624898711976055, "chrf_score": 60.49981638067293, "xcomet_score": 0.7915244698524475, "xcomet_qe_score": 0.7509368658065796, "metricx_score": 5.584792137145996, "metricx_qe_score": 6.1106672286987305, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour,  \nNous sommes heureux de vous présenter notre travail sur VoAOS, une référence indépendante des tâches destinée à tester les modèles de vision et de langage avec des phénomènes linguistiques spécifiques.", "metrics": {"bleu_score": 44.43375405832116, "chrf_score": 79.6038196441252, "xcomet_score": 0.5590071082115173, "xcomet_qe_score": 0.601553201675415, "metricx_score": 5.658921241760254, "metricx_qe_score": 5.32938814163208, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Pourquoi avons-nous rencontré des difficultés à établir ce benchmark ?", "metrics": {"bleu_score": 6.225616866546953, "chrf_score": 37.07647700447233, "xcomet_score": 0.22066684067249298, "xcomet_qe_score": 0.47648969292640686, "metricx_score": 15.297365188598633, "metricx_qe_score": 8.449380874633789, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Eh bien, au cours des dernières années, nous avons assisté à une explosion de modèles de vision et de langage basés sur des transformateurs, pré-entraînés sur de grandes quantités de paires d'images et de textes.", "metrics": {"bleu_score": 45.920941854034346, "chrf_score": 75.18456121213597, "xcomet_score": 0.9447667598724365, "xcomet_qe_score": 0.9879385232925415, "metricx_score": 2.7362353801727295, "metricx_qe_score": 2.433215618133545, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun de ces modèles repousse les limites de l'état de l'art dans les tâches de vision et de langage telles que la réponse à des questions visuelles, le raisonnement sur le sens commun visuel, la récupération d'images, l'ancrage de phrases.", "metrics": {"bleu_score": 30.638657254237277, "chrf_score": 68.54900002642619, "xcomet_score": 0.6605558395385742, "xcomet_qe_score": 0.685393750667572, "metricx_score": 4.236676216125488, "metricx_qe_score": 3.7649309635162354, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc reçu un message. Les précisions sur ces points de référence spécifiques aux tâches augmentent régulièrement.", "metrics": {"bleu_score": 40.16446725033441, "chrf_score": 81.75426552843358, "xcomet_score": 0.9303339719772339, "xcomet_qe_score": 0.5224019289016724, "metricx_score": 4.912893772125244, "metricx_qe_score": 6.589598178863525, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "Mais savons-nous réellement ce que les modèles ont appris ?", "metrics": {"bleu_score": 51.69731539571708, "chrf_score": 87.01056627810956, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2264529466629028, "metricx_qe_score": 2.1026551723480225, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce qu'un transformateur de vision et de langage a compris lorsqu'il a attribué un score élevé pour que cette image et cette phrase correspondent ?", "metrics": {"bleu_score": 48.221575329820354, "chrf_score": 79.32837875334661, "xcomet_score": 0.7451979517936707, "xcomet_qe_score": 0.5714974403381348, "metricx_score": 2.6634278297424316, "metricx_qe_score": 2.7875521183013916, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "Et le faible score pour celui-ci.", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 50.1759551454885, "xcomet_score": 0.8763413429260254, "xcomet_qe_score": 0.8651506900787354, "metricx_score": 4.820855140686035, "metricx_qe_score": 5.258237361907959, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur la bonne chose ?", "metrics": {"bleu_score": 32.281751885843555, "chrf_score": 68.20305147191763, "xcomet_score": 0.7724132537841797, "xcomet_qe_score": 0.7463480830192566, "metricx_score": 1.717067003250122, "metricx_qe_score": 2.1995620727539062, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "Ou se concentrent-ils sur les biais tels que démontrés par les travaux antérieurs ?", "metrics": {"bleu_score": 36.362270465000705, "chrf_score": 65.67172680024657, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9018996953964233, "metricx_qe_score": 1.1912939548492432, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour éclairer davantage cet aspect, nous proposons une approche plus indépendante de la tâche et introduisons des voyelles qui testent la sensibilité des modèles de vision et de langage à des phénomènes linguistiques spécifiques qui affectent à la fois les modalités linguistiques et visuelles.", "metrics": {"bleu_score": 53.939207840927025, "chrf_score": 82.3308444204703, "xcomet_score": 0.5824065208435059, "xcomet_qe_score": 0.6348001956939697, "metricx_score": 6.23360538482666, "metricx_qe_score": 5.767622947692871, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la co-référence des entités.", "metrics": {"bleu_score": 80.03526445867712, "chrf_score": 91.68263575556392, "xcomet_score": 0.8970412611961365, "xcomet_qe_score": 0.8409974575042725, "metricx_score": 2.689277172088623, "metricx_qe_score": 3.4542324542999268, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "Mais comment tester si les modèles de vision et de langage ont saisi ce phénomène ?", "metrics": {"bleu_score": 52.66403878479269, "chrf_score": 73.62177018386052, "xcomet_score": 0.9021210670471191, "xcomet_qe_score": 0.8536651134490967, "metricx_score": 1.5198142528533936, "metricx_qe_score": 2.0375516414642334, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant le foilage, une méthode précédemment appliquée pour les modèles de vision et de langage, uniquement pour les groupes nominaux par Ravi Shekhar et ses collaborateurs, et sur le comptage par nous dans des travaux antérieurs.", "metrics": {"bleu_score": 34.79857106948536, "chrf_score": 70.64895821164946, "xcomet_score": 0.5641617774963379, "xcomet_qe_score": 0.6624354124069214, "metricx_score": 6.228175163269043, "metricx_qe_score": 6.378002166748047, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Le « foiling » signifie essentiellement que nous prenons la légende d'une image et produisons un « foil » en modifiant la légende de telle sorte qu'elle ne décrit plus l'image.", "metrics": {"bleu_score": 54.895488899892044, "chrf_score": 83.66011815312919, "xcomet_score": 0.9235228896141052, "xcomet_qe_score": 0.9660822749137878, "metricx_score": 2.232985258102417, "metricx_qe_score": 5.014932155609131, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous effectuons ces modifications de phrases en nous concentrant sur six éléments spécifiques, tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et l'éntitécoférence, où chaque élément peut consister en un ou plusieurs instruments, au cas où nous trouverions plus d'une manière intéressante de créer des instances FOIL.", "metrics": {"bleu_score": 69.67894476633792, "chrf_score": 83.75305706374331, "xcomet_score": 0.6889463663101196, "xcomet_qe_score": 0.6356038451194763, "metricx_score": 6.18066930770874, "metricx_qe_score": 6.359976768493652, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans le cas de la pièce d'action, nous avons deux instruments : l'un dans lequel le verbe d'action est remplacé par une action différente, et l'autre dans lequel les actants sont échangés.", "metrics": {"bleu_score": 51.5113454600139, "chrf_score": 75.79528287565907, "xcomet_score": 0.582237720489502, "xcomet_qe_score": 0.5922386646270752, "metricx_score": 5.213307857513428, "metricx_qe_score": 5.235644340515137, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la coréférence sont également des pièces qui comportent plus d'un instrument.", "metrics": {"bleu_score": 50.31747626530137, "chrf_score": 71.50229424014427, "xcomet_score": 0.7357687950134277, "xcomet_qe_score": 0.6760996580123901, "metricx_score": 4.577033996582031, "metricx_qe_score": 3.8990001678466797, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous créons ces faux par le fait de nous assurer qu'ils ne parviennent pas à décrire l'image, qu'ils sont des phrases grammaticales et autrement valides.", "metrics": {"bleu_score": 36.76308284763634, "chrf_score": 72.04351537589568, "xcomet_score": 0.6174365282058716, "xcomet_qe_score": 0.5003321170806885, "metricx_score": 8.3626708984375, "metricx_qe_score": 6.612709999084473, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "Ce n'est pas facile à faire parce qu'une légende aFOId peut être moins probable qu'une légende originale.", "metrics": {"bleu_score": 38.488276585047046, "chrf_score": 71.92811947390251, "xcomet_score": 0.7671659588813782, "xcomet_qe_score": 0.7756156921386719, "metricx_score": 10.079859733581543, "metricx_qe_score": 11.971390724182129, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien que ce ne soit pas impossible, il est statistiquement moins probable qu'une plante coupe un homme qu'un homme coupe des plantes, et les grands modèles de vision et de langage pourraient s'en rendre compte.", "metrics": {"bleu_score": 53.61806810457202, "chrf_score": 78.13104091601005, "xcomet_score": 0.785429060459137, "xcomet_qe_score": 0.7641260027885437, "metricx_score": 2.3604583740234375, "metricx_qe_score": 2.572516918182373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour obtenir des lames valides, nous devons agir.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 88.03360259381346, "xcomet_score": 0.8294509649276733, "xcomet_qe_score": 0.8252901434898376, "metricx_score": 3.554013967514038, "metricx_qe_score": 1.5871697664260864, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous utilisons des modèles linguistiques puissants pour proposer des FOIls.", "metrics": {"bleu_score": 50.698033524721, "chrf_score": 73.00327332666059, "xcomet_score": 0.806797981262207, "xcomet_qe_score": 0.6842989921569824, "metricx_score": 4.910693645477295, "metricx_qe_score": 7.083702564239502, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence du langage naturel, ou NLI court, pour filtrer les fichiers qui pourraient encore décrire l'image, car lors de la construction des fichiers, nous devons nous assurer qu'ils ne parviennent pas à décrire l'image.", "metrics": {"bleu_score": 52.13881081163798, "chrf_score": 80.17514677312316, "xcomet_score": 0.6303982734680176, "xcomet_qe_score": 0.7207238078117371, "metricx_score": 7.653842926025391, "metricx_qe_score": 7.093363285064697, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Pour tester cela automatiquement, nous appliquons l'inférence du langage naturel avec la logique suivante.", "metrics": {"bleu_score": 49.025517878204084, "chrf_score": 74.21178809689445, "xcomet_score": 0.9903548955917358, "xcomet_qe_score": 0.9898281097412109, "metricx_score": 1.1603026390075684, "metricx_qe_score": 1.0455312728881836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "Nous considérons une image comme la prémisse, et sa légende comme l'hypothèse qu'elle implique.", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 63.72404157053826, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8080034255981445, "metricx_qe_score": 0.9119473099708557, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous considérons la légende comme la prémisse, et le contre-pied comme son hypothèse.", "metrics": {"bleu_score": 65.40585844910977, "chrf_score": 77.88295004399036, "xcomet_score": 0.6968333721160889, "xcomet_qe_score": 0.6197133660316467, "metricx_score": 4.248615264892578, "metricx_qe_score": 2.5324156284332275, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit que le FOIL contredit ou est neutre par rapport à la légende, nous considérons cela comme un indicateur d'un FOIL valide.", "metrics": {"bleu_score": 59.817595536558535, "chrf_score": 73.33130145135452, "xcomet_score": 0.6695801019668579, "xcomet_qe_score": 0.6926940679550171, "metricx_score": 4.631582736968994, "metricx_qe_score": 5.547378063201904, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si une NLI prédit que le contre-exemple est impliqué par la légende, il ne peut pas être un bon contre-exemple puisqu'il donnera, par transitivité, une description vraie de l'image et nous filtrons ces contre-exemples.", "metrics": {"bleu_score": 39.317734814836555, "chrf_score": 61.47700692144495, "xcomet_score": 0.4747275710105896, "xcomet_qe_score": 0.5081540942192078, "metricx_score": 7.796477794647217, "metricx_qe_score": 6.545897483825684, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cette procédure n'est pas parfaite. Elle n'est qu'un indicateur pour validFOI.", "metrics": {"bleu_score": 32.709154517102014, "chrf_score": 61.79181250200825, "xcomet_score": 0.814982533454895, "xcomet_qe_score": 0.6953263282775879, "metricx_score": 7.8386640548706055, "metricx_qe_score": 8.116120338439941, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, comme troisième mesure pour générer des FOIL valides, nous faisons appel à des annotateurs humains pour valider les données utilisées dans Vse.", "metrics": {"bleu_score": 56.74773954614978, "chrf_score": 77.6911291735901, "xcomet_score": 0.8886541128158569, "xcomet_qe_score": 0.8392504453659058, "metricx_score": 6.3679914474487305, "metricx_qe_score": 8.307456016540527, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, après filtrage et évaluation humaine, nous avons autant d'exemples de test que ceux décrits dans ce tableau.", "metrics": {"bleu_score": 61.79396438001991, "chrf_score": 80.00454727922742, "xcomet_score": 0.9657013416290283, "xcomet_qe_score": 0.9653283357620239, "metricx_score": 1.9923498630523682, "metricx_qe_score": 2.553736686706543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que Valse ne fournit aucune donnée d'entraînement, mais uniquement des données de test.", "metrics": {"bleu_score": 28.304895944141947, "chrf_score": 55.44691955794476, "xcomet_score": 0.9715268611907959, "xcomet_qe_score": 0.9902081489562988, "metricx_score": 2.0744009017944336, "metricx_qe_score": 2.2930359840393066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "puisqu'il s'agit uniquement d'un benchmark de test sans entraînement préalable, il est conçu pour exploiter les capacités existantes des modèles de vision et de langage après l'entraînement préalable.", "metrics": {"bleu_score": 29.348988265841673, "chrf_score": 55.95973555506956, "xcomet_score": 0.8587496280670166, "xcomet_qe_score": 0.8636201620101929, "metricx_score": 3.0514097213745117, "metricx_qe_score": 3.141892910003662, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "Le réglage fin ne permettrait qu'aux modèles d'exploiter des artefacts ou des biais statistiques dans les données.", "metrics": {"bleu_score": 65.91096049931349, "chrf_score": 79.46468247380966, "xcomet_score": 0.9497354030609131, "xcomet_qe_score": 0.9627677798271179, "metricx_score": 1.871721625328064, "metricx_qe_score": 2.2211921215057373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998902082443237, "xcomet_qe_score": 1.0, "metricx_score": 1.3476738929748535, "metricx_qe_score": 2.4462342262268066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et, comme nous l'avons dit, nous sommes intéressés à évaluer les capacités des modèles de vision et de langage après l'entraînement préalable.", "metrics": {"bleu_score": 34.047842630254415, "chrf_score": 65.90920042786969, "xcomet_score": 0.9886112213134766, "xcomet_qe_score": 1.0, "metricx_score": 1.444520115852356, "metricx_qe_score": 1.6707096099853516, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec cinq modèles de vision et de langage sur les voyelles, à savoir avec CCL, Alex Mert, Wilbert, Wilbert 11 en 1 et Visual bird.", "metrics": {"bleu_score": 27.30879756698326, "chrf_score": 53.313841767759975, "xcomet_score": 0.17933231592178345, "xcomet_qe_score": 0.2351928949356079, "metricx_score": 11.428420066833496, "metricx_qe_score": 9.536911964416504, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos métriques d'évaluation les plus importantes sont la précision des modèles dans la classification des paires d'images et de phrases en légendes et FOI.", "metrics": {"bleu_score": 42.098621027254744, "chrf_score": 79.52390366616562, "xcomet_score": 0.7658820152282715, "xcomet_qe_score": 0.8037568926811218, "metricx_score": 4.869454860687256, "metricx_qe_score": 5.214695930480957, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "Peut-être plus pertinent pour cette vidéo, nous allons présenter notre métrique plus permissive, la précision par paire, qui mesure si le score d'alignement de la phrase d'image est plus élevé pour la paire de texte d'image correcte que pour sa paire contrefaite.", "metrics": {"bleu_score": 54.00953186762318, "chrf_score": 71.47867918987662, "xcomet_score": 0.5515322089195251, "xcomet_qe_score": 0.5272539854049683, "metricx_score": 5.791715621948242, "metricx_qe_score": 4.884999752044678, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "Pour plus de mesures et de résultats à leur sujet, consultez notre article.", "metrics": {"bleu_score": 36.15855225145533, "chrf_score": 71.81765130966649, "xcomet_score": 0.9703108072280884, "xcomet_qe_score": 0.9889576435089111, "metricx_score": 2.0646443367004395, "metricx_qe_score": 1.7676552534103394, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats en termes de précision par paire sont présentés ici et ils sont cohérents avec les résultats obtenus avec les autres métriques. Il s'agit du fait que la meilleure performance en zéro coup est réalisée par Wilbert 12 in 1, suivi de Wilbert, Alex Mert Clip et enfin Visual Bir.", "metrics": {"bleu_score": 23.534380053674465, "chrf_score": 57.08031492156008, "xcomet_score": 0.240266352891922, "xcomet_qe_score": 0.2598121166229248, "metricx_score": 9.486041069030762, "metricx_qe_score": 10.757125854492188, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est remarquable de constater que les instruments centrés sur des objets individuels comme l'existence et les phrases nominales sont presque résolus par Wilbert 12 in1, soulignant que les modèles sont capables d'identifier les objets nommés et leur présence dans les images.", "metrics": {"bleu_score": 65.1198766644416, "chrf_score": 85.24064478034288, "xcomet_score": 0.6622790098190308, "xcomet_qe_score": 0.5955138206481934, "metricx_score": 5.487713813781738, "metricx_qe_score": 5.4723052978515625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucune des pièces restantes ne peut être résolue de manière fiable dans nos paramètres d'opposition contradictoire.", "metrics": {"bleu_score": 34.14088641890569, "chrf_score": 65.70281354435463, "xcomet_score": 0.6875821352005005, "xcomet_qe_score": 0.686808705329895, "metricx_score": 6.405132293701172, "metricx_qe_score": 4.488535404205322, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "On constate, à travers les instruments de pluralité et de comptage, que les modèles de vision et de langage ont du mal à distinguer les références à un seul objet par rapport à plusieurs objets ou à les compter dans une image.", "metrics": {"bleu_score": 53.43811692100355, "chrf_score": 75.38614361279483, "xcomet_score": 0.9500389099121094, "xcomet_qe_score": 0.9232500791549683, "metricx_score": 2.027986764907837, "metricx_qe_score": 2.9640707969665527, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "La pièce de relation montre qu'ils ont des difficultés à classer correctement une relation spatiale nommée entre des objets dans une image.", "metrics": {"bleu_score": 90.67110266941049, "chrf_score": 92.93299474142468, "xcomet_score": 0.7587360143661499, "xcomet_qe_score": 0.6939899921417236, "metricx_score": 5.114096641540527, "metricx_qe_score": 5.364658355712891, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "Ils ont également du mal à distinguer les actions et à identifier leurs participants, même si cela est soutenu par des biais de plausibilité, comme nous le voyons dans la section sur les actions.", "metrics": {"bleu_score": 60.41292073836065, "chrf_score": 82.67908818556016, "xcomet_score": 0.8716142773628235, "xcomet_qe_score": 0.8994886875152588, "metricx_score": 2.0253262519836426, "metricx_qe_score": 2.4873149394989014, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "D'après le texte de la conférence, nous apprenons que le fait de retracer plusieurs références au même objet dans une image en utilisant des pronoms est également difficile pour les modèles de vision et de langage.", "metrics": {"bleu_score": 54.81476935712057, "chrf_score": 74.94462745720615, "xcomet_score": 0.6649349331855774, "xcomet_qe_score": 0.7227181196212769, "metricx_score": 4.9684062004089355, "metricx_qe_score": 5.511147975921631, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "À titre de vérification de cohérence, et parce que c'est une expérience intéressante, nous évaluons également deux modèles textuels, GPT un et GPT deux, pour déterminer si Valse est résoluble par ces modèles unimodaux en calculant la perplexité de la légende correcte et de la légende contrefaite, sans image ici, et en prédisant l'entrée avec la perplexité la plus faible.", "metrics": {"bleu_score": 54.44641592297988, "chrf_score": 72.29300944460913, "xcomet_score": 0.6666531562805176, "xcomet_qe_score": 0.7654362916946411, "metricx_score": 6.698134899139404, "metricx_qe_score": 6.064242839813232, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "Si la perplexité est plus élevée pour le texte masqué, nous considérons cela comme une indication que la légende masquée peut souffrir d'un biais de plausibilité ou d'autres biais linguistiques.", "metrics": {"bleu_score": 67.38463979895549, "chrf_score": 83.74827103512747, "xcomet_score": 0.692534863948822, "xcomet_qe_score": 0.6928061246871948, "metricx_score": 4.892007827758789, "metricx_qe_score": 4.442228317260742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est intéressant de constater que, dans certains cas, les modèles GPT basés uniquement sur le texte ont mieux capturé la plausibilité du monde que les modèles de vision et de langage.", "metrics": {"bleu_score": 46.21080293282983, "chrf_score": 73.93207081518625, "xcomet_score": 0.9918035268783569, "xcomet_qe_score": 0.9621990919113159, "metricx_score": 2.8297908306121826, "metricx_qe_score": 3.2190215587615967, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, VAL est une référence qui utilise la lentille des constructions linguistiques pour aider la communauté à améliorer les modèles de vision et de langage en testant rigoureusement leurs capacités d'ancrage visuel.", "metrics": {"bleu_score": 38.15659884752199, "chrf_score": 69.84140343978306, "xcomet_score": 0.398665189743042, "xcomet_qe_score": 0.4643717110157013, "metricx_score": 7.610060691833496, "metricx_qe_score": 7.486800193786621, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que les modèles de vision et de langage identifient bien les objets nommés dans leur présence dans les images, comme le montre l'existence de la pièce, mais ont du mal à fonder leur interdépendance et leurs relations dans les scènes visuelles lorsqu'ils sont forcés de respecter les indicateurs linguistiques.", "metrics": {"bleu_score": 53.653312327831884, "chrf_score": 83.73566650059617, "xcomet_score": 0.594347357749939, "xcomet_qe_score": 0.620630145072937, "metricx_score": 6.220794677734375, "metricx_qe_score": 5.827075481414795, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions vraiment encourager la communauté à utiliser ValAs pour mesurer les progrès réalisés dans le domaine de l'ancrage linguistique avec des modèles de vision et de langage.", "metrics": {"bleu_score": 44.348492631401015, "chrf_score": 73.76239696045876, "xcomet_score": 0.7229381799697876, "xcomet_qe_score": 0.7603373527526855, "metricx_score": 6.94365119934082, "metricx_qe_score": 6.737318515777588, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les valves pourraient être utilisées comme une évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou le réglage fin pour voir si un ensemble de données aide les modèles à s'améliorer sur l'un des aspects testés par les valves.", "metrics": {"bleu_score": 39.58442393362032, "chrf_score": 70.6583275019213, "xcomet_score": 0.6888823509216309, "xcomet_qe_score": 0.7214885950088501, "metricx_score": 9.174391746520996, "metricx_qe_score": 8.031097412109375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "si vous êtes intéressé, consultez les données wallsse sur github et si vous avez des questions, n'hésitez pas à nous contacter", "metrics": {"bleu_score": 68.5115341709536, "chrf_score": 83.02285380912143, "xcomet_score": 0.8195517063140869, "xcomet_qe_score": 0.7994927167892456, "metricx_score": 6.427369594573975, "metricx_qe_score": 6.580848693847656, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kaisura de l'Université de Tokyo.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 84.07538774745196, "xcomet_score": 0.5718578100204468, "xcomet_qe_score": 0.6083223819732666, "metricx_score": 5.716151714324951, "metricx_qe_score": 6.71976375579834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter un article intitulé « O En sum : un désert à grande échelle pour la notation automatique et la comxiisation ».", "metrics": {"bleu_score": 22.718716287659607, "chrf_score": 49.67625048689314, "xcomet_score": 0.14520381391048431, "xcomet_qe_score": 0.14952000975608826, "metricx_score": 18.079011917114258, "metricx_qe_score": 19.546592712402344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "Avez-vous de l'expérience dans ce domaine ?", "metrics": {"bleu_score": 5.693025330278465, "chrf_score": 25.58087978345717, "xcomet_score": 0.12209061533212662, "xcomet_qe_score": 0.10666011273860931, "metricx_score": 18.044025421142578, "metricx_qe_score": 22.2884464263916, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je vais présenter la liste automatique de non-durée sur laquelle nous travaillons dans cette recherche.", "metrics": {"bleu_score": 62.682008780706, "chrf_score": 77.61836453083939, "xcomet_score": 0.4107903242111206, "xcomet_qe_score": 0.3668021261692047, "metricx_score": 11.87563705444336, "metricx_qe_score": 11.397846221923828, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "La note de mise à jour est un document technique qui résume les changements distribués avec chaque version d'un produit logiciel.", "metrics": {"bleu_score": 51.23350305765596, "chrf_score": 71.75247158577926, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5716398358345032, "metricx_qe_score": 0.45924487709999084, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'image montre la note de poignet pour la version 2.6", "metrics": {"bleu_score": 9.650666943528389, "chrf_score": 35.57133093578248, "xcomet_score": 0.1432211995124817, "xcomet_qe_score": 0.1561414748430252, "metricx_score": 11.866894721984863, "metricx_qe_score": 16.695222854614258, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Bibliothèque JavaScript. Ces notes jouent un rôle important dans le développement open source, mais elles prennent beaucoup de temps à préparer manuellement.", "metrics": {"bleu_score": 51.32029568291751, "chrf_score": 70.23540660916912, "xcomet_score": 0.1644745171070099, "xcomet_qe_score": 0.10737485438585281, "metricx_score": 10.5453519821167, "metricx_qe_score": 12.932703018188477, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Il serait donc très utile de pouvoir générer automatiquement un nœud de libération de haute qualité.", "metrics": {"bleu_score": 39.84098807009827, "chrf_score": 67.09601732884029, "xcomet_score": 0.6026244163513184, "xcomet_qe_score": 0.6385097503662109, "metricx_score": 5.851921558380127, "metricx_qe_score": 4.983207702636719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais me référer à deux recherches antérieures sur la génération automatique d'écoute.", "metrics": {"bleu_score": 47.13585889212891, "chrf_score": 68.0589987539966, "xcomet_score": 0.5898422002792358, "xcomet_qe_score": 0.6104273796081543, "metricx_score": 8.685425758361816, "metricx_qe_score": 9.022918701171875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier est un système appelé a. Il a été lancé en 2014", "metrics": {"bleu_score": 19.67497981115564, "chrf_score": 37.13024469264154, "xcomet_score": 0.2034417986869812, "xcomet_qe_score": 0.3036249876022339, "metricx_score": 10.520392417907715, "metricx_qe_score": 9.356431007385254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "adopte une approche basée sur des règles, par exemple, en utilisant l'extracteur de modifications pour extraire les différences fondamentales, les modifications de bibliothèque et les modifications de documents à partir des différences entre les versions, et en les combinant enfin.", "metrics": {"bleu_score": 56.90386124196765, "chrf_score": 75.30901279759311, "xcomet_score": 0.7619543671607971, "xcomet_qe_score": 0.8475067615509033, "metricx_score": 4.552639484405518, "metricx_qe_score": 3.4407541751861572, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus notable de ce système est l'icône d'extraction de données dans le coin supérieur droit.", "metrics": {"bleu_score": 68.59238121837059, "chrf_score": 81.85631684366292, "xcomet_score": 0.8721339106559753, "xcomet_qe_score": 0.944656491279602, "metricx_score": 4.3375725746154785, "metricx_qe_score": 4.260319709777832, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "Cela doit être lié à Jira, l'écosystème des problèmes, et ne peut être appliqué qu'aux projets qui utilisent Jira.", "metrics": {"bleu_score": 51.40873715205899, "chrf_score": 76.90869756364032, "xcomet_score": 0.6850920915603638, "xcomet_qe_score": 0.629651665687561, "metricx_score": 5.931578159332275, "metricx_qe_score": 5.618244647979736, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, il ne peut pas être utilisé pour de nombreux projets sur GitHub.", "metrics": {"bleu_score": 84.82198619370465, "chrf_score": 91.46112044357582, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5660356283187866, "metricx_qe_score": 0.6357637643814087, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "Le deuxième est un deuil récemment annoncé dans Vingt", "metrics": {"bleu_score": 5.0735520042259505, "chrf_score": 41.34879817720643, "xcomet_score": 0.1642225682735443, "xcomet_qe_score": 0.21192196011543274, "metricx_score": 18.515228271484375, "metricx_qe_score": 15.088472366333008, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "vingt Il est disponible sur Internet et peut être stocké via Peep.", "metrics": {"bleu_score": 20.78060434846712, "chrf_score": 60.5089745843309, "xcomet_score": 0.14891143143177032, "xcomet_qe_score": 0.14835873246192932, "metricx_score": 15.963376998901367, "metricx_qe_score": 16.276891708374023, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système utilise un modèle de classification de texte basé sur un fonctionnement simple et génère cinq paramètres, tels que des fonctionnalités ou des corrections de bogues, pour chaque message de commit d'entrée.", "metrics": {"bleu_score": 31.742216972240694, "chrf_score": 57.534533995921144, "xcomet_score": 0.5414218902587891, "xcomet_qe_score": 0.6297299861907959, "metricx_score": 5.024505615234375, "metricx_qe_score": 5.150660037994385, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un exemple d'utilisation qui renvoie un cerable corrigé ou corrigé d'un bogue.", "metrics": {"bleu_score": 32.547779910216, "chrf_score": 58.59591069406951, "xcomet_score": 0.5088833570480347, "xcomet_qe_score": 0.45872762799263, "metricx_score": 9.009242057800293, "metricx_qe_score": 8.84714126586914, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "Les données d'entraînement de Quifer sont assez limitées, environ cinq mille, et seront présentées dans les expériences décrites ci-dessous.", "metrics": {"bleu_score": 51.43894472390287, "chrf_score": 71.77804171727095, "xcomet_score": 0.6010042428970337, "xcomet_qe_score": 0.6293977499008179, "metricx_score": 8.424123764038086, "metricx_qe_score": 9.604981422424316, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "Les performances du modèle de classification de texte ne sont pas élevées.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6730300188064575, "metricx_qe_score": 0.8122236728668213, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches connexes, mais il y a des problèmes d'applicabilité limitée et de ressources de données rares.", "metrics": {"bleu_score": 48.45766087853282, "chrf_score": 82.35147828234967, "xcomet_score": 0.9677211046218872, "xcomet_qe_score": 0.9111800193786621, "metricx_score": 1.0704854726791382, "metricx_qe_score": 1.2610890865325928, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des résultats de haute qualité.", "metrics": {"bleu_score": 70.0418991088418, "chrf_score": 82.96714507848351, "xcomet_score": 0.8807588219642639, "xcomet_qe_score": 0.9289770126342773, "metricx_score": 1.991029143333435, "metricx_qe_score": 3.3552396297454834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Avec un programme ACO limité, nous proposons une méthode de résumé de classificateur de haute qualité utilisant uniquement le message de commit comme entrée.", "metrics": {"bleu_score": 26.803820153629978, "chrf_score": 54.064807344469465, "xcomet_score": 0.5494024157524109, "xcomet_qe_score": 0.5823681354522705, "metricx_score": 9.344907760620117, "metricx_qe_score": 10.035181045532227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée pour toutes les entrées de bibliothèque de livres en anglais.", "metrics": {"bleu_score": 39.56716729452429, "chrf_score": 73.01947755143163, "xcomet_score": 0.8406970500946045, "xcomet_qe_score": 0.951979398727417, "metricx_score": 3.863349437713623, "metricx_qe_score": 3.0502407550811768, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème des ressources effrayantes, nous avons construit notre propre base de données composée d'environ quatre-vingt-deux mille données en corrigeant les données provenant de dépôts publics GitHub en utilisant l'API GitHub.", "metrics": {"bleu_score": 28.47966518385993, "chrf_score": 67.76159423161707, "xcomet_score": 0.548869252204895, "xcomet_qe_score": 0.5201746225357056, "metricx_score": 12.419900894165039, "metricx_qe_score": 11.747875213623047, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décris notre désert.", "metrics": {"bleu_score": 22.772101321113862, "chrf_score": 41.252730026822185, "xcomet_score": 0.3890964388847351, "xcomet_qe_score": 0.4221149682998657, "metricx_score": 12.627046585083008, "metricx_qe_score": 13.441385269165039, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre exemple de données.", "metrics": {"bleu_score": 53.7284965911771, "chrf_score": 76.85915067385532, "xcomet_score": 0.946622908115387, "xcomet_qe_score": 0.9420696496963501, "metricx_score": 0.9208157062530518, "metricx_qe_score": 1.0900479555130005, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche est un message de commit, sur le côté droit se trouve sa note.", "metrics": {"bleu_score": 41.180376356915765, "chrf_score": 51.47029675094631, "xcomet_score": 0.731848955154419, "xcomet_qe_score": 0.6859049797058105, "metricx_score": 5.562530040740967, "metricx_qe_score": 6.22825813293457, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "Ces notes sont présentées comme des améliorations de bureaux, etc.", "metrics": {"bleu_score": 14.820988823055043, "chrf_score": 46.224410623369614, "xcomet_score": 0.5487716197967529, "xcomet_qe_score": 0.5680465698242188, "metricx_score": 10.753678321838379, "metricx_qe_score": 11.084146499633789, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons configuré une tâche qui prend les messages de commit en entrée et produit le nœud rabbit.", "metrics": {"bleu_score": 29.699432487416427, "chrf_score": 41.56703444102168, "xcomet_score": 0.5977902412414551, "xcomet_qe_score": 0.6355010867118835, "metricx_score": 10.525676727294922, "metricx_qe_score": 11.301074981689453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de résumé.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 80.28616903243483, "xcomet_score": 0.9564080238342285, "xcomet_qe_score": 0.9850058555603027, "metricx_score": 1.28573477268219, "metricx_qe_score": 0.8809378743171692, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons prédéfini quatre types de modifications : fonctionnalités, améliorations, corrections de bogues, dépréciations, suppressions et modifications de freinage.", "metrics": {"bleu_score": 33.573064840973224, "chrf_score": 77.2560174343184, "xcomet_score": 0.5327775478363037, "xcomet_qe_score": 0.4911785423755646, "metricx_score": 8.791494369506836, "metricx_qe_score": 7.418725967407227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces normes ont été établies en fonction de l'utilisation des porcs et d'autres facteurs.", "metrics": {"bleu_score": 24.601372576927535, "chrf_score": 45.95728811569479, "xcomet_score": 0.2944943904876709, "xcomet_qe_score": 0.2227175533771515, "metricx_score": 11.106027603149414, "metricx_qe_score": 10.7830810546875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a des notes en bas à droite et extraites de la liste des notes affichées en bas à gauche.", "metrics": {"bleu_score": 29.4467310498826, "chrf_score": 53.50043265511314, "xcomet_score": 0.5584721565246582, "xcomet_qe_score": 0.6204391717910767, "metricx_score": 7.713593482971191, "metricx_qe_score": 8.7010498046875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce moment, il est nécessaire de détecter les quatre lapins qui ont été placés dans un passage.", "metrics": {"bleu_score": 43.09809162747323, "chrf_score": 57.29671852907604, "xcomet_score": 0.2278590202331543, "xcomet_qe_score": 0.1825108826160431, "metricx_score": 14.485732078552246, "metricx_qe_score": 15.74592399597168, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les lèvres ne sont pas toujours cohérentes entre elles.", "metrics": {"bleu_score": 38.09694917244036, "chrf_score": 55.38003651542681, "xcomet_score": 0.38437607884407043, "xcomet_qe_score": 0.2938292622566223, "metricx_score": 14.892719268798828, "metricx_qe_score": 16.599557876586914, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, de telles améliorations encouragent plutôt des améliorations, des perfectionnements, des optimisations, et ainsi de suite.", "metrics": {"bleu_score": 43.41999352730602, "chrf_score": 76.14953541985864, "xcomet_score": 0.7164740562438965, "xcomet_qe_score": 0.6124309301376343, "metricx_score": 8.99610424041748, "metricx_qe_score": 9.658878326416016, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste de vocabulaire d'environ trente chiffres pour chacune de ces variations de notation.", "metrics": {"bleu_score": 71.60350546947924, "chrf_score": 79.02177084238171, "xcomet_score": 0.7760843634605408, "xcomet_qe_score": 0.7560725808143616, "metricx_score": 8.458165168762207, "metricx_qe_score": 8.558452606201172, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez-le pour détecter s'il n'y a pas de croûtes, et citez le texte du reste qui suit, car il n'y a pas de phrase ou de croûte.", "metrics": {"bleu_score": 4.323317055456997, "chrf_score": 29.17916214872279, "xcomet_score": 0.12473471462726593, "xcomet_qe_score": 0.1267583668231964, "metricx_score": 20.248394012451172, "metricx_qe_score": 20.321998596191406, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, il y a un message de commit.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 68.6805532750581, "xcomet_score": 0.8390024900436401, "xcomet_qe_score": 0.9567588567733765, "metricx_score": 4.6736555099487305, "metricx_qe_score": 4.267538070678711, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de Comer ne sont pas liés à chaque voix.", "metrics": {"bleu_score": 54.52469119630866, "chrf_score": 64.01915260654768, "xcomet_score": 0.3327700197696686, "xcomet_qe_score": 0.33775267004966736, "metricx_score": 15.54589557647705, "metricx_qe_score": 13.803764343261719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "Comme le montre l'image ci-dessous, si le risque actuel est supérieur à 2,5 à 19, nous devons identifier", "metrics": {"bleu_score": 20.845510252184262, "chrf_score": 41.668626509607755, "xcomet_score": 0.22068491578102112, "xcomet_qe_score": 0.23505160212516785, "metricx_score": 22.763532638549805, "metricx_qe_score": 20.860193252563477, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "Selon les versions précédentes des devoirs, de deux à dix-huit, et faites-le bien. C'est un peu fastidieux, et ce n'est pas suffisant de simplement obtenir une liste des versions et de regarder le avant et l'après.", "metrics": {"bleu_score": 15.60154507253141, "chrf_score": 65.32958473134136, "xcomet_score": 0.12760576605796814, "xcomet_qe_score": 0.1322093904018402, "metricx_score": 22.279666900634766, "metricx_qe_score": 21.863956451416016, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons créé une colle d'appariement heuristique pour obtenir les versions précédente et suivante.", "metrics": {"bleu_score": 40.53746225697867, "chrf_score": 63.64298730711314, "xcomet_score": 0.5994235277175903, "xcomet_qe_score": 0.5210878849029541, "metricx_score": 8.204167366027832, "metricx_qe_score": 8.008323669433594, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "Ils s'assoient sur l'infirmière.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 9.075907590759074, "xcomet_score": 0.09423098713159561, "xcomet_qe_score": 0.07475781440734863, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "Au final, 7 200 dépôts.", "metrics": {"bleu_score": 1.3493313280850905, "chrf_score": 6.9315244870094075, "xcomet_score": 0.14163926243782043, "xcomet_qe_score": 0.14601045846939087, "metricx_score": 20.874006271362305, "metricx_qe_score": 20.493770599365234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de cibles raisonnables est de soixante-trois, ce qui est assez élevé pour les tâches de résumé.", "metrics": {"bleu_score": 47.761152007880774, "chrf_score": 59.76202015234513, "xcomet_score": 0.5374202728271484, "xcomet_qe_score": 0.44378945231437683, "metricx_score": 11.084476470947266, "metricx_qe_score": 8.450703620910645, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre de jetons uniques est assez élevé, à huit millions huit cent trente mille. C'est", "metrics": {"bleu_score": 37.62957149383416, "chrf_score": 62.205591230110116, "xcomet_score": 0.36145687103271484, "xcomet_qe_score": 0.3201407492160797, "metricx_score": 11.013885498046875, "metricx_qe_score": 7.952822685241699, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "en raison du grand nombre de noms de méthodes uniques trouvés en laboratoire.", "metrics": {"bleu_score": 20.23302501778005, "chrf_score": 50.21244032090609, "xcomet_score": 0.24933581054210663, "xcomet_qe_score": 0.25626635551452637, "metricx_score": 8.554696083068848, "metricx_qe_score": 7.758387088775635, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, j'expliquerai la méthode proposée.", "metrics": {"bleu_score": 36.74145494215666, "chrf_score": 75.59105076499984, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26971232891082764, "metricx_qe_score": 0.1778177171945572, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de résumé extractif et abstratif transversal se compose de deux modules neuronaux.", "metrics": {"bleu_score": 46.029511774162, "chrf_score": 60.6102436641934, "xcomet_score": 0.8118475675582886, "xcomet_qe_score": 0.8203780651092529, "metricx_score": 4.067645072937012, "metricx_qe_score": 2.9339873790740967, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "Un tir croisé utilisant une barre ou appelé barre, et le générateur utilisant Bart.", "metrics": {"bleu_score": 6.690080689159478, "chrf_score": 43.436795488795255, "xcomet_score": 0.1481878161430359, "xcomet_qe_score": 0.1358412802219391, "metricx_score": 20.031673431396484, "metricx_qe_score": 21.722383499145508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "First cs utilise un classificateur pour classer chaque message de commit en cinq classes de nœuds de base : fonctionnalités implémentées, corrections de bugs, dépréciations et autres.", "metrics": {"bleu_score": 29.784750149958793, "chrf_score": 56.67067269093079, "xcomet_score": 0.3089280128479004, "xcomet_qe_score": 0.3106655776500702, "metricx_score": 10.251445770263672, "metricx_qe_score": 10.090616226196289, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages du comité sont classés comme « a » ou écartés.", "metrics": {"bleu_score": 9.669265690880861, "chrf_score": 45.168667940379876, "xcomet_score": 0.3277682960033417, "xcomet_qe_score": 0.4863691031932831, "metricx_score": 11.193418502807617, "metricx_qe_score": 11.011781692504883, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Puis elle attribue un prix à chaque document en caoutchouc indépendamment et génère cette note pour chaque classe.", "metrics": {"bleu_score": 16.49807842102966, "chrf_score": 45.83694209875077, "xcomet_score": 0.1474350392818451, "xcomet_qe_score": 0.14698171615600586, "metricx_score": 17.877702713012695, "metricx_qe_score": 16.583377838134766, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages de commit et les ressources ne sont pas connues.", "metrics": {"bleu_score": 65.74012849085679, "chrf_score": 74.88263771878093, "xcomet_score": 0.773914098739624, "xcomet_qe_score": 0.8014992475509644, "metricx_score": 5.18743896484375, "metricx_qe_score": 6.035212516784668, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour entraîner le classificateur, nous attribuons des pseudo-rubriques à chaque message de commit d'entrée en utilisant les dix premiers caractères de chaque message de commit.", "metrics": {"bleu_score": 50.97049681318311, "chrf_score": 67.3584436445161, "xcomet_score": 0.5555094480514526, "xcomet_qe_score": 0.7592541575431824, "metricx_score": 6.748652935028076, "metricx_qe_score": 5.713391304016113, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons la somme des sommes destructives pour l'approcher par deux méthodes définies.", "metrics": {"bleu_score": 6.649479326478728, "chrf_score": 42.77929104485726, "xcomet_score": 0.1820777952671051, "xcomet_qe_score": 0.20820394158363342, "metricx_score": 18.514707565307617, "metricx_qe_score": 19.036731719970703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons gs single, se compose d'un seul réseau de six et génère un seul long texte, voire un texte donné, à partir d'une concaténation de messages de commit d'entrée.", "metrics": {"bleu_score": 34.00657349553067, "chrf_score": 55.81614033409322, "xcomet_score": 0.11845478415489197, "xcomet_qe_score": 0.16797645390033722, "metricx_score": 12.303972244262695, "metricx_qe_score": 12.158805847167969, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte extérieur peut être divisé en segments transversaux basés sur des symboles spécifiques et des croix particulières.", "metrics": {"bleu_score": 3.831334149190149, "chrf_score": 43.78897826884875, "xcomet_score": 0.1927838921546936, "xcomet_qe_score": 0.1617637723684311, "metricx_score": 9.378031730651855, "metricx_qe_score": 8.405985832214355, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons shes much, consiste en quatre réseaux différents sec-to sec, chacun correspondant à l'une des classes de nœuds les moins importants.", "metrics": {"bleu_score": 26.819138266841293, "chrf_score": 56.784773360478745, "xcomet_score": 0.06903817504644394, "xcomet_qe_score": 0.0664169043302536, "metricx_score": 18.748491287231445, "metricx_qe_score": 17.452653884887695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, laissez-moi expliquer l'expérience.", "metrics": {"bleu_score": 6.4790667469036025, "chrf_score": 47.210365058958445, "xcomet_score": 0.9313861131668091, "xcomet_qe_score": 0.9775118827819824, "metricx_score": 1.1269221305847168, "metricx_qe_score": 0.8525193333625793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été comparées : she is, she a singer, she has smiled, pressing et Bri a étudié le deuil.", "metrics": {"bleu_score": 21.592878551044475, "chrf_score": 38.225539032427385, "xcomet_score": 0.1321001648902893, "xcomet_qe_score": 0.13635890185832977, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'aberration, dans certains cas, ce n'est pas notre résultat en plusieurs phrases.", "metrics": {"bleu_score": 42.1957770596773, "chrf_score": 62.07531913292376, "xcomet_score": 0.15009047091007233, "xcomet_qe_score": 0.15201273560523987, "metricx_score": 18.98227882385254, "metricx_qe_score": 19.489852905273438, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Puisqu'il est difficile de corriger le nombre de phrases à zéro, elles sont combinées avec des espaces et traitées comme une phrase longue.", "metrics": {"bleu_score": 60.344376594610615, "chrf_score": 75.97108602633853, "xcomet_score": 0.5689616203308105, "xcomet_qe_score": 0.5182340145111084, "metricx_score": 8.872669219970703, "metricx_qe_score": 10.391613960266113, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "La facture est imprimée lorsque le système affiche une courte phrase.", "metrics": {"bleu_score": 16.108992769687397, "chrf_score": 48.457493737004015, "xcomet_score": 0.3020865321159363, "xcomet_qe_score": 0.23704349994659424, "metricx_score": 12.36536693572998, "metricx_qe_score": 11.114218711853027, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité, qui a entraîné une valeur de bre inférieure dans l'expérience, est donc décrite ci-dessous.", "metrics": {"bleu_score": 8.562365224473284, "chrf_score": 58.345554131836884, "xcomet_score": 0.6540701389312744, "xcomet_qe_score": 0.6239657402038574, "metricx_score": 9.616864204406738, "metricx_qe_score": 10.98932933807373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons également une spécificité car rouge et brew ne peuvent pas être caricaturés si les notes du poignet sont vides.", "metrics": {"bleu_score": 24.02754880721053, "chrf_score": 61.09789927580677, "xcomet_score": 0.24204516410827637, "xcomet_qe_score": 0.21246632933616638, "metricx_score": 17.450626373291016, "metricx_qe_score": 19.224445343017578, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une spécificité élevée signifie que le modèle produit correctement du texte vide dans les cas où le nœud de lecture suppose du vide.", "metrics": {"bleu_score": 43.59194119849398, "chrf_score": 67.93443654413153, "xcomet_score": 0.812209963798523, "xcomet_qe_score": 0.9541662931442261, "metricx_score": 3.8778228759765625, "metricx_qe_score": 3.8615238666534424, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats.", "metrics": {"bleu_score": 11.521590992286539, "chrf_score": 34.57828622839441, "xcomet_score": 0.7604808807373047, "xcomet_qe_score": 1.0, "metricx_score": 0.15108263492584229, "metricx_qe_score": 0.03296280279755592, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que l'ensemble de données contient des adresses e-mail, des valeurs, etc., nous évaluons également les données propres qui les excluent.", "metrics": {"bleu_score": 24.05628925629994, "chrf_score": 60.98965875454406, "xcomet_score": 0.7189760208129883, "xcomet_qe_score": 0.7012319564819336, "metricx_score": 7.623940944671631, "metricx_qe_score": 9.232233047485352, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "Le CAS et le CAS ont obtenu des scores aériens nettement supérieurs, de plus de dix points au-dessus des valeurs de référence.", "metrics": {"bleu_score": 41.65767636794608, "chrf_score": 59.553210055572045, "xcomet_score": 0.2192566990852356, "xcomet_qe_score": 0.15750862658023834, "metricx_score": 13.984399795532227, "metricx_qe_score": 14.39073657989502, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur l'ensemble de test coréen, l'écart de score entre la méthode proposée et le saut du patient est supérieur à 20 points", "metrics": {"bleu_score": 53.11613208274919, "chrf_score": 71.13212302750898, "xcomet_score": 0.1849457323551178, "xcomet_qe_score": 0.10419435799121857, "metricx_score": 13.387566566467285, "metricx_qe_score": 14.989888191223145, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent que les « sheas » et les « hes » sont significativement efficaces.", "metrics": {"bleu_score": 16.467029855845905, "chrf_score": 48.242392461300895, "xcomet_score": 0.1367289423942566, "xcomet_qe_score": 0.1487138569355011, "metricx_score": 18.326215744018555, "metricx_qe_score": 16.858125686645508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "g a obtenu un meilleur score logique que g, ce qui suggère que la combinaison d'un classificateur et d'un générateur est efficace pour entraîner le classificateur en utilisant.", "metrics": {"bleu_score": 54.93979344647793, "chrf_score": 70.86800872570099, "xcomet_score": 0.13411672413349152, "xcomet_qe_score": 0.126979798078537, "metricx_score": 22.604190826416016, "metricx_qe_score": 21.77305030822754, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "Une couverture élevée des Gs peut être obtenue correctement car le classificateur peut se concentrer sur la sélection des messages de commit pertinents pour chaque classe.", "metrics": {"bleu_score": 64.32343886784393, "chrf_score": 81.19070510798917, "xcomet_score": 0.5041203498840332, "xcomet_qe_score": 0.5926402807235718, "metricx_score": 9.780823707580566, "metricx_qe_score": 9.758626937866211, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Elle a tendance à manger beaucoup plus de littérature de qualité qu'elle seule.", "metrics": {"bleu_score": 6.754312828675707, "chrf_score": 21.506990468228736, "xcomet_score": 0.12233901768922806, "xcomet_qe_score": 0.10881687700748444, "metricx_score": 25.0, "metricx_qe_score": 24.44033432006836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "Sugg suggère qu'il est également efficace de développer indépendamment différents modèles de résumé perceptif pour chaque graphe de nœud.", "metrics": {"bleu_score": 29.941991420602715, "chrf_score": 56.649404967686536, "xcomet_score": 0.23943525552749634, "xcomet_qe_score": 0.34094810485839844, "metricx_score": 5.281868934631348, "metricx_qe_score": 5.101947784423828, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "Ici et Araasis.", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 7.682121607894353, "xcomet_score": 0.1116931140422821, "xcomet_qe_score": 0.09849734604358673, "metricx_score": 20.48834800720215, "metricx_qe_score": 20.6571044921875, "linguapy_score": [1, "SHONA"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes de Shear ont tendance à produire des phrases plus courtes que la phrase de référence humaine.", "metrics": {"bleu_score": 50.14129877526366, "chrf_score": 82.89412232710582, "xcomet_score": 0.48645567893981934, "xcomet_qe_score": 0.384705513715744, "metricx_score": 10.432273864746094, "metricx_qe_score": 12.831268310546875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure à droite, la phrase différente a trois ou quatre phrases, alors qu'elle n'en a qu'une.", "metrics": {"bleu_score": 44.4672506981276, "chrf_score": 68.42230840190624, "xcomet_score": 0.3362983465194702, "xcomet_qe_score": 0.2434108406305313, "metricx_score": 12.631080627441406, "metricx_qe_score": 13.486886978149414, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette réticence moderne est que dans les données d'entraînement, seulement trente-trois pour cent des phrases sont présentes au niveau des caractéristiques et quarante pour cent dans les améliorations.", "metrics": {"bleu_score": 45.63365703433091, "chrf_score": 69.97058702950099, "xcomet_score": 0.5660622119903564, "xcomet_qe_score": 0.5890092849731445, "metricx_score": 6.502789497375488, "metricx_qe_score": 6.242063522338867, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes des CS ne peuvent pas générer de nœud de risque précis sans informations supplémentaires.", "metrics": {"bleu_score": 30.752616970214323, "chrf_score": 70.39536306210665, "xcomet_score": 0.3993692994117737, "xcomet_qe_score": 0.40620696544647217, "metricx_score": 10.966630935668945, "metricx_qe_score": 9.305704116821289, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple en haut à droite est un exemple de message com très désordonné, et la phrase complète ne peut pas être générée sans faire référence au privilège ou au problème correspondant.", "metrics": {"bleu_score": 63.730421054978585, "chrf_score": 79.45624859637313, "xcomet_score": 0.6588187217712402, "xcomet_qe_score": 0.5883249640464783, "metricx_score": 7.957548141479492, "metricx_qe_score": 6.802733421325684, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous montre que les deux messages de commit dans l'entrée sont liés et devraient être combinés en une seule phrase, mais il ne parvient pas à le faire.", "metrics": {"bleu_score": 39.0944313761396, "chrf_score": 69.35618355922927, "xcomet_score": 0.8577835559844971, "xcomet_qe_score": 0.9136546850204468, "metricx_score": 5.396671772003174, "metricx_qe_score": 5.279102325439453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, une conclusion.", "metrics": {"bleu_score": 20.252884954471366, "chrf_score": 51.7870301786907, "xcomet_score": 0.9809033870697021, "xcomet_qe_score": 1.0, "metricx_score": 1.8073315620422363, "metricx_qe_score": 2.418452262878418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons créé un nouveau jeu de données pour la génération automatique d'entreprises.", "metrics": {"bleu_score": 30.315070099566324, "chrf_score": 59.66387305709778, "xcomet_score": 0.4727686941623688, "xcomet_qe_score": 0.5597474575042725, "metricx_score": 13.269384384155273, "metricx_qe_score": 13.909401893615723, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également formulé la tâche de saisie des messages du comité et les avons résumés de manière à ce qu'ils soient applicables à tous les projets rédigés en anglais.", "metrics": {"bleu_score": 33.99033059205809, "chrf_score": 64.70508809041509, "xcomet_score": 0.7911288738250732, "xcomet_qe_score": 0.6968502998352051, "metricx_score": 3.8680355548858643, "metricx_qe_score": 3.792196750640869, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que le courant musculaire moins bruyant proposé n'est pas à une couverture plus élevée que la ligne de base.", "metrics": {"bleu_score": 34.53786557868503, "chrf_score": 63.71812262728395, "xcomet_score": 0.16683128476142883, "xcomet_qe_score": 0.17869450151920319, "metricx_score": 18.72047233581543, "metricx_qe_score": 14.727317810058594, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Vérifiez d'abord Dieu ou le désert en haut.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 13.662861515129679, "xcomet_score": 0.1254669576883316, "xcomet_qe_score": 0.11243991553783417, "metricx_score": 20.08290672302246, "metricx_qe_score": 18.870290756225586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10382990539073944, "metricx_qe_score": 0.4022793173789978, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Safari.", "metrics": {"bleu_score": 9.042266054940777, "chrf_score": 51.95600869804089, "xcomet_score": 0.15911778807640076, "xcomet_qe_score": 0.1166134923696518, "metricx_score": 7.403709888458252, "metricx_qe_score": 6.702765464782715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "Et je représente notre enrichissement de données tabulaires papier Fu en utilisant des architectures de transformateurs affinés.", "metrics": {"bleu_score": 15.752704249126122, "chrf_score": 61.04237951975351, "xcomet_score": 0.5156224966049194, "xcomet_qe_score": 0.3900204002857208, "metricx_score": 13.287924766540527, "metricx_qe_score": 12.27415943145752, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "Un scientifique analyse-t-il des données et se concentre-t-il principalement sur la manipulation des caractéristiques existantes des données ?", "metrics": {"bleu_score": 33.08548466798255, "chrf_score": 75.6539232347687, "xcomet_score": 0.6046949028968811, "xcomet_qe_score": 0.5326617956161499, "metricx_score": 5.3943305015563965, "metricx_qe_score": 6.755790710449219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "Mais parfois ses fonctionnalités sont limitées.", "metrics": {"bleu_score": 26.647313141084275, "chrf_score": 76.94819920746691, "xcomet_score": 0.96598219871521, "xcomet_qe_score": 0.969377875328064, "metricx_score": 0.4936392307281494, "metricx_qe_score": 0.3298269808292389, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "La génération de caractéristiques à l'aide d'une autre source de données peut ajouter des informations substantielles.", "metrics": {"bleu_score": 63.019085559238604, "chrf_score": 78.13911569774599, "xcomet_score": 0.9807618856430054, "xcomet_qe_score": 1.0, "metricx_score": 1.872923493385315, "metricx_qe_score": 1.3984712362289429, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique des données tabulaires à l'aide de sources externes en texte libre.", "metrics": {"bleu_score": 43.200373340115924, "chrf_score": 80.324139365827, "xcomet_score": 0.9968491792678833, "xcomet_qe_score": 1.0, "metricx_score": 0.6752551794052124, "metricx_qe_score": 0.977837860584259, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Supposons que nous ayons un ensemble de données tabulaires et une base de connaissances.", "metrics": {"bleu_score": 64.75445426291287, "chrf_score": 89.73182752598848, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7479367256164551, "metricx_qe_score": 0.9663262367248535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique qui implique le lien et l'analyse de texte pour extraire de nouvelles fonctionnalités à partir du texte libre de la base de connaissances.", "metrics": {"bleu_score": 71.00661444783827, "chrf_score": 87.28474332059605, "xcomet_score": 0.7324849963188171, "xcomet_qe_score": 0.7054352760314941, "metricx_score": 2.2280945777893066, "metricx_qe_score": 3.192950963973999, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre, d'abord, est exactement ce processus automatique.", "metrics": {"bleu_score": 51.93071778680675, "chrf_score": 83.0239016113388, "xcomet_score": 0.6430084109306335, "xcomet_qe_score": 0.5870615243911743, "metricx_score": 9.331979751586914, "metricx_qe_score": 14.827659606933594, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Supposons donc un exemple de jeu de données fourni à fest.", "metrics": {"bleu_score": 14.323145079400492, "chrf_score": 42.96444512716665, "xcomet_score": 0.5597929954528809, "xcomet_qe_score": 0.523686408996582, "metricx_score": 7.778430938720703, "metricx_qe_score": 6.6843767166137695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le jeu de données est un jeu de données universitaire.", "metrics": {"bleu_score": 18.92240568795936, "chrf_score": 71.44394706558398, "xcomet_score": 0.9318212270736694, "xcomet_qe_score": 0.8916794657707214, "metricx_score": 0.7501013278961182, "metricx_qe_score": 0.731359601020813, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "et son objectif est de classer les universités en universités de faible rang et en universités de haut rang.", "metrics": {"bleu_score": 69.3395566222006, "chrf_score": 86.2415035388041, "xcomet_score": 0.8294322490692139, "xcomet_qe_score": 0.8800429105758667, "metricx_score": 3.276940107345581, "metricx_qe_score": 2.785893678665161, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons Wikipedia comme base de connaissances.", "metrics": {"bleu_score": 16.0529461904344, "chrf_score": 68.12699120128313, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.24026861786842346, "metricx_qe_score": 0.1657801866531372, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase du fest est le couplage d'entités.", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 56.88707854192824, "xcomet_score": 0.5768506526947021, "xcomet_qe_score": 0.5470646023750305, "metricx_score": 6.620226860046387, "metricx_qe_score": 6.365229606628418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, chaque entité, le nom de l'université est lié à une entité dans la base de connaissances.", "metrics": {"bleu_score": 40.81277330545599, "chrf_score": 73.26124503795968, "xcomet_score": 0.9952373504638672, "xcomet_qe_score": 0.9910614490509033, "metricx_score": 2.796889543533325, "metricx_qe_score": 4.040868282318115, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte des entités de la base de connaissances est extrait et ajouté au jeu de données.", "metrics": {"bleu_score": 67.36041912625802, "chrf_score": 89.91782906832555, "xcomet_score": 0.9177287220954895, "xcomet_qe_score": 0.9149763584136963, "metricx_score": 1.626519799232483, "metricx_qe_score": 1.662952184677124, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le texte est le résumé de la page Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5573669075965881, "metricx_qe_score": 0.8606062531471252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Nous devons maintenant générer ou extraire des caractéristiques du texte récupéré.", "metrics": {"bleu_score": 21.099261895175324, "chrf_score": 54.32807460126669, "xcomet_score": 0.9790385961532593, "xcomet_qe_score": 1.0, "metricx_score": 1.7824831008911133, "metricx_qe_score": 1.277591586112976, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc besoin d'une phase d'extraction des caractéristiques qui inclut l'analyse de texte.", "metrics": {"bleu_score": 38.70605144677149, "chrf_score": 67.7450657326771, "xcomet_score": 0.9889019727706909, "xcomet_qe_score": 0.9709123969078064, "metricx_score": 3.97355055809021, "metricx_qe_score": 3.969383716583252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est là la principale nouveauté de cet article, et j'y plongerai plus avant dans les diapositives suivantes.", "metrics": {"bleu_score": 28.72797668292002, "chrf_score": 56.25777934856654, "xcomet_score": 0.7506488561630249, "xcomet_qe_score": 0.7965632081031799, "metricx_score": 3.8203513622283936, "metricx_qe_score": 2.921201229095459, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction des caractéristiques, il y a une phase de génération des caractéristiques lorsque nous utilisons les caractéristiques extraites pour générer un petit nombre de nouvelles caractéristiques.", "metrics": {"bleu_score": 63.224657395432004, "chrf_score": 72.98475010364008, "xcomet_score": 0.9610253572463989, "xcomet_qe_score": 0.994035005569458, "metricx_score": 2.269667387008667, "metricx_qe_score": 1.3787375688552856, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, générez des caractéristiques en fonction du nombre de classes du jeu de données original.", "metrics": {"bleu_score": 9.880782578056978, "chrf_score": 56.06289422475845, "xcomet_score": 0.8874317407608032, "xcomet_qe_score": 0.6921939849853516, "metricx_score": 4.3469767570495605, "metricx_qe_score": 3.1474545001983643, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données original comporte deux classes.", "metrics": {"bleu_score": 31.702331385234313, "chrf_score": 65.64216837325874, "xcomet_score": 0.9993909597396851, "xcomet_qe_score": 1.0, "metricx_score": 1.1682051420211792, "metricx_qe_score": 1.6217488050460815, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, commencez par générer deux nouvelles caractéristiques.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 36.93854352343672, "xcomet_score": 0.18007025122642517, "xcomet_qe_score": 0.21624116599559784, "metricx_score": 9.811700820922852, "metricx_qe_score": 7.375617980957031, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "Mais, si le jeu de données a cinq classes, générez d'abord cinq nouvelles caractéristiques.", "metrics": {"bleu_score": 12.39899236095509, "chrf_score": 47.917441479342756, "xcomet_score": 0.3445749878883362, "xcomet_qe_score": 0.38764551281929016, "metricx_score": 8.880398750305176, "metricx_qe_score": 7.940067291259766, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque caractéristique représente la probabilité pour chaque classe.", "metrics": {"bleu_score": 75.06238537503395, "chrf_score": 78.89231057183392, "xcomet_score": 0.9665066003799438, "xcomet_qe_score": 1.0, "metricx_score": 1.271324634552002, "metricx_qe_score": 1.2625250816345215, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état actuel de l'analyse hors texte, qui sont des modèles de langage basés sur les transformateurs tels que Ba Gpt x et leds, etc.", "metrics": {"bleu_score": 35.25734999573675, "chrf_score": 59.84654705784551, "xcomet_score": 0.2603808343410492, "xcomet_qe_score": 0.26614513993263245, "metricx_score": 15.631607055664062, "metricx_qe_score": 16.652921676635742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "mais il est peu probable que nous puissions entraîner un modèle linguistique en utilisant les ensembles de données d'entrée.", "metrics": {"bleu_score": 38.27673535697133, "chrf_score": 66.83118310632673, "xcomet_score": 0.8606722354888916, "xcomet_qe_score": 0.9204162359237671, "metricx_score": 2.7731752395629883, "metricx_qe_score": 2.222773551940918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, une approche naïve consisterait à affiner la tâche cible.", "metrics": {"bleu_score": 48.86103195703452, "chrf_score": 67.95142514785971, "xcomet_score": 0.9104291796684265, "xcomet_qe_score": 0.8309173583984375, "metricx_score": 1.807779312133789, "metricx_qe_score": 2.9226772785186768, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans la phase d'extraction des caractéristiques, nous pouvons télécharger un modèle de langage pré-entraîné et ajuster finement le modèle de langage sur l'ensemble de données cible.", "metrics": {"bleu_score": 21.00352704741574, "chrf_score": 62.28244511417193, "xcomet_score": 0.9305716753005981, "xcomet_qe_score": 0.9579170346260071, "metricx_score": 1.2457833290100098, "metricx_qe_score": 1.2025190591812134, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, nous allons affiner le modèle linguistique pour classer le texte en classes abstraites en classes basses ou élevées.", "metrics": {"bleu_score": 31.211920341047524, "chrf_score": 64.12491534922312, "xcomet_score": 0.5743147134780884, "xcomet_qe_score": 0.7089632749557495, "metricx_score": 4.866182327270508, "metricx_qe_score": 5.375339508056641, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "Recevoir la sortie du modèle linguistique, qui est la probabilité pour chaque classe, et l'utiliser comme nouvelles caractéristiques.", "metrics": {"bleu_score": 24.118194478141294, "chrf_score": 63.86055080273998, "xcomet_score": 0.9192417860031128, "xcomet_qe_score": 0.9138619899749756, "metricx_score": 4.228279113769531, "metricx_qe_score": 4.0141448974609375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que le jeu de données peut contenir peu de textes d'entités distinctes.", "metrics": {"bleu_score": 31.93715908050852, "chrf_score": 73.96285075874121, "xcomet_score": 0.814787745475769, "xcomet_qe_score": 0.7869080305099487, "metricx_score": 4.395913600921631, "metricx_qe_score": 4.452822208404541, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, près de la moitié des ensembles de données contiennent moins de 400 échantillons, et le plus petit ensemble de données contenait 35 échantillons dans son ensemble d'entraînement initial.", "metrics": {"bleu_score": 35.66978678600373, "chrf_score": 68.34203494276488, "xcomet_score": 0.9377394914627075, "xcomet_qe_score": 0.9541913270950317, "metricx_score": 1.3981897830963135, "metricx_qe_score": 1.2062033414840698, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, affiner un modèle linguistique sur ce jeu de données sera inefficace.", "metrics": {"bleu_score": 6.734395444347337, "chrf_score": 53.877796992225846, "xcomet_score": 0.9641237258911133, "xcomet_qe_score": 0.9743753671646118, "metricx_score": 1.4542535543441772, "metricx_qe_score": 1.3492319583892822, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons utiliser des connaissances antérieures sur un ensemble de données pré-analysé.", "metrics": {"bleu_score": 38.720157050710164, "chrf_score": 71.51808572718016, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.1615228652954102, "metricx_qe_score": 1.1528112888336182, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "Parce que nous appliquons rapidement une méthode à un ensemble de données multiples, nous pouvons utiliser l'ensemble de données N moins 1 pour recueillir des informations sur l'ensemble de données N moins 1 et utiliser ces informations lorsque nous analysons l'ensemble de données NNS.", "metrics": {"bleu_score": 33.03725885791958, "chrf_score": 71.35512133582739, "xcomet_score": 0.659436821937561, "xcomet_qe_score": 0.6860735416412354, "metricx_score": 6.621326446533203, "metricx_qe_score": 7.205269813537598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "Ce que nous proposons, c'est d'ajouter une autre phase de réglage fin.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 70.40315732771698, "xcomet_score": 0.9036030769348145, "xcomet_qe_score": 0.8684557676315308, "metricx_score": 2.6003315448760986, "metricx_qe_score": 2.87367844581604, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "Une phase de réglage préalable multitâche.", "metrics": {"bleu_score": 27.77619034011791, "chrf_score": 46.37560186944016, "xcomet_score": 0.8977558612823486, "xcomet_qe_score": 0.8923177719116211, "metricx_score": 2.336135149002075, "metricx_qe_score": 2.0930685997009277, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque vous trouvez que le modèle linguistique est appliqué à l'ensemble de données n moins un,", "metrics": {"bleu_score": 19.923405658137927, "chrf_score": 53.19203450383652, "xcomet_score": 0.3443811535835266, "xcomet_qe_score": 0.25784698128700256, "metricx_score": 8.967914581298828, "metricx_qe_score": 9.955758094787598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "Puis nous exécutons une autre phase d'affinage, qui est un affinage de tâche cible lorsque nous affinons le modèle linguistique sur le dernier ensemble de données cible.", "metrics": {"bleu_score": 22.7160528277135, "chrf_score": 62.90819101665191, "xcomet_score": 0.7557421922683716, "xcomet_qe_score": 0.6388235688209534, "metricx_score": 2.7458407878875732, "metricx_qe_score": 4.9249444007873535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "L'état de l'art en matière d'ajustement fin multitâche appelé tdNN.", "metrics": {"bleu_score": 5.300156689756295, "chrf_score": 41.70701275928161, "xcomet_score": 0.586967945098877, "xcomet_qe_score": 0.8005170226097107, "metricx_score": 10.577832221984863, "metricx_qe_score": 9.65781307220459, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "Dans empty dNN empty dNN, maintenez un nombre égal de tâches dans l'ensemble d'entraînement.", "metrics": {"bleu_score": 16.94357181593088, "chrf_score": 45.77688594800399, "xcomet_score": 0.1758420467376709, "xcomet_qe_score": 0.17099907994270325, "metricx_score": 17.475561141967773, "metricx_qe_score": 17.174671173095703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans cet exemple, s'il y a quatre tâches dans l'ensemble d'entraînement, on laisse le DNN vide et on maintient quatre têtes, comme vous pouvez le voir sur l'image.", "metrics": {"bleu_score": 48.92199210635082, "chrf_score": 74.18266302931062, "xcomet_score": 0.3660280704498291, "xcomet_qe_score": 0.438928484916687, "metricx_score": 8.236763954162598, "metricx_qe_score": 8.94314956665039, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "Et il sélectionne un badge aléatoire de l'ensemble d'entraînement.", "metrics": {"bleu_score": 19.331263581394154, "chrf_score": 52.556597800705326, "xcomet_score": 0.4066360294818878, "xcomet_qe_score": 0.43067246675491333, "metricx_score": 6.601493835449219, "metricx_qe_score": 6.89607048034668, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot d'exécution appartient, par exemple, aux tâches de classification de Sin et Selten, il exécute un passage avant et arrière à travers la première tête.", "metrics": {"bleu_score": 30.743175379760913, "chrf_score": 52.62321847115095, "xcomet_score": 0.3287316560745239, "xcomet_qe_score": 0.34564048051834106, "metricx_score": 11.073262214660645, "metricx_qe_score": 10.32976245880127, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot aléatoire appartient au classement par paires, une tâche est effectuée en avant et en arrière à travers la dernière tête.", "metrics": {"bleu_score": 31.32783082390859, "chrf_score": 59.170845033605914, "xcomet_score": 0.6803648471832275, "xcomet_qe_score": 0.6530030965805054, "metricx_score": 6.667912006378174, "metricx_qe_score": 8.073383331298828, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, un ensemble de données de tableau varie en nombre de classes.", "metrics": {"bleu_score": 31.53554052490134, "chrf_score": 61.210733733637234, "xcomet_score": 0.9614144563674927, "xcomet_qe_score": 0.9596951007843018, "metricx_score": 4.180682182312012, "metricx_qe_score": 5.024339199066162, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a donc beaucoup de tâches.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7176141738891602, "metricx_qe_score": 0.8257766962051392, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "tDNN maintient le nombre de classes, de têtes, de couches de sortie.", "metrics": {"bleu_score": 56.6713706600882, "chrf_score": 72.78115196171987, "xcomet_score": 0.5747244954109192, "xcomet_qe_score": 0.5083960294723511, "metricx_score": 7.765929222106934, "metricx_qe_score": 7.728211879730225, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "Et en outre, l'ADN vide doit d'abord ajouter de nouvelles têtes pour un nouvel ensemble de données avec une nouvelle tâche.", "metrics": {"bleu_score": 42.66219662386314, "chrf_score": 67.79511765805503, "xcomet_score": 0.44628244638442993, "xcomet_qe_score": 0.369155615568161, "metricx_score": 12.122537612915039, "metricx_qe_score": 13.833995819091797, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche, appelée affinage du reformulation de tâche, consiste, au lieu de maintenir plusieurs têtes, à reformuler chaque ensemble de données en une phrase par problème de classification, ce qui correspond à des tâches à deux classes.", "metrics": {"bleu_score": 36.63950768236571, "chrf_score": 61.71013835209387, "xcomet_score": 0.5272766947746277, "xcomet_qe_score": 0.43018317222595215, "metricx_score": 7.065867900848389, "metricx_qe_score": 8.743820190429688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple.", "metrics": {"bleu_score": 46.30777161991026, "chrf_score": 48.32474847235818, "xcomet_score": 0.9386066198348999, "xcomet_qe_score": 0.9773107767105103, "metricx_score": 0.2514381408691406, "metricx_qe_score": 0.34026220440864563, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre ensemble de données d'entrée qui se compose d'entités, de caractéristiques, de texte et de classes.", "metrics": {"bleu_score": 40.85639059221913, "chrf_score": 65.3853190027725, "xcomet_score": 0.9673867225646973, "xcomet_qe_score": 0.996559739112854, "metricx_score": 2.060730457305908, "metricx_qe_score": 2.9457015991210938, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous reformulons la tâche en passant de la classification du texte en faible et élevé à la classification du texte, de l'abstrait et de la classe en vrai ou faux.", "metrics": {"bleu_score": 37.58610313819115, "chrf_score": 60.65191551633093, "xcomet_score": 0.7092766761779785, "xcomet_qe_score": 0.7382036447525024, "metricx_score": 4.530405044555664, "metricx_qe_score": 3.9608101844787598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous entraînons le modèle de langage à classer des concepts abstraits et des classes abstraites en fonction de leur appartenance ou non à une classe.", "metrics": {"bleu_score": 7.6048670142811, "chrf_score": 41.17243022393036, "xcomet_score": 0.533971905708313, "xcomet_qe_score": 0.4294915199279785, "metricx_score": 4.559295177459717, "metricx_qe_score": 6.1393208503723145, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le vecteur d'étiquette dans le cas de z reste toujours, ce qui consiste toujours en deux classes.", "metrics": {"bleu_score": 36.30716142599353, "chrf_score": 75.65920987039381, "xcomet_score": 0.36316418647766113, "xcomet_qe_score": 0.44943463802337646, "metricx_score": 11.428743362426758, "metricx_qe_score": 14.707606315612793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici l'algorithme de notre approche fine ou de précision.", "metrics": {"bleu_score": 4.6409220236106705, "chrf_score": 36.57160299333152, "xcomet_score": 0.7387221455574036, "xcomet_qe_score": 0.7994222044944763, "metricx_score": 7.2776641845703125, "metricx_qe_score": 9.135032653808594, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons donc le cadre complet.", "metrics": {"bleu_score": 53.7284965911771, "chrf_score": 81.9759249161167, "xcomet_score": 0.9789191484451294, "xcomet_qe_score": 0.9587022066116333, "metricx_score": 1.1847355365753174, "metricx_qe_score": 3.205934524536133, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "un ensemble de données introduit dans Fast", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 43.889772165694765, "xcomet_score": 0.17432552576065063, "xcomet_qe_score": 0.17390076816082, "metricx_score": 5.906019687652588, "metricx_qe_score": 4.525345802307129, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "Puis une exécution rapide dans la phase de liaison.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 49.74623376977784, "xcomet_score": 0.31742510199546814, "xcomet_qe_score": 0.5051066279411316, "metricx_score": 14.504457473754883, "metricx_qe_score": 14.387221336364746, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "il extrait le texte de la base de connaissances, qui dans cet exemple est le résumé de la page Wikipédia.", "metrics": {"bleu_score": 95.10699415570296, "chrf_score": 98.8018938583582, "xcomet_score": 0.9654701948165894, "xcomet_qe_score": 0.9213699698448181, "metricx_score": 2.0358121395111084, "metricx_qe_score": 3.023637056350708, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, il a reformulé la tâche en une paire de phrases par tâche de classification.", "metrics": {"bleu_score": 62.01424013200414, "chrf_score": 84.43356676643519, "xcomet_score": 0.7641792297363281, "xcomet_qe_score": 0.7320645451545715, "metricx_score": 8.56879997253418, "metricx_qe_score": 8.737338066101074, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "Appliquer le modèle linguistique à la nouvelle tâche et à la probabilité de sortie pour chaque classe.", "metrics": {"bleu_score": 56.09383777282962, "chrf_score": 77.91227019204902, "xcomet_score": 0.7234805822372437, "xcomet_qe_score": 0.7441447973251343, "metricx_score": 4.582015037536621, "metricx_qe_score": 4.295452117919922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que le modèle linguistique est déjà affiné sur un ensemble de données n moins un en utilisant un affinage préalable multitâche.", "metrics": {"bleu_score": 32.59889346257788, "chrf_score": 57.53501771414808, "xcomet_score": 0.9453411102294922, "xcomet_qe_score": 0.8575859069824219, "metricx_score": 1.6884359121322632, "metricx_qe_score": 2.3082292079925537, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous utilisons le vecteur de sortie du modèle linguistique comme une nouvelle caractéristique générée dans le nombre de classes.", "metrics": {"bleu_score": 67.40705509899853, "chrf_score": 77.82797724718824, "xcomet_score": 0.891135573387146, "xcomet_qe_score": 0.9339526891708374, "metricx_score": 3.8746848106384277, "metricx_qe_score": 5.268843650817871, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un ensemble de données de classification tabulaire de dix-sept exemples qui définissent la taille, les caractéristiques, l'équilibre, le domaine et la performance initiale.", "metrics": {"bleu_score": 28.217173644496484, "chrf_score": 73.56928818924378, "xcomet_score": 0.746712327003479, "xcomet_qe_score": 0.6203398704528809, "metricx_score": 3.757450580596924, "metricx_qe_score": 4.471688270568848, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "Dans son dépotoir de connaissances, nous utilisons Wikipédia.", "metrics": {"bleu_score": 52.31223689135345, "chrf_score": 72.69937061531058, "xcomet_score": 0.6675247550010681, "xcomet_qe_score": 0.7768959403038025, "metricx_score": 6.305263042449951, "metricx_qe_score": 4.662227153778076, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concevons notre expérience comme une évaluation de type « leave one out » lorsque nous effectuons un entraînement rapide sur seize ensembles de données et l’appliquons au dix-septième ensemble de données.", "metrics": {"bleu_score": 21.853715647401973, "chrf_score": 66.99967507126554, "xcomet_score": 0.5615357160568237, "xcomet_qe_score": 0.49342888593673706, "metricx_score": 6.042943954467773, "metricx_qe_score": 6.556189060211182, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "nous divisons également chaque ensemble de données en un faux et appliquons une fausse validation croisée.", "metrics": {"bleu_score": 17.61544515868727, "chrf_score": 67.25594649686093, "xcomet_score": 0.2471429854631424, "xcomet_qe_score": 0.45081475377082825, "metricx_score": 18.038043975830078, "metricx_qe_score": 18.947790145874023, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous générons la nouvelle fonctionnalité et les évaluons à l'aide de cinq classificateurs d'évaluation.", "metrics": {"bleu_score": 35.23089031737454, "chrf_score": 74.96907095996136, "xcomet_score": 0.92185378074646, "xcomet_qe_score": 0.9126148819923401, "metricx_score": 2.8427164554595947, "metricx_qe_score": 4.1992387771606445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons dans notre expérience une architecture basée sur les oiseaux.", "metrics": {"bleu_score": 8.930069801473408, "chrf_score": 37.00083719376059, "xcomet_score": 0.20864075422286987, "xcomet_qe_score": 0.4832649528980255, "metricx_score": 17.145708084106445, "metricx_qe_score": 14.555671691894531, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre expérience", "metrics": {"bleu_score": 43.01250851313264, "chrf_score": 82.19264658791012, "xcomet_score": 0.9809447526931763, "xcomet_qe_score": 0.9860361814498901, "metricx_score": 0.37098801136016846, "metricx_qe_score": 0.7129753828048706, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "On peut voir que nous comparons notre cadre au réglage fin ciblé sur l'ensemble de données, au réglage fin ciblé sur la tâche et au réglage fin préliminaire tDNN.", "metrics": {"bleu_score": 24.12960690480583, "chrf_score": 50.767212610704874, "xcomet_score": 0.7102077007293701, "xcomet_qe_score": 0.6525444984436035, "metricx_score": 7.538171768188477, "metricx_qe_score": 6.595323085784912, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "Et notre affinage reformulé atteint le meilleur résultat, la meilleure performance.", "metrics": {"bleu_score": 52.664038784792666, "chrf_score": 80.3226868969538, "xcomet_score": 0.8423348665237427, "xcomet_qe_score": 0.8473266959190369, "metricx_score": 2.479022741317749, "metricx_qe_score": 3.1749253273010254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "Alors que dNN a obtenu une amélioration de deux pour cent par rapport à l'ajustement fin du jeu de données cible.", "metrics": {"bleu_score": 45.96980088392873, "chrf_score": 73.48996047148594, "xcomet_score": 0.33222126960754395, "xcomet_qe_score": 0.37808677554130554, "metricx_score": 7.758852958679199, "metricx_qe_score": 7.265918254852295, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "Notre rendement a augmenté de six pour cent.", "metrics": {"bleu_score": 38.875142041440206, "chrf_score": 37.60566472012854, "xcomet_score": 0.8606078624725342, "xcomet_qe_score": 0.9336328506469727, "metricx_score": 4.87946891784668, "metricx_qe_score": 4.978270053863525, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous examinons le petit ensemble de données, nous pouvons voir que la performance de mtdNN diminue et que l'amélioration de la phase de réglage fin multitâche préliminaire diminue à un point cinq par pour cent.", "metrics": {"bleu_score": 37.765494709123615, "chrf_score": 70.89310347767224, "xcomet_score": 0.7799568772315979, "xcomet_qe_score": 0.7787494659423828, "metricx_score": 7.250519752502441, "metricx_qe_score": 6.74769926071167, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "Mais notre performance a augmenté de onze pour cent par rapport au seul affinage fin de la tâche cible.", "metrics": {"bleu_score": 28.65515486360906, "chrf_score": 65.3167331867803, "xcomet_score": 0.8632584810256958, "xcomet_qe_score": 0.8419233560562134, "metricx_score": 4.522669315338135, "metricx_qe_score": 5.064845085144043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "Car la sommation rapide permet d'enrichir rapidement une trentaine d'échantillons dans notre expérience.", "metrics": {"bleu_score": 2.6149826893840222, "chrf_score": 42.92043982207416, "xcomet_score": 0.5508926510810852, "xcomet_qe_score": 0.5241016149520874, "metricx_score": 9.433746337890625, "metricx_qe_score": 10.600281715393066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "Il utilise une architecture pour l'ensemble des tâches de données.", "metrics": {"bleu_score": 41.72261448611506, "chrf_score": 72.76652346915972, "xcomet_score": 0.964952826499939, "xcomet_qe_score": 0.8808225393295288, "metricx_score": 5.104371547698975, "metricx_qe_score": 6.720098495483398, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "Et il conserve la tête du modèle.", "metrics": {"bleu_score": 59.4603557501361, "chrf_score": 68.60498861472179, "xcomet_score": 0.9025007486343384, "xcomet_qe_score": 0.6470153331756592, "metricx_score": 3.7993338108062744, "metricx_qe_score": 6.2746782302856445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cela ajoute une phase de reformulation.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3430850505828857, "metricx_qe_score": 2.587543487548828, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "Pour augmenter l'ensemble de formation et ses besoins d'une valeur cible avec un sens sémantique, afin que nous puissions l'introduire dans le modèle linguistique et l'utiliser dans le problème de classification par phrase.", "metrics": {"bleu_score": 58.38659307501705, "chrf_score": 83.58311858808383, "xcomet_score": 0.5624182224273682, "xcomet_qe_score": 0.43949106335639954, "metricx_score": 8.484297752380371, "metricx_qe_score": 9.382795333862305, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Merci.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10382990539073944, "metricx_qe_score": 0.4022793173789978, "linguapy_score": [1, "ITALIAN"]}}
