{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous ! Aujourd'hui, je vais présenter nos travaux de recherche sur l'apprentissage de la raisonnement déductif et la résolution de problèmes complexes en tant qu'expression de régions complexes.", "metrics": {"bleu_score": 12.109273887269673, "chrf_score": 52.74501384862171, "xcomet_score": 0.4787331819534302, "xcomet_qe_score": 0.48638883233070374, "metricx_score": 7.355560302734375, "metricx_qe_score": 7.441636085510254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "Je suis du laboratoire de recherche aérienne de Biden et ce travail est une collaboration avec Jerry de l'Université du Texas à Austin et Wadu de SUDD.", "metrics": {"bleu_score": 22.970184525752483, "chrf_score": 45.65149221923876, "xcomet_score": 0.1370549350976944, "xcomet_qe_score": 0.16027168929576874, "metricx_score": 18.567975997924805, "metricx_qe_score": 19.04598045349121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, j'aimerais aborder notre motivation pour le raisonnement.", "metrics": {"bleu_score": 64.07117598241614, "chrf_score": 85.47864077852374, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.6316269636154175, "metricx_qe_score": 1.7437201738357544, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "nous avons montré des exemples où une raisonnement en plusieurs étapes est utile.", "metrics": {"bleu_score": 39.91650792326117, "chrf_score": 70.6921399077401, "xcomet_score": 0.796755313873291, "xcomet_qe_score": 0.8202027082443237, "metricx_score": 3.1237635612487793, "metricx_qe_score": 3.2774550914764404, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "La figure est extraite du document en anglais où ils effectuent une incitation pour résoudre le problème de méthode dans un scénario d'apprentissage par immersion totale.", "metrics": {"bleu_score": 12.712357001082976, "chrf_score": 46.224812918563366, "xcomet_score": 0.2624211013317108, "xcomet_qe_score": 0.32810619473457336, "metricx_score": 9.911796569824219, "metricx_qe_score": 9.303050994873047, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Sur la gauche, nous pouvons observer que si nous fournissons des échantillons avec uniquement des questions et des réponses, nous pourrions ne pas obtenir les réponses les plus pertinentes.", "metrics": {"bleu_score": 39.78229947875153, "chrf_score": 64.07846161338604, "xcomet_score": 0.8993208408355713, "xcomet_qe_score": 0.9509727954864502, "metricx_score": 2.716432571411133, "metricx_qe_score": 1.9120359420776367, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si nous fournissons une description plus raisonnée, le modèle est capable de prédire la description de la raison et de faire également une prédiction correcte ici.", "metrics": {"bleu_score": 29.129199684126146, "chrf_score": 61.63599999482924, "xcomet_score": 0.6868101358413696, "xcomet_qe_score": 0.7641021013259888, "metricx_score": 5.39630651473999, "metricx_qe_score": 5.688520908355713, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Eh bien, il est bénéfique d'obtenir un raisonnement multi-étapes interprétable en tant que sortie.", "metrics": {"bleu_score": 6.150343144231885, "chrf_score": 45.67239652411624, "xcomet_score": 0.9772878885269165, "xcomet_qe_score": 0.9662780165672302, "metricx_score": 2.5348331928253174, "metricx_qe_score": 3.1430277824401855, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pensons également que Math problem est une application directe pour évaluer de telles capacités de raisonnement.", "metrics": {"bleu_score": 62.608853446615484, "chrf_score": 76.64591272675487, "xcomet_score": 0.7759611010551453, "xcomet_qe_score": 0.6974658966064453, "metricx_score": 7.166640281677246, "metricx_qe_score": 7.455402851104736, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Voici donc, dans notre énoncé de problème, compte tenu des questions posées, nous devons résoudre cette question et obtenir les réponses numériques.", "metrics": {"bleu_score": 70.16116562610198, "chrf_score": 82.64931628264172, "xcomet_score": 0.9511736631393433, "xcomet_qe_score": 0.9489008784294128, "metricx_score": 3.127535820007324, "metricx_qe_score": 3.2540645599365234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre ensemble de données, on nous fournit également l'expression mathématique qui conduit à cette réponse particulière.", "metrics": {"bleu_score": 43.7241098509127, "chrf_score": 79.35270918314818, "xcomet_score": 0.9780811071395874, "xcomet_qe_score": 0.9724938869476318, "metricx_score": 2.3253629207611084, "metricx_qe_score": 2.8161675930023193, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, certaines hypothèses s'appliquent également, comme dans les travaux précédents.", "metrics": {"bleu_score": 49.73567356124543, "chrf_score": 78.03586015335881, "xcomet_score": 0.9974579811096191, "xcomet_qe_score": 1.0, "metricx_score": 1.719216227531433, "metricx_qe_score": 2.3451690673828125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que la précision des quantités est connue.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.0283783674240112, "metricx_qe_score": 1.3673415184020996, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous ne considérons que les opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentiation.", "metrics": {"bleu_score": 92.10589320522861, "chrf_score": 95.68299687983432, "xcomet_score": 0.969541072845459, "xcomet_qe_score": 0.9754696488380432, "metricx_score": 1.1877816915512085, "metricx_qe_score": 0.6469014883041382, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les opérateurs complexes peuvent en réalité être décomposés en ces opérateurs de base.", "metrics": {"bleu_score": 50.7196093945688, "chrf_score": 69.8708284380725, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5208061337471008, "metricx_qe_score": 0.4972343444824219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, les travaux précédents en résolution de problèmes mathématiques peuvent en fait être catégorisés en modèles de séquence à séquence et de séquence à arbre.", "metrics": {"bleu_score": 22.79716305257816, "chrf_score": 64.48669215822214, "xcomet_score": 0.6779940128326416, "xcomet_qe_score": 0.6896837949752808, "metricx_score": 4.375771999359131, "metricx_qe_score": 4.474512577056885, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de séquence à séquence traditionnels convertissent l'expression en une séquence spécifique pour la génération.", "metrics": {"bleu_score": 56.35190098079901, "chrf_score": 86.9620549120146, "xcomet_score": 0.8227502107620239, "xcomet_qe_score": 0.7702916860580444, "metricx_score": 2.2815446853637695, "metricx_qe_score": 3.030402660369873, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Et sa mise en œuvre est plutôt aisée, tout en permettant de généraliser à de nombreux problèmes complexes et variés.", "metrics": {"bleu_score": 14.230715327204656, "chrf_score": 51.3201585849419, "xcomet_score": 0.9775742292404175, "xcomet_qe_score": 1.0, "metricx_score": 1.532957673072815, "metricx_qe_score": 1.2765885591506958, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, le revers de la performance est en général généralement pas meilleur que le modèle structurel, et il manque d'interprétabilité pour la prédiction.", "metrics": {"bleu_score": 9.562406574442017, "chrf_score": 61.83966034931178, "xcomet_score": 0.6997731924057007, "xcomet_qe_score": 0.6999397277832031, "metricx_score": 12.01146125793457, "metricx_qe_score": 11.433717727661133, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en réalité, cette approche reste assez populaire grâce au modèle de transformateur.", "metrics": {"bleu_score": 26.36932645412712, "chrf_score": 46.8627138171017, "xcomet_score": 0.7733383774757385, "xcomet_qe_score": 0.8268519043922424, "metricx_score": 4.097032070159912, "metricx_qe_score": 2.5474743843078613, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans les modèles basés sur des arbres, nous structurons en réalité ces expressions sous forme d'arbre et suivons une traversée en ordre préfixe sur trois générations.", "metrics": {"bleu_score": 53.46930670550587, "chrf_score": 73.6053093824767, "xcomet_score": 0.5954015254974365, "xcomet_qe_score": 0.6028043031692505, "metricx_score": 7.505805015563965, "metricx_qe_score": 6.767153739929199, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous continuons à générer les opérateurs jusqu'à atteindre les élévations, qui sont les quantités.", "metrics": {"bleu_score": 38.488276585047046, "chrf_score": 60.62477011645891, "xcomet_score": 0.6779224872589111, "xcomet_qe_score": 0.5712394714355469, "metricx_score": 8.201693534851074, "metricx_qe_score": 10.014925956726074, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Voici donc le point positif : cela nous fournit en réalité cette structure d'arbre binaire, et c'est assez contre-intuitif car nous générons d'abord l'opérateur, puis à la fin, nous générons les quantités.", "metrics": {"bleu_score": 35.09052580244965, "chrf_score": 66.92797081990366, "xcomet_score": 0.9589687585830688, "xcomet_qe_score": 0.955849289894104, "metricx_score": 3.7304701805114746, "metricx_qe_score": 4.572831153869629, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est qu'elle contient également certains calculs répétitifs.", "metrics": {"bleu_score": 42.86982293646294, "chrf_score": 81.65232219346137, "xcomet_score": 0.922925591468811, "xcomet_qe_score": 0.9670112133026123, "metricx_score": 1.6212388277053833, "metricx_qe_score": 1.2855981588363647, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, si nous examinons cette expression, huit fois trois plus trois est en réalité généré deux fois. Cependant, en réalité, nous devrions réutiliser les résultats.", "metrics": {"bleu_score": 63.05341259384346, "chrf_score": 81.4286811559186, "xcomet_score": 0.9917389154434204, "xcomet_qe_score": 0.9866330623626709, "metricx_score": 1.1240777969360352, "metricx_qe_score": 1.6475681066513062, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre approche de proposition, nous souhaitons résoudre ces problèmes de manière progressive et interprétable.", "metrics": {"bleu_score": 31.142220978542806, "chrf_score": 68.82393958438931, "xcomet_score": 0.8734349608421326, "xcomet_qe_score": 0.8551597595214844, "metricx_score": 4.362128734588623, "metricx_qe_score": 4.094692230224609, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, par exemple, ici à la deuxième étape, nous pouvons obtenir ce diviseur, qui est vingt-sept. et", "metrics": {"bleu_score": 35.562549056277234, "chrf_score": 75.74389542752373, "xcomet_score": 0.678815484046936, "xcomet_qe_score": 0.6493077278137207, "metricx_score": 4.8694868087768555, "metricx_qe_score": 3.1291699409484863, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "vous pouvez également vous référer aux questions originales pour trouver les contenus pertinents.", "metrics": {"bleu_score": 35.00482776497398, "chrf_score": 78.59149273492442, "xcomet_score": 0.9765967130661011, "xcomet_qe_score": 0.9772644639015198, "metricx_score": 3.7291150093078613, "metricx_qe_score": 3.9460556507110596, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous obtenons les dispositifs.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 80.79986258438548, "xcomet_score": 0.6616076231002808, "xcomet_qe_score": 0.6974775195121765, "metricx_score": 6.695829391479492, "metricx_qe_score": 10.915413856506348, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi donc, et ensuite, à cette troisième étape, nous obtenons en réalité le quotient.", "metrics": {"bleu_score": 46.60608712358324, "chrf_score": 75.10558730227852, "xcomet_score": 0.9655381441116333, "xcomet_qe_score": 0.9729160666465759, "metricx_score": 5.171137809753418, "metricx_qe_score": 4.799617767333984, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, après ces trois étapes, nous pouvons en fait réutiliser les résultats de la deuxième étape et obtenir ensuite les résultats de la quatrième étape. Et enfin, nous pouvons obtenir les dividendes.", "metrics": {"bleu_score": 62.17996832309681, "chrf_score": 81.91673884276064, "xcomet_score": 0.9807291030883789, "xcomet_qe_score": 0.9702417850494385, "metricx_score": 1.7479339838027954, "metricx_qe_score": 2.9095656871795654, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, nous générons en fait l'expression entière directement plutôt que de générer des opérateurs ou des quantités individuelles.", "metrics": {"bleu_score": 39.080227521872686, "chrf_score": 64.37617971500515, "xcomet_score": 0.9843628406524658, "xcomet_qe_score": 0.9744850993156433, "metricx_score": 1.2532000541687012, "metricx_qe_score": 1.3570153713226318, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, cela rend le processus plus précis.", "metrics": {"bleu_score": 58.73949094699213, "chrf_score": 92.30925451391424, "xcomet_score": 0.930930495262146, "xcomet_qe_score": 0.8418465852737427, "metricx_score": 1.2148860692977905, "metricx_qe_score": 1.332200050354004, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "dans notre système déductif, nous commençons d'abord avec un ensemble de quantités présentées dans les questions et incluant également certaines constantes comme notre état initial.", "metrics": {"bleu_score": 60.99007394781878, "chrf_score": 83.96408470145586, "xcomet_score": 0.9475812911987305, "xcomet_qe_score": 0.9041585922241211, "metricx_score": 3.2945451736450195, "metricx_qe_score": 4.419834613800049, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, l'expression est représentée par e i jP.", "metrics": {"bleu_score": 64.069143843707, "chrf_score": 93.08322617669988, "xcomet_score": 0.9408328533172607, "xcomet_qe_score": 0.9351246953010559, "metricx_score": 1.6524181365966797, "metricx_qe_score": 2.6382479667663574, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "Où nous effectuons des opérations de Q à q j, et cette expression est en fait dirigée.", "metrics": {"bleu_score": 54.05009771023598, "chrf_score": 75.68699708733956, "xcomet_score": 0.8267869353294373, "xcomet_qe_score": 0.7962257862091064, "metricx_score": 7.678349494934082, "metricx_qe_score": 9.545829772949219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc également ici la soustraction inverse pour représenter la direction opposée.", "metrics": {"bleu_score": 43.94900482337444, "chrf_score": 76.7253145360072, "xcomet_score": 0.9056967496871948, "xcomet_qe_score": 0.9568901062011719, "metricx_score": 1.820184588432312, "metricx_qe_score": 2.885394334793091, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "Ceci est assez similaire à l'extraction de relations.", "metrics": {"bleu_score": 28.24099048856542, "chrf_score": 70.13435410341606, "xcomet_score": 0.909714937210083, "xcomet_qe_score": 0.929241418838501, "metricx_score": 1.5483946800231934, "metricx_qe_score": 2.768643617630005, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans un système datatif formel, à l'instant t, nous appliquons l'opérateur entre la paire Q et qj, et nous obtenons ensuite ces nouvelles expressions.", "metrics": {"bleu_score": 17.71011839845468, "chrf_score": 55.1871613102269, "xcomet_score": 0.796669602394104, "xcomet_qe_score": 0.9014080762863159, "metricx_score": 10.688644409179688, "metricx_qe_score": 7.997631072998047, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons ajouté à l'étape suivante pour devenir une nouvelle quantité.", "metrics": {"bleu_score": 44.833867003844595, "chrf_score": 72.54614897554352, "xcomet_score": 0.6734277009963989, "xcomet_qe_score": 0.5712767243385315, "metricx_score": 5.689430236816406, "metricx_qe_score": 6.593803405761719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, cette tranche visualise en fait l'évolution des états où nous ajoutons continuellement des expressions aux états courants.", "metrics": {"bleu_score": 5.92472957307066, "chrf_score": 47.46363915052647, "xcomet_score": 0.7103018760681152, "xcomet_qe_score": 0.6694663763046265, "metricx_score": 8.181777000427246, "metricx_qe_score": 7.136075973510742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos implémentations de modèle, nous utilisons d'abord un modèle pré-entraîné qui peut être de type BERT (Birds) ou RoBERTa (robothoods), puis nous encodons la phrase et obtenons ainsi des représentations quantitatives.", "metrics": {"bleu_score": 48.3914051626627, "chrf_score": 71.85414231124412, "xcomet_score": 0.5395941138267517, "xcomet_qe_score": 0.6048527359962463, "metricx_score": 6.408026218414307, "metricx_qe_score": 6.53913688659668, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Une fois que nous obtenons les représentations quantitatives, nous pouvons commencer à effectuer des inférences.", "metrics": {"bleu_score": 45.090228049186024, "chrf_score": 74.4130013088617, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.4022859334945679, "metricx_qe_score": 1.4757791757583618, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "ici, nous vous montrons un exemple de q1 pour obtenir la représentation de q1 divisé par q2 puis multiplié par Q", "metrics": {"bleu_score": 13.329708230751935, "chrf_score": 64.3350108012049, "xcomet_score": 0.6089999675750732, "xcomet_qe_score": 0.6212403774261475, "metricx_score": 12.658247947692871, "metricx_qe_score": 8.075679779052734, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous obtenons la représentation en paires, qui n'est en fait que la concaténation entre q un et q deux. Ensuite, nous appliquons un réseau de neurones à propagation directe qui est paramétré par l'opérateur.", "metrics": {"bleu_score": 37.22235635917212, "chrf_score": 65.71966592087225, "xcomet_score": 0.9154460430145264, "xcomet_qe_score": 0.9218019247055054, "metricx_score": 3.7078123092651367, "metricx_qe_score": 2.9756076335906982, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, nous obtenons la représentation de l'expression q un divisé par q deux.", "metrics": {"bleu_score": 56.38653104251221, "chrf_score": 83.30172763024997, "xcomet_score": 0.9191746115684509, "xcomet_qe_score": 0.9319008588790894, "metricx_score": 2.7051637172698975, "metricx_qe_score": 3.4191837310791016, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en pratique, lors de l'étape d'inférence, nous pourrions également obtenir l'expression incorrecte.", "metrics": {"bleu_score": 23.97838621953249, "chrf_score": 70.53485517481977, "xcomet_score": 0.9854354858398438, "xcomet_qe_score": 0.9987838268280029, "metricx_score": 1.6104421615600586, "metricx_qe_score": 2.1196162700653076, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, l'ensemble des expressions possibles est égal à trois fois le nombre d'opérateurs.", "metrics": {"bleu_score": 42.61082723917019, "chrf_score": 68.0387686742242, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7184386253356934, "metricx_qe_score": 1.0969130992889404, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, l'aspect intéressant ici est que nous pouvons facilement ajouter des contraintes pour contrôler cet espace de recherche.", "metrics": {"bleu_score": 60.91456162918895, "chrf_score": 80.13527714605317, "xcomet_score": 0.9865596294403076, "xcomet_qe_score": 0.9642374515533447, "metricx_score": 1.5025100708007812, "metricx_qe_score": 1.5551488399505615, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement supprimer cette expression dans notre espace de recherche.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9995723962783813, "xcomet_qe_score": 0.9972200393676758, "metricx_score": 0.43808066844940186, "metricx_qe_score": 0.45326462388038635, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans la deuxième étape, nous faisons la même chose, mais la seule différence est l'ajout d'une quantité supplémentaire.", "metrics": {"bleu_score": 69.09163682888774, "chrf_score": 80.1719318352929, "xcomet_score": 0.9505224227905273, "xcomet_qe_score": 0.8707467317581177, "metricx_score": 3.8130767345428467, "metricx_qe_score": 5.414261817932129, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "les quantités proviennent de l'expression calculée précédente.", "metrics": {"bleu_score": 19.493995755254467, "chrf_score": 59.44052983050414, "xcomet_score": 0.9890286922454834, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.2600319385528564, "metricx_qe_score": 1.7276439666748047, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous pouvons ajouter cette dernière expression q.", "metrics": {"bleu_score": 9.586514611843183, "chrf_score": 39.645223837061664, "xcomet_score": 0.3144582211971283, "xcomet_qe_score": 0.4614098370075226, "metricx_score": 16.90144920349121, "metricx_qe_score": 16.87690544128418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "fois Q4. et nous pouvons également constater que le nombre de toutes les expressions possibles est différent de l'étape précédente.", "metrics": {"bleu_score": 58.52187596735431, "chrf_score": 82.16576914782426, "xcomet_score": 0.4887429177761078, "xcomet_qe_score": 0.24882060289382935, "metricx_score": 8.152146339416504, "metricx_qe_score": 12.066709518432617, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, une telle différence rend l'application de la recherche de faisceau difficile, car la distribution de probabilité entre ces deux étapes est déséquilibrée.", "metrics": {"bleu_score": 66.7619194068951, "chrf_score": 86.42905964719627, "xcomet_score": 0.9517136812210083, "xcomet_qe_score": 0.9649785757064819, "metricx_score": 2.248016834259033, "metricx_qe_score": 2.2347300052642822, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "La procédure d'entraînement est donc similaire à celle d'un modèle séquence-à-séquence, où nous optimisons la perte à chaque pas de temps.", "metrics": {"bleu_score": 52.98134210609742, "chrf_score": 73.75570430399661, "xcomet_score": 0.6901940107345581, "xcomet_qe_score": 0.672497034072876, "metricx_score": 2.5416531562805176, "metricx_qe_score": 4.09617805480957, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également ce tau pour représenter le moment où nous devrions mettre fin à ce processus de génération.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.225374698638916, "metricx_qe_score": 3.699932813644409, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent d'une séquence à l'autre car l'espace varie à chaque fois, alors que dans un modèle de séquence à séquence traditionnel, c'est le nombre de mots du vocabulaire qui est pris en compte.", "metrics": {"bleu_score": 43.22600177872536, "chrf_score": 71.6887500905444, "xcomet_score": 0.650368332862854, "xcomet_qe_score": 0.7047762870788574, "metricx_score": 6.290417194366455, "metricx_qe_score": 7.471227169036865, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela permet également d'imposer certaines contraintes à partir de connaissances antérieures.", "metrics": {"bleu_score": 81.49492131269727, "chrf_score": 93.22695782244715, "xcomet_score": 0.9546537399291992, "xcomet_qe_score": 0.9280358552932739, "metricx_score": 1.4146288633346558, "metricx_qe_score": 1.6419800519943237, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Nous menons donc des expériences sur l'ensemble de données de problèmes de méthode couramment utilisé, MAWPS, Metth3K, MathQA et Swam.", "metrics": {"bleu_score": 40.57473284975201, "chrf_score": 69.43087977095432, "xcomet_score": 0.5929372906684875, "xcomet_qe_score": 0.6197881698608398, "metricx_score": 7.743795394897461, "metricx_qe_score": 8.217111587524414, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous présentons brièvement les résultats en comparaison avec les meilleures approches précédentes.", "metrics": {"bleu_score": 25.33654946448646, "chrf_score": 66.42451679941773, "xcomet_score": 0.9979698657989502, "xcomet_qe_score": 0.9868038892745972, "metricx_score": 0.4384419918060303, "metricx_qe_score": 0.7541411519050598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre arme la plus performante est la raison déductive de Roberta.", "metrics": {"bleu_score": 21.97281387499715, "chrf_score": 54.277176982750206, "xcomet_score": 0.6268918514251709, "xcomet_qe_score": 0.6741154789924622, "metricx_score": 5.526547908782959, "metricx_qe_score": 5.3092732429504395, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "En fait, nous n'utilisons pas la recherche par faisceau, contrairement aux approches évidentes utilisant cette technique.", "metrics": {"bleu_score": 17.268162918696405, "chrf_score": 45.91485000704073, "xcomet_score": 0.7538012266159058, "xcomet_qe_score": 0.7977325916290283, "metricx_score": 4.3211140632629395, "metricx_qe_score": 4.126294136047363, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, donc les approches les plus efficaces sont souvent basées sur un modèle arborescent.", "metrics": {"bleu_score": 8.225964699966557, "chrf_score": 45.26355502723884, "xcomet_score": 0.977860689163208, "xcomet_qe_score": 0.9776912927627563, "metricx_score": 0.6411316394805908, "metricx_qe_score": 0.5095633268356323, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, notre raisonneur est en mesure de surperformer significativement ce modèle basé sur un arbre.", "metrics": {"bleu_score": 28.43329181530769, "chrf_score": 66.75712243219, "xcomet_score": 0.9795706272125244, "xcomet_qe_score": 0.9417070150375366, "metricx_score": 5.626899719238281, "metricx_qe_score": 7.842465400695801, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, nous pouvons constater que le nombre absolu sur MathQA ou Swam n'est pas réellement élevé.", "metrics": {"bleu_score": 11.306082351602983, "chrf_score": 50.54153859635757, "xcomet_score": 0.8332204818725586, "xcomet_qe_score": 0.7612583041191101, "metricx_score": 2.439209461212158, "metricx_qe_score": 2.3599114418029785, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez donc vous référer aux résultats de l'enquête.", "metrics": {"bleu_score": 5.0243511979240845, "chrf_score": 29.283466524010322, "xcomet_score": 0.12426462769508362, "xcomet_qe_score": 0.13678260147571564, "metricx_score": 6.885494709014893, "metricx_qe_score": 7.84743070602417, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "et cet ensemble de données est difficile car l'auteur a tenté d'ajouter manuellement des éléments pour confondre le modèle NMLB, comme par exemple des informations sur l'environnement et des quantités supplémentaires.", "metrics": {"bleu_score": 21.246013384112064, "chrf_score": 55.67667033342957, "xcomet_score": 0.5016735196113586, "xcomet_qe_score": 0.459674596786499, "metricx_score": 6.48810338973999, "metricx_qe_score": 7.442355155944824, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre prédiction, nous constatons que certaines des valeurs intermédiaires sont en réalité négatives.", "metrics": {"bleu_score": 62.685933350049744, "chrf_score": 82.43575700515215, "xcomet_score": 0.9865103960037231, "xcomet_qe_score": 1.0, "metricx_score": 1.2363011837005615, "metricx_qe_score": 0.6570975184440613, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans ces questions, nous demandons combien de pommes Jake possède.", "metrics": {"bleu_score": 57.81682559080759, "chrf_score": 84.38608419818041, "xcomet_score": 0.999131441116333, "xcomet_qe_score": 0.9961707592010498, "metricx_score": 1.9230387210845947, "metricx_qe_score": 2.3104751110076904, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous disposons d'informations supplémentaires, telles que dix-sept lancers de terrain, et Stephen a huit lancers, ce qui est tout à fait pertinent.", "metrics": {"bleu_score": 12.645915844702076, "chrf_score": 50.58962018613299, "xcomet_score": 0.2715177536010742, "xcomet_qe_score": 0.07600825279951096, "metricx_score": 15.92340087890625, "metricx_qe_score": 13.566638946533203, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait certaines prédictions de cette manière, ce qui génère des valeurs négatives.", "metrics": {"bleu_score": 27.694132751313415, "chrf_score": 50.483184501402164, "xcomet_score": 0.9684487581253052, "xcomet_qe_score": 0.9907879829406738, "metricx_score": 2.564526319503784, "metricx_qe_score": 1.739417552947998, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous observons ces deux expressions.", "metrics": {"bleu_score": 11.835764736093042, "chrf_score": 35.591235893124356, "xcomet_score": 0.2292582094669342, "xcomet_qe_score": 0.3586346507072449, "metricx_score": 16.36252784729004, "metricx_qe_score": 20.465259552001953, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous pouvons en fait limiter cet espace de recherche en éliminant les résultats similaires à ceux qui sont négatifs, de manière à pouvoir obtenir une réponse correcte.", "metrics": {"bleu_score": 21.71788734284663, "chrf_score": 61.48407269989686, "xcomet_score": 0.8675509691238403, "xcomet_qe_score": 0.7473355531692505, "metricx_score": 4.226871013641357, "metricx_qe_score": 5.17688512802124, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Nous constatons donc que cette contrainte améliore en réalité de manière significative les performances de certains modèles.", "metrics": {"bleu_score": 41.180376356915765, "chrf_score": 68.69293804729512, "xcomet_score": 0.977615237236023, "xcomet_qe_score": 0.9818390607833862, "metricx_score": 1.2951353788375854, "metricx_qe_score": 1.4993716478347778, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "par exemple, pour les oiseaux, nous avons amélioré sept points, et pour le modèle basé sur les robots, nous avons en fait amélioré de deux points.", "metrics": {"bleu_score": 25.512681188286848, "chrf_score": 49.8547700894572, "xcomet_score": 0.4108535051345825, "xcomet_qe_score": 0.46126827597618103, "metricx_score": 12.663738250732422, "metricx_qe_score": 10.997797012329102, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Un meilleur modèle linguistique possède de meilleures capacités de compréhension du langage, d'où un nombre plus élevé pour Roberta et plus faible pour les oiseaux ici.", "metrics": {"bleu_score": 23.26530933612589, "chrf_score": 48.2218605891606, "xcomet_score": 0.6967445611953735, "xcomet_qe_score": 0.7942166924476624, "metricx_score": 12.91308879852295, "metricx_qe_score": 11.81794261932373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "nous essayons également d'analyser la difficulté sous-jacente à cette BP", "metrics": {"bleu_score": 42.326181966045375, "chrf_score": 65.38960491392363, "xcomet_score": 0.39040735363960266, "xcomet_qe_score": 0.44374731183052063, "metricx_score": 7.684835910797119, "metricx_qe_score": 10.176997184753418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que la quantité de la quantité non utilisée peut être considérée comme une information pertinente ici.", "metrics": {"bleu_score": 16.258466729949635, "chrf_score": 71.65474619767416, "xcomet_score": 0.6218875050544739, "xcomet_qe_score": 0.3855776786804199, "metricx_score": 14.73408317565918, "metricx_qe_score": 15.615760803222656, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, nous pouvons voir que nous avons le lot, le pourcentage d'échantillons que nous utilisons en quantités, et le jeu de données MP a la plus grande portion.", "metrics": {"bleu_score": 33.51318042725036, "chrf_score": 69.28103619293663, "xcomet_score": 0.3997531533241272, "xcomet_qe_score": 0.30566683411598206, "metricx_score": 15.280521392822266, "metricx_qe_score": 16.895217895507812, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous présentons également la performance globale.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 84.01072369616061, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.136033058166504, "metricx_qe_score": 1.222168207168579, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "pour ces échantillons sans quantités inutilisées, de sorte que la performance globale est en réalité supérieure à la performance globale.", "metrics": {"bleu_score": 60.52665103345166, "chrf_score": 91.53856364702085, "xcomet_score": 0.48983991146087646, "xcomet_qe_score": 0.38684025406837463, "metricx_score": 8.424699783325195, "metricx_qe_score": 10.274547576904297, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "Mais pour ces échantillons dont la quantité non utilisée est en réalité bien pire que la précédente.", "metrics": {"bleu_score": 17.18548758791047, "chrf_score": 49.2946857532717, "xcomet_score": 0.7434684634208679, "xcomet_qe_score": 0.7238835096359253, "metricx_score": 10.810858726501465, "metricx_qe_score": 11.400924682617188, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "pour les MAWPS, nous n'avons pas vraiment beaucoup de cas de décès, donc j'ignore simplement cette partie.", "metrics": {"bleu_score": 48.81010344921758, "chrf_score": 74.30312501130243, "xcomet_score": 0.6012839078903198, "xcomet_qe_score": 0.6298669576644897, "metricx_score": 7.658203601837158, "metricx_qe_score": 7.901455879211426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, finalement, nous souhaitons démontrer les capacités d'interprétabilité à travers un exemple de collision et de présentation.", "metrics": {"bleu_score": 21.951524426618455, "chrf_score": 57.32250313950961, "xcomet_score": 0.3400656580924988, "xcomet_qe_score": 0.4611685872077942, "metricx_score": 7.1022725105285645, "metricx_qe_score": 8.51461124420166, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, notre modèle fait en réalité une prédiction erronée dès la première étape.", "metrics": {"bleu_score": 36.00565854285029, "chrf_score": 67.84706434636945, "xcomet_score": 0.99074387550354, "xcomet_qe_score": 0.9882351756095886, "metricx_score": 0.9161722660064697, "metricx_qe_score": 0.7885745763778687, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc en fait corréler cette expression avec la phrase ici, d'accord.", "metrics": {"bleu_score": 40.926666521068235, "chrf_score": 62.037940177652004, "xcomet_score": 0.9826978445053101, "xcomet_qe_score": 1.0, "metricx_score": 2.1269118785858154, "metricx_qe_score": 2.713076114654541, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous pensons que cette phrase pourrait induire le modèle en erreur et conduire à une prédiction incorrecte.", "metrics": {"bleu_score": 42.22374352161797, "chrf_score": 70.46633951184816, "xcomet_score": 0.9917862415313721, "xcomet_qe_score": 0.9793418645858765, "metricx_score": 0.8759045004844666, "metricx_qe_score": 0.5118520855903625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, imprimer trente-cinq autres éléments fait que le modèle pense qu'il devrait s'agir d'un opérateur d'addition.", "metrics": {"bleu_score": 12.401006001680987, "chrf_score": 64.36845706958123, "xcomet_score": 0.6711615324020386, "xcomet_qe_score": 0.45098501443862915, "metricx_score": 4.8997087478637695, "metricx_qe_score": 4.588358402252197, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous essayons de réviser la phrase pour qu'elle soit formulée ainsi : le nombre de poiriers est inférieur de trois à cinq à celui des pommiers.", "metrics": {"bleu_score": 41.73260194691079, "chrf_score": 67.21074469191988, "xcomet_score": 0.7470026016235352, "xcomet_qe_score": 0.8282075524330139, "metricx_score": 5.870600700378418, "metricx_qe_score": 8.172085762023926, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous l'adaptons pour transmettre une sémantique plus précise, de sorte que le modèle soit en mesure de faire une prédiction correcte.", "metrics": {"bleu_score": 27.748702735605818, "chrf_score": 61.51400275608753, "xcomet_score": 0.9520381689071655, "xcomet_qe_score": 0.963471531867981, "metricx_score": 1.8330905437469482, "metricx_qe_score": 1.861388921737671, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Cette étude démontre ainsi comment les prédictions interprétables nous aident à comprendre le comportement du modèle.", "metrics": {"bleu_score": 56.33639605518702, "chrf_score": 83.79982807017629, "xcomet_score": 0.9970816373825073, "xcomet_qe_score": 1.0, "metricx_score": 0.9685249328613281, "metricx_qe_score": 0.7737677693367004, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure nos travaux, notre modèle s'avère donc plutôt efficace.", "metrics": {"bleu_score": 12.920606398131978, "chrf_score": 50.55801582666546, "xcomet_score": 0.996038556098938, "xcomet_qe_score": 0.9940167665481567, "metricx_score": 1.0721218585968018, "metricx_qe_score": 1.0528178215026855, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous sommes en mesure de fournir une procédure de résolution interprétable.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0080623626708984, "metricx_qe_score": 1.129818081855774, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pouvons facilement intégrer certaines connaissances préalables en tant que contraintes, ce qui peut aider à améliorer les performances.", "metrics": {"bleu_score": 28.261688976967957, "chrf_score": 72.02893072569653, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.48536571860313416, "metricx_qe_score": 0.5391262173652649, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, le mécanisme sous-jacent ne s'applique pas uniquement aux tâches de résolution de problèmes en réseau, mais également à d'autres tâches impliquant un raisonnement en plusieurs étapes.", "metrics": {"bleu_score": 29.488830525482744, "chrf_score": 70.3430634157332, "xcomet_score": 0.9974780082702637, "xcomet_qe_score": 1.0, "metricx_score": 0.39419546723365784, "metricx_qe_score": 0.4208986163139343, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons également certaines limitations.", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 84.91693802156698, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.18605005741119385, "metricx_qe_score": 0.20433780550956726, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "Si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0386240482330322, "metricx_qe_score": 1.0148998498916626, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est que, comme mentionné, en raison de la distribution de probabilité déséquilibrée entre les différentes étapes temporelles, il est également assez difficile d'appliquer des recherches par faisceau.", "metrics": {"bleu_score": 50.594458373545955, "chrf_score": 76.23924569554192, "xcomet_score": 0.8954390287399292, "xcomet_qe_score": 0.9437116384506226, "metricx_score": 2.6811652183532715, "metricx_qe_score": 2.764594793319702, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "Voici donc la fin de l'exposé, et les questions sont les bienvenues. Merci.", "metrics": {"bleu_score": 41.74441728660793, "chrf_score": 58.02316913152566, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7645331025123596, "metricx_qe_score": 0.603451669216156, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je viens de l'Université de Maastricht.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 90.46894018144044, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.377380132675171, "metricx_qe_score": 0.664887011051178, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai mon travail sur John avec Jerry, qui porte sur un nouveau jeu de données pour la récupération d'articles législatifs.", "metrics": {"bleu_score": 25.634410755992985, "chrf_score": 53.865747876585836, "xcomet_score": 0.3165929913520813, "xcomet_qe_score": 0.25893309712409973, "metricx_score": 9.16736888885498, "metricx_qe_score": 8.983392715454102, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions juridiques font partie intégrante de la vie de nombreuses personnes.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4274544417858124, "metricx_qe_score": 0.3648781478404999, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et les processus juridiques fondamentaux.", "metrics": {"bleu_score": 56.42499050012735, "chrf_score": 87.41036983440266, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7825152277946472, "metricx_qe_score": 1.0045620203018188, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "En conséquence, de nombreux citoyens vulnérables qui ne peuvent se permettre l'assistance coûteuse d'un expert juridique restent non protégés, voire sont exploités.", "metrics": {"bleu_score": 32.61854565699772, "chrf_score": 61.5800070386603, "xcomet_score": 0.998159646987915, "xcomet_qe_score": 1.0, "metricx_score": 2.3265695571899414, "metricx_qe_score": 2.1630725860595703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Tout travail vise à combler le fossé entre les individus et la loi en développant des systèmes de récupération efficaces pour les articles législatifs.", "metrics": {"bleu_score": 37.49263325519968, "chrf_score": 62.20687125012476, "xcomet_score": 0.8618680834770203, "xcomet_qe_score": 0.897268533706665, "metricx_score": 4.178802490234375, "metricx_qe_score": 4.2719645500183105, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "Un tel système pourrait offrir un service d'aide juridique professionnelle gratuite aux personnes non qualifiées.", "metrics": {"bleu_score": 53.7284965911771, "chrf_score": 86.81847632675043, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6423779726028442, "metricx_qe_score": 0.7113671898841858, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de nous plonger dans la principale contribution de ce travail, décrivons d'abord le problème de la récupération d'articles législatifs.", "metrics": {"bleu_score": 42.911876041020285, "chrf_score": 68.11867364865248, "xcomet_score": 0.8619253039360046, "xcomet_qe_score": 0.9299176931381226, "metricx_score": 4.28786563873291, "metricx_qe_score": 2.662682056427002, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné une question simple sur les questions d'allèles, telle que quel risque cours-je si je viole le secret professionnel ?", "metrics": {"bleu_score": 9.231606884401236, "chrf_score": 46.53893130718359, "xcomet_score": 0.6448869109153748, "xcomet_qe_score": 0.37832364439964294, "metricx_score": 7.921584606170654, "metricx_qe_score": 8.412818908691406, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle est nécessaire pour extraire tous les articles législatifs pertinents d'un vaste corpus de lois.", "metrics": {"bleu_score": 55.17062567322721, "chrf_score": 79.68782406339284, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7987467050552368, "metricx_qe_score": 0.8819458484649658, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche de récupération d'informations s'accompagne de ses propres défis.", "metrics": {"bleu_score": 10.234459018728545, "chrf_score": 49.148165506015786, "xcomet_score": 0.9879382848739624, "xcomet_qe_score": 1.0, "metricx_score": 1.4421614408493042, "metricx_qe_score": 1.2193554639816284, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, il traite de deux types de langage.", "metrics": {"bleu_score": 48.326978309062206, "chrf_score": 77.70626446580955, "xcomet_score": 0.7698017358779907, "xcomet_qe_score": 0.9778584241867065, "metricx_score": 2.369997024536133, "metricx_qe_score": 1.0847606658935547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "Un langage naturel courant pour les questions et un langage juridique complexe pour les statuts.", "metrics": {"bleu_score": 31.53554052490134, "chrf_score": 63.27213373253119, "xcomet_score": 0.7938545942306519, "xcomet_qe_score": 0.87550950050354, "metricx_score": 4.313218593597412, "metricx_qe_score": 2.758528709411621, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence dans la répartition des langues rend plus difficile pour un système la récupération de candidats pertinents, car elle exige indirectement un système d'interprétation inhérent capable de traduire une question naturelle en une question juridique correspondant à la terminologie des textes de loi.", "metrics": {"bleu_score": 52.087530999077565, "chrf_score": 79.13709746854495, "xcomet_score": 0.8894720077514648, "xcomet_qe_score": 0.8381671905517578, "metricx_score": 5.070718288421631, "metricx_qe_score": 6.006514072418213, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "En plus, le droit législatif n'est pas une pile d'articles indépendants qui peuvent être traités comme une source d'information complète en eux-mêmes, comme les nouvelles ou les recettes, par exemple.", "metrics": {"bleu_score": 54.36137510661515, "chrf_score": 75.1243029247118, "xcomet_score": 0.9883962869644165, "xcomet_qe_score": 0.987637996673584, "metricx_score": 4.579534530639648, "metricx_qe_score": 3.9477944374084473, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'agit plutôt d'une collection de dispositions légales qui n'acquièrent leur sens complet que lorsqu'elles sont considérées dans leur contexte global, incluant les informations complémentaires des articles adjacents, les domaines et sous-domaines auxquels elles appartiennent, ainsi que leur place dans la structure de la loi.", "metrics": {"bleu_score": 40.28487564974578, "chrf_score": 70.13019291409933, "xcomet_score": 0.9800708293914795, "xcomet_qe_score": 0.9959050416946411, "metricx_score": 1.129501223564148, "metricx_qe_score": 1.1914077997207642, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, les articles législatifs sont présentés en petits paragraphes, ce qui constitue généralement l'unité de récupération typique dans la plupart des travaux de recherche d'information.", "metrics": {"bleu_score": 30.62049088236489, "chrf_score": 67.25758466401963, "xcomet_score": 0.46714887022972107, "xcomet_qe_score": 0.6717004776000977, "metricx_score": 12.779576301574707, "metricx_qe_score": 11.810783386230469, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "Voici des documents longs qui peuvent atteindre six unités.", "metrics": {"bleu_score": 6.061512325492642, "chrf_score": 41.687043267665466, "xcomet_score": 0.67667156457901, "xcomet_qe_score": 0.7104981541633606, "metricx_score": 11.219554901123047, "metricx_qe_score": 13.638494491577148, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les récentes avancées en traitement automatique du langage naturel (TALN) ont suscité un vif intérêt pour de nombreuses tâches juridiques, telles que la prédiction de jugements légaux ou la révision automatique de contrats de contact.", "metrics": {"bleu_score": 46.36945686979328, "chrf_score": 71.65321260401454, "xcomet_score": 0.7464580535888672, "xcomet_qe_score": 0.9208415746688843, "metricx_score": 2.5956625938415527, "metricx_qe_score": 2.341830253601074, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, la récupération d'articles légaux par référence statutaire est restée principalement hors de portée en raison du manque de grands ensembles de données étiquetés de grande qualité.", "metrics": {"bleu_score": 16.927318970546587, "chrf_score": 55.735235126994944, "xcomet_score": 0.6239973306655884, "xcomet_qe_score": 0.5841363668441772, "metricx_score": 5.531797885894775, "metricx_qe_score": 4.369121074676514, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce travail, nous présentons un nouveau jeu de données centré sur les citoyens natifs français pour étudier si un modèle de récupération peut approcher l'efficacité et la fiabilité d'un expert juridique pour la tâche de récupération d'articles de loi.", "metrics": {"bleu_score": 36.63414044136266, "chrf_score": 67.79464534138151, "xcomet_score": 0.5783319473266602, "xcomet_qe_score": 0.5103638768196106, "metricx_score": 6.408312797546387, "metricx_qe_score": 5.032440185546875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "Actuellement, l'ensemble de données de récupération d'articles de la législation belge comprend plus de 1100 éléments.", "metrics": {"bleu_score": 4.352632551621176, "chrf_score": 31.50431249731671, "xcomet_score": 0.24177195131778717, "xcomet_qe_score": 0.2845954895019531, "metricx_score": 7.2981672286987305, "metricx_qe_score": 9.238066673278809, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "Ces questions couvrent un large éventail de sujets, allant de la famille, du logement, de l'argent, au travail et à la sécurité sociale.", "metrics": {"bleu_score": 53.544522675366245, "chrf_score": 80.43253445272669, "xcomet_score": 0.9829789400100708, "xcomet_qe_score": 1.0, "metricx_score": 1.3764208555221558, "metricx_qe_score": 0.5793664455413818, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun d'eux a été étiqueté par des juristes expérimentés avec des références aux articles pertinents d'un corpus de plus de vingt-deux mille six cents.", "metrics": {"bleu_score": 46.512846588495364, "chrf_score": 68.20106962194801, "xcomet_score": 0.46945834159851074, "xcomet_qe_score": 0.7197357416152954, "metricx_score": 9.030842781066895, "metricx_qe_score": 9.457769393920898, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Codes de loi belges. Parlons maintenant de la manière dont nous avons collecté ces ensembles de données.", "metrics": {"bleu_score": 34.51395513935864, "chrf_score": 75.12558015028455, "xcomet_score": 0.1854272186756134, "xcomet_qe_score": 0.17712369561195374, "metricx_score": 14.32770824432373, "metricx_qe_score": 17.993621826171875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous avons commencé par compiler un grand corpus d'articles en langue liliale.", "metrics": {"bleu_score": 73.67565054628355, "chrf_score": 84.77545380512197, "xcomet_score": 0.31813058257102966, "xcomet_qe_score": 0.261832594871521, "metricx_score": 7.681349277496338, "metricx_qe_score": 8.084575653076172, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons examiné trente-deux codes belges publiquement disponibles et extrait l'ensemble de leurs articles ainsi que les titres de sections correspondants.", "metrics": {"bleu_score": 47.86623002056991, "chrf_score": 76.46776076299673, "xcomet_score": 0.9996852874755859, "xcomet_qe_score": 1.0, "metricx_score": 2.1673383712768555, "metricx_qe_score": 1.895862102508545, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous avons recueilli des questions juridiques avec des références aux lois pertinentes.", "metrics": {"bleu_score": 49.35578819979934, "chrf_score": 82.09435374895043, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3494468927383423, "metricx_qe_score": 1.6452088356018066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous collaborons avec le cabinet d'avocats belge qui reçoit chaque année environ quatre mille courriels de citoyens belges demandant des conseils sur une question juridique personnelle.", "metrics": {"bleu_score": 84.46593249975186, "chrf_score": 90.70257635619332, "xcomet_score": 0.9751340746879578, "xcomet_qe_score": 0.9836691617965698, "metricx_score": 0.6677900552749634, "metricx_qe_score": 0.6025882959365845, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance d'obtenir un accès à leurs sites web, où leur équipe de juristes expérimentés aborde les questions juridiques les plus courantes en Belgique.", "metrics": {"bleu_score": 76.77026013716566, "chrf_score": 88.12777036883553, "xcomet_score": 0.9949733018875122, "xcomet_qe_score": 1.0, "metricx_score": 2.31860613822937, "metricx_qe_score": 1.9564908742904663, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons recueilli des milliers de questions, annotées avec des catégories, des sous-catégories et des références juridiques aux lois pertinentes.", "metrics": {"bleu_score": 87.87419089273847, "chrf_score": 97.83316694837981, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7929880619049072, "metricx_qe_score": 0.969219446182251, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons passé en revue les références légales et écarté les questions dont les références n'étaient pas des articles dans l'un des codes de loi que nous avons examinés.", "metrics": {"bleu_score": 56.10270450354139, "chrf_score": 71.99251401905953, "xcomet_score": 0.9631067514419556, "xcomet_qe_score": 0.9601156115531921, "metricx_score": 1.300262451171875, "metricx_qe_score": 1.5887584686279297, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "Les références restantes ont été mises en correspondance et converties en identifiants d'articles correspondants à partir de la base de données allCopus.", "metrics": {"bleu_score": 19.850823739068115, "chrf_score": 69.18981314350869, "xcomet_score": 0.9368973970413208, "xcomet_qe_score": 0.9634512662887573, "metricx_score": 3.670681953430176, "metricx_qe_score": 3.8815088272094727, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons finalement abouti à mille cent huit questions, chacune soigneusement étiquetée avec les identifiants des articles pertinents.", "metrics": {"bleu_score": 35.144644781371035, "chrf_score": 56.56571888580297, "xcomet_score": 0.7712975740432739, "xcomet_qe_score": 0.8993966579437256, "metricx_score": 6.056150436401367, "metricx_qe_score": 9.829253196716309, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, chaque question est associée à une catégorie principale et à une concaténation de sous-catégories.", "metrics": {"bleu_score": 40.335820725998886, "chrf_score": 66.22500352337477, "xcomet_score": 0.9470884799957275, "xcomet_qe_score": 0.9659475684165955, "metricx_score": 4.806862831115723, "metricx_qe_score": 4.9145894050598145, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque article est accompagné d'une concaténation de leur sous-titre ultérieur dans la structure de la loi.", "metrics": {"bleu_score": 34.9632789320766, "chrf_score": 48.378601814222364, "xcomet_score": 0.6838215589523315, "xcomet_qe_score": 0.7032320499420166, "metricx_score": 9.861747741699219, "metricx_qe_score": 9.515547752380371, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Ces informations supplémentaires ne sont pas utilisées dans le présent travail, mais pourraient présenter un intérêt pour de futures recherches sur la récupération d'informations juridiques ou la classification de textes juridiques.", "metrics": {"bleu_score": 77.93192104298524, "chrf_score": 92.65738034477343, "xcomet_score": 0.9844694137573242, "xcomet_qe_score": 1.0, "metricx_score": 1.2954332828521729, "metricx_qe_score": 1.2001839876174927, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons quelques caractéristiques de notre ensemble de données.", "metrics": {"bleu_score": 10.798033448421632, "chrf_score": 52.1647406075578, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.23903164267539978, "metricx_qe_score": 0.27872389554977417, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions varient en longueur de cinq à quarante-quatre mots, avec une médiane de quarante.", "metrics": {"bleu_score": 8.767411578311545, "chrf_score": 54.23833878401204, "xcomet_score": 0.6855859756469727, "xcomet_qe_score": 0.7177684307098389, "metricx_score": 8.853034019470215, "metricx_qe_score": 6.768643379211426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont beaucoup plus longs, avec une longueur médiane de 77 mots et 140 caractères.", "metrics": {"bleu_score": 27.35477552240645, "chrf_score": 44.0412539845736, "xcomet_score": 0.1798226535320282, "xcomet_qe_score": 0.25137951970100403, "metricx_score": 11.260787963867188, "metricx_qe_score": 11.986039161682129, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "d'entre eux dépassant le millier", "metrics": {"bleu_score": 0.0, "chrf_score": 13.197832318214148, "xcomet_score": 0.15328657627105713, "xcomet_qe_score": 0.1492435783147812, "metricx_score": 21.939720153808594, "metricx_qe_score": 17.69178581237793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "Comme mentionné précédemment, la question couvrait un large éventail de sujets, dont environ quatre-vingt-cinq pour cent portaient sur la famille, le logement, l'argent ou la justice.", "metrics": {"bleu_score": 62.36555681133301, "chrf_score": 78.26138130312555, "xcomet_score": 0.7967965602874756, "xcomet_qe_score": 0.7578635215759277, "metricx_score": 3.351715564727783, "metricx_qe_score": 3.4326021671295166, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "Les quinze pour cent restants concernent soit la sécurité sociale, soit les étrangers, soit le travail.", "metrics": {"bleu_score": 40.569661365913525, "chrf_score": 78.66942608974355, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9791104793548584, "metricx_qe_score": 1.16695237159729, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très divers, car ils proviennent de 32 codes belges différents qui couvrent un grand nombre de sujets juridiques.", "metrics": {"bleu_score": 51.02002548573252, "chrf_score": 77.11398468633138, "xcomet_score": 0.9291741847991943, "xcomet_qe_score": 0.9881991147994995, "metricx_score": 1.239342212677002, "metricx_qe_score": 0.9468382000923157, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles recueillis à partir de chacun de ces codes belges.", "metrics": {"bleu_score": 80.03203203845001, "chrf_score": 85.33400976915524, "xcomet_score": 0.9932454824447632, "xcomet_qe_score": 1.0, "metricx_score": 1.5812472105026245, "metricx_qe_score": 2.8229246139526367, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Sur les 22 633 articles, seulement 1 612 sont considérés comme pertinents pour au moins un domaine.", "metrics": {"bleu_score": 5.6199559830533685, "chrf_score": 35.60189958726575, "xcomet_score": 0.4517570436000824, "xcomet_qe_score": 0.5371394753456116, "metricx_score": 3.7628183364868164, "metricx_qe_score": 4.681955337524414, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "une question dans l'ensemble de données. Et environ 80 % de ces articles cités proviennent soit du Code civil, des codes judiciaires, du Code d'instruction criminelle ou des codes pénaux.", "metrics": {"bleu_score": 39.24414299082404, "chrf_score": 67.81429756257644, "xcomet_score": 0.26515236496925354, "xcomet_qe_score": 0.3191372752189636, "metricx_score": 10.792716979980469, "metricx_qe_score": 14.931573867797852, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "Entre-temps, dix-huit des trente-deux codes comportent moins de cinq articles mentionnés comme pertinents pour au moins une question.", "metrics": {"bleu_score": 72.67243939670054, "chrf_score": 89.09978149688827, "xcomet_score": 0.9672911167144775, "xcomet_qe_score": 0.966130793094635, "metricx_score": 1.2877306938171387, "metricx_qe_score": 1.483218789100647, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Ce qui peut s'expliquer par le fait que ce code se concentre moins sur les individus et leurs préoccupations.", "metrics": {"bleu_score": 70.39848207052137, "chrf_score": 86.71174382500652, "xcomet_score": 0.9518214464187622, "xcomet_qe_score": 0.9716758728027344, "metricx_score": 3.9763171672821045, "metricx_qe_score": 4.323531627655029, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le nombre médian de citations pour ces articles cités est de 2, et moins de 2 pour cent d'entre eux le sont.", "metrics": {"bleu_score": 49.50267194106542, "chrf_score": 66.89610366121757, "xcomet_score": 0.21786025166511536, "xcomet_qe_score": 0.2980189323425293, "metricx_score": 19.560997009277344, "metricx_qe_score": 17.75986099243164, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant nos ensembles de données, nous évaluons plusieurs approches de récupération, incluant les architectures lexicales et denses.", "metrics": {"bleu_score": 11.124661907380256, "chrf_score": 56.784078366023294, "xcomet_score": 0.7764801383018494, "xcomet_qe_score": 0.9090820550918579, "metricx_score": 4.261045932769775, "metricx_qe_score": 3.8446972370147705, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné une requête dans un article, un modèle lexical attribue un score à la paire requête-article en calculant la somme, sur les termes de la requête, des poids de chacun de ces termes dans cet article.", "metrics": {"bleu_score": 68.6555146522301, "chrf_score": 86.78492596952056, "xcomet_score": 0.9279265999794006, "xcomet_qe_score": 0.9310508966445923, "metricx_score": 3.4661154747009277, "metricx_qe_score": 3.7856619358062744, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec les fonctions de classement standard TF-IDF et BM25.", "metrics": {"bleu_score": 66.36154805687889, "chrf_score": 90.65201472600005, "xcomet_score": 0.9941763877868652, "xcomet_qe_score": 0.9998935461044312, "metricx_score": 1.1771973371505737, "metricx_qe_score": 2.00666880607605, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème avec ces approches est qu'elles ne peuvent récupérer que des articles contenant des mots-clés présents dans la requête.", "metrics": {"bleu_score": 64.7084148066781, "chrf_score": 85.61375321620676, "xcomet_score": 0.9920238256454468, "xcomet_qe_score": 1.0, "metricx_score": 0.9047468900680542, "metricx_qe_score": 0.9476295709609985, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour surmonter cette limitation, nous expérimentons avec une architecture basée sur les réseaux neuronaux qui peut saisir les relations sémantiques entre les requêtes et les articles.", "metrics": {"bleu_score": 45.617777001985004, "chrf_score": 80.99652935107778, "xcomet_score": 0.9026706218719482, "xcomet_qe_score": 0.9679667949676514, "metricx_score": 0.8684665560722351, "metricx_qe_score": 0.8838399052619934, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle B-Encodeur qui cartographie les requêtes et les articles en représentations vectorielles denses et calcule un score de pertinence entre une paire requête-article en fonction de la similarité de leurs incorporations.", "metrics": {"bleu_score": 50.07336776885109, "chrf_score": 78.83396962599117, "xcomet_score": 0.7798717021942139, "xcomet_qe_score": 0.7715392112731934, "metricx_score": 4.976692199707031, "metricx_qe_score": 6.012468338012695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces embeddings résultent généralement d'une opération de pooling appliquée à la sortie d'un modèle d'embedding de mots.", "metrics": {"bleu_score": 34.49651062777743, "chrf_score": 61.62630342856708, "xcomet_score": 0.5897881984710693, "xcomet_qe_score": 0.7398167252540588, "metricx_score": 7.127813339233398, "metricx_qe_score": 7.859184265136719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous étudions l'efficacité des encodeurs siamés binaires dans un contexte d'évaluation à zéro coup, ce qui signifie que les modèles d'embedding de mots pré-entraînés sont appliqués tels quels, sans aucun réglage fin supplémentaire.", "metrics": {"bleu_score": 29.74652031241092, "chrf_score": 63.10406229075702, "xcomet_score": 0.5207467079162598, "xcomet_qe_score": 0.5302523374557495, "metricx_score": 6.6924333572387695, "metricx_qe_score": 6.133089065551758, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec des encodeurs de texte indépendants du contexte, à savoir Word2Vec et FastText, ainsi qu'avec des modèles d'embedding dépendants du contexte, notamment RoBERTa et plus spécifiquement CammBERT, qui est un modèle RoBERTa en français.", "metrics": {"bleu_score": 27.20431621491436, "chrf_score": 64.1252291100175, "xcomet_score": 0.7829403877258301, "xcomet_qe_score": 0.8406051397323608, "metricx_score": 4.837831974029541, "metricx_qe_score": 4.286778450012207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous entraînons notre propre modèle basé sur camem bird au-delà des programmeurs.", "metrics": {"bleu_score": 15.917012694603715, "chrf_score": 38.95058971121642, "xcomet_score": 0.22086761891841888, "xcomet_qe_score": 0.23539777100086212, "metricx_score": 15.268566131591797, "metricx_qe_score": 15.107969284057617, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "Sur tous les ensembles de données, notez que pour l'entraînement, nous expérimentons avec les deux variantes de l'architecture Biancoda.", "metrics": {"bleu_score": 26.934666326316563, "chrf_score": 63.35846033055239, "xcomet_score": 0.3364308476448059, "xcomet_qe_score": 0.41407591104507446, "metricx_score": 11.22545337677002, "metricx_qe_score": 11.595726013183594, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "Siamese, qui utilise un modèle d'incrustation de mots unique qui cartographie la requête et l'article ensemble dans un espace vectoriel dense partagé, et Tuto, qui utilise deux modèles d'incrustation de mots indépendants qui codent la requête et l'article séparément dans différents espaces d'incrustation.", "metrics": {"bleu_score": 48.12279254083712, "chrf_score": 75.50396414846598, "xcomet_score": 0.5758470296859741, "xcomet_qe_score": 0.623079240322113, "metricx_score": 12.241449356079102, "metricx_qe_score": 11.603713989257812, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec le pooling moyen, maximal et CLS, ainsi que le produit en décimales et le cosinus pour calculer les similarités.", "metrics": {"bleu_score": 37.41569352955004, "chrf_score": 70.07368506303683, "xcomet_score": 0.7190490961074829, "xcomet_qe_score": 0.7339873313903809, "metricx_score": 6.263266563415527, "metricx_qe_score": 5.7164201736450195, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats d'une ligne de base sur l'ensemble de test.", "metrics": {"bleu_score": 17.827531042796263, "chrf_score": 59.827487634090645, "xcomet_score": 0.6542210578918457, "xcomet_qe_score": 0.5838482975959778, "metricx_score": 6.034921646118164, "metricx_qe_score": 6.114847660064697, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "Avec les méthodes lexicales mentionnées ci-dessus, les biancodeurs siamois ont été évalués dans un contexte sans tir (zero shot) au centre, et les biancodeurs affinés se trouvent en dessous.", "metrics": {"bleu_score": 15.31305080006172, "chrf_score": 64.43934628131832, "xcomet_score": 0.23988264799118042, "xcomet_qe_score": 0.28335434198379517, "metricx_score": 12.857821464538574, "metricx_qe_score": 11.024502754211426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, les encodeurs fine-Ttuune B surclassent considérablement toutes les autres lignes de basse.", "metrics": {"bleu_score": 16.451929399933114, "chrf_score": 49.34368591698367, "xcomet_score": 0.4978022575378418, "xcomet_qe_score": 0.487520307302475, "metricx_score": 14.07054328918457, "metricx_qe_score": 14.168534278869629, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle à deux tours se montre supérieur à sa variante siamoise en termes de rappel à cent, mais présente des performances similaires sur les allométries.", "metrics": {"bleu_score": 27.495837173447466, "chrf_score": 49.13897016876989, "xcomet_score": 0.5466214418411255, "xcomet_qe_score": 0.36689475178718567, "metricx_score": 3.8592374324798584, "metricx_qe_score": 5.0265398025512695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "bien que bm vingt-cinq ait sous-performé le train au-delà de Ku de manière significative, ses performances indiquent qu'il constitue toujours une base solide pour la récupération d'informations spécifiques au domaine.", "metrics": {"bleu_score": 33.68756616854967, "chrf_score": 69.086227569598, "xcomet_score": 0.4225282371044159, "xcomet_qe_score": 0.3315468728542328, "metricx_score": 13.457133293151855, "metricx_qe_score": 13.473292350769043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation de la méthode « zero-shot » de SiameseBiancoder, nous constatons que l'utilisation directe des embeddings d'un modèle Cammbertt pré-entraîné, sans optimisation pour la tâche de récupération d'information, donne des résultats médiocres, ce qui est cohérent avec les découvertes antérieures.", "metrics": {"bleu_score": 35.09511395160899, "chrf_score": 67.10659089384768, "xcomet_score": 0.573986291885376, "xcomet_qe_score": 0.6635065078735352, "metricx_score": 5.9326491355896, "metricx_qe_score": 5.422277927398682, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous constatons que le codeur basé sur les oiseaux de type word-to-vec a considérablement surpassé les modèles fastex et basé sur les oiseaux, ce qui suggère que les embeddings de mots pré-entraînés au niveau des mots pourraient être plus adaptés à la tâche que les embeddings au niveau des caractères ou des sous-mots lorsqu'ils sont utilisés tels quels.", "metrics": {"bleu_score": 7.23632703077333, "chrf_score": 38.72746948926049, "xcomet_score": 0.10001455992460251, "xcomet_qe_score": 0.11486414074897766, "metricx_score": 18.34191131591797, "metricx_qe_score": 17.340171813964844, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que prometteurs, ces résultats suggèrent une marge de progression considérable par rapport à un expert compétent capable de récupérer à terme tous les articles pertinents en lien avec n'importe quelle question et d'obtenir ainsi des scores parfaits.", "metrics": {"bleu_score": 33.12252998773406, "chrf_score": 59.381048219025026, "xcomet_score": 0.9558337926864624, "xcomet_qe_score": 0.9838347434997559, "metricx_score": 2.2432868480682373, "metricx_qe_score": 2.678006172180176, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Terminons en abordant deux limitations inhérentes à toutes les bases de données.", "metrics": {"bleu_score": 7.768562846380176, "chrf_score": 44.240996601700836, "xcomet_score": 0.9963326454162598, "xcomet_qe_score": 1.0, "metricx_score": 3.8099722862243652, "metricx_qe_score": 2.3691582679748535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, le corpus d'articles est limité à ceux recueillis auprès des trente-deux codes belges considérés, ce qui ne couvre pas l'ensemble du droit belge, puisque les articles des décrets, directives et ordonnances font défaut.", "metrics": {"bleu_score": 61.763240975515785, "chrf_score": 75.83626680409903, "xcomet_score": 0.8920483589172363, "xcomet_qe_score": 0.9390127658843994, "metricx_score": 2.991973876953125, "metricx_qe_score": 2.731752634048462, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Pendant la construction de l'ensemble de données, toutes les références à ces articles non collectés sont ignorées, ce qui fait que certaines questions se retrouvent avec seulement une fraction du nombre initial d'articles pertinents.", "metrics": {"bleu_score": 71.63123216653572, "chrf_score": 86.34629405659464, "xcomet_score": 0.9877351522445679, "xcomet_qe_score": 0.9937875270843506, "metricx_score": 1.6623467206954956, "metricx_qe_score": 1.8759636878967285, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cette perte d'information implique que la réponse contenue dans les articles pertinents restants pourrait être incomplète, bien qu'elle soit toujours tout à fait appropriée.", "metrics": {"bleu_score": 68.87246539984304, "chrf_score": 89.37236228825259, "xcomet_score": 0.9688940644264221, "xcomet_qe_score": 0.9670678377151489, "metricx_score": 2.134427785873413, "metricx_qe_score": 1.8046678304672241, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, il convient de noter que toutes les questions juridiques ne peuvent être résolues par la seule consultation des textes de loi.", "metrics": {"bleu_score": 32.04144198812986, "chrf_score": 64.07751823486994, "xcomet_score": 0.9523282051086426, "xcomet_qe_score": 0.9884613156318665, "metricx_score": 0.7909531593322754, "metricx_qe_score": 0.8412426114082336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question : « Puis-je expulser mes locataires s'ils font trop de bruit ? »", "metrics": {"bleu_score": 72.76817202342096, "chrf_score": 93.42350457985576, "xcomet_score": 0.9943251609802246, "xcomet_qe_score": 0.9901989698410034, "metricx_score": 0.8008524179458618, "metricx_qe_score": 1.207775354385376, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "Il est possible qu'il n'y ait pas de réponse détaillée dans la loi statutaire qui quantifie un seuil de bruit spécifique au-delà duquel l'éviction est probable.", "metrics": {"bleu_score": 32.54455687469726, "chrf_score": 58.43049182851471, "xcomet_score": 0.8735451698303223, "xcomet_qe_score": 0.9387142062187195, "metricx_score": 4.295161724090576, "metricx_qe_score": 3.181455135345459, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, le propriétaire devrait probablement s'appuyer davantage sur la jurisprudence et trouver des précédents similaires à sa situation actuelle.", "metrics": {"bleu_score": 88.43865924896839, "chrf_score": 96.00693419793949, "xcomet_score": 0.9974983930587769, "xcomet_qe_score": 0.9999064207077026, "metricx_score": 0.9097432494163513, "metricx_qe_score": 1.021873950958252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le locataire organise deux fêtes par semaine jusqu'à deux heures du matin.", "metrics": {"bleu_score": 47.86471554577891, "chrf_score": 76.20432750180495, "xcomet_score": 0.9560570120811462, "xcomet_qe_score": 0.8980585932731628, "metricx_score": 2.5696845054626465, "metricx_qe_score": 1.7586041688919067, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, certaines questions sont mieux adaptées que d'autres à la tâche de récupération d'articles légaux, et le domaine de celles qui sont moins appropriées reste à déterminer.", "metrics": {"bleu_score": 56.64731353491229, "chrf_score": 77.12270476736994, "xcomet_score": 0.8461073637008667, "xcomet_qe_score": 0.6601830124855042, "metricx_score": 3.7983036041259766, "metricx_qe_score": 4.11455774307251, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que tous ces travaux susciteront un intérêt pour le développement de modèles de récupération d'articles légaux pratiques et fiables.", "metrics": {"bleu_score": 19.857943409196785, "chrf_score": 66.72675501334031, "xcomet_score": 0.7973412275314331, "xcomet_qe_score": 0.7741513848304749, "metricx_score": 4.01465368270874, "metricx_qe_score": 3.569023370742798, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut contribuer à améliorer l'accès à la justice dans son ensemble.", "metrics": {"bleu_score": 44.08231875586728, "chrf_score": 68.51846699210225, "xcomet_score": 0.9312018156051636, "xcomet_qe_score": 0.9802741408348083, "metricx_score": 1.297353982925415, "metricx_qe_score": 0.7892271876335144, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre article qui se trouve encodé aux liens suivants. Merci.", "metrics": {"bleu_score": 49.909578890518176, "chrf_score": 71.76210647878642, "xcomet_score": 0.8338472843170166, "xcomet_qe_score": 0.7920095920562744, "metricx_score": 6.276952743530273, "metricx_qe_score": 6.452884197235107, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, nous sommes ravis de vous présenter notre travail sur VoAOS, un benchmark indépendant de la tâche conçu pour évaluer les modèles de vision et de langage avec des phénomènes linguistiques spécifiques.", "metrics": {"bleu_score": 43.424740050044946, "chrf_score": 70.24321044569668, "xcomet_score": 0.5650882720947266, "xcomet_qe_score": 0.6552044749259949, "metricx_score": 5.766546249389648, "metricx_qe_score": 5.629883289337158, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Pourquoi avons-nous pris la peine d'établir cette référence ?", "metrics": {"bleu_score": 29.453347733166957, "chrf_score": 63.545167064137296, "xcomet_score": 0.9426090717315674, "xcomet_qe_score": 0.9910906553268433, "metricx_score": 2.509566068649292, "metricx_qe_score": 2.9316372871398926, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Eh bien, au cours des dernières années, nous avons assisté à une explosion des modèles de vision et de langage basés sur les transformateurs, pré-entraînés sur de grandes quantités de paires image-texte.", "metrics": {"bleu_score": 46.65354628064651, "chrf_score": 72.88225762596427, "xcomet_score": 0.9456652402877808, "xcomet_qe_score": 0.9861211776733398, "metricx_score": 2.60099720954895, "metricx_qe_score": 3.024915933609009, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun de ces modèles repousse les limites de l'état de l'art dans les tâches de vision et de langage, telles que la réponse à des questions visuelles, le raisonnement de bon sens visuel, la récupération d'images et l'ancrage de phrases.", "metrics": {"bleu_score": 43.25773824140569, "chrf_score": 74.36025721043347, "xcomet_score": 0.5992852449417114, "xcomet_qe_score": 0.7048564553260803, "metricx_score": 4.192392349243164, "metricx_qe_score": 3.7715466022491455, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous avons reçu un message. Les précisions sur ces benchmarks spécifiques à la tâche augmentent de manière régulière.", "metrics": {"bleu_score": 12.582205558459375, "chrf_score": 57.076850456826655, "xcomet_score": 0.7434040307998657, "xcomet_qe_score": 0.7269910573959351, "metricx_score": 6.031408786773682, "metricx_qe_score": 7.321688652038574, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "Mais savons-nous réellement ce que les modèles ont appris ?", "metrics": {"bleu_score": 51.69731539571708, "chrf_score": 87.01056627810956, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2264529466629028, "metricx_qe_score": 2.1026551723480225, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce qu'un transformateur de vision et de langage a compris en attribuant un score élevé à cette image et à cette phrase pour les faire correspondre ?", "metrics": {"bleu_score": 10.48987838961543, "chrf_score": 65.31965858639798, "xcomet_score": 0.8188614845275879, "xcomet_qe_score": 0.7145155072212219, "metricx_score": 2.6937437057495117, "metricx_qe_score": 2.6948859691619873, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "Et le faible score pour celui-ci.", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 50.1759551454885, "xcomet_score": 0.8763413429260254, "xcomet_qe_score": 0.8651506900787354, "metricx_score": 4.820855140686035, "metricx_qe_score": 5.258237361907959, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur la bonne chose ?", "metrics": {"bleu_score": 32.281751885843555, "chrf_score": 68.20305147191763, "xcomet_score": 0.7724132537841797, "xcomet_qe_score": 0.7463480830192566, "metricx_score": 1.717067003250122, "metricx_qe_score": 2.1995620727539062, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "Ou bien se concentrent-ils sur les biais mis en évidence par les travaux antérieurs ?", "metrics": {"bleu_score": 26.760322756637922, "chrf_score": 60.01812587758526, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7396416664123535, "metricx_qe_score": 0.92469322681427, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour apporter davantage de clarté à cet aspect, nous proposons une approche plus indépendante de la tâche et introduisons des voyelles qui évaluent la sensibilité des modèles de vision et de langage à des phénomènes linguistiques spécifiques affectant à la fois les modalités linguistique et visuelle.", "metrics": {"bleu_score": 43.51484527430479, "chrf_score": 77.2005933213046, "xcomet_score": 0.5470587015151978, "xcomet_qe_score": 0.5623716711997986, "metricx_score": 6.288947105407715, "metricx_qe_score": 5.9970502853393555, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la coférence des entités.", "metrics": {"bleu_score": 80.03526445867712, "chrf_score": 90.28106130859399, "xcomet_score": 0.9164220094680786, "xcomet_qe_score": 0.9329609870910645, "metricx_score": 3.1381566524505615, "metricx_qe_score": 3.7574660778045654, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "Mais comment tester si les modèles de vision et de langage ont capturé ce phénomène ?", "metrics": {"bleu_score": 66.689548656192, "chrf_score": 86.48384771051212, "xcomet_score": 0.9451210498809814, "xcomet_qe_score": 0.8704403638839722, "metricx_score": 1.6412419080734253, "metricx_qe_score": 2.121593952178955, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "Par l'utilisation de la technique de « foiling », une méthode précédemment appliquée pour les modèles de vision et de langage, uniquement pour les groupes nominaux par Ravi Shekhar et ses collaborateurs, et sur le comptage par nos soins dans un travail antérieur.", "metrics": {"bleu_score": 26.517937136830277, "chrf_score": 63.568376319766585, "xcomet_score": 0.5848971605300903, "xcomet_qe_score": 0.684067964553833, "metricx_score": 4.071075916290283, "metricx_qe_score": 5.266175746917725, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Le procédé de « foiling » consiste essentiellement à prendre la légende d'une image et à en créer une contre-légende en modifiant la légende originale de manière à ce qu'elle ne décrive plus l'image.", "metrics": {"bleu_score": 31.03910269754489, "chrf_score": 61.65882504951558, "xcomet_score": 0.9821842908859253, "xcomet_qe_score": 0.9888601303100586, "metricx_score": 1.7087990045547485, "metricx_qe_score": 1.912483811378479, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous effectuons ces modifications de phrases en nous concentrant sur six éléments spécifiques, tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la coférence des entités, où chaque élément peut consister en un ou plusieurs instruments, au cas où nous aurions trouvé plusieurs façons intéressantes de créer des instances FOIL.", "metrics": {"bleu_score": 73.52370804386021, "chrf_score": 88.01971706594706, "xcomet_score": 0.7274304628372192, "xcomet_qe_score": 0.62310791015625, "metricx_score": 4.409994602203369, "metricx_qe_score": 4.97138786315918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans le cas de la pièce sur les actions, nous disposons de deux instruments : l'un où le verbe d'action est modifié par une autre action, et l'autre où les actants sont intervertis.", "metrics": {"bleu_score": 29.20048059359763, "chrf_score": 54.80214372893785, "xcomet_score": 0.470826655626297, "xcomet_qe_score": 0.5479262471199036, "metricx_score": 6.191891193389893, "metricx_qe_score": 5.718452453613281, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la coréférence sont également des éléments qui impliquent plusieurs instruments.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 93.40256672183436, "xcomet_score": 0.9778286218643188, "xcomet_qe_score": 0.952937126159668, "metricx_score": 2.4053845405578613, "metricx_qe_score": 2.9613938331604004, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous créons ces leurres en veillant à ce qu'ils ne décrivent pas l'image, qu'ils soient grammaticalement corrects et autrement valides en tant que phrases.", "metrics": {"bleu_score": 28.436025391440335, "chrf_score": 66.59435511211719, "xcomet_score": 0.9800900220870972, "xcomet_qe_score": 0.9906834363937378, "metricx_score": 3.6710290908813477, "metricx_qe_score": 5.159478187561035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "Ce n'est pas facile à faire car la légende générée par l'IA est moins probable que la légende originale.", "metrics": {"bleu_score": 53.67659014253398, "chrf_score": 68.5126933156147, "xcomet_score": 0.7335324287414551, "xcomet_qe_score": 0.5302605628967285, "metricx_score": 3.3812127113342285, "metricx_qe_score": 1.7334049940109253, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien que ce ne soit pas impossible, il est statistiquement moins probable que des plantes coupent un homme plutôt qu'un homme ne coupe des plantes, et de grands modèles de vision et de langage pourraient saisir cette nuance.", "metrics": {"bleu_score": 50.615515769007175, "chrf_score": 79.6511948572415, "xcomet_score": 0.9201494455337524, "xcomet_qe_score": 0.9393297433853149, "metricx_score": 3.2749545574188232, "metricx_qe_score": 3.468413829803467, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour obtenir des résultats valides, nous devons agir.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 86.73725624316575, "xcomet_score": 0.9702205657958984, "xcomet_qe_score": 0.919377326965332, "metricx_score": 3.293989896774292, "metricx_qe_score": 3.6436421871185303, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous utilisons des modèles linguistiques robustes pour proposer des FOIls.", "metrics": {"bleu_score": 50.698033524721, "chrf_score": 72.21658713508194, "xcomet_score": 0.7697698473930359, "xcomet_qe_score": 0.6900885105133057, "metricx_score": 4.692544937133789, "metricx_qe_score": 6.97020149230957, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence en langage naturel, ou NLI, pour filtrer les fichiers qui pourraient encore décrire l'image, car lors de la construction des fichiers, nous devons nous assurer qu'ils échouent à décrire l'image.", "metrics": {"bleu_score": 51.752050994817836, "chrf_score": 76.47401238039703, "xcomet_score": 0.6437505483627319, "xcomet_qe_score": 0.7570977210998535, "metricx_score": 6.816040515899658, "metricx_qe_score": 5.490582466125488, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Pour tester cela automatiquement, nous appliquons l'inférence en langage naturel avec la logique suivante.", "metrics": {"bleu_score": 49.025517878204084, "chrf_score": 73.3542673880474, "xcomet_score": 0.9879379272460938, "xcomet_qe_score": 0.9977468252182007, "metricx_score": 1.0219922065734863, "metricx_qe_score": 0.8449519872665405, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "Nous considérons une image comme la prémisse, et sa légende comme l'hypothèse qui en découle.", "metrics": {"bleu_score": 13.32358437599213, "chrf_score": 60.050733352213456, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.8190795183181763, "metricx_qe_score": 0.9513603448867798, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous considérons la légende comme la prémisse, et le contre-exemple en est l'hypothèse.", "metrics": {"bleu_score": 59.74970909115024, "chrf_score": 74.39144199420613, "xcomet_score": 0.7695314884185791, "xcomet_qe_score": 0.6527189016342163, "metricx_score": 4.190845489501953, "metricx_qe_score": 2.7311835289001465, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit que le FOIL contredit ou est neutre par rapport à la légende, nous considérons cela comme un indicateur d'une foiL valide.", "metrics": {"bleu_score": 56.04138933843061, "chrf_score": 74.67409043594854, "xcomet_score": 0.6155771017074585, "xcomet_qe_score": 0.5572879314422607, "metricx_score": 7.598338603973389, "metricx_qe_score": 8.501102447509766, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si un NLI prédit que le contre-exemple est impliqué par la légende, il ne peut pas être un bon contre-exemple, car par transitivité, il fournira une description véridique de l'image, et nous excluons ces contre-exemples.", "metrics": {"bleu_score": 37.6481378383008, "chrf_score": 59.6259663448857, "xcomet_score": 0.5975412130355835, "xcomet_qe_score": 0.5599610805511475, "metricx_score": 9.022176742553711, "metricx_qe_score": 6.77232551574707, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cette procédure n'est pas parfaite. Il s'agit simplement d'un indicateur pour une FOI valide.", "metrics": {"bleu_score": 50.7196093945688, "chrf_score": 80.74769589966697, "xcomet_score": 0.8419218063354492, "xcomet_qe_score": 0.8224537372589111, "metricx_score": 4.252175807952881, "metricx_qe_score": 3.766688346862793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, en tant que troisième mesure pour générer des FOIL valides, nous faisons appel à des annotateurs humains pour valider les données utilisées dans Vse.", "metrics": {"bleu_score": 41.4337303262533, "chrf_score": 72.61557203053455, "xcomet_score": 0.8907763957977295, "xcomet_qe_score": 0.8337857723236084, "metricx_score": 6.488897800445557, "metricx_qe_score": 8.401440620422363, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, après filtrage et évaluation humaine, nous disposons d'autant d'instances de test que décrites dans ce tableau.", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 84.22157908468806, "xcomet_score": 0.9969282150268555, "xcomet_qe_score": 0.9879427552223206, "metricx_score": 1.3790948390960693, "metricx_qe_score": 1.936598539352417, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez noter que Valse ne fournit pas de données d'entraînement, mais uniquement des données de test.", "metrics": {"bleu_score": 42.08598069524091, "chrf_score": 60.95420548687566, "xcomet_score": 0.9748625755310059, "xcomet_qe_score": 0.9875434637069702, "metricx_score": 1.352325201034546, "metricx_qe_score": 1.519812822341919, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "puisqu'il s'agit uniquement d'un benchmark de test à zéro coup, il est conçu pour tirer parti des capacités existantes des modèles de vision et de langage après l'apprentissage préalable.", "metrics": {"bleu_score": 46.80699469593125, "chrf_score": 64.53290315951867, "xcomet_score": 0.6945382356643677, "xcomet_qe_score": 0.6641223430633545, "metricx_score": 5.350037574768066, "metricx_qe_score": 5.364495277404785, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "L'ajustement fin ne ferait que permettre aux modèles d'exploiter des artefacts ou des biais statistiques dans les données.", "metrics": {"bleu_score": 65.53609623522635, "chrf_score": 79.62616290881589, "xcomet_score": 0.9875519275665283, "xcomet_qe_score": 0.9946352243423462, "metricx_score": 1.9488697052001953, "metricx_qe_score": 2.3068864345550537, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998902082443237, "xcomet_qe_score": 1.0, "metricx_score": 1.3476738929748535, "metricx_qe_score": 2.4462342262268066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et, comme nous l'avons dit, nous sommes intéressés à évaluer les capacités que possèdent les modèles de vision et de langage après l'apprentissage préalable.", "metrics": {"bleu_score": 20.664181816537017, "chrf_score": 62.363089862509355, "xcomet_score": 0.9844992160797119, "xcomet_qe_score": 1.0, "metricx_score": 1.615140676498413, "metricx_qe_score": 1.8505265712738037, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec cinq modèles de vision et de langage sur les voyelles, à savoir CCL, Alex Mert, Wilbert, Wilbert 11 en 1, et Visual bird.", "metrics": {"bleu_score": 24.28133621314367, "chrf_score": 50.7358391566898, "xcomet_score": 0.16471077501773834, "xcomet_qe_score": 0.20298124849796295, "metricx_score": 11.241836547851562, "metricx_qe_score": 9.710638999938965, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos indicateurs d'évaluation les plus importants sont la précision des modèles dans la classification de paires de phrases d'images en légendes et en FOI (faits observables).", "metrics": {"bleu_score": 68.13943375905717, "chrf_score": 91.54486906450853, "xcomet_score": 0.7163287401199341, "xcomet_qe_score": 0.741919755935669, "metricx_score": 5.047050952911377, "metricx_qe_score": 4.045556545257568, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "Peut-être plus pertinent pour cette vidéo, nous présenterons notre métrique plus permissive, la précision par paire, qui mesure si le score d'alignement des phrases d'image est plus élevé pour la paire texte-image correcte que pour sa paire altérée.", "metrics": {"bleu_score": 55.18739176072437, "chrf_score": 73.49698533287851, "xcomet_score": 0.7118878364562988, "xcomet_qe_score": 0.6635900735855103, "metricx_score": 4.6216840744018555, "metricx_qe_score": 4.325948715209961, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "Pour plus de métriques et de résultats à leur sujet, veuillez consulter notre article.", "metrics": {"bleu_score": 17.915645938206772, "chrf_score": 62.83186212229461, "xcomet_score": 0.9481048583984375, "xcomet_qe_score": 0.9711786508560181, "metricx_score": 1.7641372680664062, "metricx_qe_score": 1.4938781261444092, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats avec précision paire sont présentés ici et ils sont cohérents avec ceux obtenus à partir des autres métriques. En effet, la meilleure performance en zéro coup est atteinte par Wilbert 12 en 1, suivie de Wilbert, Alex Mert Clip, puis enfin Visual Bir.", "metrics": {"bleu_score": 16.267392600305726, "chrf_score": 51.055781202879224, "xcomet_score": 0.3151179254055023, "xcomet_qe_score": 0.30051904916763306, "metricx_score": 9.550803184509277, "metricx_qe_score": 11.424678802490234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est remarquable de constater que les instruments axés sur des objets individuels tels que l'existence et les groupes nominaux sont presque résolus par Wilbert 12 en 1, mettant en évidence la capacité des modèles à identifier des objets nommés et leur présence dans les images.", "metrics": {"bleu_score": 35.303440171637476, "chrf_score": 65.5766279840325, "xcomet_score": 0.6456605792045593, "xcomet_qe_score": 0.6523006558418274, "metricx_score": 5.0726237297058105, "metricx_qe_score": 5.39692497253418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucune des pièces restantes ne peut être résolue de manière fiable dans nos paramètres de contournement adversarial.", "metrics": {"bleu_score": 40.1577332834242, "chrf_score": 67.96264289026772, "xcomet_score": 0.7646112442016602, "xcomet_qe_score": 0.8011974096298218, "metricx_score": 5.522130012512207, "metricx_qe_score": 5.017922401428223, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "Nous observons, à partir de la pluralité et des instruments de comptage, que les modèles de vision et de langage ont du mal à distinguer les références à un objet unique par rapport à plusieurs objets ou à les compter sur une image.", "metrics": {"bleu_score": 40.598738349634985, "chrf_score": 75.94405142037617, "xcomet_score": 0.9555622339248657, "xcomet_qe_score": 0.9441206455230713, "metricx_score": 3.1957807540893555, "metricx_qe_score": 4.001473903656006, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "La pièce de relation révèle qu'ils ont des difficultés à classer correctement une relation spatiale nommée entre des objets dans une image.", "metrics": {"bleu_score": 79.85065516266611, "chrf_score": 86.92363172426784, "xcomet_score": 0.7615975737571716, "xcomet_qe_score": 0.7450745701789856, "metricx_score": 4.996596813201904, "metricx_qe_score": 5.628585338592529, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "Ils ont également du mal à distinguer les actions et à identifier leurs participants, même lorsqu'ils sont soutenus par des biais de plausibilité, comme nous le voyons dans la partie sur les actions.", "metrics": {"bleu_score": 68.04366873393866, "chrf_score": 87.57997878478315, "xcomet_score": 0.9312673807144165, "xcomet_qe_score": 0.9536677598953247, "metricx_score": 2.56169056892395, "metricx_qe_score": 3.9398341178894043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "À partir de la pièce de la conférence, nous découvrons que la localisation de multiples références au même objet dans une image en utilisant des pronoms est également difficile pour les modèles de vision et de langage.", "metrics": {"bleu_score": 57.704995685438426, "chrf_score": 77.21430386216274, "xcomet_score": 0.5269708633422852, "xcomet_qe_score": 0.5828351974487305, "metricx_score": 7.299602031707764, "metricx_qe_score": 7.272584438323975, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "À titre de vérification de cohérence et parce que c'est une expérience intéressante, nous comparons également deux modèles textuels uniquement, GPT un et GPT deux, pour évaluer si la tâche de génération de légendes (captioning) peut être résolue par ces modèles unimodaux en calculant la perplexité de la légende correcte et de la légende erronée, sans image ici, et en prédisant l'entrée avec la perplexité la plus faible.", "metrics": {"bleu_score": 54.289473779182536, "chrf_score": 76.84688695634834, "xcomet_score": 0.7366889715194702, "xcomet_qe_score": 0.8345515727996826, "metricx_score": 6.39778995513916, "metricx_qe_score": 5.414676189422607, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "Si la perplexité est plus élevée pour le texte de contrôle, nous interprétons cela comme un indice que la légende avec texte de contrôle pourrait souffrir de biais de plausibilité ou d'autres biais linguistiques.", "metrics": {"bleu_score": 50.72570733389086, "chrf_score": 71.94253664548806, "xcomet_score": 0.7743970155715942, "xcomet_qe_score": 0.702147364616394, "metricx_score": 6.662267684936523, "metricx_qe_score": 5.741985321044922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est intéressant de constater que, dans certains cas, les modèles GPT basés uniquement sur le texte ont mieux saisi la plausibilité du monde que les modèles de vision et de langage.", "metrics": {"bleu_score": 43.01150032551201, "chrf_score": 69.9473592417539, "xcomet_score": 0.9681233167648315, "xcomet_qe_score": 0.814601719379425, "metricx_score": 3.0447278022766113, "metricx_qe_score": 3.494168996810913, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, VAL est un outil de référence qui utilise le prisme des constructions linguistiques pour aider la communauté à améliorer les modèles de vision et de langage en testant rigoureusement leurs capacités de référencement visuel.", "metrics": {"bleu_score": 43.85459213189966, "chrf_score": 70.7175418030671, "xcomet_score": 0.5851191878318787, "xcomet_qe_score": 0.7004479765892029, "metricx_score": 6.335090637207031, "metricx_qe_score": 6.3973188400268555, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences démontrent que les modèles de vision et de langage identifient bien les objets nommés lorsqu'ils sont présents dans des images, comme le montre l'exemple fourni, mais peinent à établir leur interdépendance et leurs relations dans des scènes visuelles lorsqu'ils sont contraints de respecter des indicateurs linguistiques.", "metrics": {"bleu_score": 50.598414718771856, "chrf_score": 76.48108934625596, "xcomet_score": 0.8761428594589233, "xcomet_qe_score": 0.9169877767562866, "metricx_score": 2.310495138168335, "metricx_qe_score": 2.6125264167785645, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions vraiment encourager la communauté à utiliser ValAs pour mesurer les progrès vers l'ancrage linguistique avec des modèles de vision et de langage.", "metrics": {"bleu_score": 49.546696992958005, "chrf_score": 77.9508136487543, "xcomet_score": 0.7406675815582275, "xcomet_qe_score": 0.7695168256759644, "metricx_score": 7.029928207397461, "metricx_qe_score": 7.139488697052002, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "Et même plus, les soupapes pourraient être utilisées comme une évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou le réglage fin pour déterminer si un ensemble de données aide les modèles à s'améliorer sur l'un des aspects testés par les soupapes.", "metrics": {"bleu_score": 37.371885682131335, "chrf_score": 68.32602209915056, "xcomet_score": 0.5841022729873657, "xcomet_qe_score": 0.5969753861427307, "metricx_score": 10.006003379821777, "metricx_qe_score": 7.688928604125977, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "si vous êtes intéressé, n'hésitez pas à consulter les données wallsse sur GitHub et si vous avez des questions, veuillez nous contacter sans hésiter.", "metrics": {"bleu_score": 44.82847734611616, "chrf_score": 75.49338244891341, "xcomet_score": 0.8518804311752319, "xcomet_qe_score": 0.8332400321960449, "metricx_score": 6.542739391326904, "metricx_qe_score": 6.85800838470459, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kaisura de l'Université de Tokyo.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 84.07538774745196, "xcomet_score": 0.5718578100204468, "xcomet_qe_score": 0.6083223819732666, "metricx_score": 5.716151714324951, "metricx_qe_score": 6.71976375579834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai un article intitulé « O En sum : un désert à grande échelle pour la re-notation automatique de la comxiisation. »", "metrics": {"bleu_score": 18.338344704611274, "chrf_score": 47.72949274948316, "xcomet_score": 0.025207199156284332, "xcomet_qe_score": 0.15849559009075165, "metricx_score": 19.194194793701172, "metricx_qe_score": 19.882610321044922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "Avez-vous de l'expérience dans ce domaine ?", "metrics": {"bleu_score": 5.693025330278465, "chrf_score": 25.58087978345717, "xcomet_score": 0.12209061533212662, "xcomet_qe_score": 0.10666011273860931, "metricx_score": 18.044025421142578, "metricx_qe_score": 22.2884464263916, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je vais présenter la liste automatique, non la durée, sur laquelle nous travaillons dans le cadre de cette recherche.", "metrics": {"bleu_score": 43.64460225519446, "chrf_score": 72.89178101645727, "xcomet_score": 0.43251103162765503, "xcomet_qe_score": 0.2240447700023651, "metricx_score": 14.379013061523438, "metricx_qe_score": 15.941959381103516, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "Une note de version est un document technique qui résume les modifications distribuées avec chaque version d'un produit logiciel.", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 96.10880154327184, "xcomet_score": 0.9950299263000488, "xcomet_qe_score": 0.9676945209503174, "metricx_score": 0.332943320274353, "metricx_qe_score": 0.3595074713230133, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'image présente la note de poignet pour la version 2.6.", "metrics": {"bleu_score": 9.533743950493708, "chrf_score": 29.350487478662902, "xcomet_score": 0.1586298793554306, "xcomet_qe_score": 0.2071247100830078, "metricx_score": 10.339439392089844, "metricx_qe_score": 13.41203784942627, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "bibliothèque JavaScript. Ces notes jouent un rôle important dans le développement open source, mais leur préparation manuelle est chronophage.", "metrics": {"bleu_score": 43.876426825490896, "chrf_score": 60.265163180115565, "xcomet_score": 0.404575377702713, "xcomet_qe_score": 0.3978464901447296, "metricx_score": 10.243627548217773, "metricx_qe_score": 13.620824813842773, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Il serait donc très utile de pouvoir générer automatiquement des nœuds de sortie de haute qualité.", "metrics": {"bleu_score": 46.00160223062214, "chrf_score": 68.70378175312007, "xcomet_score": 0.7341983318328857, "xcomet_qe_score": 0.7711290717124939, "metricx_score": 6.691636562347412, "metricx_qe_score": 6.2465105056762695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "Je me référerai à deux recherches antérieures sur la génération automatique d'écoute.", "metrics": {"bleu_score": 46.95736291157361, "chrf_score": 71.37084450870816, "xcomet_score": 0.6097708344459534, "xcomet_qe_score": 0.579389750957489, "metricx_score": 8.774530410766602, "metricx_qe_score": 8.831404685974121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier est un système appelé a. Il a été lancé en 2014.", "metrics": {"bleu_score": 18.20705281109213, "chrf_score": 36.99602477226831, "xcomet_score": 0.20889514684677124, "xcomet_qe_score": 0.3023587763309479, "metricx_score": 10.08035945892334, "metricx_qe_score": 8.9598970413208, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "adopte une approche basée sur des règles, par exemple, en utilisant l'extracteur de modifications pour extraire les différences fondamentales, les modifications de bibliothèque et les modifications de documents à partir des différences entre les versions, puis en les combinant finalement.", "metrics": {"bleu_score": 54.244946080639004, "chrf_score": 73.68890199609216, "xcomet_score": 0.7612764835357666, "xcomet_qe_score": 0.84540194272995, "metricx_score": 4.385135173797607, "metricx_qe_score": 3.067605972290039, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus remarquable de ce système est l'extrait de question situé dans le coin supérieur droit.", "metrics": {"bleu_score": 51.61040075276384, "chrf_score": 74.98666110764101, "xcomet_score": 0.7273531556129456, "xcomet_qe_score": 0.6605304479598999, "metricx_score": 6.820030212402344, "metricx_qe_score": 6.578273296356201, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "Qui doit être lié à Jira, l'écosystème des problèmes, et ne peut être appliqué qu'aux projets utilisant Jira.", "metrics": {"bleu_score": 33.40683832446, "chrf_score": 69.84205255250413, "xcomet_score": 0.5777122974395752, "xcomet_qe_score": 0.6117764115333557, "metricx_score": 6.842568397521973, "metricx_qe_score": 6.49205207824707, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, il ne peut être utilisé pour de nombreux projets sur GitHub.", "metrics": {"bleu_score": 67.05624049819114, "chrf_score": 83.8043038783597, "xcomet_score": 0.9997879266738892, "xcomet_qe_score": 0.9898210167884827, "metricx_score": 0.7139981389045715, "metricx_qe_score": 0.8693636655807495, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "Le second est le deuil récemment annoncé en vingt.", "metrics": {"bleu_score": 5.934202609760488, "chrf_score": 51.539680142402524, "xcomet_score": 0.20962855219841003, "xcomet_qe_score": 0.29402437806129456, "metricx_score": 20.613235473632812, "metricx_qe_score": 18.104001998901367, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "vingt Il est disponible sur Internet et peut être stocké via peep.", "metrics": {"bleu_score": 20.78060434846712, "chrf_score": 61.77456654637334, "xcomet_score": 0.1494472324848175, "xcomet_qe_score": 0.14463114738464355, "metricx_score": 15.301177978515625, "metricx_qe_score": 16.418800354003906, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système intègre un modèle de classification de texte basé sur le traitement automatique du langage naturel, qui génère cinq paramètres sous forme de caractéristiques ou de corrections de bogues pour chaque message d'engagement en entrée.", "metrics": {"bleu_score": 25.676375293941867, "chrf_score": 51.70558763745014, "xcomet_score": 0.3990883231163025, "xcomet_qe_score": 0.5298275947570801, "metricx_score": 4.902814865112305, "metricx_qe_score": 4.297214984893799, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un exemple d'utilisation qui retourne un résultat corrigé ou un correctif pour un bogue.", "metrics": {"bleu_score": 23.287896954139942, "chrf_score": 54.263937445070745, "xcomet_score": 0.7537682056427002, "xcomet_qe_score": 0.8732135891914368, "metricx_score": 3.1293890476226807, "metricx_qe_score": 3.1896920204162598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "Les données d'entraînement de Quifer sont relativement réduites, environ cinq mille, et seront présentées dans les expériences décrites ci-dessous.", "metrics": {"bleu_score": 49.70449067437272, "chrf_score": 69.47447864167215, "xcomet_score": 0.5026547908782959, "xcomet_qe_score": 0.5331085920333862, "metricx_score": 8.323870658874512, "metricx_qe_score": 9.39068603515625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "La performance du modèle de classification de texte n'est pas élevée.", "metrics": {"bleu_score": 41.24914892312113, "chrf_score": 77.37520089391352, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7285580635070801, "metricx_qe_score": 1.104062795639038, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches connexes, mais il existe des problèmes de faible applicabilité et de ressources de données limitées.", "metrics": {"bleu_score": 36.30716142599353, "chrf_score": 72.93078782018884, "xcomet_score": 0.9606995582580566, "xcomet_qe_score": 0.934094250202179, "metricx_score": 1.320996880531311, "metricx_qe_score": 1.3566319942474365, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des résultats de haute qualité.", "metrics": {"bleu_score": 70.0418991088418, "chrf_score": 82.96714507848351, "xcomet_score": 0.8807588219642639, "xcomet_qe_score": 0.9289770126342773, "metricx_score": 1.991029143333435, "metricx_qe_score": 3.3552396297454834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Avec un programme ACO limité, nous proposons une méthode de résumé de classificateur de haute qualité utilisant uniquement les messages de validation comme entrée.", "metrics": {"bleu_score": 34.672583531400704, "chrf_score": 64.4772858676341, "xcomet_score": 0.6328397989273071, "xcomet_qe_score": 0.5215036273002625, "metricx_score": 8.261492729187012, "metricx_qe_score": 8.544084548950195, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée pour toutes les séries de bibliothèques de livres en anglais.", "metrics": {"bleu_score": 39.56716729452429, "chrf_score": 72.77862970725236, "xcomet_score": 0.7981150150299072, "xcomet_qe_score": 0.8478755950927734, "metricx_score": 4.191580772399902, "metricx_qe_score": 3.658116579055786, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème relatif aux ressources limitées, nous avons construit notre propre ensemble de données composé d'environ quatre-vingt-deux mille éléments, en corrigeant les données provenant de dépôts publics sur GitHub à l'aide de l'API GitHub.", "metrics": {"bleu_score": 23.768240335710885, "chrf_score": 62.71244710822453, "xcomet_score": 0.7010357975959778, "xcomet_qe_score": 0.6385210752487183, "metricx_score": 6.49380350112915, "metricx_qe_score": 6.369165420532227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décris notre désert.", "metrics": {"bleu_score": 22.772101321113862, "chrf_score": 41.252730026822185, "xcomet_score": 0.3890964388847351, "xcomet_qe_score": 0.4221149682998657, "metricx_score": 12.627046585083008, "metricx_qe_score": 13.441385269165039, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre exemple de données.", "metrics": {"bleu_score": 53.7284965911771, "chrf_score": 76.85915067385532, "xcomet_score": 0.946622908115387, "xcomet_qe_score": 0.9420696496963501, "metricx_score": 0.9208157062530518, "metricx_qe_score": 1.0900479555130005, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche présente un message de validation (commit message), tandis que le côté droit contient une note.", "metrics": {"bleu_score": 20.46592065585361, "chrf_score": 61.667140489072025, "xcomet_score": 0.7965880036354065, "xcomet_qe_score": 0.7911387085914612, "metricx_score": 5.395775318145752, "metricx_qe_score": 5.217642784118652, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "Ces notes sont conçues comme des améliorations pour les bureaux, etc.", "metrics": {"bleu_score": 14.211672443220438, "chrf_score": 43.218251331894066, "xcomet_score": 0.209786519408226, "xcomet_qe_score": 0.3240848183631897, "metricx_score": 11.138845443725586, "metricx_qe_score": 10.197986602783203, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons mis en place une tâche qui prend les messages de validation comme entrée et produit le nœud du lapin en sortie.", "metrics": {"bleu_score": 57.28145662417077, "chrf_score": 66.34726741707051, "xcomet_score": 0.6072214841842651, "xcomet_qe_score": 0.5301278233528137, "metricx_score": 7.452237129211426, "metricx_qe_score": 8.279529571533203, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de résumé.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 80.28616903243483, "xcomet_score": 0.9564080238342285, "xcomet_qe_score": 0.9850058555603027, "metricx_score": 1.28573477268219, "metricx_qe_score": 0.8809378743171692, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons prédéfini quatre catégories : fonctionnalités, améliorations, corrections de bogues, dépréciations, suppressions et modifications bloquantes.", "metrics": {"bleu_score": 33.38980625502128, "chrf_score": 76.26099662632456, "xcomet_score": 0.5890340805053711, "xcomet_qe_score": 0.5850504040718079, "metricx_score": 7.172292232513428, "metricx_qe_score": 5.900816917419434, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces paramètres ont été définis en fonction de l'utilisation des porcs et d'autres facteurs.", "metrics": {"bleu_score": 20.333448190047886, "chrf_score": 36.97001738198908, "xcomet_score": 0.24624893069267273, "xcomet_qe_score": 0.27966219186782837, "metricx_score": 12.185062408447266, "metricx_qe_score": 11.182896614074707, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a des notes en bas à droite et extraites de la liste de notes affichées en bas à gauche.", "metrics": {"bleu_score": 30.09429889037876, "chrf_score": 53.66000894187347, "xcomet_score": 0.5610795617103577, "xcomet_qe_score": 0.6096025705337524, "metricx_score": 7.177911758422852, "metricx_qe_score": 8.027140617370605, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce stade, il est nécessaire de détecter les quatre lapins qui ont été placés dans un passage.", "metrics": {"bleu_score": 56.42864776886819, "chrf_score": 64.77689379847592, "xcomet_score": 0.3388954997062683, "xcomet_qe_score": 0.25782033801078796, "metricx_score": 13.50972843170166, "metricx_qe_score": 14.918015480041504, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les derniers ne sont pas toujours cohérents avec chaque lèvre.", "metrics": {"bleu_score": 29.50234363196403, "chrf_score": 62.36392452833167, "xcomet_score": 0.20179909467697144, "xcomet_qe_score": 0.1709170639514923, "metricx_score": 11.093812942504883, "metricx_qe_score": 11.832225799560547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, ces améliorations encouragent plutôt des améliorations, des renforcements, des optimisations, et ainsi de suite.", "metrics": {"bleu_score": 28.592291256793107, "chrf_score": 65.56396842144633, "xcomet_score": 0.6394346952438354, "xcomet_qe_score": 0.5362462997436523, "metricx_score": 9.126590728759766, "metricx_qe_score": 9.452481269836426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste de vocabulaire d'environ trente nombres pour chacune de ces variations de notation.", "metrics": {"bleu_score": 71.60350546947924, "chrf_score": 79.01704943603377, "xcomet_score": 0.8392044305801392, "xcomet_qe_score": 0.8365087509155273, "metricx_score": 9.598918914794922, "metricx_qe_score": 9.79552936553955, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez-le pour détecter l'absence de croûtes, et citez le texte restant tel quel, car il n'y a pas de phrase ou de croûte.", "metrics": {"bleu_score": 3.4299879249733487, "chrf_score": 28.535752509979428, "xcomet_score": 0.12642179429531097, "xcomet_qe_score": 0.12222735583782196, "metricx_score": 16.07655143737793, "metricx_qe_score": 16.111160278320312, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "En suivant, un message d'engagement.", "metrics": {"bleu_score": 10.175282441454787, "chrf_score": 37.117170581662705, "xcomet_score": 0.42330503463745117, "xcomet_qe_score": 0.7244790196418762, "metricx_score": 5.120975017547607, "metricx_qe_score": 4.213433265686035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de Comer ne sont pas associés à chaque voix.", "metrics": {"bleu_score": 24.808415001701803, "chrf_score": 56.13725866048409, "xcomet_score": 0.38930121064186096, "xcomet_qe_score": 0.43703505396842957, "metricx_score": 14.361800193786621, "metricx_qe_score": 11.625229835510254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "Comme illustré dans l'image ci-dessous, si le risque actuel est supérieur à 2,5 et inférieur à 19, nous devons identifier", "metrics": {"bleu_score": 13.775499893079486, "chrf_score": 36.8073215548657, "xcomet_score": 0.21683360636234283, "xcomet_qe_score": 0.23094436526298523, "metricx_score": 22.75580596923828, "metricx_qe_score": 20.735607147216797, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "Selon la version précédente des devoirs, section 2.5 à 18, et assurez-vous que le texte soit rigoureux. Cette étape est un peu fastidieuse, et il ne suffit pas d'obtenir une liste des versions et de comparer avant et après.", "metrics": {"bleu_score": 20.03554941023862, "chrf_score": 62.27252779445891, "xcomet_score": 0.1276157945394516, "xcomet_qe_score": 0.13852322101593018, "metricx_score": 22.39175796508789, "metricx_qe_score": 22.232318878173828, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons créé une colle de correspondance heuristique pour obtenir les versions précédente et suivante.", "metrics": {"bleu_score": 55.33409598501604, "chrf_score": 78.49824596858818, "xcomet_score": 0.8297292590141296, "xcomet_qe_score": 0.6893731355667114, "metricx_score": 8.475892066955566, "metricx_qe_score": 9.207757949829102, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "Ils s'assoient sur l'infirmière.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 9.075907590759074, "xcomet_score": 0.09423098713159561, "xcomet_qe_score": 0.07475781440734863, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "À la fin, 7 200 dépôts.", "metrics": {"bleu_score": 1.7426130460477305, "chrf_score": 6.741845838363571, "xcomet_score": 0.14176954329013824, "xcomet_qe_score": 0.14590364694595337, "metricx_score": 21.544116973876953, "metricx_qe_score": 20.370868682861328, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de cibles raisonnables est de soixante-trois, ce qui est assez élevé pour des tâches de sommation.", "metrics": {"bleu_score": 47.761152007880774, "chrf_score": 60.37549410223536, "xcomet_score": 0.49233004450798035, "xcomet_qe_score": 0.41592952609062195, "metricx_score": 13.23240852355957, "metricx_qe_score": 8.923521041870117, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre de jetons uniques est assez élevé, s'élevant à huit mille huit cent trente mille. c'est", "metrics": {"bleu_score": 59.61621647299124, "chrf_score": 75.0355944602338, "xcomet_score": 0.4257853329181671, "xcomet_qe_score": 0.32995498180389404, "metricx_score": 6.936435222625732, "metricx_qe_score": 3.3925201892852783, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "au grand nombre de casts uniques de noms de méthodes trouvés dans le laboratoire.", "metrics": {"bleu_score": 23.850080213378284, "chrf_score": 58.394542210600676, "xcomet_score": 0.15014398097991943, "xcomet_qe_score": 0.14793291687965393, "metricx_score": 16.24215316772461, "metricx_qe_score": 14.70898151397705, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, j'expliquerai la méthode proposée.", "metrics": {"bleu_score": 36.74145494215666, "chrf_score": 75.59105076499984, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26971232891082764, "metricx_qe_score": 0.1778177171945572, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de résumé extractif et abstrait en croix se compose de deux modules neuronaux.", "metrics": {"bleu_score": 45.788313721339826, "chrf_score": 59.9394677612249, "xcomet_score": 0.6662644147872925, "xcomet_qe_score": 0.6592811346054077, "metricx_score": 5.703158378601074, "metricx_qe_score": 5.0267558097839355, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "Un tir croisé utilisant une barre ou appelé barre, et le générateur utilisant Bart.", "metrics": {"bleu_score": 6.690080689159478, "chrf_score": 43.436795488795255, "xcomet_score": 0.1481878161430359, "xcomet_qe_score": 0.1358412802219391, "metricx_score": 20.031673431396484, "metricx_qe_score": 21.722383499145508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier CS utilise un classifieur pour catégoriser chaque message de commit en cinq classes de nœuds de base : fonctionnalités, correctifs de bogues, dépréciations, et autres.", "metrics": {"bleu_score": 14.335691723248912, "chrf_score": 51.924809864908624, "xcomet_score": 0.33404260873794556, "xcomet_qe_score": 0.32465967535972595, "metricx_score": 9.868607521057129, "metricx_qe_score": 10.937536239624023, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages du comité classés comme « a » ou rejetés.", "metrics": {"bleu_score": 10.127993013562818, "chrf_score": 43.6146045758554, "xcomet_score": 0.3054549992084503, "xcomet_qe_score": 0.32987719774246216, "metricx_score": 16.204036712646484, "metricx_qe_score": 15.094405174255371, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, elle est un prix saturé aux quatre documents en caoutchouc indépendamment et génère cette note pour chaque classe. \n\n(Note : La phrase en anglais semble contenir des erreurs ou des maladresses, ce qui rend la traduction littérale un peu confuse. Dans un contexte académique ou instructif, il serait peut-être plus approprié d'interpréter cette phrase ainsi : \"Ensuite, elle attribue des notes saturées aux quatre documents en caoutchouc indépendamment pour chaque classe.\")", "metrics": {"bleu_score": 5.814212446089335, "chrf_score": 43.075932053541536, "xcomet_score": 0.1429717093706131, "xcomet_qe_score": 0.13949990272521973, "metricx_score": 25.0, "metricx_qe_score": 23.822370529174805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages de validation (commit messages) et les résultats (res) ne sont pas connues.", "metrics": {"bleu_score": 56.680061739951036, "chrf_score": 80.48130717052913, "xcomet_score": 0.8208348751068115, "xcomet_qe_score": 0.8564211130142212, "metricx_score": 4.546720027923584, "metricx_qe_score": 5.273256778717041, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour entraîner le classifieur, nous attribuons des frottements pseudo-aléatoires à chaque message de validation d'entrée en utilisant les dix premiers caractères de chaque message de validation.", "metrics": {"bleu_score": 55.595557945360895, "chrf_score": 75.33581951082458, "xcomet_score": 0.48040905594825745, "xcomet_qe_score": 0.4862654209136963, "metricx_score": 7.392439842224121, "metricx_qe_score": 6.580023765563965, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons la transversale des sommes destructrices pour approcher deux méthodes définies.", "metrics": {"bleu_score": 6.299392144493405, "chrf_score": 40.68534449015141, "xcomet_score": 0.13851237297058105, "xcomet_qe_score": 0.14504921436309814, "metricx_score": 19.923259735107422, "metricx_qe_score": 19.851581573486328, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons gs simple, se compose d'un unique réseau six six et génère un texte long unique en fonction d'une concaténation de messages d'engagement d'entrée.", "metrics": {"bleu_score": 27.88074162678989, "chrf_score": 56.07522781106468, "xcomet_score": 0.15947186946868896, "xcomet_qe_score": 0.3109767735004425, "metricx_score": 14.441251754760742, "metricx_qe_score": 15.220345497131348, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte extérieur peut être divisé en segments transversaux en fonction de symboles spécifiques à chaque croix.", "metrics": {"bleu_score": 5.125985541856496, "chrf_score": 38.59607481834061, "xcomet_score": 0.25340205430984497, "xcomet_qe_score": 0.2789021134376526, "metricx_score": 12.150052070617676, "metricx_qe_score": 9.906316757202148, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons « shes much », consiste en quatre réseaux sec-à-sec différents, chacun correspondant à l'une des classes de nœuds les moins importantes.", "metrics": {"bleu_score": 27.501804610524818, "chrf_score": 58.192206255838485, "xcomet_score": 0.07261394709348679, "xcomet_qe_score": 0.08063571155071259, "metricx_score": 16.880390167236328, "metricx_qe_score": 15.963800430297852, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, laissez-moi expliquer l'expérience.", "metrics": {"bleu_score": 6.4790667469036025, "chrf_score": 47.210365058958445, "xcomet_score": 0.9313861131668091, "xcomet_qe_score": 0.9775118827819824, "metricx_score": 1.1269221305847168, "metricx_qe_score": 0.8525193333625793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été comparées. elle est, elle une chanteuse, elle a souri, en appuyant, et Bri a étudié le deuil.", "metrics": {"bleu_score": 15.822637961675994, "chrf_score": 39.81303529057088, "xcomet_score": 0.12874145805835724, "xcomet_qe_score": 0.13491429388523102, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'aberration, dans certains cas, cela ne correspond pas à notre sortie en plusieurs phrases.", "metrics": {"bleu_score": 39.898493411026585, "chrf_score": 61.33134264230043, "xcomet_score": 0.1457742154598236, "xcomet_qe_score": 0.1544964462518692, "metricx_score": 17.142393112182617, "metricx_qe_score": 15.99124526977539, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné qu'il est difficile de corriger le nombre de phrases à zéro, elles sont combinées avec des espaces et traitées comme une seule phrase longue.", "metrics": {"bleu_score": 64.85614278660147, "chrf_score": 77.6210186875518, "xcomet_score": 0.5763077735900879, "xcomet_qe_score": 0.525881290435791, "metricx_score": 7.870542526245117, "metricx_qe_score": 9.077749252319336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "La facture est prête lorsque le système génère une phrase courte.", "metrics": {"bleu_score": 31.702331385234313, "chrf_score": 56.84734592765444, "xcomet_score": 0.19800493121147156, "xcomet_qe_score": 0.17276756465435028, "metricx_score": 15.603972434997559, "metricx_qe_score": 13.770389556884766, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité entraîne une légère diminution de la valeur de br dans l'expérience, comme décrit ci-après.", "metrics": {"bleu_score": 6.0745880708766835, "chrf_score": 42.15692346234106, "xcomet_score": 0.8381078243255615, "xcomet_qe_score": 0.8430444598197937, "metricx_score": 6.97305154800415, "metricx_qe_score": 7.788784980773926, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous chargeons également une spécificité car le rouge et la brume ne peuvent être chargés si les notes de poignet sont vides.", "metrics": {"bleu_score": 21.494052714772316, "chrf_score": 57.21214853234192, "xcomet_score": 0.28827136754989624, "xcomet_qe_score": 0.2543933689594269, "metricx_score": 10.629738807678223, "metricx_qe_score": 9.061198234558105, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une haute spécificité signifie que le modèle produit correctement des textes vides dans les cas où le nœud de lecture suppose un vide.", "metrics": {"bleu_score": 30.945753895751707, "chrf_score": 60.26010262524962, "xcomet_score": 0.8295575976371765, "xcomet_qe_score": 0.9575725793838501, "metricx_score": 3.8283493518829346, "metricx_qe_score": 4.108493804931641, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats.", "metrics": {"bleu_score": 11.521590992286539, "chrf_score": 34.57828622839441, "xcomet_score": 0.7604808807373047, "xcomet_qe_score": 1.0, "metricx_score": 0.15108263492584229, "metricx_qe_score": 0.03296280279755592, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que le jeu de données contient des adresses e-mail, des valeurs, etc., nous évaluons également les données nettoyées qui les excluent.", "metrics": {"bleu_score": 26.077480195426233, "chrf_score": 67.44900733881461, "xcomet_score": 0.7703975439071655, "xcomet_qe_score": 0.5831087827682495, "metricx_score": 6.247273921966553, "metricx_qe_score": 8.67530632019043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "Les scores CAS et CAS ont atteint des valeurs élevées, dépassant de plus de dix points les valeurs de référence.", "metrics": {"bleu_score": 21.27988282044162, "chrf_score": 40.66453515338089, "xcomet_score": 0.2724403142929077, "xcomet_qe_score": 0.23336437344551086, "metricx_score": 12.927286148071289, "metricx_qe_score": 13.088369369506836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur l'ensemble de données de test coréen, l'écart de score entre la méthode proposée et le saut patient augmente de plus de 20 parties.", "metrics": {"bleu_score": 47.16792033214353, "chrf_score": 69.58424872520662, "xcomet_score": 0.07483721524477005, "xcomet_qe_score": 0.18154233694076538, "metricx_score": 16.52870750427246, "metricx_qe_score": 16.071428298950195, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent que « elle » et « il » sont significativement efficaces.", "metrics": {"bleu_score": 18.92240568795936, "chrf_score": 45.996433849804816, "xcomet_score": 0.1397714614868164, "xcomet_qe_score": 0.15364405512809753, "metricx_score": 20.738801956176758, "metricx_qe_score": 17.335298538208008, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "g a obtenu un meilleur score de logique que g, ce qui suggère que la combinaison d'un classifieur et d'un générateur est efficace dans l'entraînement du classifieur en utilisant.", "metrics": {"bleu_score": 41.82108872884494, "chrf_score": 61.358704902866066, "xcomet_score": 0.13340578973293304, "xcomet_qe_score": 0.12346000224351883, "metricx_score": 22.214332580566406, "metricx_qe_score": 22.269813537597656, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "Une couverture élevée des Gs peut être obtenue de manière adéquate car le classifieur peut se concentrer sur la sélection des messages de validation pertinents pour chaque classe.", "metrics": {"bleu_score": 60.94880572755877, "chrf_score": 82.766511052989, "xcomet_score": 0.5307761430740356, "xcomet_qe_score": 0.5340490341186523, "metricx_score": 8.397845268249512, "metricx_qe_score": 8.670223236083984, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Elle a tendance à consommer une littérature plus raffinée qu'elle ne le fait pour un seul repas.", "metrics": {"bleu_score": 3.0372940354383413, "chrf_score": 20.599518975105443, "xcomet_score": 0.11747267842292786, "xcomet_qe_score": 0.10605189949274063, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "Suggérer qu'il est également efficace de développer indépendamment différents modèles de résumé perceptif pour chaque nœud de graphe.", "metrics": {"bleu_score": 29.722070478348186, "chrf_score": 56.78040002439077, "xcomet_score": 0.33669549226760864, "xcomet_qe_score": 0.4175889492034912, "metricx_score": 5.681528091430664, "metricx_qe_score": 5.83717155456543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "Ici et Araasis.", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 7.682121607894353, "xcomet_score": 0.1116931140422821, "xcomet_qe_score": 0.09849734604358673, "metricx_score": 20.48834800720215, "metricx_qe_score": 20.6571044921875, "linguapy_score": [1, "SHONA"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes de Shear ont tendance à produire des phrases plus courtes que les phrases de référence humaines.", "metrics": {"bleu_score": 80.86627571031983, "chrf_score": 92.84553458313619, "xcomet_score": 0.5996298789978027, "xcomet_qe_score": 0.4292909801006317, "metricx_score": 9.963709831237793, "metricx_qe_score": 12.313870429992676, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure à droite, la phrase différente se compose de trois ou quatre phrases, tandis qu'elle n'en a qu'une seule.", "metrics": {"bleu_score": 40.57473284975201, "chrf_score": 71.63608014192914, "xcomet_score": 0.25500690937042236, "xcomet_qe_score": 0.16134721040725708, "metricx_score": 11.501385688781738, "metricx_qe_score": 12.220572471618652, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette réticence moderne est que dans les données d'entraînement, seulement trente-trois pour cent des phrases sont présentes au niveau des caractéristiques et quarante pour cent au niveau des améliorations.", "metrics": {"bleu_score": 44.52235620125657, "chrf_score": 67.72828805540124, "xcomet_score": 0.5129847526550293, "xcomet_qe_score": 0.5417301654815674, "metricx_score": 6.391512393951416, "metricx_qe_score": 6.021488189697266, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes des CS ne peuvent pas générer de nœuds de risque précis sans informations supplémentaires.", "metrics": {"bleu_score": 30.752616970214323, "chrf_score": 70.41844539041591, "xcomet_score": 0.41612347960472107, "xcomet_qe_score": 0.4887797236442566, "metricx_score": 10.178159713745117, "metricx_qe_score": 8.858083724975586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple en haut à droite est un exemple d'un message très désordonné, et la phrase complète ne peut être générée sans faire référence au prerogatif ou à l'enjeu correspondant.", "metrics": {"bleu_score": 45.5791908078982, "chrf_score": 68.97302328543363, "xcomet_score": 0.6755231618881226, "xcomet_qe_score": 0.698432207107544, "metricx_score": 7.242717742919922, "metricx_qe_score": 7.146389007568359, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous illustre que les deux messages de validation dans l'entrée sont liés et devraient être combinés en une seule phrase, mais il échoue à le faire.", "metrics": {"bleu_score": 38.55843077233733, "chrf_score": 72.87038319757905, "xcomet_score": 0.9352969527244568, "xcomet_qe_score": 0.8995837569236755, "metricx_score": 2.760295867919922, "metricx_qe_score": 2.3535332679748535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, une conclusion.", "metrics": {"bleu_score": 20.252884954471366, "chrf_score": 51.7870301786907, "xcomet_score": 0.9809033870697021, "xcomet_qe_score": 1.0, "metricx_score": 1.8073315620422363, "metricx_qe_score": 2.418452262878418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons construit un nouvel ensemble de données pour la génération automatique de textes commerciaux.", "metrics": {"bleu_score": 40.325042950627804, "chrf_score": 70.62469268818678, "xcomet_score": 0.604311466217041, "xcomet_qe_score": 0.7214757204055786, "metricx_score": 6.483513355255127, "metricx_qe_score": 5.254386901855469, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également formulé la tâche consistant à saisir les messages du comité et à les résumer de manière à ce qu'elle soit applicable à tous les projets rédigés en anglais.", "metrics": {"bleu_score": 33.27780914156996, "chrf_score": 68.08482068315877, "xcomet_score": 0.7433608770370483, "xcomet_qe_score": 0.7444692850112915, "metricx_score": 4.082623481750488, "metricx_qe_score": 3.8447704315185547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences démontrent que le courant musculaire proposé, moins bruyant, n'offre pas une couverture supérieure à celle de la référence.", "metrics": {"bleu_score": 5.856458233275369, "chrf_score": 49.091393342369415, "xcomet_score": 0.15002256631851196, "xcomet_qe_score": 0.13026610016822815, "metricx_score": 13.424887657165527, "metricx_qe_score": 8.168810844421387, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Vérifiez Dieu ou le désert en haut.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 13.264810566860765, "xcomet_score": 0.12887080013751984, "xcomet_qe_score": 0.11578445881605148, "metricx_score": 20.655317306518555, "metricx_qe_score": 20.023406982421875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10382990539073944, "metricx_qe_score": 0.4022793173789978, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Safari.", "metrics": {"bleu_score": 9.042266054940777, "chrf_score": 51.95600869804089, "xcomet_score": 0.15911778807640076, "xcomet_qe_score": 0.1166134923696518, "metricx_score": 7.403709888458252, "metricx_qe_score": 6.702765464782715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "Et je présente notre article sur l'enrichissement de données tabulaires à l'aide de l'affinage des architectures de transformateurs.", "metrics": {"bleu_score": 11.977165750310858, "chrf_score": 68.75088674930035, "xcomet_score": 0.9359159469604492, "xcomet_qe_score": 0.9047234058380127, "metricx_score": 3.8819828033447266, "metricx_qe_score": 5.230895042419434, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "Un scientifique analyse les données et se concentre principalement sur la manipulation des caractéristiques existantes des données.", "metrics": {"bleu_score": 47.18372009351201, "chrf_score": 78.50547815579387, "xcomet_score": 0.9930011034011841, "xcomet_qe_score": 0.9458763599395752, "metricx_score": 3.8039889335632324, "metricx_qe_score": 5.821810722351074, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "Mais parfois, ses fonctionnalités sont limitées.", "metrics": {"bleu_score": 34.57207846419412, "chrf_score": 79.32680426075792, "xcomet_score": 0.9753564596176147, "xcomet_qe_score": 0.9769328236579895, "metricx_score": 0.5491150617599487, "metricx_qe_score": 0.3486204743385315, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "La génération de caractéristiques à partir d'une autre source de données peut ajouter une information substantielle.", "metrics": {"bleu_score": 37.709297891717654, "chrf_score": 69.01112048538039, "xcomet_score": 0.9180338382720947, "xcomet_qe_score": 0.9985805749893188, "metricx_score": 2.1714093685150146, "metricx_qe_score": 2.2942323684692383, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique de données tabulaires à l'aide de textes libres provenant de sources externes.", "metrics": {"bleu_score": 61.50523394042868, "chrf_score": 86.07454513632908, "xcomet_score": 0.9993120431900024, "xcomet_qe_score": 0.9955283403396606, "metricx_score": 0.6056214570999146, "metricx_qe_score": 0.7470424175262451, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Supposons que nous disposions d'un ensemble de données tabulaires et d'une base de connaissances.", "metrics": {"bleu_score": 30.405596969012933, "chrf_score": 78.51046077725172, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5891768932342529, "metricx_qe_score": 0.6362053155899048, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique qui implique la liaison et l'analyse textuelle pour extraire de nouvelles caractéristiques du texte libre de la base de connaissances.", "metrics": {"bleu_score": 68.53178012903952, "chrf_score": 82.76720873193453, "xcomet_score": 0.8003997802734375, "xcomet_qe_score": 0.8052131533622742, "metricx_score": 2.6046347618103027, "metricx_qe_score": 2.5111119747161865, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre, tout d'abord, est exactement ce processus automatique.", "metrics": {"bleu_score": 46.92470064105597, "chrf_score": 81.69909680733168, "xcomet_score": 0.6364120244979858, "xcomet_qe_score": 0.6418845653533936, "metricx_score": 8.170618057250977, "metricx_qe_score": 13.2792329788208, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Prenons un exemple dans l'ensemble de données alimentant fest.", "metrics": {"bleu_score": 16.058516370438436, "chrf_score": 37.015272173482636, "xcomet_score": 0.6728243827819824, "xcomet_qe_score": 0.7049403190612793, "metricx_score": 6.548799514770508, "metricx_qe_score": 5.836133003234863, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le jeu de données est un jeu de données universitaire.", "metrics": {"bleu_score": 18.92240568795936, "chrf_score": 71.44394706558398, "xcomet_score": 0.9318212270736694, "xcomet_qe_score": 0.8916794657707214, "metricx_score": 0.7501013278961182, "metricx_qe_score": 0.731359601020813, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "et son objectif est de classer les universités en universités mal classées et en universités bien classées.", "metrics": {"bleu_score": 38.95496694796876, "chrf_score": 67.96636383832896, "xcomet_score": 0.825165867805481, "xcomet_qe_score": 0.8343062996864319, "metricx_score": 4.175870895385742, "metricx_qe_score": 3.2712366580963135, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que base de connaissances, nous utilisons Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.37776264548301697, "metricx_qe_score": 0.43033844232559204, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase du processus est la liaison d'entités.", "metrics": {"bleu_score": 52.53819788848316, "chrf_score": 78.18697278171253, "xcomet_score": 0.674052894115448, "xcomet_qe_score": 0.7663103938102722, "metricx_score": 2.887300968170166, "metricx_qe_score": 4.336094379425049, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque chaque entité dans cet exemple, comme le nom de l'université, est liée à une entité au sein de la base de connaissances.", "metrics": {"bleu_score": 82.62204872346386, "chrf_score": 93.16036508268635, "xcomet_score": 0.9490735530853271, "xcomet_qe_score": 0.9527246952056885, "metricx_score": 1.3731073141098022, "metricx_qe_score": 1.7542260885238647, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "Et le texte des entités de la base de connaissances est extrait et ajouté à l'ensemble de données.", "metrics": {"bleu_score": 75.08561371925762, "chrf_score": 89.29686666264199, "xcomet_score": 0.9856945276260376, "xcomet_qe_score": 0.9550593495368958, "metricx_score": 0.996070146560669, "metricx_qe_score": 1.6853023767471313, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le texte est l'abstract de la page Wikipédia.", "metrics": {"bleu_score": 70.4805090506219, "chrf_score": 80.25615613463867, "xcomet_score": 0.9735019207000732, "xcomet_qe_score": 1.0, "metricx_score": 2.88716983795166, "metricx_qe_score": 1.020815372467041, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Maintenant, nous devons générer ou extraire des caractéristiques à partir du texte récupéré.", "metrics": {"bleu_score": 66.06328636027618, "chrf_score": 74.38270866226682, "xcomet_score": 0.9849499464035034, "xcomet_qe_score": 1.0, "metricx_score": 2.2474172115325928, "metricx_qe_score": 1.7546055316925049, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc besoin d'une phase d'extraction de caractéristiques qui inclut l'analyse de texte.", "metrics": {"bleu_score": 35.404085389375965, "chrf_score": 67.05674683570516, "xcomet_score": 0.9895591735839844, "xcomet_qe_score": 0.9749805331230164, "metricx_score": 3.9873640537261963, "metricx_qe_score": 3.9620933532714844, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est là la principale nouveauté de cet article, et j'y consacrerai les prochaines diapositives.", "metrics": {"bleu_score": 38.983691387368935, "chrf_score": 62.65059721898426, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.062376618385315, "metricx_qe_score": 1.1401605606079102, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction des caractéristiques, il y a une phase de génération de caractéristiques durant laquelle nous utilisons les caractéristiques extraites pour générer un petit nombre de nouvelles caractéristiques.", "metrics": {"bleu_score": 61.14887872946488, "chrf_score": 69.15063741560739, "xcomet_score": 0.9688011407852173, "xcomet_qe_score": 0.9981883764266968, "metricx_score": 2.111966848373413, "metricx_qe_score": 0.9248752593994141, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, générez les caractéristiques en fonction du nombre de classes du jeu de données original.", "metrics": {"bleu_score": 9.880782578056978, "chrf_score": 55.311963230322846, "xcomet_score": 0.9391524791717529, "xcomet_qe_score": 0.7985422611236572, "metricx_score": 3.7980892658233643, "metricx_qe_score": 3.3019614219665527, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le jeu de données original possède deux classes.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 67.70436694018464, "xcomet_score": 0.983077883720398, "xcomet_qe_score": 0.9392397999763489, "metricx_score": 1.2739492654800415, "metricx_qe_score": 1.855926275253296, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, générez deux nouvelles caractéristiques.", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 36.22726608585019, "xcomet_score": 0.15267963707447052, "xcomet_qe_score": 0.16810239851474762, "metricx_score": 9.563228607177734, "metricx_qe_score": 7.223948955535889, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, si le jeu de données comporte cinq classes, générez d'abord cinq nouvelles caractéristiques.", "metrics": {"bleu_score": 12.03921753741131, "chrf_score": 46.71262427836081, "xcomet_score": 0.31183648109436035, "xcomet_qe_score": 0.23353345692157745, "metricx_score": 8.351090431213379, "metricx_qe_score": 7.579161643981934, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque caractéristique représente la probabilité pour chaque classe.", "metrics": {"bleu_score": 75.06238537503395, "chrf_score": 78.89231057183392, "xcomet_score": 0.9665066003799438, "xcomet_qe_score": 1.0, "metricx_score": 1.271324634552002, "metricx_qe_score": 1.2625250816345215, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état actuel de l'analyse hors texte, qui sont des modèles linguistiques basés sur des transformateurs tels que BERT, GPT-x et autres.", "metrics": {"bleu_score": 33.595010195687195, "chrf_score": 58.23989972034638, "xcomet_score": 0.5860862731933594, "xcomet_qe_score": 0.5262572765350342, "metricx_score": 8.20669174194336, "metricx_qe_score": 8.301645278930664, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "mais il est peu probable que nous puissions entraîner un modèle linguistique à l'aide des jeux de données d'entrée.", "metrics": {"bleu_score": 32.64128346656048, "chrf_score": 55.7460034129885, "xcomet_score": 0.7945720553398132, "xcomet_qe_score": 0.8433791399002075, "metricx_score": 3.2209274768829346, "metricx_qe_score": 2.5025174617767334, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, une approche naïve sera affinée par un réglage fin de la tâche cible.", "metrics": {"bleu_score": 53.07074109851437, "chrf_score": 73.49212938921532, "xcomet_score": 0.8307968974113464, "xcomet_qe_score": 0.8083821535110474, "metricx_score": 3.2993433475494385, "metricx_qe_score": 4.534295082092285, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, lors de la phase d'extraction des caractéristiques, nous pouvons télécharger un modèle linguistique pré-entraîné et affiner ce modèle sur l'ensemble de données cible.", "metrics": {"bleu_score": 20.333448190047886, "chrf_score": 60.234485543716055, "xcomet_score": 0.9435098767280579, "xcomet_qe_score": 0.9628103971481323, "metricx_score": 0.9988235235214233, "metricx_qe_score": 0.9075871706008911, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, nous affinons le modèle linguistique pour classer le texte en deux catégories : abstrait ou concret.", "metrics": {"bleu_score": 22.671559787228198, "chrf_score": 43.36089435435974, "xcomet_score": 0.14651906490325928, "xcomet_qe_score": 0.6182854771614075, "metricx_score": 4.012702465057373, "metricx_qe_score": 6.138749122619629, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "Recevez la sortie du modèle de langage, qui est la probabilité pour chaque classe, et utilisez-la comme nouvelles caractéristiques.", "metrics": {"bleu_score": 26.728255206224986, "chrf_score": 60.35345224291015, "xcomet_score": 0.7828344702720642, "xcomet_qe_score": 0.7979739904403687, "metricx_score": 3.774458169937134, "metricx_qe_score": 2.3896255493164062, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que le jeu de données peut contenir peu de textes d'entités distinctes.", "metrics": {"bleu_score": 31.93715908050852, "chrf_score": 73.96285075874121, "xcomet_score": 0.814787745475769, "xcomet_qe_score": 0.7869080305099487, "metricx_score": 4.395913600921631, "metricx_qe_score": 4.452822208404541, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, près de la moitié du jeu de données contient moins de 400 échantillons, et le plus petit jeu de données comprenait 35 échantillons dans son ensemble de formation initial.", "metrics": {"bleu_score": 28.321567486629075, "chrf_score": 66.93575171414021, "xcomet_score": 0.8668278455734253, "xcomet_qe_score": 0.6473587155342102, "metricx_score": 2.577500581741333, "metricx_qe_score": 2.991419792175293, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, affiner un modèle linguistique sur cet ensemble de données serait inefficace.", "metrics": {"bleu_score": 6.734395444347337, "chrf_score": 55.07229722407667, "xcomet_score": 0.9858578443527222, "xcomet_qe_score": 0.996005654335022, "metricx_score": 1.1392936706542969, "metricx_qe_score": 1.0218287706375122, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons exploiter les connaissances préalables sur les ensembles de données préanalysés.", "metrics": {"bleu_score": 19.104081613647544, "chrf_score": 74.50443261572303, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7798202037811279, "metricx_qe_score": 0.8568917512893677, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que nous appliquons rapidement une méthode sur un ensemble de données multiples, nous pouvons utiliser l'ensemble de données N-1 pour recueillir des informations sur cet ensemble de données N-1 et exploiter ces informations lors de l'analyse de l'ensemble de données NNS.", "metrics": {"bleu_score": 22.06099613424276, "chrf_score": 60.73759648825126, "xcomet_score": 0.5055936574935913, "xcomet_qe_score": 0.5680907368659973, "metricx_score": 6.6194939613342285, "metricx_qe_score": 6.652946472167969, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "Ce que nous suggérons, c'est d'ajouter une autre phase de réglage fin.", "metrics": {"bleu_score": 77.4403141014203, "chrf_score": 83.66255173202686, "xcomet_score": 0.9029428958892822, "xcomet_qe_score": 0.830672025680542, "metricx_score": 2.539712905883789, "metricx_qe_score": 2.851675033569336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "Une phase préliminaire de réglage fin multitâche.", "metrics": {"bleu_score": 14.535768424205482, "chrf_score": 63.46906805536442, "xcomet_score": 0.956749439239502, "xcomet_qe_score": 0.9388917088508606, "metricx_score": 3.2955214977264404, "metricx_qe_score": 3.856738328933716, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque vous effectuez le modèle linguistique sur l'ensemble de données n moins un,", "metrics": {"bleu_score": 25.400289715190983, "chrf_score": 62.032492114311175, "xcomet_score": 0.6977245807647705, "xcomet_qe_score": 0.6051474213600159, "metricx_score": 7.501728057861328, "metricx_qe_score": 8.584982872009277, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous exécutons une autre phase d'ajustement fin, qui est un ajustement fin pour la tâche cible lorsque nous affinons le modèle linguistique sur le jeu de données cible final.", "metrics": {"bleu_score": 23.509511061626252, "chrf_score": 64.40049297398954, "xcomet_score": 0.6178585290908813, "xcomet_qe_score": 0.5761862993240356, "metricx_score": 5.510542392730713, "metricx_qe_score": 5.522037029266357, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "L'état de l'art dans l'affinage multitâche de précision appelé tdNN.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 43.52995678973211, "xcomet_score": 0.7050840854644775, "xcomet_qe_score": 0.7078852653503418, "metricx_score": 9.64059066772461, "metricx_qe_score": 9.416829109191895, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "Dans les réseaux de neurones vides, conservez un nombre de têtes correspondant au nombre de tâches dans l'ensemble d'entraînement.", "metrics": {"bleu_score": 19.69221590285716, "chrf_score": 48.859370880303736, "xcomet_score": 0.16458064317703247, "xcomet_qe_score": 0.17008955776691437, "metricx_score": 7.848167419433594, "metricx_qe_score": 7.899117946624756, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans cet exemple, s'il y a quatre tâches dans l'ensemble d'entraînement, gardez le DNN vide et conservez quatre têtes, comme vous pouvez le voir sur l'image.", "metrics": {"bleu_score": 51.55802176328615, "chrf_score": 70.67570067773545, "xcomet_score": 0.43785205483436584, "xcomet_qe_score": 0.42160773277282715, "metricx_score": 8.81091594696045, "metricx_qe_score": 8.734100341796875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "Et il sélectionne au hasard un insigne de l'ensemble d'entraînement.", "metrics": {"bleu_score": 11.731175160263996, "chrf_score": 36.90581907078281, "xcomet_score": 0.47752436995506287, "xcomet_qe_score": 0.32824739813804626, "metricx_score": 8.494521141052246, "metricx_qe_score": 8.356876373291016, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot d'exécution appartient, par exemple, aux tâches de classification de Sin et Selten, il effectue une passe avant et arrière à travers la première tête.", "metrics": {"bleu_score": 28.791406714051643, "chrf_score": 51.5380280757666, "xcomet_score": 0.31157636642456055, "xcomet_qe_score": 0.319436252117157, "metricx_score": 10.60538101196289, "metricx_qe_score": 10.024994850158691, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot aléatoire appartient au classement par paires, une tâche est d'attituder le passage aller et retour à travers la dernière tête. \n\n(Note : \"attituder\" n'est pas un verbe français standard, j'ai donc utilisé cette forme pour conserver le sens de l'original anglais \"to attitude\". Dans un contexte plus formel, vous pourriez remplacer par \"effectuer une évaluation\" ou un terme plus approprié selon le domaine spécifique.)", "metrics": {"bleu_score": 10.209094486354678, "chrf_score": 48.75912093400889, "xcomet_score": 0.48376181721687317, "xcomet_qe_score": 0.4758888781070709, "metricx_score": 11.59322738647461, "metricx_qe_score": 11.37833023071289, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, un jeu de données de type tableau présente un nombre de classes variable.", "metrics": {"bleu_score": 20.706193828327603, "chrf_score": 59.872418991644395, "xcomet_score": 0.9761544466018677, "xcomet_qe_score": 0.9408486485481262, "metricx_score": 1.0536750555038452, "metricx_qe_score": 1.2273846864700317, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a donc de nombreuses tâches.", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 47.41051467416685, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5774499177932739, "metricx_qe_score": 0.8413035869598389, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "tDNN conserve le nombre de classes, de têtes et de couches de sortie.", "metrics": {"bleu_score": 74.45389400758131, "chrf_score": 76.4212037656227, "xcomet_score": 0.6288299560546875, "xcomet_qe_score": 0.5063655376434326, "metricx_score": 7.804349899291992, "metricx_qe_score": 7.776756763458252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, un ADN vide doit initialement ajouter de nouvelles têtes pour un nouveau jeu de données avec une nouvelle tâche.", "metrics": {"bleu_score": 32.920103612911184, "chrf_score": 66.2558735124216, "xcomet_score": 0.3686647415161133, "xcomet_qe_score": 0.33068105578422546, "metricx_score": 13.279109001159668, "metricx_qe_score": 15.618364334106445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche, appelée reformulation de tâche avec accord fin, consiste, au lieu de maintenir plusieurs têtes, à reformuler chaque jeu de données en une phrase par problème de classification, ce qui correspond à des tâches à deux classes.", "metrics": {"bleu_score": 34.49506874882265, "chrf_score": 60.87972725992602, "xcomet_score": 0.4809962809085846, "xcomet_qe_score": 0.4304638206958771, "metricx_score": 8.25216007232666, "metricx_qe_score": 9.404684066772461, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple.", "metrics": {"bleu_score": 46.30777161991026, "chrf_score": 48.32474847235818, "xcomet_score": 0.9386066198348999, "xcomet_qe_score": 0.9773107767105103, "metricx_score": 0.2514381408691406, "metricx_qe_score": 0.34026220440864563, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "voici notre ensemble de données d'entrée qui se compose d'entités, de caractéristiques textuelles et de classes.", "metrics": {"bleu_score": 21.555378801920327, "chrf_score": 55.72875244694192, "xcomet_score": 0.8683359622955322, "xcomet_qe_score": 0.9185681343078613, "metricx_score": 3.6136441230773926, "metricx_qe_score": 3.170269727706909, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous reformulons la tâche, passant de la classification du texte en bas et haut, à la classification du texte, de l'abstrait et de la classe en vrai ou faux.", "metrics": {"bleu_score": 40.19046405329026, "chrf_score": 63.610529662105066, "xcomet_score": 0.6706863641738892, "xcomet_qe_score": 0.6560543775558472, "metricx_score": 4.036093711853027, "metricx_qe_score": 3.753934144973755, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous entraînons le modèle linguistique à classer les concepts abstraits et la classe abstraite selon que l'abstrait appartient ou non à la classe.", "metrics": {"bleu_score": 7.54372634521684, "chrf_score": 39.2886298804394, "xcomet_score": 0.5554835796356201, "xcomet_qe_score": 0.42942172288894653, "metricx_score": 6.091457843780518, "metricx_qe_score": 6.559420585632324, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le vecteur étiquette dans le cas de z reste toujours composé de deux classes.", "metrics": {"bleu_score": 15.844501337268932, "chrf_score": 59.31801167852758, "xcomet_score": 0.8403747081756592, "xcomet_qe_score": 0.8560652732849121, "metricx_score": 7.177695274353027, "metricx_qe_score": 9.174270629882812, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici l'algorithme de notre approche de réglage fin ou de réglage fin formulé.", "metrics": {"bleu_score": 7.188959550044094, "chrf_score": 44.131094412410185, "xcomet_score": 0.6577175855636597, "xcomet_qe_score": 0.7424412369728088, "metricx_score": 9.228815078735352, "metricx_qe_score": 8.528727531433105, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, examinons le cadre complet.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 76.19927045772855, "xcomet_score": 0.7875310182571411, "xcomet_qe_score": 0.684473991394043, "metricx_score": 3.407548427581787, "metricx_qe_score": 5.211164951324463, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "un ensemble de données alimenté à grande vitesse", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 26.695490653419117, "xcomet_score": 0.14388145506381989, "xcomet_qe_score": 0.1513439118862152, "metricx_score": 9.562091827392578, "metricx_qe_score": 8.624932289123535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "Et ensuite une exécution rapide dans la phase de liaison.", "metrics": {"bleu_score": 24.808415001701817, "chrf_score": 48.86581474353073, "xcomet_score": 0.37754005193710327, "xcomet_qe_score": 0.6413689255714417, "metricx_score": 13.377130508422852, "metricx_qe_score": 13.529455184936523, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "il extrait le texte de la base de connaissances, qui dans cet exemple est le résumé de la page Wikipédia.", "metrics": {"bleu_score": 95.10699415570296, "chrf_score": 98.8018938583582, "xcomet_score": 0.9654701948165894, "xcomet_qe_score": 0.9213699698448181, "metricx_score": 2.0358121395111084, "metricx_qe_score": 3.023637056350708, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, il a reformulé la tâche sous forme de paires de phrases par tâches de classification.", "metrics": {"bleu_score": 40.21074690812007, "chrf_score": 73.49160680428804, "xcomet_score": 0.7165054678916931, "xcomet_qe_score": 0.723361611366272, "metricx_score": 8.714645385742188, "metricx_qe_score": 9.0281400680542, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "J'ai appliqué le modèle linguistique à la nouvelle tâche et j'ai calculé la probabilité de sortie pour chaque classe.", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 81.30359871891635, "xcomet_score": 0.8606890439987183, "xcomet_qe_score": 0.8221110105514526, "metricx_score": 2.3861234188079834, "metricx_qe_score": 2.3724982738494873, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que le modèle linguistique est déjà affiné sur un jeu de données n moins un à l'aide d'un premier affinement multitâche.", "metrics": {"bleu_score": 15.726637857788463, "chrf_score": 53.02624287968314, "xcomet_score": 0.9063903093338013, "xcomet_qe_score": 0.8075623512268066, "metricx_score": 1.676851511001587, "metricx_qe_score": 2.9234681129455566, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous utilisons le vecteur de sortie du modèle linguistique en tant que nouvelle caractéristique générée dans le nombre de classes.", "metrics": {"bleu_score": 64.3604545490784, "chrf_score": 72.82942871306652, "xcomet_score": 0.8950217962265015, "xcomet_qe_score": 0.8771193623542786, "metricx_score": 3.722079277038574, "metricx_qe_score": 5.193233013153076, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un ensemble de données de classification tabulaire de dix-sept éléments, qui définit la taille, les caractéristiques, l'équilibre, le domaine et les performances initiales.", "metrics": {"bleu_score": 24.543612792919674, "chrf_score": 70.54919832829695, "xcomet_score": 0.7348630428314209, "xcomet_qe_score": 0.5595857501029968, "metricx_score": 3.827493190765381, "metricx_qe_score": 4.623634338378906, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "Dans sa déchets de connaissances, nous utilisons Wikipédia.", "metrics": {"bleu_score": 52.31223689135345, "chrf_score": 73.57914548668799, "xcomet_score": 0.4489753842353821, "xcomet_qe_score": 0.3838818371295929, "metricx_score": 12.687919616699219, "metricx_qe_score": 9.90098762512207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concevons notre expérience comme une évaluation de type « leave-one-out » lorsque nous entraînons rapidement seize ensembles de données et appliquons le modèle au dix-septième ensemble de données.", "metrics": {"bleu_score": 22.935466869603196, "chrf_score": 64.56601403251868, "xcomet_score": 0.645548403263092, "xcomet_qe_score": 0.5758506059646606, "metricx_score": 5.363976001739502, "metricx_qe_score": 6.102292537689209, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "nous divisons également chaque ensemble de données en deux parties, puis appliquons une validation croisée « fork false ».", "metrics": {"bleu_score": 17.976451428761386, "chrf_score": 66.7840852510456, "xcomet_score": 0.3500518500804901, "xcomet_qe_score": 0.3796088695526123, "metricx_score": 10.671542167663574, "metricx_qe_score": 11.310527801513672, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous générons la nouvelle caractéristique et les évaluons à l'aide de cinq classifieurs d'évaluation.", "metrics": {"bleu_score": 23.693055763743093, "chrf_score": 65.17266127520178, "xcomet_score": 0.8220556974411011, "xcomet_qe_score": 0.8390675187110901, "metricx_score": 3.7473037242889404, "metricx_qe_score": 4.000733375549316, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons dans notre architecture basée sur les expériences une approche centrée sur les oiseaux.", "metrics": {"bleu_score": 9.716915779575569, "chrf_score": 40.57750215290891, "xcomet_score": 0.16969290375709534, "xcomet_qe_score": 0.32413098216056824, "metricx_score": 16.361276626586914, "metricx_qe_score": 13.779401779174805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "voici les résultats de notre expérience", "metrics": {"bleu_score": 25.57539057896621, "chrf_score": 79.00866406325905, "xcomet_score": 0.9657515287399292, "xcomet_qe_score": 0.9607553482055664, "metricx_score": 0.5018711686134338, "metricx_qe_score": 0.9315534234046936, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez constater que nous comparons notre cadre à l'ajustement fin du jeu de données cible, à l'ajustement fin de la tâche cible et à l'ajustement préliminaire du tDNN.", "metrics": {"bleu_score": 29.793360868600033, "chrf_score": 62.01998060865739, "xcomet_score": 0.6077994704246521, "xcomet_qe_score": 0.5374845266342163, "metricx_score": 6.5461907386779785, "metricx_qe_score": 6.09025764465332, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "Et notre recalibrage reformulé atteint le meilleur résultat, la meilleure performance.", "metrics": {"bleu_score": 52.664038784792666, "chrf_score": 78.35917645182195, "xcomet_score": 0.8807377219200134, "xcomet_qe_score": 0.9332830905914307, "metricx_score": 1.7678048610687256, "metricx_qe_score": 1.4311461448669434, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "Pendant que dNN a atteint une amélioration de deux pour cent par rapport au réglage fin du jeu de données cible.", "metrics": {"bleu_score": 39.71588681839356, "chrf_score": 61.80019258251568, "xcomet_score": 0.513169527053833, "xcomet_qe_score": 0.508861780166626, "metricx_score": 8.051178932189941, "metricx_qe_score": 7.302659511566162, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche a permis une amélioration de six pour cent.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 81.90064480412373, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0292426347732544, "metricx_qe_score": 1.5172368288040161, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous examinons le petit ensemble de données, nous constatons que les performances de mtdNN diminuent et que l'amélioration de la phase de réglage fin multitâche préliminaire se réduit à un point cinq pour cent.", "metrics": {"bleu_score": 23.128925909261746, "chrf_score": 60.57946142899075, "xcomet_score": 0.8110849857330322, "xcomet_qe_score": 0.8460347652435303, "metricx_score": 5.915223598480225, "metricx_qe_score": 6.357708930969238, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, notre performance a augmenté de onze pour cent par rapport au seul réglage fin de la tâche cible.", "metrics": {"bleu_score": 20.090239552893994, "chrf_score": 58.75551053326268, "xcomet_score": 0.9413567781448364, "xcomet_qe_score": 0.9180586338043213, "metricx_score": 4.705273628234863, "metricx_qe_score": 4.456132411956787, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "La sommation rapide permet un enrichissement en quelques tirs à partir de trente-cinq échantillons dans notre expérience.", "metrics": {"bleu_score": 45.05700411689425, "chrf_score": 73.38994142948603, "xcomet_score": 0.46670588850975037, "xcomet_qe_score": 0.4908263087272644, "metricx_score": 5.9698381423950195, "metricx_qe_score": 5.134762287139893, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "Il utilise une seule architecture pour l'ensemble des tâches de l'ensemble de données.", "metrics": {"bleu_score": 16.06455374563062, "chrf_score": 66.01560254236605, "xcomet_score": 0.9270566701889038, "xcomet_qe_score": 0.8900580406188965, "metricx_score": 1.9103076457977295, "metricx_qe_score": 2.345831871032715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "Et il conserve la tête du modèle.", "metrics": {"bleu_score": 59.4603557501361, "chrf_score": 68.60498861472179, "xcomet_score": 0.9025007486343384, "xcomet_qe_score": 0.6470153331756592, "metricx_score": 3.7993338108062744, "metricx_qe_score": 6.2746782302856445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cela ajoute une phase de reformulation.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3430850505828857, "metricx_qe_score": 2.587543487548828, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "pour augmenter l'ensemble de données d'entraînement et ses besoins en une valeur cible sémantiquement significative, de sorte que nous puissions l'intégrer au modèle linguistique et l'utiliser dans la phrase selon le problème de classification.", "metrics": {"bleu_score": 14.23112277264479, "chrf_score": 61.57131429313416, "xcomet_score": 0.3940437436103821, "xcomet_qe_score": 0.440865695476532, "metricx_score": 8.468843460083008, "metricx_qe_score": 7.671041488647461, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Merci.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10382990539073944, "metricx_qe_score": 0.4022793173789978, "linguapy_score": [1, "ITALIAN"]}}
