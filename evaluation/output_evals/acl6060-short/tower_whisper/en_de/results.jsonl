{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen, heute werde ich unsere Forschungsarbeit „Lernen, deduktiv zu argumentieren, metabolische Problemlösung als komplexe Regionsextraktion“ vorstellen.", "metrics": {"bleu_score": 13.20376974315548, "chrf_score": 50.10799507802213, "xcomet_score": 0.7643387317657471, "xcomet_qe_score": 0.7564921379089355, "metricx_score": 5.66763973236084, "metricx_qe_score": 6.755621433258057, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan vom ByteDance AI Lab und dies ist eine gemeinsame Arbeit mit Jerry von der University of Texas in Austin und Weilu von der SUTD", "metrics": {"bleu_score": 52.74156280173285, "chrf_score": 81.38584631276356, "xcomet_score": 0.7807114720344543, "xcomet_qe_score": 0.7861713767051697, "metricx_score": 4.205833435058594, "metricx_qe_score": 3.730921745300293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Argumentieren sprechen", "metrics": {"bleu_score": 90.48374180359599, "chrf_score": 98.7149277235364, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2055715024471283, "metricx_qe_score": 0.9913173913955688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel, bei dem mehrstufiges Denken hilfreich ist", "metrics": {"bleu_score": 43.64990448369015, "chrf_score": 68.1225185697182, "xcomet_score": 0.981427013874054, "xcomet_qe_score": 0.9928324222564697, "metricx_score": 0.40180933475494385, "metricx_qe_score": 0.477255642414093, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung stammt aus dem Artikel von Pound, in dem sie demonstrieren, wie man durch gezielte Anregung mathematische Probleme in einem Few-Shot-Learning-Szenario lösen kann.", "metrics": {"bleu_score": 25.13073726775429, "chrf_score": 53.428579423287104, "xcomet_score": 0.7752571702003479, "xcomet_qe_score": 0.7338061332702637, "metricx_score": 5.674633026123047, "metricx_qe_score": 5.401620864868164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der linken Seite können wir sehen, dass wir möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten, wenn wir einige Beispiele mit nur Fragen und Antworten geben.", "metrics": {"bleu_score": 25.011851152889697, "chrf_score": 64.68734068677693, "xcomet_score": 0.9671052694320679, "xcomet_qe_score": 0.9720717072486877, "metricx_score": 0.8694115877151489, "metricx_qe_score": 0.761832594871521, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir eine detailliertere Beschreibung des Schlussfolgerungsprozesses liefern, kann das Modell diese Beschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen.", "metrics": {"bleu_score": 8.867705537625364, "chrf_score": 48.52231917417662, "xcomet_score": 0.9969028234481812, "xcomet_qe_score": 0.9986943006515503, "metricx_score": 0.28999537229537964, "metricx_qe_score": 0.3261643648147583, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es gut, interpretierbare mehrstufige Argumentationen als Ergebnis zu haben.", "metrics": {"bleu_score": 35.24025452531097, "chrf_score": 79.62819477057333, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.40980157256126404, "metricx_qe_score": 0.6520670652389526, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind auch der Meinung, dass das Methodenproblem eine einfache Anwendung ist, um solche Denkfähigkeiten zu bewerten.", "metrics": {"bleu_score": 17.55756616570918, "chrf_score": 55.96755313417155, "xcomet_score": 0.8868966698646545, "xcomet_qe_score": 0.8777809739112854, "metricx_score": 4.619956016540527, "metricx_qe_score": 4.0125837326049805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Also hier in unserer Problemstellung, gegeben die Fragen, müssen wir diese Frage lösen und die numerischen Antworten erhalten.", "metrics": {"bleu_score": 42.155030936737305, "chrf_score": 69.07694404794913, "xcomet_score": 0.9656219482421875, "xcomet_qe_score": 0.9515513181686401, "metricx_score": 1.250336766242981, "metricx_qe_score": 1.3719356060028076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck gegeben, der zu dieser bestimmten Antwort führt.", "metrics": {"bleu_score": 36.658827296012404, "chrf_score": 74.73137008179833, "xcomet_score": 0.9740564823150635, "xcomet_qe_score": 0.9811362624168396, "metricx_score": 1.7983722686767578, "metricx_qe_score": 2.8622915744781494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten.", "metrics": {"bleu_score": 55.70438815301074, "chrf_score": 77.83370476158633, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.9207534193992615, "metricx_qe_score": 1.0926321744918823, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Mengen bekannt ist.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.44066566228866577, "metricx_qe_score": 0.5024028420448303, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponentialfunktion.", "metrics": {"bleu_score": 88.43946454355333, "chrf_score": 92.45512886074718, "xcomet_score": 0.9999830722808838, "xcomet_qe_score": 1.0, "metricx_score": 0.4685169756412506, "metricx_qe_score": 0.6687296032905579, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese Basiseratoren zerlegt werden.", "metrics": {"bleu_score": 46.59538415189962, "chrf_score": 81.80422813319804, "xcomet_score": 0.9681638479232788, "xcomet_qe_score": 0.970799446105957, "metricx_score": 1.9439005851745605, "metricx_qe_score": 1.446823000907898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "So lassen sich frühere Arbeiten zur Methodenentwicklung zur Problemlösung tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baum-Modelle einteilen.", "metrics": {"bleu_score": 12.996186443727149, "chrf_score": 63.34238440659152, "xcomet_score": 0.9232358932495117, "xcomet_qe_score": 0.804806113243103, "metricx_score": 3.4942691326141357, "metricx_qe_score": 4.341549396514893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "So konvertieren traditionelle Sequenz-zu-Sequenz-Modelle den Ausdruck in eine spezifische Sequenz für die Generierung.", "metrics": {"bleu_score": 54.291218877831355, "chrf_score": 82.24417318125438, "xcomet_score": 0.9252536296844482, "xcomet_qe_score": 0.8934308886528015, "metricx_score": 0.47508835792541504, "metricx_qe_score": 0.7880005836486816, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist ziemlich einfach zu implementieren und kann auf viele verschiedene komplizierte Probleme verallgemeinert werden.", "metrics": {"bleu_score": 69.64705665515706, "chrf_score": 93.24197113909592, "xcomet_score": 0.9958667755126953, "xcomet_qe_score": 0.9888020753860474, "metricx_score": 0.1623116433620453, "metricx_qe_score": 0.18862929940223694, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Nachteile der Leistung sind im Allgemeinen nicht besser als beim strukturierten Modell. Und es fehlt die Interpretierbarkeit für Vorhersagen.", "metrics": {"bleu_score": 15.405414340847187, "chrf_score": 64.59281561038885, "xcomet_score": 0.9369344711303711, "xcomet_qe_score": 0.9317607879638672, "metricx_score": 5.591737747192383, "metricx_qe_score": 5.92293119430542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Richtung aufgrund des Transformer-Modells immer noch ziemlich beliebt.", "metrics": {"bleu_score": 36.362270465000705, "chrf_score": 71.46287182780632, "xcomet_score": 0.993114709854126, "xcomet_qe_score": 0.9854347705841064, "metricx_score": 0.8096921443939209, "metricx_qe_score": 1.5173392295837402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumgestützten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer vorrangigen Durchmusterung bei der Baumgenerierung.", "metrics": {"bleu_score": 33.38080021677296, "chrf_score": 65.5049188663781, "xcomet_score": 0.9168567657470703, "xcomet_qe_score": 0.9244505167007446, "metricx_score": 2.997572422027588, "metricx_qe_score": 2.2925262451171875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also weiterhin die Operatoren, bis wir die Blätter erreichen, die die Mengen darstellen.", "metrics": {"bleu_score": 58.068035053871284, "chrf_score": 77.01097019929338, "xcomet_score": 0.9865514039993286, "xcomet_qe_score": 0.9703897833824158, "metricx_score": 0.777895987033844, "metricx_qe_score": 1.2348867654800415, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute daran ist also, dass es uns diese binäre Baumstruktur liefert. Aber eigentlich ist es ziemlich kontraintuitiv, weil wir zuerst den Operator generieren und dann am Ende die Größen.", "metrics": {"bleu_score": 44.60616097899725, "chrf_score": 71.42842108897007, "xcomet_score": 0.9838472604751587, "xcomet_qe_score": 0.96638023853302, "metricx_score": 1.7777749300003052, "metricx_qe_score": 2.536311626434326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und die zweite Sache ist, dass es auch einige repetitive Berechnungen enthält.", "metrics": {"bleu_score": 7.141816289329644, "chrf_score": 47.727223318293795, "xcomet_score": 0.9655945301055908, "xcomet_qe_score": 0.9763085842132568, "metricx_score": 0.7164250612258911, "metricx_qe_score": 0.46059226989746094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck ansehen, wird 8 mal 3 plus 3 tatsächlich zweimal generiert. Aber in Wirklichkeit sollten wir die Ergebnisse wiederverwenden.", "metrics": {"bleu_score": 54.06964703993757, "chrf_score": 77.68251616012908, "xcomet_score": 0.9993480443954468, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3547213077545166, "metricx_qe_score": 0.5270187258720398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme daher schrittweise und interpretierbar lösen.", "metrics": {"bleu_score": 25.274266580956596, "chrf_score": 73.30348179249545, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3830789625644684, "metricx_qe_score": 0.41366979479789734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "So können wir hier im zweiten Schritt beispielsweise diesen Divisor erhalten, der 27 ist.", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 56.983655608470166, "xcomet_score": 0.8876749873161316, "xcomet_qe_score": 0.9265271425247192, "metricx_score": 1.8557639122009277, "metricx_qe_score": 1.5365667343139648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um die relevanten Inhalte zu finden.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2288219928741455, "metricx_qe_score": 0.19367283582687378, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler.", "metrics": {"bleu_score": 72.59795291154772, "chrf_score": 95.55813636296386, "xcomet_score": 0.9975470304489136, "xcomet_qe_score": 0.9964474439620972, "metricx_score": 0.46138083934783936, "metricx_qe_score": 1.0272918939590454, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir in diesem dritten Schritt den Quotienten.", "metrics": {"bleu_score": 39.76353643835254, "chrf_score": 81.47415424805625, "xcomet_score": 0.9974765777587891, "xcomet_qe_score": 0.9892153739929199, "metricx_score": 0.9299668669700623, "metricx_qe_score": 1.714087963104248, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schrittes tatsächlich verwenden und dann die Ergebnisse des vierten Schrittes erhalten. Und schließlich können wir die Dividenden erhalten.", "metrics": {"bleu_score": 42.774464413593606, "chrf_score": 82.40197025030712, "xcomet_score": 0.9810312986373901, "xcomet_qe_score": 0.9750946760177612, "metricx_score": 1.35080087184906, "metricx_qe_score": 1.71632981300354, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu erzeugen.", "metrics": {"bleu_score": 5.653041175801492, "chrf_score": 45.16881228220234, "xcomet_score": 0.9837803840637207, "xcomet_qe_score": 0.9762426614761353, "metricx_score": 1.0409696102142334, "metricx_qe_score": 0.9677609801292419, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Das macht den Prozess genauer.", "metrics": {"bleu_score": 30.213753973567677, "chrf_score": 53.38238387625975, "xcomet_score": 0.9950906038284302, "xcomet_qe_score": 0.977350115776062, "metricx_score": 0.31846505403518677, "metricx_qe_score": 0.9903241395950317, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen präsentiert werden, und schließen einige Konstanten als unseren Ausgangszustand ein.", "metrics": {"bleu_score": 58.01735820744288, "chrf_score": 74.6623668633232, "xcomet_score": 0.9736273288726807, "xcomet_qe_score": 0.9599170684814453, "metricx_score": 1.4110934734344482, "metricx_qe_score": 2.0039496421813965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt.", "metrics": {"bleu_score": 36.06452879987793, "chrf_score": 80.28357106983552, "xcomet_score": 0.9844173192977905, "xcomet_qe_score": 0.9895853400230408, "metricx_score": 1.127659559249878, "metricx_qe_score": 2.294699192047119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Dabei führen wir den Operator von QI zu QJ aus, und ein solcher Ausdruck wird tatsächlich gerichtet.", "metrics": {"bleu_score": 12.961373830972104, "chrf_score": 55.40301474691819, "xcomet_score": 0.9406012296676636, "xcomet_qe_score": 0.956322193145752, "metricx_score": 2.918602466583252, "metricx_qe_score": 3.579958438873291, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben hier also auch die Subtraktion umgekehrt, um die entgegengesetzte Richtung darzustellen.", "metrics": {"bleu_score": 38.70605144677149, "chrf_score": 72.62029046366091, "xcomet_score": 0.9560556411743164, "xcomet_qe_score": 0.9068313241004944, "metricx_score": 2.1392643451690674, "metricx_qe_score": 2.2317025661468506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie die Relationsextraktion.", "metrics": {"bleu_score": 7.267884212102741, "chrf_score": 42.3679063659331, "xcomet_score": 0.9993832111358643, "xcomet_qe_score": 0.9989855289459229, "metricx_score": 1.9776597023010254, "metricx_qe_score": 2.9239537715911865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formalen deduktiven System wenden wir zum Zeitpunkt t den Operator auf das Paar qi und qj an und erhalten dann diese neuen Ausdrücke.", "metrics": {"bleu_score": 30.601758484756367, "chrf_score": 66.86475973958702, "xcomet_score": 0.9746226668357849, "xcomet_qe_score": 0.9789078831672668, "metricx_score": 0.8913902044296265, "metricx_qe_score": 1.6698403358459473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen sie dem nächsten Zustand hinzu, um eine neue Größe zu werden.", "metrics": {"bleu_score": 54.451788461394045, "chrf_score": 68.28266996004608, "xcomet_score": 0.9115155935287476, "xcomet_qe_score": 0.9588823914527893, "metricx_score": 2.678921699523926, "metricx_qe_score": 2.5968291759490967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folie veranschaulicht also die Entwicklung des Zustands, bei dem wir dem aktuellen Zustand ständig Ausdrücke hinzufügen.", "metrics": {"bleu_score": 45.307778036928106, "chrf_score": 77.66445125558255, "xcomet_score": 0.9825006127357483, "xcomet_qe_score": 0.9246337413787842, "metricx_score": 0.8554598689079285, "metricx_qe_score": 1.551713466644287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modelimplementierungen verwenden wir zunächst ein vorgefertigtes Sprachmodell, das Brits oder Robertas sein kann, kodieren dann einen Satz und erhalten diese Mengenrepräsentationen.", "metrics": {"bleu_score": 13.423568412000323, "chrf_score": 64.36939600200955, "xcomet_score": 0.8729760646820068, "xcomet_qe_score": 0.888327956199646, "metricx_score": 4.3469014167785645, "metricx_qe_score": 6.638952732086182, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengenrepräsentationen erhalten haben, können wir mit der Inferenz beginnen.", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 80.11342334668107, "xcomet_score": 0.9894499778747559, "xcomet_qe_score": 0.9962592124938965, "metricx_score": 1.265170931816101, "metricx_qe_score": 5.284395694732666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 geteilt durch Q2 und dann mal Q4 zu erhalten.", "metrics": {"bleu_score": 34.40445127469277, "chrf_score": 78.19760113689462, "xcomet_score": 0.8723385334014893, "xcomet_qe_score": 0.8578542470932007, "metricx_score": 7.934911727905273, "metricx_qe_score": 6.607987403869629, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paarrepräsentation, die im Grunde genommen nur die Verkettung zwischen Q1 und Q2 ist. Und dann wenden wir ein Feedforward-Netzwerk an, das durch den Operator parametrisiert ist.", "metrics": {"bleu_score": 53.033171484560874, "chrf_score": 79.2434965550873, "xcomet_score": 0.9769686460494995, "xcomet_qe_score": 0.9100092053413391, "metricx_score": 1.782541275024414, "metricx_qe_score": 2.480076551437378, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksdarstellung Q1 geteilt durch Q2", "metrics": {"bleu_score": 8.572272939203375, "chrf_score": 73.01240155881459, "xcomet_score": 0.9971432685852051, "xcomet_qe_score": 0.9843287467956543, "metricx_score": 0.5010871291160583, "metricx_qe_score": 0.8305094242095947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis, in der Inferenzphase, könnten wir möglicherweise auch den falschen Ausdruck erhalten.", "metrics": {"bleu_score": 50.081499862950906, "chrf_score": 87.70671886691974, "xcomet_score": 0.9981194734573364, "xcomet_qe_score": 0.9877760410308838, "metricx_score": 0.9419288635253906, "metricx_qe_score": 1.8318780660629272, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Somit ist hier der gesamte mögliche Ausdruck gleich 3 mal der Anzahl der Operatoren.", "metrics": {"bleu_score": 25.748661016289674, "chrf_score": 50.89703234605152, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3212435245513916, "metricx_qe_score": 1.1842552423477173, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir problemlos Einschränkungen hinzufügen können, um diesen Suchraum zu kontrollieren.", "metrics": {"bleu_score": 83.94327083733333, "chrf_score": 90.51905160562616, "xcomet_score": 0.9895412921905518, "xcomet_qe_score": 0.9804093837738037, "metricx_score": 0.7070599794387817, "metricx_qe_score": 0.9419331550598145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck zum Beispiel nicht erlaubt ist, können wir diesen Ausdruck einfach aus unserem Suchraum entfernen.", "metrics": {"bleu_score": 79.12619863720215, "chrf_score": 91.91935873447683, "xcomet_score": 0.9946538209915161, "xcomet_qe_score": 0.9921896457672119, "metricx_score": 0.6625986099243164, "metricx_qe_score": 0.9155831336975098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir also dasselbe, aber der einzige Unterschied ist eine weitere Größe.", "metrics": {"bleu_score": 38.55962091870962, "chrf_score": 62.88389126318682, "xcomet_score": 0.8894035816192627, "xcomet_qe_score": 0.9171209931373596, "metricx_score": 3.2714710235595703, "metricx_qe_score": 4.554620742797852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Menge stammt aus dem vorherigen berechneten Ausdruck.", "metrics": {"bleu_score": 66.90484408935988, "chrf_score": 90.6651605090456, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5240357518196106, "metricx_qe_score": 1.7341002225875854, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "So können wir schließlich diesen endgültigen Ausdruck Q erhalten", "metrics": {"bleu_score": 34.48559825502726, "chrf_score": 82.2793325514127, "xcomet_score": 0.8857206106185913, "xcomet_qe_score": 0.8608652949333191, "metricx_score": 5.980470180511475, "metricx_qe_score": 12.461871147155762, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Zeiten Q4. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke sich vom vorherigen Schritt unterscheidet.", "metrics": {"bleu_score": 47.44757224228201, "chrf_score": 78.10054903966181, "xcomet_score": 0.8201305270195007, "xcomet_qe_score": 0.7267172932624817, "metricx_score": 6.904479503631592, "metricx_qe_score": 8.410490036010742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Unterschied macht es schwierig, die Strahlsuchmethode anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgewogen ist.", "metrics": {"bleu_score": 50.66732571810761, "chrf_score": 70.38083979250777, "xcomet_score": 0.874114990234375, "xcomet_qe_score": 0.9680449962615967, "metricx_score": 1.2724559307098389, "metricx_qe_score": 1.2999207973480225, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Das Training erfolgt also ähnlich wie bei einem Sequenz-zu-Sequenz-Modell, bei dem wir den Verlust in jedem Zeitschritt optimieren.", "metrics": {"bleu_score": 40.85639059221913, "chrf_score": 72.3212275103395, "xcomet_score": 0.9580971002578735, "xcomet_qe_score": 0.9148491621017456, "metricx_score": 0.3901296854019165, "metricx_qe_score": 0.6046336889266968, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir dieses Tau auch, um darzustellen, wann wir diesen Generierungsprozess beenden sollten.", "metrics": {"bleu_score": 77.7811122305422, "chrf_score": 93.16890559489094, "xcomet_score": 0.9863818883895874, "xcomet_qe_score": 0.9747627973556519, "metricx_score": 0.6836692094802856, "metricx_qe_score": 1.0776443481445312, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier unterscheidet sich der Raum von Sequenz zu Sequenz, weil der Raum in jedem Zeitschritt unterschiedlich ist, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl der Vokabeln ist.", "metrics": {"bleu_score": 49.85596549989156, "chrf_score": 81.77982805051809, "xcomet_score": 0.9373610615730286, "xcomet_qe_score": 0.9272539615631104, "metricx_score": 1.1547002792358398, "metricx_qe_score": 1.8436691761016846, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht uns auch, bestimmte Einschränkungen aufgrund von Vorwissen aufzuerlegen.", "metrics": {"bleu_score": 27.968424579665367, "chrf_score": 71.67160707664709, "xcomet_score": 0.9803454875946045, "xcomet_qe_score": 0.974533200263977, "metricx_score": 0.6423646807670593, "metricx_qe_score": 1.0084218978881836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Daher führen wir Experimente an den häufig verwendeten Problem-Datensätzen MAWPS, MAT23K, MATQA und SWAMP durch.", "metrics": {"bleu_score": 19.024397535997736, "chrf_score": 57.961580336573284, "xcomet_score": 0.9678084254264832, "xcomet_qe_score": 0.9744305610656738, "metricx_score": 2.640916347503662, "metricx_qe_score": 1.9470231533050537, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen Batch-Ansätzen.", "metrics": {"bleu_score": 61.153805769010226, "chrf_score": 77.75348315709721, "xcomet_score": 0.850550651550293, "xcomet_qe_score": 0.86098712682724, "metricx_score": 3.379429817199707, "metricx_qe_score": 3.995258331298828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere am besten performende Variante ist daher der Robeta Dictative Reasoner.", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 46.084371254788046, "xcomet_score": 0.8963750600814819, "xcomet_qe_score": 0.8932158350944519, "metricx_score": 4.085351467132568, "metricx_qe_score": 5.417837142944336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "und tatsächlich verwenden wir keine Beam Search, im Gegensatz zu offensichtlichen Ansätzen, die Beam Search verwenden", "metrics": {"bleu_score": 58.527733690258756, "chrf_score": 80.15835418127195, "xcomet_score": 0.8063804507255554, "xcomet_qe_score": 0.768830418586731, "metricx_score": 5.6577653884887695, "metricx_qe_score": 6.067642688751221, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, also sind die besten Ansätze oft baumgestützte Modelle", "metrics": {"bleu_score": 36.72056269893591, "chrf_score": 61.822878839151684, "xcomet_score": 0.9763427972793579, "xcomet_qe_score": 0.9566954970359802, "metricx_score": 1.7997751235961914, "metricx_qe_score": 2.078772783279419, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Schlussfolgerungssystem dieses baumgestützte Modell deutlich übertreffen.", "metrics": {"bleu_score": 6.061512325492642, "chrf_score": 43.31730551069549, "xcomet_score": 0.9319398999214172, "xcomet_qe_score": 0.9234322905540466, "metricx_score": 1.4663845300674438, "metricx_qe_score": 1.6771076917648315, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf Mathqa oder SWAM nicht wirklich hoch sind.", "metrics": {"bleu_score": 66.54377827941899, "chrf_score": 79.87115625621196, "xcomet_score": 0.9482028484344482, "xcomet_qe_score": 0.9285423755645752, "metricx_score": 1.2376011610031128, "metricx_qe_score": 1.1926087141036987, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen daher die Ergebnisse weiter", "metrics": {"bleu_score": 11.708995388048026, "chrf_score": 54.46875744510433, "xcomet_score": 0.9961315393447876, "xcomet_qe_score": 0.9859098196029663, "metricx_score": 1.3801002502441406, "metricx_qe_score": 2.432136058807373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist herausfordernd, weil der Autor versucht hat, dem NLP-Modell etwas hinzuzufügen, um es zu verwirren, wie zum Beispiel die Hinzufügung irrelevanter Informationen und zusätzlicher Mengen.", "metrics": {"bleu_score": 44.82907809719587, "chrf_score": 78.25588546650025, "xcomet_score": 0.9729534387588501, "xcomet_qe_score": 0.951483964920044, "metricx_score": 0.7610920667648315, "metricx_qe_score": 1.147608757019043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Vorhersage stellen wir fest, dass einige der Zwischenschritte tatsächlich negative Werte sind.", "metrics": {"bleu_score": 49.35578819979934, "chrf_score": 74.96601625991262, "xcomet_score": 0.9361467361450195, "xcomet_qe_score": 0.9332655072212219, "metricx_score": 1.5173468589782715, "metricx_qe_score": 1.310813307762146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel hat Drake?", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 61.677860405893604, "xcomet_score": 0.8487570285797119, "xcomet_qe_score": 0.8232401609420776, "metricx_score": 3.9376285076141357, "metricx_qe_score": 3.8272454738616943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie 17 weniger Pitches, und Steven hat 8 Pitches, was völlig irrelevant ist.", "metrics": {"bleu_score": 54.405770769345864, "chrf_score": 76.25365969208585, "xcomet_score": 0.8258825540542603, "xcomet_qe_score": 0.8236528635025024, "metricx_score": 6.0492987632751465, "metricx_qe_score": 4.81101655960083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine Vorhersage wie diese, die negative Werte produziert.", "metrics": {"bleu_score": 85.5526185871245, "chrf_score": 89.61492330592665, "xcomet_score": 0.9857891798019409, "xcomet_qe_score": 0.9767706394195557, "metricx_score": 0.8259428143501282, "metricx_qe_score": 0.9031760096549988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "und wir beobachten diese beiden Ausdrücke", "metrics": {"bleu_score": 9.408660393931463, "chrf_score": 33.72231721253372, "xcomet_score": 0.7100077867507935, "xcomet_qe_score": 0.8392543196678162, "metricx_score": 10.409055709838867, "metricx_qe_score": 12.031658172607422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum also tatsächlich einschränken, indem wir die Ergebnisse entfernen, die negativ sind, damit wir die Antwort korrekt machen können.", "metrics": {"bleu_score": 18.627639656696825, "chrf_score": 65.8422525444599, "xcomet_score": 0.9379256963729858, "xcomet_qe_score": 0.850101113319397, "metricx_score": 1.9739363193511963, "metricx_qe_score": 2.630582571029663, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen außerdem fest, dass eine solche Einschränkung bei einigen Modellen tatsächlich zu einer erheblichen Verbesserung führt.", "metrics": {"bleu_score": 23.83041256525615, "chrf_score": 61.77685468856657, "xcomet_score": 0.9896655082702637, "xcomet_qe_score": 0.9792482852935791, "metricx_score": 0.581524670124054, "metricx_qe_score": 0.6082695126533508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei den Vögeln sieben Punkte verbessert. Und dann haben wir beim Robeta-basierten Modell tatsächlich zwei Punkte verbessert.", "metrics": {"bleu_score": 18.931747781986427, "chrf_score": 59.47702611442133, "xcomet_score": 0.8130776286125183, "xcomet_qe_score": 0.8187803030014038, "metricx_score": 9.627998352050781, "metricx_qe_score": 8.788432121276855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat eine bessere Sprachverständnisfähigkeit, sodass die Zahl hier für Robita höher und für Bird niedriger ist.", "metrics": {"bleu_score": 33.45794609803645, "chrf_score": 71.9318200766311, "xcomet_score": 0.8424898386001587, "xcomet_qe_score": 0.8446674346923828, "metricx_score": 4.694033145904541, "metricx_qe_score": 5.6640424728393555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch, die Schwierigkeit dahinter zu analysieren.", "metrics": {"bleu_score": 28.291332071489855, "chrf_score": 64.95413272249276, "xcomet_score": 0.8864922523498535, "xcomet_qe_score": 0.8106286525726318, "metricx_score": 1.0357882976531982, "metricx_qe_score": 3.20353102684021, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information betrachtet werden kann.", "metrics": {"bleu_score": 62.947717160248736, "chrf_score": 84.17764605695129, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3106567859649658, "metricx_qe_score": 0.33078187704086304, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben, und der SWAMP-Datensatz hat den größten Anteil.", "metrics": {"bleu_score": 71.94785842181871, "chrf_score": 87.76968601380177, "xcomet_score": 0.9444458484649658, "xcomet_qe_score": 0.9401670098304749, "metricx_score": 2.0043649673461914, "metricx_qe_score": 2.715261936187744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung.", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 95.153554655332, "xcomet_score": 0.9975186586380005, "xcomet_qe_score": 0.9953868389129639, "metricx_score": 0.17540127038955688, "metricx_qe_score": 0.28346192836761475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "für diese Proben ohne ungenutzte Mengen. Daher ist die Gesamtleistung tatsächlich höher als die Gesamtleistung.", "metrics": {"bleu_score": 38.989389329183524, "chrf_score": 71.34804010495294, "xcomet_score": 0.6240261793136597, "xcomet_qe_score": 0.5076066255569458, "metricx_score": 4.856621742248535, "metricx_qe_score": 6.502374172210693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben ist die ungenutzte Menge tatsächlich viel schlimmer als die viel schlimmere.", "metrics": {"bleu_score": 20.14941615706457, "chrf_score": 54.215168968186454, "xcomet_score": 0.7783361673355103, "xcomet_qe_score": 0.7440294027328491, "metricx_score": 9.984914779663086, "metricx_qe_score": 11.811991691589355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Leistung. Für MAWPS haben wir nicht wirklich zu viele Disk-Gehäuse, daher ignoriere ich diesen Teil einfach.", "metrics": {"bleu_score": 45.80519369844352, "chrf_score": 70.72583203199629, "xcomet_score": 0.6776725053787231, "xcomet_qe_score": 0.6057403683662415, "metricx_score": 5.677863121032715, "metricx_qe_score": 5.019310474395752, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretierbarkeit anhand eines Crash- und Störungsexamples zeigen.", "metrics": {"bleu_score": 37.70063804549471, "chrf_score": 69.66854378397525, "xcomet_score": 0.8797905445098877, "xcomet_qe_score": 0.8635330200195312, "metricx_score": 5.8051958084106445, "metricx_qe_score": 5.8916754722595215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Hier macht unser Modell also tatsächlich im ersten Schritt eine falsche Vorhersage.", "metrics": {"bleu_score": 59.18821883387651, "chrf_score": 91.4722764404711, "xcomet_score": 0.9996235370635986, "xcomet_qe_score": 0.9887526035308838, "metricx_score": 0.18725332617759705, "metricx_qe_score": 0.28759485483169556, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier in Verbindung bringen.", "metrics": {"bleu_score": 69.30977286178778, "chrf_score": 76.40515341985318, "xcomet_score": 0.9992719888687134, "xcomet_qe_score": 1.0, "metricx_score": 0.5691086649894714, "metricx_qe_score": 0.6621484756469727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben daher, dass dieser Satz das Modell zu einer falschen Vorhersage verleiten könnte.", "metrics": {"bleu_score": 47.92365811426397, "chrf_score": 75.20665452469345, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.21269065141677856, "metricx_qe_score": 0.23636576533317566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn hier also noch 35 gedruckt werden, denkt das Modell, es handele sich um einen Additionsoperator.", "metrics": {"bleu_score": 5.897112026633552, "chrf_score": 40.70470786006178, "xcomet_score": 0.8721019625663757, "xcomet_qe_score": 0.8430843353271484, "metricx_score": 3.581963539123535, "metricx_qe_score": 3.403233528137207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz wie folgt zu überarbeiten: Die Anzahl der Birnbäume ist 55 geringer als die der Apfelbäume.", "metrics": {"bleu_score": 21.800193956058212, "chrf_score": 63.42967543034995, "xcomet_score": 0.9801526069641113, "xcomet_qe_score": 0.9832316637039185, "metricx_score": 2.3734970092773438, "metricx_qe_score": 1.890670895576477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir sorgen also dafür, dass die Semantik genauer vermittelt wird, damit das Modell die Vorhersage korrekt treffen kann.", "metrics": {"bleu_score": 30.10981307923018, "chrf_score": 67.86152825515848, "xcomet_score": 0.9855793714523315, "xcomet_qe_score": 0.9739902019500732, "metricx_score": 0.6583218574523926, "metricx_qe_score": 1.0642732381820679, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt also, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen.", "metrics": {"bleu_score": 72.13989879855205, "chrf_score": 92.34032208451053, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.49593037366867065, "metricx_qe_score": 0.6270440220832825, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, so ist zunächst unser Modell tatsächlich ziemlich effizient.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 89.61043306105663, "xcomet_score": 0.9739148020744324, "xcomet_qe_score": 0.9458500146865845, "metricx_score": 0.5305981040000916, "metricx_qe_score": 0.7917218804359436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind in der Lage, ein interpretierbares Lösungsverfahren bereitzustellen.", "metrics": {"bleu_score": 63.15552371794033, "chrf_score": 82.26594593526863, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20745600759983063, "metricx_qe_score": 0.2974579334259033, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "und wir können problemlos vorhandenes Wissen als Einschränkung einbeziehen, was die Leistung verbessern kann", "metrics": {"bleu_score": 10.581143537579976, "chrf_score": 47.75213599353159, "xcomet_score": 0.9712501764297485, "xcomet_qe_score": 0.963119626045227, "metricx_score": 1.5479762554168701, "metricx_qe_score": 1.7281488180160522, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur für Mapwork-Problemlösungsaufgaben gilt, sondern auch für andere Aufgaben, die mehrstufiges Denken erfordern.", "metrics": {"bleu_score": 42.396156294478345, "chrf_score": 67.86290618699115, "xcomet_score": 0.9600134491920471, "xcomet_qe_score": 0.9279508590698242, "metricx_score": 1.5922482013702393, "metricx_qe_score": 1.6981103420257568, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen", "metrics": {"bleu_score": 0.0, "chrf_score": 17.661274327545314, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.004679501056671143, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4435056149959564, "metricx_qe_score": 0.46961158514022827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und die zweite Sache ist, wie bereits erwähnt, dass es aufgrund der ungleichmäßigen Wahrscheinlichkeitsverteilung zu verschiedenen Zeitpunkten auch ziemlich herausfordernd ist, die Strahlsuchmethode anzuwenden.", "metrics": {"bleu_score": 5.911245883122323, "chrf_score": 60.40845365454959, "xcomet_score": 0.9122811555862427, "xcomet_qe_score": 0.9193309545516968, "metricx_score": 1.090302586555481, "metricx_qe_score": 0.8866783976554871, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das war's dann auch schon mit dem Vortrag, und Fragen sind willkommen. Vielen Dank.", "metrics": {"bleu_score": 10.123734869668828, "chrf_score": 39.84217824615072, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.38633492588996887, "metricx_qe_score": 0.2567053735256195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Universität Maastricht.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 89.89040636842799, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07355811446905136, "metricx_qe_score": 0.018026236444711685, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine Zeichnung mit Jerry präsentieren, die sich auf einen neuen Datensatz für die gesetzliche Artikelabfrage bezieht.", "metrics": {"bleu_score": 17.48420417921227, "chrf_score": 46.84253756071427, "xcomet_score": 0.8662921190261841, "xcomet_qe_score": 0.8029813766479492, "metricx_score": 6.769222736358643, "metricx_qe_score": 6.074214935302734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtliche Fragen sind ein fester Bestandteil des Lebens vieler Menschen.", "metrics": {"bleu_score": 51.93071778680675, "chrf_score": 80.02423853964953, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.12561479210853577, "metricx_qe_score": 0.2410045564174652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Doch die Mehrheit der Bürger hat kaum oder gar kein Wissen über ihre Rechte und grundlegende rechtliche Verfahren.", "metrics": {"bleu_score": 55.78537980042048, "chrf_score": 75.11751233731934, "xcomet_score": 0.998786211013794, "xcomet_qe_score": 1.0, "metricx_score": 0.31476089358329773, "metricx_qe_score": 0.37527570128440857, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Infolgedessen bleiben viele schutzbedürftige Bürger, die sich die kostspielige Hilfe eines Rechtsberaters nicht leisten können, ungeschützt oder, schlimmer noch, werden ausgebeutet.", "metrics": {"bleu_score": 44.535356254412434, "chrf_score": 68.45194534555647, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.32397782802581787, "metricx_qe_score": 0.3034353256225586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Kluft zwischen den Menschen und dem Gesetz zu überbrücken, indem wir effektive Abrufsysteme für Gesetzesartikel entwickeln.", "metrics": {"bleu_score": 71.03600666390408, "chrf_score": 82.61927131847457, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6802735328674316, "metricx_qe_score": 0.39618268609046936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen professionellen Rechtshilfsdienst für ungelernte Menschen bereitstellen.", "metrics": {"bleu_score": 51.424016050282624, "chrf_score": 79.2533699098534, "xcomet_score": 0.9722024202346802, "xcomet_qe_score": 0.9760989546775818, "metricx_score": 0.24687537550926208, "metricx_qe_score": 0.14615485072135925, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem des gesetzlichen Artikelabrufs.", "metrics": {"bleu_score": 38.14127542721386, "chrf_score": 65.60114247324701, "xcomet_score": 0.969606876373291, "xcomet_qe_score": 0.9752712249755859, "metricx_score": 1.2604432106018066, "metricx_qe_score": 1.0085551738739014, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen, es wird eine einfache Frage zu einem kleinen Thema gestellt, wie zum Beispiel: Was riskiert man, wenn man die berufliche Vertraulichkeit verletzt?", "metrics": {"bleu_score": 6.798898171917449, "chrf_score": 44.58917915067851, "xcomet_score": 0.9166496396064758, "xcomet_qe_score": 0.9184972047805786, "metricx_score": 1.706909418106079, "metricx_qe_score": 1.7869222164154053, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ein Modell erforderlich, um alle relevanten Gesetzesartikel aus einem umfangreichen Gesetzeswerk abzurufen.", "metrics": {"bleu_score": 39.538546443358655, "chrf_score": 56.304269694584875, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.29860931634902954, "metricx_qe_score": 0.2683919668197632, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsbeschaffungaufgabe bringt ihre eigenen Herausforderungen mit sich.", "metrics": {"bleu_score": 29.5580130165708, "chrf_score": 80.41547300241102, "xcomet_score": 0.9893065690994263, "xcomet_qe_score": 0.9853190779685974, "metricx_score": 0.060156676918268204, "metricx_qe_score": 0.17629507184028625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst befasst es sich mit zwei Arten von Sprache.", "metrics": {"bleu_score": 39.281465090051306, "chrf_score": 55.994172611278145, "xcomet_score": 0.9388857483863831, "xcomet_qe_score": 0.941964864730835, "metricx_score": 0.14668114483356476, "metricx_qe_score": 0.17115271091461182, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Verständliche Alltagssprache für die Fragen und komplexe juristische Sprache für die Statuten.", "metrics": {"bleu_score": 39.48627814210998, "chrf_score": 63.12008557375668, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3790134191513062, "metricx_qe_score": 0.7908676266670227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Unterschied in der Sprachverteilung erschwert es einem System, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die der Terminologie der Gesetze entspricht.", "metrics": {"bleu_score": 76.31937819302073, "chrf_score": 87.76418445222518, "xcomet_score": 0.9843072891235352, "xcomet_qe_score": 0.9167357683181763, "metricx_score": 0.48874443769454956, "metricx_qe_score": 0.6167373657226562, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das Gesetzbuch kein Stapel unabhängiger Artikel, die wie eine vollständige Informationsquelle für sich allein behandelt werden können, im Gegensatz zu Nachrichten oder Rezepten zum Beispiel.", "metrics": {"bleu_score": 19.696929778934532, "chrf_score": 68.29744312676242, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8795948028564453, "metricx_qe_score": 0.7242836952209473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen handelt es sich um eine strukturierte Sammlung von Rechtsvorschriften, die erst in ihrem Gesamtzusammenhang, also zusammen mit den ergänzenden Informationen aus den benachbarten Artikeln, den Bereichen und Teilbereichen, zu denen sie gehören, und ihrem Platz in der Struktur des Rechts, eine vollständige Bedeutung haben.", "metrics": {"bleu_score": 49.785632443202324, "chrf_score": 76.11524890149364, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.1689653992652893, "metricx_qe_score": 0.21605037152767181, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Zuletzt sind gesetzliche Artikel keine kleinen Absätze, was in den meisten Dokumenten normalerweise die typische Abrufeinheit ist.", "metrics": {"bleu_score": 9.779314884333477, "chrf_score": 36.50508888222081, "xcomet_score": 0.9578456282615662, "xcomet_qe_score": 0.9523098468780518, "metricx_score": 1.2599599361419678, "metricx_qe_score": 1.1557016372680664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier gibt es lange Dokumente, die bis zu sechs Seiten umfassen können.", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 76.84514517071142, "xcomet_score": 0.9986963272094727, "xcomet_qe_score": 1.0, "metricx_score": 0.6939531564712524, "metricx_qe_score": 0.4866970181465149, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in der NLP haben großes Interesse an vielen rechtlichen Aufgaben geweckt, wie der Vorhersage von Gerichtsurteilen oder der automatisierten Vertragsüberprüfung.", "metrics": {"bleu_score": 27.876125942808734, "chrf_score": 68.87533477674228, "xcomet_score": 0.9824735522270203, "xcomet_qe_score": 0.9796125888824463, "metricx_score": 0.7610461115837097, "metricx_qe_score": 1.5529361963272095, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Aber der gesetzliche Artikelabruf ist aufgrund des Mangels an großen und hochwertigen Label-Datensätzen weitgehend unangetastet geblieben.", "metrics": {"bleu_score": 33.16612678087121, "chrf_score": 59.18432960079281, "xcomet_score": 0.9546796679496765, "xcomet_qe_score": 0.9756178855895996, "metricx_score": 1.7108362913131714, "metricx_qe_score": 1.2895649671554565, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir einen neuen, französischsprachigen, bürgerorientierten Datensatz, um zu untersuchen, ob ein Abrufmodell die Effizienz und Zuverlässigkeit eines juristischen Experten für die Aufgabe des Abrufs von Gesetzesartikeln annähern kann.", "metrics": {"bleu_score": 16.266176344046823, "chrf_score": 56.637227441564576, "xcomet_score": 0.8728020191192627, "xcomet_qe_score": 0.9163663387298584, "metricx_score": 2.8275184631347656, "metricx_qe_score": 2.867234468460083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Unser belgischer gesetzlicher Artikel-Abrufsatz, PSART, besteht aus mehr als 1.100 rechtlichen", "metrics": {"bleu_score": 16.216978789449843, "chrf_score": 36.52512172401145, "xcomet_score": 0.6063750982284546, "xcomet_qe_score": 0.640464723110199, "metricx_score": 9.376803398132324, "metricx_qe_score": 7.063432216644287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen decken ein breites Spektrum von Themen ab, von Familie, Wohnen, Geld bis hin zu Arbeit und Sozialversicherung.", "metrics": {"bleu_score": 76.06811142113595, "chrf_score": 83.4675625365499, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1865127980709076, "metricx_qe_score": 0.08286432921886444, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einem Korpus von mehr als 22.600 versehen.", "metrics": {"bleu_score": 70.84542882975748, "chrf_score": 70.15667667514667, "xcomet_score": 0.8191946744918823, "xcomet_qe_score": 0.8582974672317505, "metricx_score": 2.890660285949707, "metricx_qe_score": 3.886301279067993, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Gesetzbücher. Lassen Sie uns nun darüber sprechen, wie wir diese Datensätze gesammelt haben.", "metrics": {"bleu_score": 56.35190098079901, "chrf_score": 81.12083830659668, "xcomet_score": 0.6875137090682983, "xcomet_qe_score": 0.7104877829551697, "metricx_score": 6.143500804901123, "metricx_qe_score": 10.299114227294922, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst begannen wir damit, ein großes Korpus an rechtlichen Artikeln zusammenzustellen.", "metrics": {"bleu_score": 4.368583925857938, "chrf_score": 53.20801371074896, "xcomet_score": 0.9988807439804077, "xcomet_qe_score": 0.9839245676994324, "metricx_score": 0.06918288767337799, "metricx_qe_score": 0.17983639240264893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich zugängliche belgische Kodizes untersucht und alle ihre Artikel sowie die entsprechenden Abschnittsüberschriften extrahiert.", "metrics": {"bleu_score": 62.685933350049744, "chrf_score": 81.05894387178886, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.1510508060455322, "metricx_qe_score": 3.386601448059082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend haben wir rechtliche Fragen mit Verweisen auf relevante Gesetze zusammengetragen.", "metrics": {"bleu_score": 54.91004867761124, "chrf_score": 73.34652591000264, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1119459867477417, "metricx_qe_score": 0.14111986756324768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr rund 4.000 E-Mails von belgischen Bürgern erhält, die um Rat bei einem persönlichen Rechtsproblem bitten.", "metrics": {"bleu_score": 63.5361252026423, "chrf_score": 77.55729580259455, "xcomet_score": 0.9982819557189941, "xcomet_qe_score": 1.0, "metricx_score": 0.08281306177377701, "metricx_qe_score": 0.12916970252990723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team erfahrener Juristen die häufigsten rechtlichen Probleme in Belgien behandelt.", "metrics": {"bleu_score": 67.32378032068624, "chrf_score": 75.45597118707808, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5246574878692627, "metricx_qe_score": 0.6252104043960571, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen gesammelt, die mit Kategorien, Unterkategorien und rechtlichen Verweisen auf relevante Gesetze annotiert sind.", "metrics": {"bleu_score": 45.50680330812803, "chrf_score": 79.20109396728624, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3917781412601471, "metricx_qe_score": 0.5909736156463623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Zuletzt haben wir die rechtlichen Verweise analysiert und die Fragen herausgefiltert, deren Verweise nicht auf Artikel in einem der von uns berücksichtigten Gesetzbücher verweisen.", "metrics": {"bleu_score": 62.56538561604213, "chrf_score": 77.64370845432484, "xcomet_score": 0.9814163446426392, "xcomet_qe_score": 0.9782521724700928, "metricx_score": 0.3278161883354187, "metricx_qe_score": 0.5831894874572754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Referenzen wurden mit den entsprechenden Artikel-IDs aus Ocorpus abgeglichen und in diese umgewandelt.", "metrics": {"bleu_score": 15.467294147156862, "chrf_score": 62.75405357857717, "xcomet_score": 0.9771789312362671, "xcomet_qe_score": 0.9748181104660034, "metricx_score": 3.2530579566955566, "metricx_qe_score": 2.8772847652435303, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen schließlich auf 1108 Fragen, die jeweils sorgfältig mit den IDs der relevanten Artikel versehen waren.", "metrics": {"bleu_score": 22.797979039517884, "chrf_score": 43.3578232178112, "xcomet_score": 0.9505676031112671, "xcomet_qe_score": 0.9196412563323975, "metricx_score": 3.0644702911376953, "metricx_qe_score": 7.183855056762695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zudem ist jede Frage mit einer Hauptkategorie und einer Verkettung von Unterkategorien versehen.", "metrics": {"bleu_score": 16.06455374563062, "chrf_score": 68.95843444781995, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4411522150039673, "metricx_qe_score": 1.2067121267318726, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel wird in der Struktur des Gesetzes mit einer Verkettung der nachfolgenden Überschrift versehen.", "metrics": {"bleu_score": 6.468490584192431, "chrf_score": 55.27891807386137, "xcomet_score": 0.9814059734344482, "xcomet_qe_score": 0.9695024490356445, "metricx_score": 2.1075282096862793, "metricx_qe_score": 3.5232431888580322, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten aber für zukünftige Forschungen zum rechtlichen Informationsbeschaffung oder zur rechtlichen Steuerklassifizierung von Interesse sein.", "metrics": {"bleu_score": 63.04186117582763, "chrf_score": 74.93384849287075, "xcomet_score": 0.804519772529602, "xcomet_qe_score": 0.8152749538421631, "metricx_score": 5.6547322273254395, "metricx_qe_score": 5.538740158081055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns einige Merkmale unserer Datensätze betrachten.", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 58.694921872395845, "xcomet_score": 0.9891918897628784, "xcomet_qe_score": 0.9995100498199463, "metricx_score": 0.9365360140800476, "metricx_qe_score": 0.5409671068191528, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen sind zwischen 5 und 44 Wörter lang, mit einem Median von 14 Wörtern.", "metrics": {"bleu_score": 51.18285025257892, "chrf_score": 71.74379524340985, "xcomet_score": 0.9524668455123901, "xcomet_qe_score": 0.9768293499946594, "metricx_score": 1.5249773263931274, "metricx_qe_score": 0.6789079904556274, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer mittleren Länge von 77 Wörtern, mit 142", "metrics": {"bleu_score": 18.947653508428846, "chrf_score": 44.463946572350046, "xcomet_score": 0.7980879545211792, "xcomet_qe_score": 0.7633353471755981, "metricx_score": 11.516230583190918, "metricx_qe_score": 8.936517715454102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "über 1000.", "metrics": {"bleu_score": 0.0, "chrf_score": 3.1223711161098002, "xcomet_score": 0.15183743834495544, "xcomet_qe_score": 0.14607326686382294, "metricx_score": 17.027915954589844, "metricx_qe_score": 15.756256103515625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, decken die Fragen ein breites Spektrum an Themen ab, wobei etwa 85 % von ihnen entweder über Familie, Wohnen, Geld oder Justiz handeln.", "metrics": {"bleu_score": 52.751142851837024, "chrf_score": 66.6810449198444, "xcomet_score": 0.9775189161300659, "xcomet_qe_score": 0.9759153127670288, "metricx_score": 0.7539572715759277, "metricx_qe_score": 0.23951411247253418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "während die restlichen 15 % entweder die soziale Sicherheit, Ausländer oder die Arbeit betreffen.", "metrics": {"bleu_score": 29.482060124869072, "chrf_score": 75.07753995814053, "xcomet_score": 0.9811129570007324, "xcomet_qe_score": 0.976283073425293, "metricx_score": 0.5030264258384705, "metricx_qe_score": 0.7423563003540039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind ebenfalls sehr vielfältig, da sie aus 32 verschiedenen belgischen Kodizes stammen, die eine große Anzahl von Rechtsfragen abdecken.", "metrics": {"bleu_score": 56.72254631483797, "chrf_score": 72.79885593681773, "xcomet_score": 0.9823241233825684, "xcomet_qe_score": 0.9772416353225708, "metricx_score": 1.3306283950805664, "metricx_qe_score": 0.8947384357452393, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Codes gesammelt wurden.", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 74.7960335439847, "xcomet_score": 0.9758502244949341, "xcomet_qe_score": 0.94249027967453, "metricx_score": 3.0755269527435303, "metricx_qe_score": 2.747055768966675, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den 22.633 Artikeln werden nur 1.612 als relevant bezeichnet, d. h. sie werden mindestens", "metrics": {"bleu_score": 47.364158261679506, "chrf_score": 64.19730331483004, "xcomet_score": 0.8223525285720825, "xcomet_qe_score": 0.7623257637023926, "metricx_score": 7.889686584472656, "metricx_qe_score": 4.70147705078125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "eine Frage in den Datensätzen. Und etwa 80 % dieser zitierten Artikel stammen entweder aus dem Bürgerlichen Gesetzbuch, dem Gerichtsverfassungsgesetz, dem Strafprozessgesetz oder den Strafgesetzbüchern.", "metrics": {"bleu_score": 25.47296653715805, "chrf_score": 60.58414299246985, "xcomet_score": 0.7633459568023682, "xcomet_qe_score": 0.6885239481925964, "metricx_score": 7.725444316864014, "metricx_qe_score": 10.852606773376465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit haben 18 von 32 Codes weniger als 5 Artikel, die als relevant für mindestens eine Frage erwähnt werden.", "metrics": {"bleu_score": 29.81792160679168, "chrf_score": 59.53187849533139, "xcomet_score": 0.9622370004653931, "xcomet_qe_score": 0.984467625617981, "metricx_score": 3.1422224044799805, "metricx_qe_score": 2.8033885955810547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies lässt sich dadurch erklären, dass diese Codes weniger auf Einzelpersonen und deren Anliegen fokussiert sind.", "metrics": {"bleu_score": 42.94652316126124, "chrf_score": 58.825427863669454, "xcomet_score": 0.9909590482711792, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 3.776792049407959, "metricx_qe_score": 2.423426866531372, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt beträgt die durchschnittliche Anzahl der Zitate für diese zitierten Artikel 2, und weniger als 25 % von ihnen sind", "metrics": {"bleu_score": 21.152103870133466, "chrf_score": 52.04861022675049, "xcomet_score": 0.8462777137756348, "xcomet_qe_score": 0.853327751159668, "metricx_score": 9.9996976852417, "metricx_qe_score": 9.2339448928833, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen vergleichen wir mehrere Abrufansätze, einschließlich lexikalischer und dichter Architektur.", "metrics": {"bleu_score": 26.305333213389257, "chrf_score": 51.86906528535297, "xcomet_score": 0.8923498392105103, "xcomet_qe_score": 0.8912854194641113, "metricx_score": 0.7241061925888062, "metricx_qe_score": 0.7118077874183655, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Anfrage in einem Artikel weist ein lexikales Modell dem Anfrage-Artikel-Paar eine Punktzahl zu, indem es die Summe der Gewichte jedes dieser Begriffe in dem Artikel berechnet.", "metrics": {"bleu_score": 36.90178968839034, "chrf_score": 70.88434338427723, "xcomet_score": 0.9254919290542603, "xcomet_qe_score": 0.8737531900405884, "metricx_score": 3.7065579891204834, "metricx_qe_score": 2.917313575744629, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TF-IDF- und BM25-Rankingfunktionen.", "metrics": {"bleu_score": 32.46679154750989, "chrf_score": 80.48629023814786, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.425211638212204, "metricx_qe_score": 0.840278148651123, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die Schlüsselwörter enthalten, die in der Abfrage vorhanden sind.", "metrics": {"bleu_score": 72.67072830982373, "chrf_score": 86.87286610204312, "xcomet_score": 0.9916040897369385, "xcomet_qe_score": 0.9922547340393066, "metricx_score": 0.5713827610015869, "metricx_qe_score": 0.6251809000968933, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Suchanfragen und Artikeln erfassen kann.", "metrics": {"bleu_score": 75.22135016840222, "chrf_score": 90.65919573710315, "xcomet_score": 0.996170163154602, "xcomet_qe_score": 0.9968985319137573, "metricx_score": 0.36060380935668945, "metricx_qe_score": 0.21915337443351746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein b-Encoder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen abbildet und einen relevanten Score zwischen einem Abfrage-Artikel-Paar durch die Ähnlichkeit ihrer Einbettungen berechnet.", "metrics": {"bleu_score": 43.441091034192404, "chrf_score": 77.7455707164173, "xcomet_score": 0.9166275858879089, "xcomet_qe_score": 0.8626529574394226, "metricx_score": 4.029072284698486, "metricx_qe_score": 4.734221458435059, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen entstehen in der Regel durch eine Pooling-Operation am Ausgabewert eines Worteinbettungsmodells.", "metrics": {"bleu_score": 19.369604994860264, "chrf_score": 71.71405999023582, "xcomet_score": 0.9252197742462158, "xcomet_qe_score": 0.8571969270706177, "metricx_score": 0.9906667470932007, "metricx_qe_score": 1.7652883529663086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit von Siamese-b-Encodierern in einem Zero-Shot-Evaluierungssetup, was bedeutet, dass vorgefertigte Wood-Embedding-Modelle ohne zusätzliche Feinabstimmung direkt angewendet werden.", "metrics": {"bleu_score": 19.16345623438237, "chrf_score": 64.20421725407392, "xcomet_score": 0.7336555123329163, "xcomet_qe_score": 0.7314049005508423, "metricx_score": 6.957364082336426, "metricx_qe_score": 6.4824934005737305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Texterodierern, nämlich Word2Vec und FastText, und kontextbasierten Einbettungsmodellen, nämlich Robota und insbesondere Camembert, einem französischen Robota-Modell.", "metrics": {"bleu_score": 18.85850947396187, "chrf_score": 74.16368776684537, "xcomet_score": 0.8952290415763855, "xcomet_qe_score": 0.909212589263916, "metricx_score": 5.479214191436768, "metricx_qe_score": 4.224648475646973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus trainieren wir unser eigenes Camembert-basiertes Modell über die Programmierer hinaus.", "metrics": {"bleu_score": 27.838424262216993, "chrf_score": 53.71196517230212, "xcomet_score": 0.7103447914123535, "xcomet_qe_score": 0.7408765554428101, "metricx_score": 7.058988571166992, "metricx_qe_score": 7.980074405670166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den beiden Varianten der Bianco-Architektur experimentieren.", "metrics": {"bleu_score": 44.47608928410895, "chrf_score": 79.76798978413443, "xcomet_score": 0.7031469345092773, "xcomet_qe_score": 0.6498051881790161, "metricx_score": 8.712711334228516, "metricx_qe_score": 8.966689109802246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamesisch, das ein einzigartiges Wortverteilungsmodell verwendet, das die Abfrage und den Artikel in einem gemeinsamen dichten Vektorraum zusammenführt. Und Tutowa, das zwei unabhängige Wortverteilungsmodelle verwendet, die die Abfrage und den Artikel separat in unterschiedliche Verteilungsräume kodieren.", "metrics": {"bleu_score": 46.39465060874216, "chrf_score": 71.29644957791173, "xcomet_score": 0.6896371245384216, "xcomet_qe_score": 0.6927958726882935, "metricx_score": 6.3373494148254395, "metricx_qe_score": 6.150266170501709, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Mean-, Max- und CLS-Pooling sowie dem Punktprodukt und dem Kosinus zur Berechnung von Ähnlichkeiten.", "metrics": {"bleu_score": 25.010742987310106, "chrf_score": 67.34889853130439, "xcomet_score": 0.6708004474639893, "xcomet_qe_score": 0.6847902536392212, "metricx_score": 4.026608943939209, "metricx_qe_score": 3.332911491394043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Basislinie auf dem Testdatensatz.", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 69.48607336697465, "xcomet_score": 0.8655760288238525, "xcomet_qe_score": 0.8417695164680481, "metricx_score": 2.5483734607696533, "metricx_qe_score": 3.6482584476470947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den oben genannten lexikalischen Methoden wurden die siamesischen b-Encoder in einem Zero-Shot-Setup in der Mitte und die fein abgestimmten b-Encoder unten bewertet.", "metrics": {"bleu_score": 43.29440137460168, "chrf_score": 75.88467732234145, "xcomet_score": 0.8822095394134521, "xcomet_qe_score": 0.9019937515258789, "metricx_score": 4.525883674621582, "metricx_qe_score": 4.144309997558594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertrifft der fein abgestimmte B-Encoder alle anderen Basslinien deutlich.", "metrics": {"bleu_score": 44.97332084013507, "chrf_score": 85.54202486603707, "xcomet_score": 0.8442572355270386, "xcomet_qe_score": 0.8382745981216431, "metricx_score": 4.854062080383301, "metricx_qe_score": 4.470639228820801, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Zwei-Türme-Modell übertrifft seine siamesische Variante bei Recall bei 100, zeigt aber bei den anderen Metriken ähnliche Ergebnisse.", "metrics": {"bleu_score": 19.398130898389823, "chrf_score": 51.769137126926836, "xcomet_score": 0.9626177549362183, "xcomet_qe_score": 0.9507251381874084, "metricx_score": 4.383770942687988, "metricx_qe_score": 4.59975004196167, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM25 die trainierte Biancoda-Version deutlich unterbot, deutet seine Leistung darauf hin, dass es immer noch eine starke Ausgangsbasis für domänenspezifisches Retrieval darstellt.", "metrics": {"bleu_score": 10.34888513994061, "chrf_score": 58.80059509130244, "xcomet_score": 0.8529007434844971, "xcomet_qe_score": 0.8290014266967773, "metricx_score": 6.268258571624756, "metricx_qe_score": 6.710601806640625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Zero-Shot-Auswertung von Siamese Biancoder stellen wir fest, dass die direkte Verwendung der Einbettungen eines vorgefertigten Camembert-Modells ohne Optimierung für die Informationsbeschaffung zu schlechten Ergebnissen führt, was mit früheren Erkenntnissen übereinstimmt.", "metrics": {"bleu_score": 51.86011471360956, "chrf_score": 72.02628016742678, "xcomet_score": 0.6906468272209167, "xcomet_qe_score": 0.704584002494812, "metricx_score": 6.265666484832764, "metricx_qe_score": 4.908509731292725, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellten wir fest, dass der auf Word2Vec basierende Biancoder das auf FastText und Bird basierende Modell deutlich übertraf, was darauf hindeutet, dass vorgefertigte Wortembodimentierungen für die Aufgabe möglicherweise geeigneter sind als Zeichen- oder Subwort-Embeddings, wenn sie sofort verwendet werden.", "metrics": {"bleu_score": 31.16302413326723, "chrf_score": 55.71948686802182, "xcomet_score": 0.5865458250045776, "xcomet_qe_score": 0.6386911273002625, "metricx_score": 7.950887680053711, "metricx_qe_score": 7.112774848937988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl vielversprechend, deuten diese Ergebnisse auf reichlich Verbesserungspotenzial im Vergleich zu einem erfahrenen Rechtsexperten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Ergebnisse erzielen kann.", "metrics": {"bleu_score": 38.46814643805403, "chrf_score": 75.4083923453217, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.25267115235328674, "metricx_qe_score": 0.28529298305511475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns abschließend zwei Einschränkungen aller Datensätze diskutieren.", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 51.17416320578897, "xcomet_score": 0.9352281093597412, "xcomet_qe_score": 0.9325929880142212, "metricx_score": 3.5926592350006104, "metricx_qe_score": 2.4222865104675293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Korpus der Artikel auf diejenigen beschränkt, die aus den 32 betrachteten belgischen Kodizes gesammelt wurden, was nicht das gesamte belgische Recht abdeckt, da Artikel aus Dekreten, Richtlinien und Verordnungen fehlen.", "metrics": {"bleu_score": 54.15022510030436, "chrf_score": 72.54241416961933, "xcomet_score": 0.9713542461395264, "xcomet_qe_score": 0.9423990249633789, "metricx_score": 1.6076151132583618, "metricx_qe_score": 1.3384215831756592, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während des Datensatzaufbaus werden alle Verweise auf diese nicht gesammelten Artikel ignoriert, was dazu führt, dass einige Fragen nur mit einem Bruchteil der anfänglichen Anzahl relevanter Artikel enden.", "metrics": {"bleu_score": 35.413571145594794, "chrf_score": 65.59587833470138, "xcomet_score": 0.9691524505615234, "xcomet_qe_score": 0.9638634920120239, "metricx_score": 1.9561842679977417, "metricx_qe_score": 1.5072755813598633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsverlust bedeutet, dass die in den verbleibenden relevanten Artikeln enthaltene Antwort unvollständig sein könnte, obwohl sie dennoch völlig angemessen ist.", "metrics": {"bleu_score": 32.23833286593517, "chrf_score": 71.39148061335665, "xcomet_score": 0.9784382581710815, "xcomet_qe_score": 0.9664433002471924, "metricx_score": 1.5495657920837402, "metricx_qe_score": 1.495908498764038, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.111781045794487, "metricx_qe_score": 0.16189205646514893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage, ob ich meine Mieter beeinflussen kann, wenn sie zu viel Lärm machen.", "metrics": {"bleu_score": 44.89771072202119, "chrf_score": 68.33048578953115, "xcomet_score": 0.8637295961380005, "xcomet_qe_score": 0.8247015476226807, "metricx_score": 3.6800537109375, "metricx_qe_score": 4.965860843658447, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt möglicherweise keine detaillierte Antwort im Gesetz, die eine spezifische Lärmschwelle quantifiziert, bei der eine Räumung zulässig ist.", "metrics": {"bleu_score": 36.334899523165326, "chrf_score": 69.84398998654233, "xcomet_score": 0.9530479311943054, "xcomet_qe_score": 0.9636569023132324, "metricx_score": 1.191791296005249, "metricx_qe_score": 1.0595588684082031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte sich der Vermieter wahrscheinlich stärker auf die Rechtsprechung verlassen und Präzedenzfälle finden, die seiner aktuellen Situation ähnlich sind.", "metrics": {"bleu_score": 68.48075777090853, "chrf_score": 84.80091616883692, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3991543650627136, "metricx_qe_score": 0.26826012134552, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Mieter zwei Partys pro Woche bis 2 Uhr morgens", "metrics": {"bleu_score": 43.55452009157203, "chrf_score": 65.33294834432822, "xcomet_score": 0.9627497792243958, "xcomet_qe_score": 0.9675049185752869, "metricx_score": 0.4491729140281677, "metricx_qe_score": 0.43993446230888367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher eignen sich einige Fragen besser als andere für die gesetzliche Artikelabruftache, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen.", "metrics": {"bleu_score": 25.177251610618846, "chrf_score": 55.1325579958271, "xcomet_score": 0.959762454032898, "xcomet_qe_score": 0.907249391078949, "metricx_score": 4.238670825958252, "metricx_qe_score": 2.996033191680908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass alle Arbeiten das Interesse an der Entwicklung praktischer und zuverlässiger gesetzlicher Artikel-Abrufmuster wecken.", "metrics": {"bleu_score": 43.23177783155441, "chrf_score": 64.78283904470838, "xcomet_score": 0.9509927034378052, "xcomet_qe_score": 0.9579204320907593, "metricx_score": 3.6571426391601562, "metricx_qe_score": 2.4797282218933105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern.", "metrics": {"bleu_score": 91.93227152249175, "chrf_score": 94.685406447034, "xcomet_score": 0.9811796545982361, "xcomet_qe_score": 1.0, "metricx_score": 0.591306209564209, "metricx_qe_score": 0.3152727484703064, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unseren Artikel, DATSET&CODE, unter den folgenden Links einsehen. Vielen Dank.", "metrics": {"bleu_score": 41.18986261905915, "chrf_score": 59.298705180000724, "xcomet_score": 0.926552951335907, "xcomet_qe_score": 0.9653634428977966, "metricx_score": 7.967260837554932, "metricx_qe_score": 6.1995086669921875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Wir freuen uns, unsere Arbeit an VAUS vorzustellen, einem aufgabenunabhängigen Benchmark, der für die Testung von Seh- und Sprachmodellen mit spezifischen sprachlichen Phänomenen gedacht ist.", "metrics": {"bleu_score": 32.40619425728408, "chrf_score": 65.29203791674311, "xcomet_score": 0.8509030342102051, "xcomet_qe_score": 0.7888962626457214, "metricx_score": 3.772090196609497, "metricx_qe_score": 4.120863437652588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark aufzustellen?", "metrics": {"bleu_score": 82.651681837938, "chrf_score": 80.38931868193252, "xcomet_score": 0.9983352422714233, "xcomet_qe_score": 1.0, "metricx_score": 0.18473100662231445, "metricx_qe_score": 0.25139009952545166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Nun, in den letzten Jahren haben wir eine Explosion von auf Transformatoren basierenden Seh- und Sprachmodellen erlebt, die mit großen Mengen an Bild-Text-Paaren vorgeprägt wurden.", "metrics": {"bleu_score": 55.2411506166109, "chrf_score": 75.10101438044174, "xcomet_score": 0.9747455716133118, "xcomet_qe_score": 0.991671085357666, "metricx_score": 3.392791509628296, "metricx_qe_score": 1.777100920677185, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle setzt neue Maßstäbe bei hochmodernen Aufgaben in den Bereichen Sehen und Sprache, wie der Beantwortung von Fragen anhand von Bildern, der Anwendung von gesundem Menschenverstand bei visuellen Aufgaben, der Bildsuche, der Verankerung von Phrasen.", "metrics": {"bleu_score": 5.190619769166795, "chrf_score": 44.97728510323567, "xcomet_score": 0.9121403694152832, "xcomet_qe_score": 0.9122596979141235, "metricx_score": 1.2125353813171387, "metricx_qe_score": 0.9647033214569092, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Nachricht erhalten. Die Genauigkeiten bei diesen aufgabenbezogenen Benchmarks steigen stetig an.", "metrics": {"bleu_score": 12.419519606393926, "chrf_score": 65.64362550298725, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8097599148750305, "metricx_qe_score": 1.0961211919784546, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5102907419204712, "metricx_qe_score": 0.9778188467025757, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was versteht ein Vision- und Sprachtransformer, wenn er diesem Bild und diesem Satz eine hohe Übereinstimmungsscore zuordnet?", "metrics": {"bleu_score": 14.344118073213723, "chrf_score": 50.5569658032358, "xcomet_score": 0.8255943655967712, "xcomet_qe_score": 0.8932415246963501, "metricx_score": 3.3788444995880127, "metricx_qe_score": 4.034710884094238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "und eine niedrige Punktzahl für diesen.", "metrics": {"bleu_score": 24.446151121745054, "chrf_score": 71.07422002913434, "xcomet_score": 0.9542865753173828, "xcomet_qe_score": 0.9444279670715332, "metricx_score": 1.0943623781204224, "metricx_qe_score": 1.1536426544189453, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Seh- und Sprachmodelle auf das Richtige?", "metrics": {"bleu_score": 54.627576446464936, "chrf_score": 70.28470866703948, "xcomet_score": 0.9749812483787537, "xcomet_qe_score": 0.9868461489677429, "metricx_score": 0.48520544171333313, "metricx_qe_score": 0.4657630920410156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie sie in früheren Arbeiten gezeigt wurden?", "metrics": {"bleu_score": 37.0304683381906, "chrf_score": 74.7020182172442, "xcomet_score": 0.9824657440185547, "xcomet_qe_score": 1.0, "metricx_score": 0.3689274787902832, "metricx_qe_score": 0.30982154607772827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt genauer zu beleuchten, schlagen wir eine aufgabenunabhängige Richtung vor und führen Ventile ein, die die Empfindlichkeit von Seh- und Sprachmodellen gegenüber spezifischen sprachlichen Phänomenen testen, die sowohl die sprachliche als auch die visuelle Modalität betreffen.", "metrics": {"bleu_score": 39.46640283851441, "chrf_score": 75.08296260464992, "xcomet_score": 0.7876063585281372, "xcomet_qe_score": 0.8015797734260559, "metricx_score": 4.701697826385498, "metricx_qe_score": 4.094910621643066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir richten uns auf Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entität-Kohärenz aus.", "metrics": {"bleu_score": 48.59373818796306, "chrf_score": 74.2063777156283, "xcomet_score": 0.9161754846572876, "xcomet_qe_score": 0.9156194925308228, "metricx_score": 2.1021485328674316, "metricx_qe_score": 2.085454225540161, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Visions- und Sprachmodelle diese Phänomene erfasst haben?", "metrics": {"bleu_score": 18.010019776510696, "chrf_score": 58.33152183596542, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 1.8368278741836548, "metricx_qe_score": 0.8596996665000916, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "durch FOILing, eine Methode, die zuvor für Seh- und Sprachmodelle angewendet wurde, nur für Nomenphrasen von Ravi Shekhar und Mitarbeitern, und durch Zählen in früheren Arbeiten von uns.", "metrics": {"bleu_score": 19.568336427344608, "chrf_score": 61.49547693829233, "xcomet_score": 0.7904165983200073, "xcomet_qe_score": 0.8188765048980713, "metricx_score": 5.677756309509277, "metricx_qe_score": 4.999914646148682, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde genommen, dass wir die Bildunterschrift eines Bildes nehmen und eine Folie erstellen, indem wir die Bildunterschrift so verändern, dass sie das Bild nicht mehr beschreibt.", "metrics": {"bleu_score": 59.26761300137113, "chrf_score": 70.26484477031258, "xcomet_score": 0.8007689714431763, "xcomet_qe_score": 0.9510306119918823, "metricx_score": 3.62799072265625, "metricx_qe_score": 1.5641944408416748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Satzveränderungen durch, indem wir uns auf sechs spezifische Elemente konzentrieren, wie Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entität-Kohärenz, wobei jedes Element aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit finden, FOIL-Instanzen zu erstellen.", "metrics": {"bleu_score": 46.62310456702386, "chrf_score": 73.00745429852189, "xcomet_score": 0.8174393773078918, "xcomet_qe_score": 0.9188700914382935, "metricx_score": 2.5470025539398193, "metricx_qe_score": 2.115882396697998, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir im Fall des Aktionsstücks zwei Instrumente, bei einem wird das Aktionsverb durch eine andere Handlung ersetzt und bei dem anderen werden die Akteure vertauscht.", "metrics": {"bleu_score": 35.66703979672829, "chrf_score": 61.3541049908348, "xcomet_score": 0.9606010317802429, "xcomet_qe_score": 0.9504063129425049, "metricx_score": 2.1785428524017334, "metricx_qe_score": 2.644927978515625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Counting und Coreferenz sind ebenfalls Stücke, die mehr als ein Instrument haben.", "metrics": {"bleu_score": 54.3742768222752, "chrf_score": 68.94063227193999, "xcomet_score": 0.7107930779457092, "xcomet_qe_score": 0.7811764478683472, "metricx_score": 8.019936561584473, "metricx_qe_score": 6.570173263549805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir erstellen diese Folien, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatisch und anderweitig gültige Sätze sind.", "metrics": {"bleu_score": 54.51502908460081, "chrf_score": 68.43925729630817, "xcomet_score": 0.8916386365890503, "xcomet_qe_score": 0.9364609122276306, "metricx_score": 4.370861530303955, "metricx_qe_score": 2.4236598014831543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist nicht einfach zu bewerkstelligen, da eine vereitelte Bildunterschrift weniger wahrscheinlich sein kann als die ursprüngliche Bildunterschrift.", "metrics": {"bleu_score": 34.03336518440548, "chrf_score": 70.87811111361553, "xcomet_score": 0.9432674646377563, "xcomet_qe_score": 0.9378186464309692, "metricx_score": 1.4055936336517334, "metricx_qe_score": 0.9284965991973877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es, obwohl es nicht unmöglich ist, statistisch gesehen unwahrscheinlicher, dass Pflanzen einen Mann schneiden, als dass ein Mann Pflanzen schneidet, und große Seh- und Sprachmodelle könnten dies erkennen.", "metrics": {"bleu_score": 40.89926520845833, "chrf_score": 77.9998370692977, "xcomet_score": 0.9248617887496948, "xcomet_qe_score": 0.9364206790924072, "metricx_score": 1.4217321872711182, "metricx_qe_score": 1.507439136505127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Daher müssen wir Maßnahmen ergreifen, um gültige Folien zu erhalten.", "metrics": {"bleu_score": 15.580105704117443, "chrf_score": 43.8251646982806, "xcomet_score": 0.914238691329956, "xcomet_qe_score": 0.9424629211425781, "metricx_score": 2.5128772258758545, "metricx_qe_score": 1.7270570993423462, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir leistungsstarke Sprachmodelle, um Folien vorzuschlagen.", "metrics": {"bleu_score": 22.957488466614326, "chrf_score": 66.18621541782016, "xcomet_score": 0.8302624225616455, "xcomet_qe_score": 0.8594093322753906, "metricx_score": 3.486029863357544, "metricx_qe_score": 1.4817301034927368, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir die natürliche Sprachinferenz, oder kurz NLI, um Folien herauszufiltern, die das Bild immer noch beschreiben könnten, da wir bei der Erstellung von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben.", "metrics": {"bleu_score": 45.00731941285453, "chrf_score": 69.63465662314655, "xcomet_score": 0.8014511466026306, "xcomet_qe_score": 0.927430272102356, "metricx_score": 5.547510623931885, "metricx_qe_score": 3.1548116207122803, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir die natürliche Sprachinferenz mit der folgenden Begründung an.", "metrics": {"bleu_score": 53.32120696150479, "chrf_score": 74.82634951584023, "xcomet_score": 0.9898126125335693, "xcomet_qe_score": 0.9867130517959595, "metricx_score": 1.2718160152435303, "metricx_qe_score": 1.360027551651001, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als Prämisse und seine Bildunterschrift als die daraus abgeleitete Hypothese.", "metrics": {"bleu_score": 61.60362085721387, "chrf_score": 83.6645216391223, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14930161833763123, "metricx_qe_score": 0.24525202810764313, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus betrachten wir die Bildunterschrift als Prämisse und das FOIL als Hypothese.", "metrics": {"bleu_score": 37.257423107540355, "chrf_score": 65.52430487056088, "xcomet_score": 0.8618289232254028, "xcomet_qe_score": 0.9443409442901611, "metricx_score": 3.0630364418029785, "metricx_qe_score": 2.5535695552825928, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass der FOIL der Bildunterschrift widerspricht oder in Bezug darauf neutral ist, betrachten wir dies als Indikator für einen gültigen FOIL.", "metrics": {"bleu_score": 25.33654946448646, "chrf_score": 60.33034605760301, "xcomet_score": 0.8231513500213623, "xcomet_qe_score": 0.9158283472061157, "metricx_score": 5.177031517028809, "metricx_qe_score": 3.064622163772583, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass das FOIL durch die Bildunterschrift impliziert wird, kann es kein gutes FOIL sein, da es durch Transitivität eine wahrheitsgetreue Beschreibung des Bildes liefert und wir diese FOILs herausfiltern.", "metrics": {"bleu_score": 28.920147774447933, "chrf_score": 59.569649935825296, "xcomet_score": 0.8101946711540222, "xcomet_qe_score": 0.8558178544044495, "metricx_score": 5.693348407745361, "metricx_qe_score": 5.11110258102417, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Verfahren ist nicht perfekt, es ist nur ein Indikator für gültige Folien.", "metrics": {"bleu_score": 34.46073377034663, "chrf_score": 64.9456307085459, "xcomet_score": 0.9003585577011108, "xcomet_qe_score": 0.9378392100334167, "metricx_score": 2.140439987182617, "metricx_qe_score": 0.7106491327285767, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher setzen wir als dritte Maßnahme zur Generierung gültiger FOI menschliche Annotatoren ein, um die in VALS verwendeten Daten zu validieren.", "metrics": {"bleu_score": 75.22135016840222, "chrf_score": 86.32978260773655, "xcomet_score": 0.903704047203064, "xcomet_qe_score": 0.9299255609512329, "metricx_score": 4.102931499481201, "metricx_qe_score": 3.5864012241363525, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nachdem wir also gefiltert und die menschlichen Bewertungen durchgeführt haben, haben wir so viele Testinstanzen wie in dieser Tabelle beschrieben.", "metrics": {"bleu_score": 32.77176740624639, "chrf_score": 69.04628423556275, "xcomet_score": 0.9968116283416748, "xcomet_qe_score": 0.9833482503890991, "metricx_score": 0.8913339972496033, "metricx_qe_score": 1.1801609992980957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten, sondern nur Testdaten liefert.", "metrics": {"bleu_score": 61.037911309497645, "chrf_score": 86.72873362317539, "xcomet_score": 0.9693964719772339, "xcomet_qe_score": 0.9949600696563721, "metricx_score": 0.46346515417099, "metricx_qe_score": 0.9033454060554504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "da es sich nur um einen Zero-Shot-Test-Benchmark handelt. Er wurde entwickelt, um die vorhandenen Fähigkeiten von Bild- und Sprachmodellen nach dem Vor-Training zu nutzen.", "metrics": {"bleu_score": 6.039782059104272, "chrf_score": 59.99074331889231, "xcomet_score": 0.9190022349357605, "xcomet_qe_score": 0.8598105907440186, "metricx_score": 3.084989547729492, "metricx_qe_score": 3.529961109161377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmungen würden den Modellen lediglich ermöglichen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen.", "metrics": {"bleu_score": 61.490732395580245, "chrf_score": 85.33623360695229, "xcomet_score": 0.9996768236160278, "xcomet_qe_score": 0.9978994131088257, "metricx_score": 0.20200496912002563, "metricx_qe_score": 0.2248767912387848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne schummeln und Abkürzungen nehmen.", "metrics": {"bleu_score": 61.62607099729587, "chrf_score": 91.83834013382479, "xcomet_score": 0.9979071617126465, "xcomet_qe_score": 0.999207615852356, "metricx_score": 0.635805606842041, "metricx_qe_score": 0.752661943435669, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie wir bereits gesagt haben, sind wir daran interessiert zu bewerten, welche Fähigkeiten die Visions- und Sprachmodelle nach dem Vor-Training haben.", "metrics": {"bleu_score": 25.823077599534503, "chrf_score": 67.11377587532304, "xcomet_score": 0.9764581918716431, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.6238411664962769, "metricx_qe_score": 1.2954578399658203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen an Vokalen, nämlich mit CLIP, LXMIRT, VILBERT, VILBERT12IN1 und VISUALBERT.", "metrics": {"bleu_score": 27.764493708491923, "chrf_score": 60.87381845204448, "xcomet_score": 0.7401057481765747, "xcomet_qe_score": 0.7257860898971558, "metricx_score": 5.997348785400391, "metricx_qe_score": 5.326331615447998, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satz-Paaren in Bildunterschriften und Folien.", "metrics": {"bleu_score": 46.09603493497927, "chrf_score": 70.47232683722866, "xcomet_score": 0.8785462379455566, "xcomet_qe_score": 0.8561040163040161, "metricx_score": 3.7462704181671143, "metricx_qe_score": 1.6717780828475952, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht noch relevanter für dieses Video ist unsere permissivere Metrik, die paarweise Genauigkeit, die misst, ob der Bildsatzzusammenführungswert für das korrekte Bild-Text-Paar höher ist als für das fehlgeschlagene Paar.", "metrics": {"bleu_score": 24.809337493666952, "chrf_score": 58.71405608307434, "xcomet_score": 0.9179370403289795, "xcomet_qe_score": 0.8930302858352661, "metricx_score": 3.418180227279663, "metricx_qe_score": 2.5858380794525146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Kennzahlen und Ergebnisse finden Sie in unserem Fachartikel.", "metrics": {"bleu_score": 30.37441422076457, "chrf_score": 63.45053959847419, "xcomet_score": 0.9983605146408081, "xcomet_qe_score": 0.9991034269332886, "metricx_score": 0.34570470452308655, "metricx_qe_score": 0.18274550139904022, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit der paarweisen Genauigkeit sind hier dargestellt und stimmen mit den Ergebnissen überein, die wir mit den anderen Metriken erhalten haben. Es zeigt sich, dass die beste Zero-Shot-Leistung von Wilbert 12 in 1 erreicht wird, gefolgt von Wilbert, Alexmert, Klip und schließlich Visualbert.", "metrics": {"bleu_score": 39.872329620302395, "chrf_score": 69.83292697762823, "xcomet_score": 0.5545493960380554, "xcomet_qe_score": 0.5816176533699036, "metricx_score": 7.207456588745117, "metricx_qe_score": 6.434581279754639, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert 12 in 1 fast vollständig gelöst werden, was zeigt, dass Modelle in der Lage sind, benannte Objekte und deren Präsenz in Bildern zu identifizieren.", "metrics": {"bleu_score": 51.955536166966276, "chrf_score": 70.30273383156236, "xcomet_score": 0.8186216950416565, "xcomet_qe_score": 0.8458598256111145, "metricx_score": 3.4374377727508545, "metricx_qe_score": 3.704054355621338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Keines der verbleibenden Rätsel kann jedoch in unseren adversarial foiling-Einstellungen zuverlässig gelöst werden.", "metrics": {"bleu_score": 43.748114312246464, "chrf_score": 69.41164107555447, "xcomet_score": 0.8437739014625549, "xcomet_qe_score": 0.8794375658035278, "metricx_score": 3.0933268070220947, "metricx_qe_score": 2.866753101348877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäts- und Zählinstrumenten geht hervor, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne vs. mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen.", "metrics": {"bleu_score": 62.54452810235592, "chrf_score": 80.20714272362855, "xcomet_score": 0.9733909368515015, "xcomet_qe_score": 0.948455810546875, "metricx_score": 0.7205372452735901, "metricx_qe_score": 0.6996423006057739, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Das Relationstück zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren.", "metrics": {"bleu_score": 63.83964846132483, "chrf_score": 76.98685690472547, "xcomet_score": 0.928693413734436, "xcomet_qe_score": 0.9018557667732239, "metricx_score": 2.698646306991577, "metricx_qe_score": 2.8219096660614014, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Teilnehmer zu identifizieren, selbst wenn sie durch Plausibilitätsvorurteile unterstützt werden, wie wir im Handlungsabschnitt sehen.", "metrics": {"bleu_score": 74.82073974516572, "chrf_score": 87.72469022367775, "xcomet_score": 0.9618733525276184, "xcomet_qe_score": 0.9036961197853088, "metricx_score": 1.2282260656356812, "metricx_qe_score": 2.294051170349121, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Koreferenzstück erfahren wir, dass es auch für Seh- und Sprachmodelle schwierig ist, mehrere Verweise auf dasselbe Objekt in einem Bild mithilfe von Pronomen zu verfolgen.", "metrics": {"bleu_score": 36.64158786944278, "chrf_score": 64.9929350434456, "xcomet_score": 0.9668158292770386, "xcomet_qe_score": 0.926973819732666, "metricx_score": 1.3404396772384644, "metricx_qe_score": 1.5370453596115112, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Zur Überprüfung und weil es ein interessantes Experiment ist, vergleichen wir auch zwei textbasierte Modelle, GPT-1 und GPT-2, um zu beurteilen, ob VALS durch diese unimodalen Modelle lösbar ist, indem wir die Perplexität der korrekten und der vereitelten Bildunterschrift berechnen und den Eintrag mit der niedrigsten Perplexität vorhersagen.", "metrics": {"bleu_score": 43.294717283089014, "chrf_score": 72.5062900577688, "xcomet_score": 0.8620741367340088, "xcomet_qe_score": 0.9020412564277649, "metricx_score": 2.0665454864501953, "metricx_qe_score": 1.8325386047363281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die FOIL höher ist, nehmen wir dies als Hinweis darauf, dass die FOILed-Bildunterschrift unter Plausibilitätsverzerrung oder anderen sprachlichen Verzerrungen leiden könnte.", "metrics": {"bleu_score": 17.335971526203704, "chrf_score": 56.6003654805225, "xcomet_score": 0.7600049376487732, "xcomet_qe_score": 0.7459024786949158, "metricx_score": 7.604529857635498, "metricx_qe_score": 6.579264163970947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Es ist interessant zu beobachten, dass die rein textbasierten GPT-Modelle in einigen Fällen die Plausibilität der Welt besser erfasst haben als die visuellen und sprachlichen Modelle.", "metrics": {"bleu_score": 49.30493209084919, "chrf_score": 72.37568723606984, "xcomet_score": 0.9882717132568359, "xcomet_qe_score": 0.975052535533905, "metricx_score": 0.5884596705436707, "metricx_qe_score": 0.7170965075492859, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend ist VALS ein Benchmark, der die Linse sprachlicher Konstrukte nutzt, um der Gemeinschaft zu helfen, Seh- und Sprachmodelle zu verbessern, indem er deren visuelle Begründungsmöglichkeiten gründlich testet.", "metrics": {"bleu_score": 7.298802419077642, "chrf_score": 49.06509943657012, "xcomet_score": 0.8896237015724182, "xcomet_qe_score": 0.9044778347015381, "metricx_score": 2.772270441055298, "metricx_qe_score": 3.050987482070923, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und deren Präsenz in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre Wechselbeziehungen und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren.", "metrics": {"bleu_score": 51.203696730285166, "chrf_score": 70.29992804330689, "xcomet_score": 0.8787615299224854, "xcomet_qe_score": 0.8094558715820312, "metricx_score": 2.762620687484741, "metricx_qe_score": 3.0744781494140625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich dazu ermutigen, VALS zur Messung des Fortschritts bei der sprachlichen Verankerung mit Visionen und Sprachmodellen zu verwenden.", "metrics": {"bleu_score": 40.76128826387552, "chrf_score": 71.82651291641548, "xcomet_score": 0.928864061832428, "xcomet_qe_score": 0.9116917252540588, "metricx_score": 2.3906984329223633, "metricx_qe_score": 3.8299553394317627, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus könnte VALS als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz den Modellen bei der Verbesserung der von VALS getesteten Aspekte hilft.", "metrics": {"bleu_score": 51.13485410113679, "chrf_score": 73.91412638891217, "xcomet_score": 0.999950647354126, "xcomet_qe_score": 0.9996787309646606, "metricx_score": 0.3214156925678253, "metricx_qe_score": 0.43396228551864624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, werfen Sie einen Blick auf die VALS-Daten auf GitHub und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren.", "metrics": {"bleu_score": 42.75215862300699, "chrf_score": 65.59319090481549, "xcomet_score": 0.9913125038146973, "xcomet_qe_score": 0.9938784837722778, "metricx_score": 1.435712456703186, "metricx_qe_score": 0.9372817873954773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kami Zerua von der Universität Tokio.", "metrics": {"bleu_score": 63.40466277046863, "chrf_score": 85.52444193023891, "xcomet_score": 0.8398730754852295, "xcomet_qe_score": 0.8375144600868225, "metricx_score": 3.063661813735962, "metricx_qe_score": 2.9113340377807617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Vortrag mit dem Titel RNSUM halten, einem umfangreichen Datensatz für automatische Listenannotation durch Commit-Log-Zusammenfassung.", "metrics": {"bleu_score": 4.03314518298892, "chrf_score": 27.512816767045837, "xcomet_score": 0.9251730442047119, "xcomet_qe_score": 0.915993332862854, "metricx_score": 3.3946926593780518, "metricx_qe_score": 2.8609495162963867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 88.05371765891114, "xcomet_score": 0.9900722503662109, "xcomet_qe_score": 0.983869731426239, "metricx_score": 0.4221750497817993, "metricx_qe_score": 0.7891620397567749, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risiko-Benachrichtigung vorstellen, an der wir in dieser Forschung arbeiten.", "metrics": {"bleu_score": 71.9548353625319, "chrf_score": 73.10954945155154, "xcomet_score": 0.7960824966430664, "xcomet_qe_score": 0.8028043508529663, "metricx_score": 3.7694454193115234, "metricx_qe_score": 1.3294531106948853, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNode ist ein technisches Dokument, das die mit jeder Version eines Softwareprodukts verteilten Änderungen zusammenfasst.", "metrics": {"bleu_score": 52.75568628444888, "chrf_score": 74.1996191725174, "xcomet_score": 0.8179765939712524, "xcomet_qe_score": 0.8127360939979553, "metricx_score": 6.841137409210205, "metricx_qe_score": 6.207374095916748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Versionshinweise für Version 2.6.1.", "metrics": {"bleu_score": 18.70274255449444, "chrf_score": 56.500452076012934, "xcomet_score": 0.4467293620109558, "xcomet_qe_score": 0.6208859086036682, "metricx_score": 4.992263317108154, "metricx_qe_score": 2.4205451011657715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Dies spielt bei der Open-Source-Entwicklung keine wichtige Rolle, aber sie sind zeitaufwendig, wenn sie manuell vorbereitet werden.", "metrics": {"bleu_score": 18.45895819969781, "chrf_score": 60.612175093677365, "xcomet_score": 0.8519673347473145, "xcomet_qe_score": 0.8330874443054199, "metricx_score": 7.388883590698242, "metricx_qe_score": 7.492918014526367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, automatisch hochwertige Versionshinweise zu erstellen.", "metrics": {"bleu_score": 31.46660996956415, "chrf_score": 63.1928417989476, "xcomet_score": 0.9991512298583984, "xcomet_qe_score": 0.9856826066970825, "metricx_score": 0.40793439745903015, "metricx_qe_score": 0.49929553270339966, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zur automatischen Zuhörergenerierung verweisen.", "metrics": {"bleu_score": 12.320255516768906, "chrf_score": 58.39997340877221, "xcomet_score": 0.7336549758911133, "xcomet_qe_score": 0.7572499513626099, "metricx_score": 8.97756576538086, "metricx_qe_score": 8.685535430908203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens Arena, das 2014 veröffentlicht wurde.", "metrics": {"bleu_score": 19.209413468550956, "chrf_score": 52.08972312408571, "xcomet_score": 0.9819424152374268, "xcomet_qe_score": 0.9836039543151855, "metricx_score": 0.3357934057712555, "metricx_qe_score": 0.4636992812156677, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es wird ein regelbasierter Ansatz verwendet, bei dem beispielsweise der Änderungs-Extractor verwendet wird, um die wesentlichen Unterschiede, Bibliotheksänderungen und Dokumentänderungen aus den Unterschieden zwischen den Versionen zu extrahieren und sie schließlich zu kombinieren.", "metrics": {"bleu_score": 40.85492989646262, "chrf_score": 74.6718525385536, "xcomet_score": 0.9450137615203857, "xcomet_qe_score": 0.9546427130699158, "metricx_score": 0.9465689659118652, "metricx_qe_score": 1.0619127750396729, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das auffälligste Merkmal dieses Systems ist der Issue-Extractor in der oberen rechten Ecke.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 69.51410378159578, "xcomet_score": 0.8349988460540771, "xcomet_qe_score": 0.8857951164245605, "metricx_score": 4.131425380706787, "metricx_qe_score": 3.8075649738311768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "die mit Jira, dem Problemdiskussions-System, verknüpft werden müssen und nur auf Projekte angewendet werden können, die Jira verwenden.", "metrics": {"bleu_score": 39.96806384679825, "chrf_score": 59.67859062264688, "xcomet_score": 0.9095748066902161, "xcomet_qe_score": 0.9236859083175659, "metricx_score": 3.0011861324310303, "metricx_qe_score": 2.814751386642456, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, es kann für viele Projekte auf GitHub nicht verwendet werden.", "metrics": {"bleu_score": 42.2106812637453, "chrf_score": 81.67885297080673, "xcomet_score": 0.9911297559738159, "xcomet_qe_score": 0.9907432198524475, "metricx_score": 0.30483803153038025, "metricx_qe_score": 0.4738426208496094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite ist GRIF. Kürzlich im Jahr 2020 angekündigt,", "metrics": {"bleu_score": 10.71174444166974, "chrf_score": 54.55757122222179, "xcomet_score": 0.760765790939331, "xcomet_qe_score": 0.6923757791519165, "metricx_score": 6.693415641784668, "metricx_qe_score": 5.683579921722412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Es ist im Internet verfügbar und kann über PIP gespeichert werden.", "metrics": {"bleu_score": 67.0422683816333, "chrf_score": 75.53137210277426, "xcomet_score": 0.9232152104377747, "xcomet_qe_score": 0.9601089954376221, "metricx_score": 3.5335781574249268, "metricx_qe_score": 2.9840102195739746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, lernbasiertes Textklassifizierungsmodul und gibt für jede Eingabeaufgabenmeldung eine von fünf Variablen aus, wie z. B. Funktionen oder Fehlerbehebungen.", "metrics": {"bleu_score": 37.20337795006883, "chrf_score": 68.39698957489698, "xcomet_score": 0.8521178960800171, "xcomet_qe_score": 0.8498961925506592, "metricx_score": 2.1415750980377197, "metricx_qe_score": 1.4910469055175781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt eine Beispielnutzung, die ein Korrektur- oder Fehlerbehebungsetikett zurückgibt.", "metrics": {"bleu_score": 6.455266723185131, "chrf_score": 48.762886563495094, "xcomet_score": 0.9492772817611694, "xcomet_qe_score": 0.9567798376083374, "metricx_score": 2.019239664077759, "metricx_qe_score": 2.138319969177246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsdaten von Goyafet sind ziemlich klein, etwa 5000, und werden in den unten beschriebenen Experimenten gezeigt.", "metrics": {"bleu_score": 70.76534431960266, "chrf_score": 90.16850770335668, "xcomet_score": 0.7960028648376465, "xcomet_qe_score": 0.7782979607582092, "metricx_score": 6.738102912902832, "metricx_qe_score": 7.484884738922119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des Textklassifizierungsmodells ist nicht hoch.", "metrics": {"bleu_score": 50.000000000000014, "chrf_score": 83.33360912349363, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20595994591712952, "metricx_qe_score": 0.44808152318000793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich stelle zwei verwandte Forschungen vor, aber es gab Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen.", "metrics": {"bleu_score": 19.90581597344524, "chrf_score": 68.67596819165054, "xcomet_score": 0.984217643737793, "xcomet_qe_score": 0.98597651720047, "metricx_score": 1.0368106365203857, "metricx_qe_score": 0.44146546721458435, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit löst diese beiden Probleme und erzeugt automatisch hochwertige Release-Knoten.", "metrics": {"bleu_score": 24.925832743644712, "chrf_score": 55.052330658774494, "xcomet_score": 0.8292806148529053, "xcomet_qe_score": 0.8164113759994507, "metricx_score": 5.1427788734436035, "metricx_qe_score": 4.545675277709961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das Programm zur begrenzten Anwendbarkeit schlagen wir eine hochwertige Klassifikationsmethode zur Zusammenfassung vor, die nur Commit-Nachrichten als Eingabe verwendet.", "metrics": {"bleu_score": 51.137980322398526, "chrf_score": 71.64504994353217, "xcomet_score": 0.8891305327415466, "xcomet_qe_score": 0.8824198842048645, "metricx_score": 3.8974783420562744, "metricx_qe_score": 3.8750736713409424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Bibliotheken verwendet werden.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 81.26668189233305, "xcomet_score": 0.9857702851295471, "xcomet_qe_score": 1.0, "metricx_score": 1.3870874643325806, "metricx_qe_score": 1.591305136680603, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der knappen Datenressourcen haben wir einen RNSUM-Datensatz erstellt, der aus etwa 82.000 Datensätzen besteht, indem wir Daten aus öffentlichen GitHub-Repositories mithilfe der GitHub-API gesammelt haben.", "metrics": {"bleu_score": 53.646552861740275, "chrf_score": 82.38255625384934, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.5149587392807007, "metricx_qe_score": 1.0396323204040527, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich, wie sie sitzen.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 45.81888337431841, "xcomet_score": 0.8469996452331543, "xcomet_qe_score": 0.8392122983932495, "metricx_score": 3.1890149116516113, "metricx_qe_score": 3.5065932273864746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel für Daten.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 81.3052385800557, "xcomet_score": 0.9865502119064331, "xcomet_qe_score": 0.9950288534164429, "metricx_score": 0.11113797873258591, "metricx_qe_score": 0.3509396016597748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Auf der linken Seite ist die Commit-Nachricht, und auf der rechten Seite ist die Versionsnotiz.", "metrics": {"bleu_score": 45.72082891936412, "chrf_score": 74.26384340868388, "xcomet_score": 0.9214202761650085, "xcomet_qe_score": 0.8378679752349854, "metricx_score": 0.6768712997436523, "metricx_qe_score": 0.8808423280715942, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Versionshinweise sind als Verbesserungen, Arbeitsplätze usw. gekennzeichnet.", "metrics": {"bleu_score": 41.72261448611506, "chrf_score": 63.792825743768645, "xcomet_score": 0.850112795829773, "xcomet_qe_score": 0.8241182565689087, "metricx_score": 3.57106614112854, "metricx_qe_score": 4.287738800048828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die engagierten Nachrichten als Eingabe verwendet und die rohen Verdrahtungs-Knoten als Ausgabe liefert.", "metrics": {"bleu_score": 40.276720463657746, "chrf_score": 56.732918995733094, "xcomet_score": 0.6734750270843506, "xcomet_qe_score": 0.6070088148117065, "metricx_score": 10.632763862609863, "metricx_qe_score": 11.829877853393555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassung betrachtet werden.", "metrics": {"bleu_score": 35.640264633541825, "chrf_score": 70.59235623874235, "xcomet_score": 0.9989168643951416, "xcomet_qe_score": 0.9841593503952026, "metricx_score": 0.2331073135137558, "metricx_qe_score": 0.43441444635391235, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier vordefinierte Stufen. Funktionen, Verbesserungen, Fehlerbehebungen, Veraltungen, Entfernungen und Bruchänderungen.", "metrics": {"bleu_score": 33.49923255785667, "chrf_score": 61.93952333300279, "xcomet_score": 0.7202841639518738, "xcomet_qe_score": 0.7808985114097595, "metricx_score": 6.849063873291016, "metricx_qe_score": 6.705058574676514, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden auf der Grundlage früherer Forschungen und anderer Faktoren gesagt.", "metrics": {"bleu_score": 35.72281085191041, "chrf_score": 72.02993903084982, "xcomet_score": 0.9492574334144592, "xcomet_qe_score": 0.9568391442298889, "metricx_score": 3.2480924129486084, "metricx_qe_score": 4.453771114349365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Randnotizen rechts unten sind aus den Randnotizen links unten extrahiert.", "metrics": {"bleu_score": 11.731175160263996, "chrf_score": 40.071491259124684, "xcomet_score": 0.9984356164932251, "xcomet_qe_score": 1.0, "metricx_score": 1.123146891593933, "metricx_qe_score": 1.3976129293441772, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zeitpunkt ist es notwendig, die vier im Voraus festgelegten Ebenen zu erkennen.", "metrics": {"bleu_score": 14.152447972070973, "chrf_score": 43.19746145691411, "xcomet_score": 0.9208931922912598, "xcomet_qe_score": 0.9119939208030701, "metricx_score": 1.408889651298523, "metricx_qe_score": 0.9937087297439575, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Die Stufen stimmen jedoch nicht immer mit jeder Bibliothek überein.", "metrics": {"bleu_score": 25.965358893403383, "chrf_score": 43.28428902755955, "xcomet_score": 0.8409713506698608, "xcomet_qe_score": 0.7998030185699463, "metricx_score": 3.8018462657928467, "metricx_qe_score": 2.3297183513641357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel umfasst die Verbesserungsstufe Verbesserungen, Erweiterungen, Optimierungen und so weiter.", "metrics": {"bleu_score": 61.153805769010226, "chrf_score": 72.387273429412, "xcomet_score": 0.932660698890686, "xcomet_qe_score": 0.923793613910675, "metricx_score": 1.3386733531951904, "metricx_qe_score": 1.223949670791626, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben für jede dieser Notationsschwierigkeitsgrade eine Vokabelliste der Teilstudienebenen erstellt.", "metrics": {"bleu_score": 16.21599014882373, "chrf_score": 51.78313350441772, "xcomet_score": 0.8192193508148193, "xcomet_qe_score": 0.798197865486145, "metricx_score": 7.094044208526611, "metricx_qe_score": 7.358325004577637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Freigabehinweis-Klasse zu erkennen und den Text der folgenden Liste als Freigabehinweis-Satz für die Klasse zu korrigieren.", "metrics": {"bleu_score": 9.230947454856247, "chrf_score": 40.550905740899545, "xcomet_score": 0.7710021138191223, "xcomet_qe_score": 0.7394513487815857, "metricx_score": 7.940009593963623, "metricx_qe_score": 6.384369850158691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes folgt eine Commit-Nachricht.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9995623826980591, "xcomet_qe_score": 0.9971550703048706, "metricx_score": 0.8402528166770935, "metricx_qe_score": 1.1925365924835205, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Verbindingsnachrichten sind nicht an eine Liste gebunden.", "metrics": {"bleu_score": 22.811360354329615, "chrf_score": 53.88603203817076, "xcomet_score": 0.7469820976257324, "xcomet_qe_score": 0.7452272176742554, "metricx_score": 8.346271514892578, "metricx_qe_score": 6.2255377769470215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der Abbildung unten gezeigt, müssen wir, wenn es sich bei der aktuellen Liste um Version 2.5 bis 19 handelt, Folgendes identifizieren:", "metrics": {"bleu_score": 19.55198139027402, "chrf_score": 51.96278780854308, "xcomet_score": 0.7911043167114258, "xcomet_qe_score": 0.7006179094314575, "metricx_score": 4.835695266723633, "metricx_qe_score": 6.858442306518555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "die vorherige Versionsausgabe, 2.5.18, und gehen Sie in die Tiefe. Das ist etwas langweilig, und es reicht nicht aus, einfach eine Liste der Versionen zu erhalten und sich das Vorher und Nachher anzusehen.", "metrics": {"bleu_score": 16.4343493968404, "chrf_score": 50.486426093006685, "xcomet_score": 0.6641870737075806, "xcomet_qe_score": 0.6087620258331299, "metricx_score": 12.08375072479248, "metricx_qe_score": 10.607282638549805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine heuristische Matching-Regel erstellt, um die vorherige und die nächste Version zu erhalten.", "metrics": {"bleu_score": 70.85876411943929, "chrf_score": 78.47869645738267, "xcomet_score": 0.9953608512878418, "xcomet_qe_score": 1.0, "metricx_score": 1.3833861351013184, "metricx_qe_score": 0.9230278730392456, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist Tanarsis.", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 13.160941647712605, "xcomet_score": 0.13266929984092712, "xcomet_qe_score": 0.09725843369960785, "metricx_score": 3.8086347579956055, "metricx_qe_score": 4.650173187255859, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende 7200 Repositories.", "metrics": {"bleu_score": 9.346579571601447, "chrf_score": 39.23284304120118, "xcomet_score": 0.5573707818984985, "xcomet_qe_score": 0.20920604467391968, "metricx_score": 14.78959846496582, "metricx_qe_score": 18.42436408996582, "linguapy_score": [1, "CATALAN"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Auch die durchschnittliche Anzahl der Release-Knoten-Token beträgt 63, was für eine Zusammenfassung recht hoch ist.", "metrics": {"bleu_score": 47.373073491120294, "chrf_score": 64.58179393109789, "xcomet_score": 0.8339815139770508, "xcomet_qe_score": 0.8330960869789124, "metricx_score": 4.879054069519043, "metricx_qe_score": 4.223078727722168, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Anzahl der eindeutigen Token ist mit 8.830.000 recht groß.", "metrics": {"bleu_score": 39.181891500702136, "chrf_score": 82.98087084002344, "xcomet_score": 0.9760404825210571, "xcomet_qe_score": 0.9788083434104919, "metricx_score": 1.486060380935669, "metricx_qe_score": 1.8731516599655151, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl einzigartiger Klassen- und Methodenamen, die im Repository gefunden wurden.", "metrics": {"bleu_score": 6.917184228205472, "chrf_score": 43.742937942563636, "xcomet_score": 0.9907201528549194, "xcomet_qe_score": 0.9880805015563965, "metricx_score": 0.9818951487541199, "metricx_qe_score": 0.8170817494392395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes werde ich die vorgeschlagene Methode erläutern.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das klassenweise extraktive und dann abstrahierende Zusammenfassungmodell besteht aus zwei neuronalen Modulen.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 96.57655834813556, "xcomet_score": 0.9893054962158203, "xcomet_qe_score": 0.9788857102394104, "metricx_score": 1.2860162258148193, "metricx_qe_score": 2.794158458709717, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "ein Klassifikator, der BERT oder CodeBert verwendet, und ein Generator, der BERT verwendet.", "metrics": {"bleu_score": 12.39899236095509, "chrf_score": 72.31089275967017, "xcomet_score": 0.9667581915855408, "xcomet_qe_score": 0.9581570625305176, "metricx_score": 4.315376281738281, "metricx_qe_score": 3.2586095333099365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet CAS einen Klassifikator, um jede Commit-Nachricht in fünf Versionshinweis-Klassen einzuteilen. Wir wählen Implementierungen, Bugfixes, Deprecationen, Plus und Sonstiges.", "metrics": {"bleu_score": 26.80790169417069, "chrf_score": 51.82638583135358, "xcomet_score": 0.6942518949508667, "xcomet_qe_score": 0.7550175786018372, "metricx_score": 6.17879581451416, "metricx_qe_score": 5.816305637359619, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als „Sonstiges“ eingestuften Commit-Nachrichten werden verworfen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9994972944259644, "xcomet_qe_score": 0.9905409812927246, "metricx_score": 0.7939783334732056, "metricx_qe_score": 0.951912522315979, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wendet CES den Generator unabhängig auf die vier Etikettendokumente an und generiert Freigabenodizes für jede Klasse.", "metrics": {"bleu_score": 22.095434806633396, "chrf_score": 50.38212977777381, "xcomet_score": 0.8034976124763489, "xcomet_qe_score": 0.8305006623268127, "metricx_score": 7.134777069091797, "metricx_qe_score": 6.559991836547852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Korrespondenzen zwischen Commit-Nachrichten und gelesenen Knoten nicht bekannt.", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 84.34441266111084, "xcomet_score": 0.879207968711853, "xcomet_qe_score": 0.8139369487762451, "metricx_score": 3.404689311981201, "metricx_qe_score": 4.382169246673584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Daher weisen wir jedem Eingabekommitten-Nachrichtensudo-Label die ersten 10 Zeichen jeder Kommitten-Nachricht zu, um den Klassifikator zu trainieren.", "metrics": {"bleu_score": 13.522400449734791, "chrf_score": 51.807670393962034, "xcomet_score": 0.7303152084350586, "xcomet_qe_score": 0.762215256690979, "metricx_score": 8.715087890625, "metricx_qe_score": 8.156559944152832, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die klassenweise abstrahierende Zusammenfassung durch unseren Ansatz mit zwei verschiedenen Methoden.", "metrics": {"bleu_score": 4.246549372656572, "chrf_score": 63.15503032794145, "xcomet_score": 0.8993089199066162, "xcomet_qe_score": 0.8980852365493774, "metricx_score": 2.3718459606170654, "metricx_qe_score": 3.2384860515594482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir cssingle nennen, besteht aus einem einzigen sex-to-sex-Netzwerk und generiert einen einzigen langen Knotentext, wenn eine Verkettung von Eingabe-Commit-Nachrichten gegeben ist.", "metrics": {"bleu_score": 40.95434825884115, "chrf_score": 71.98151813276378, "xcomet_score": 0.6688048243522644, "xcomet_qe_score": 0.6787339448928833, "metricx_score": 9.35438346862793, "metricx_qe_score": 10.59748363494873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgabetext kann in klassenweite Segmente unterteilt werden, die auf speziellen klassenbezogenen Endpunktsymbolen basieren.", "metrics": {"bleu_score": 10.82597837309053, "chrf_score": 55.551547288530955, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.596513032913208, "metricx_qe_score": 0.7681682109832764, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir CAS-Merge nennen, besteht aus vier verschiedenen sec-to-sec-Netzwerken, von denen jedes einer der am wenigsten bekannten Klassen entspricht.", "metrics": {"bleu_score": 55.70963651533937, "chrf_score": 75.72207732843789, "xcomet_score": 0.5783066749572754, "xcomet_qe_score": 0.5910062789916992, "metricx_score": 8.045777320861816, "metricx_qe_score": 7.924141883850098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, lassen Sie mich das Experiment erklären.", "metrics": {"bleu_score": 9.535414040914192, "chrf_score": 49.75269042427508, "xcomet_score": 0.9954168796539307, "xcomet_qe_score": 0.9940097332000732, "metricx_score": 0.2833854854106903, "metricx_qe_score": 0.276653915643692, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden fünf Methoden verglichen: CAS, CS single, CS merge, Clustering und die Trauermethode aus der vorherigen Studie.", "metrics": {"bleu_score": 10.308675254291913, "chrf_score": 54.74058101038061, "xcomet_score": 0.6961286067962646, "xcomet_qe_score": 0.698571503162384, "metricx_score": 10.755341529846191, "metricx_qe_score": 11.897377014160156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Auswertung werden diese Knoten in einigen Fällen in mehreren Sätzen ausgegeben.", "metrics": {"bleu_score": 29.5560575580374, "chrf_score": 53.77402016468724, "xcomet_score": 0.8581080436706543, "xcomet_qe_score": 0.8358318209648132, "metricx_score": 5.6257500648498535, "metricx_qe_score": 5.0326337814331055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt.", "metrics": {"bleu_score": 83.95876230925758, "chrf_score": 91.66775843741057, "xcomet_score": 0.998297929763794, "xcomet_qe_score": 1.0, "metricx_score": 0.625493586063385, "metricx_qe_score": 1.1572595834732056, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Blau ist in Felder unterteilt, wenn das System einen kurzen Satz ausgibt.", "metrics": {"bleu_score": 55.12003357447276, "chrf_score": 65.81445455315614, "xcomet_score": 0.8411411643028259, "xcomet_qe_score": 0.8432736992835999, "metricx_score": 6.6541547775268555, "metricx_qe_score": 4.843220233917236, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt in den nachfolgend beschriebenen Versuchsergebnissen zu einem niedrigeren Blauwert.", "metrics": {"bleu_score": 40.89601472043678, "chrf_score": 78.2448913455097, "xcomet_score": 0.9264285564422607, "xcomet_qe_score": 0.9436612129211426, "metricx_score": 3.1566224098205566, "metricx_qe_score": 2.884765863418579, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich berechnen wir auch die Spezifität, da Rouge und Blue nicht berechnet werden können, wenn die Freisetzungsknoten leer sind.", "metrics": {"bleu_score": 64.7084148066781, "chrf_score": 74.80602836247155, "xcomet_score": 0.7794004082679749, "xcomet_qe_score": 0.7736621499061584, "metricx_score": 4.796268463134766, "metricx_qe_score": 3.4946227073669434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell in Fällen, in denen die Freisetzungsknoten leer sind, korrekt einen leeren Text ausgibt.", "metrics": {"bleu_score": 62.13643627153653, "chrf_score": 74.72847026991954, "xcomet_score": 0.9145894646644592, "xcomet_qe_score": 0.9084482789039612, "metricx_score": 2.919950246810913, "metricx_qe_score": 2.7896158695220947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse.", "metrics": {"bleu_score": 42.72870063962342, "chrf_score": 48.96283815298874, "xcomet_score": 0.9982582330703735, "xcomet_qe_score": 0.9951757192611694, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, haben wir auch den bereinigten Datensatz ausgewertet, der diese ausschließt.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9878028631210327, "xcomet_qe_score": 0.9883376955986023, "metricx_score": 0.32451337575912476, "metricx_qe_score": 0.373135507106781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "CEAS und CAS erreichten lockere L-Werte, die mehr als 10 Punkte über den Basiswerten lagen.", "metrics": {"bleu_score": 37.8311388907207, "chrf_score": 69.19513956097798, "xcomet_score": 0.8455451726913452, "xcomet_qe_score": 0.8592199087142944, "metricx_score": 5.799825668334961, "metricx_qe_score": 6.2729010581970215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere beim sauberen Testset sprang die Punktdifferenz zwischen den vorgeschlagenen Methoden und der Basis auf mehr als 20 Punkte.", "metrics": {"bleu_score": 10.61028736691441, "chrf_score": 54.31149750002078, "xcomet_score": 0.876332700252533, "xcomet_qe_score": 0.9191184639930725, "metricx_score": 5.638695240020752, "metricx_qe_score": 4.8505473136901855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse deuten darauf hin, dass CES und GS signifikant wirksam sind.", "metrics": {"bleu_score": 10.571070857151541, "chrf_score": 55.01972540858656, "xcomet_score": 0.6859430074691772, "xcomet_qe_score": 0.7559380531311035, "metricx_score": 7.385797500610352, "metricx_qe_score": 7.742034912109375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "CAS erzielte einen besseren Root-Fail-Score als CAS, was darauf hindeutet, dass die Kombination eines Klassifikators und eines Generators bei der Klassifikator-Schulung mit Pseudo-Doubles effektiv ist.", "metrics": {"bleu_score": 57.51167640035277, "chrf_score": 73.21762731650867, "xcomet_score": 0.5623301267623901, "xcomet_qe_score": 0.5392897129058838, "metricx_score": 10.71003532409668, "metricx_qe_score": 10.98613452911377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von CAS kann wahrscheinlich erreicht werden, weil der Klassifikator sich darauf konzentrieren kann, relevante Commit-Nachrichten für jede Klasse auszuwählen.", "metrics": {"bleu_score": 38.08007348386316, "chrf_score": 80.40402129546405, "xcomet_score": 0.8843511343002319, "xcomet_qe_score": 0.8920745849609375, "metricx_score": 3.822906732559204, "metricx_qe_score": 5.704619884490967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "CAS-Match führt tendenziell zu höheren Ergebnissen als CAS Single.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 40.815147623535125, "xcomet_score": 0.7833812236785889, "xcomet_qe_score": 0.8382118940353394, "metricx_score": 7.517213821411133, "metricx_qe_score": 8.806670188903809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es ebenfalls effektiv ist, für jede Freigabeknoten-Klasse eigenständig unterschiedlich absorbierende Zusammenfassungmodelle zu entwickeln.", "metrics": {"bleu_score": 13.405854162194855, "chrf_score": 49.05119790666353, "xcomet_score": 0.824171781539917, "xcomet_qe_score": 0.7964807748794556, "metricx_score": 5.833226680755615, "metricx_qe_score": 5.286787033081055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Helden- und Fehleranalyse", "metrics": {"bleu_score": 0.0, "chrf_score": 49.905038499517325, "xcomet_score": 0.4836306571960449, "xcomet_qe_score": 0.5852845907211304, "metricx_score": 4.304367542266846, "metricx_qe_score": 5.341307640075684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "CS-Methoden neigen dazu, kürzere Sätze als menschliche Referenzsätze zu erzeugen.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 66.41760489232195, "xcomet_score": 0.9560073018074036, "xcomet_qe_score": 0.9210281372070312, "metricx_score": 2.2149550914764404, "metricx_qe_score": 2.232160806655884, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung rechts hat der Referenzsatz 3 oder 4 Sätze, während CAS nur einen hat.", "metrics": {"bleu_score": 20.838925800486027, "chrf_score": 57.299190988799786, "xcomet_score": 0.9931551218032837, "xcomet_qe_score": 0.9867093563079834, "metricx_score": 0.390564501285553, "metricx_qe_score": 0.7431989908218384, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzurückhaltung ist, dass in den Trainingsdaten nur 33 % der Sätze im Merkmalsetikett und 40 % im Verbesserungslabel vorhanden sind.", "metrics": {"bleu_score": 28.69366389832412, "chrf_score": 50.8048823460295, "xcomet_score": 0.8856755495071411, "xcomet_qe_score": 0.9616352319717407, "metricx_score": 2.9863510131835938, "metricx_qe_score": 3.453749179840088, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES-Methoden ohne zusätzliche Informationen keine genauen VsNode generieren.", "metrics": {"bleu_score": 43.66835442847811, "chrf_score": 74.31616082201272, "xcomet_score": 0.76708984375, "xcomet_qe_score": 0.7452770471572876, "metricx_score": 7.788637638092041, "metricx_qe_score": 8.62593936920166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das oberste Beispiel rechts ist ein Beispiel für eine sehr chaotische Kommentarnachricht, und der vollständige Satz kann nicht ohne Bezug auf die entsprechende Pull-Anfrage oder das Problem generiert werden.", "metrics": {"bleu_score": 48.446631758569445, "chrf_score": 66.46995646705784, "xcomet_score": 0.7934185266494751, "xcomet_qe_score": 0.7903368473052979, "metricx_score": 4.645890712738037, "metricx_qe_score": 4.175821304321289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden Commit-Nachrichten in der Eingabe miteinander verknüpft sind und in einen Satz kombiniert werden sollten, was jedoch nicht geschieht.", "metrics": {"bleu_score": 58.217473175544946, "chrf_score": 69.93370725971467, "xcomet_score": 0.9830095767974854, "xcomet_qe_score": 0.989694356918335, "metricx_score": 0.6336588859558105, "metricx_qe_score": 1.0152636766433716, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend eine Schlussfolgerung.", "metrics": {"bleu_score": 9.688464563433238, "chrf_score": 8.61068339763784, "xcomet_score": 0.9979920387268066, "xcomet_qe_score": 1.0, "metricx_score": 0.516656219959259, "metricx_qe_score": 0.07823039591312408, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben ein neues Set für die automatische Notarisierung von Fällen erstellt.", "metrics": {"bleu_score": 17.474335703431752, "chrf_score": 54.51098841454204, "xcomet_score": 0.7452616691589355, "xcomet_qe_score": 0.798628568649292, "metricx_score": 5.93420934677124, "metricx_qe_score": 4.134439468383789, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben uns auch die Aufgabe gestellt, Commit-Nachrichten einzugeben und sie so zu fassen, dass sie für alle in Englisch geschriebenen Projekte anwendbar sind.", "metrics": {"bleu_score": 9.186672262412122, "chrf_score": 57.49393110324389, "xcomet_score": 0.9834272265434265, "xcomet_qe_score": 0.9833405017852783, "metricx_score": 1.9164423942565918, "metricx_qe_score": 1.9933497905731201, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment zeigt, dass die vorgeschlagene Methode bei höherer Abdeckung weniger verrauschte Lead-Noten erzeugt als die Basislinien.", "metrics": {"bleu_score": 25.543184713657478, "chrf_score": 61.981040887650416, "xcomet_score": 0.7899885177612305, "xcomet_qe_score": 0.8390032052993774, "metricx_score": 5.139016151428223, "metricx_qe_score": 3.840700149536133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte überprüfen Sie den Code für die Registerkarte Wüstenprüfung.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 19.971607908882493, "xcomet_score": 0.13799987733364105, "xcomet_qe_score": 0.11566223204135895, "metricx_score": 7.664137840270996, "metricx_qe_score": 11.05772590637207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 87.72426647426647, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Asaf Harari.", "metrics": {"bleu_score": 54.10822690539397, "chrf_score": 81.82110562545346, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [1, "NYNORSK"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "und ich werde unseren Beitrag „Few-Shot Tabular Data Enrichment Using Fine-Tuning Transformers Architectures“ vorstellen.", "metrics": {"bleu_score": 19.56475149792291, "chrf_score": 81.26179132445913, "xcomet_score": 0.9404897689819336, "xcomet_qe_score": 0.9189703464508057, "metricx_score": 3.0999181270599365, "metricx_qe_score": 3.377906084060669, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "So analysieren Wissenschaftler Daten und konzentrieren sich hauptsächlich darauf, die vorhandenen Merkmale der Daten zu manipulieren.", "metrics": {"bleu_score": 23.909453161355017, "chrf_score": 60.12741141130661, "xcomet_score": 0.9809152483940125, "xcomet_qe_score": 0.9826661944389343, "metricx_score": 1.8770432472229004, "metricx_qe_score": 1.8494157791137695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal sind diese Funktionen jedoch eingeschränkt.", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 63.968506897091196, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05782108008861542, "metricx_qe_score": 0.015499752014875412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Generierung von Merkmalen unter Verwendung einer anderen Datenquelle kann erhebliche Informationen hinzufügen.", "metrics": {"bleu_score": 53.33505353503043, "chrf_score": 82.18509248514383, "xcomet_score": 0.934609591960907, "xcomet_qe_score": 0.9908032417297363, "metricx_score": 0.7497941255569458, "metricx_qe_score": 0.4627454876899719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Tabellen-Daten-Anreicherung mit freiem Text aus externen Quellen.", "metrics": {"bleu_score": 65.26220818377338, "chrf_score": 81.21621517856362, "xcomet_score": 0.9909963607788086, "xcomet_qe_score": 0.9810761213302612, "metricx_score": 0.518690288066864, "metricx_qe_score": 0.5698849558830261, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben einen tabellarischen Datensatz und eine Wissensdatenbank.", "metrics": {"bleu_score": 57.60844201603898, "chrf_score": 79.00937431964408, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.27129918336868286, "metricx_qe_score": 0.1727202832698822, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Entitäten und die Textanalyse umfasst, um neue Merkmale aus dem freien Text der Wissensdatenbank zu extrahieren.", "metrics": {"bleu_score": 43.00000760562836, "chrf_score": 68.78211614901795, "xcomet_score": 0.9949197769165039, "xcomet_qe_score": 0.988359808921814, "metricx_score": 0.5107790231704712, "metricx_qe_score": 0.4016355872154236, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist genau dieser automatische Prozess.", "metrics": {"bleu_score": 62.401954419369176, "chrf_score": 84.75044971165464, "xcomet_score": 0.8918439149856567, "xcomet_qe_score": 0.888335645198822, "metricx_score": 3.8839259147644043, "metricx_qe_score": 4.871129512786865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel in Datensätzen betrachten, die in FAST eingespeist werden.", "metrics": {"bleu_score": 10.940334294192507, "chrf_score": 45.32161620914168, "xcomet_score": 0.8962025046348572, "xcomet_qe_score": 0.9005604982376099, "metricx_score": 5.381176948547363, "metricx_qe_score": 5.256283283233643, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Datensatz ein Universitätsdatensatz.", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 89.90466953471022, "xcomet_score": 0.9997750520706177, "xcomet_qe_score": 0.9985378980636597, "metricx_score": 0.0, "metricx_qe_score": 0.172540083527565, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "wenn es darum geht, Universitäten in niedrigranke und hochranke Universitäten einzuteilen.", "metrics": {"bleu_score": 7.1933868327348085, "chrf_score": 47.75181658129699, "xcomet_score": 0.9518495798110962, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.5996005535125732, "metricx_qe_score": 2.016359329223633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase von FAST ist das Entity Linking.", "metrics": {"bleu_score": 39.281465090051285, "chrf_score": 76.09854282749882, "xcomet_score": 0.8380417823791504, "xcomet_qe_score": 0.834115743637085, "metricx_score": 4.62074089050293, "metricx_qe_score": 4.398411750793457, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "wenn jede Entität, in diesem Beispiel der Universitätsname, mit einer Entität in der Wissensdatenbank verknüpft ist.", "metrics": {"bleu_score": 33.63744315574223, "chrf_score": 70.97005232636619, "xcomet_score": 0.9786913990974426, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5666136145591736, "metricx_qe_score": 0.36871469020843506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Der Text der Entitäten der Wissensdatenbank wird extrahiert und dem Datensatz hinzugefügt.", "metrics": {"bleu_score": 63.436083375358535, "chrf_score": 83.52314659305554, "xcomet_score": 0.9969322681427002, "xcomet_qe_score": 0.9849759936332703, "metricx_score": 0.4604550302028656, "metricx_qe_score": 0.7611286640167236, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text das Abstract der Wikipedia-Seite.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3184393048286438, "metricx_qe_score": 0.23803302645683289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Nun müssen wir Merkmale aus dem abgerufenen Text generieren oder extrahieren.", "metrics": {"bleu_score": 73.48889200874659, "chrf_score": 82.1012529701243, "xcomet_score": 0.9525744318962097, "xcomet_qe_score": 1.0, "metricx_score": 0.8560836911201477, "metricx_qe_score": 0.31881192326545715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen eine Phasen der Merkmalsextraktion, die eine Textanalyse umfasst.", "metrics": {"bleu_score": 4.289945608476924, "chrf_score": 45.234521937619924, "xcomet_score": 0.9734147787094116, "xcomet_qe_score": 0.9694177508354187, "metricx_score": 4.263375759124756, "metricx_qe_score": 3.8965227603912354, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "und das ist die Hauptneuheit dieses Papiers und ich werde in den nächsten Folien tief darauf eingehen", "metrics": {"bleu_score": 11.022825290043492, "chrf_score": 49.07777770869763, "xcomet_score": 0.9087435007095337, "xcomet_qe_score": 0.9115777015686035, "metricx_score": 2.080768585205078, "metricx_qe_score": 2.5354630947113037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Merkmalsextraktionsphase folgt eine Merkmalgenerierungsphase, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren.", "metrics": {"bleu_score": 42.07088992176657, "chrf_score": 58.15047768082773, "xcomet_score": 0.9549112319946289, "xcomet_qe_score": 0.9854632616043091, "metricx_score": 0.38462281227111816, "metricx_qe_score": 0.31377241015434265, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Generieren Sie zunächst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes.", "metrics": {"bleu_score": 57.60844201603898, "chrf_score": 71.56285882802177, "xcomet_score": 0.8871498107910156, "xcomet_qe_score": 0.9078870415687561, "metricx_score": 2.062178134918213, "metricx_qe_score": 2.3905651569366455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08455271273851395, "metricx_qe_score": 0.3038375675678253, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "So generiert FAST zwei neue Merkmale.", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 40.97467937273226, "xcomet_score": 0.8623442649841309, "xcomet_qe_score": 0.8957184553146362, "metricx_score": 5.07655143737793, "metricx_qe_score": 4.879277229309082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, generieren Sie zunächst fünf neue Merkmale.", "metrics": {"bleu_score": 53.2800971987552, "chrf_score": 72.8157902247783, "xcomet_score": 0.9390479326248169, "xcomet_qe_score": 0.945482611656189, "metricx_score": 3.5458719730377197, "metricx_qe_score": 3.8177876472473145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jedes Merkmal repräsentiert die Wahrscheinlichkeit für jede Klasse.", "metrics": {"bleu_score": 41.80134288483487, "chrf_score": 66.03373064615856, "xcomet_score": 0.9946569204330444, "xcomet_qe_score": 0.9989062547683716, "metricx_score": 0.4736848473548889, "metricx_qe_score": 0.4538906514644623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Textanalyse, der auf Transformer-basierten Sprachmodellen wie BERT, GPT, XNL und anderen basiert.", "metrics": {"bleu_score": 53.5206455132758, "chrf_score": 80.79990108692989, "xcomet_score": 0.939846396446228, "xcomet_qe_score": 0.9174851179122925, "metricx_score": 1.0982831716537476, "metricx_qe_score": 1.7506146430969238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "aber es ist unwahrscheinlich, dass wir Sprachmodelle mit den Eingabe-Datensätzen trainieren können.", "metrics": {"bleu_score": 51.81294220614274, "chrf_score": 80.07789700920921, "xcomet_score": 0.9682919979095459, "xcomet_qe_score": 0.9503530263900757, "metricx_score": 1.1292692422866821, "metricx_qe_score": 1.8636168241500854, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wäre daher das Feintuning einer Zielaufgabe.", "metrics": {"bleu_score": 16.784459625186194, "chrf_score": 37.56574816644727, "xcomet_score": 0.9399775862693787, "xcomet_qe_score": 0.9979863166809082, "metricx_score": 1.5564582347869873, "metricx_qe_score": 1.985023856163025, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der zukünftigen Extraktions-Phase können wir das Peritrain-Sprachmodell herunterladen, das Sprachmodell über den Zieldatensatz verfeinern,", "metrics": {"bleu_score": 25.048695135470293, "chrf_score": 60.174685634720646, "xcomet_score": 0.8670847415924072, "xcomet_qe_score": 0.8679220676422119, "metricx_score": 5.069571495056152, "metricx_qe_score": 4.179590225219727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, um das Sprachmodell zu verfeinern, um Text in Klassen zu klassifizieren, in Klassen zu abstrahieren, niedrig oder hoch.", "metrics": {"bleu_score": 16.48118036705827, "chrf_score": 55.21038809284813, "xcomet_score": 0.8313863277435303, "xcomet_qe_score": 0.8537076115608215, "metricx_score": 6.389988899230957, "metricx_qe_score": 4.439932823181152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen Sie die Ausgabe des Sprachmodells entgegen, die die Wahrscheinlichkeit für jede Klasse darstellt, und verwenden Sie diese als neue Merkmale.", "metrics": {"bleu_score": 55.925988689124864, "chrf_score": 76.76108817104807, "xcomet_score": 0.9111985564231873, "xcomet_qe_score": 0.9504566192626953, "metricx_score": 1.7607396841049194, "metricx_qe_score": 0.8687825202941895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass der Datensatz möglicherweise nur wenige eindeutige Entitätitags enthält.", "metrics": {"bleu_score": 47.82215756494833, "chrf_score": 62.92432253828344, "xcomet_score": 0.9658665060997009, "xcomet_qe_score": 0.9677998423576355, "metricx_score": 5.394352436065674, "metricx_qe_score": 4.532362937927246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthalten fast die Hälfte der Datensätze weniger als 400 Proben, und der kleinste Datensatz enthält 35 Proben in seinem Trainingsdatensatz.", "metrics": {"bleu_score": 52.694542150482285, "chrf_score": 78.67721788129502, "xcomet_score": 0.9733237028121948, "xcomet_qe_score": 0.9724398851394653, "metricx_score": 0.829192578792572, "metricx_qe_score": 0.9646579623222351, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wird das Feinabstimmen eines Sprachmodells mit diesem Datensatz unwirksam sein.", "metrics": {"bleu_score": 8.516593018819643, "chrf_score": 60.45310312729215, "xcomet_score": 0.9917244911193848, "xcomet_qe_score": 0.9892953634262085, "metricx_score": 0.456582248210907, "metricx_qe_score": 0.4526948928833008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "aber wir können Vorwissen über bereits analysierte Datensätze nutzen,", "metrics": {"bleu_score": 40.88064519392259, "chrf_score": 71.2483324210152, "xcomet_score": 0.9774771928787231, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.2612757086753845, "metricx_qe_score": 0.1331254094839096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir FAST auf mehrere Datensätze anwenden, können wir die N-minus-eins-Datensätze nutzen, um Informationen über die N-minus-eins-Datensätze zu sammeln und diese Informationen bei der Analyse des N-ten Datensatzes verwenden.", "metrics": {"bleu_score": 33.53243168055436, "chrf_score": 69.81622787585691, "xcomet_score": 0.8429087400436401, "xcomet_qe_score": 0.8432681560516357, "metricx_score": 2.134226083755493, "metricx_qe_score": 2.331690788269043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist, eine weitere Feinabstimmungsphase hinzuzufügen.", "metrics": {"bleu_score": 46.17366309441026, "chrf_score": 87.0351397934482, "xcomet_score": 0.9773527383804321, "xcomet_qe_score": 0.9571688175201416, "metricx_score": 0.815686821937561, "metricx_qe_score": 0.9502504467964172, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Multitask-Feinabstimmungsphase.", "metrics": {"bleu_score": 36.06452879987789, "chrf_score": 87.72214299647878, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7372856140136719, "metricx_qe_score": 0.9176682233810425, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "wenn Sie das Sprachmodell mit N-1-Datensätzen verfeinern,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.14995954523332, "xcomet_score": 0.9387815594673157, "xcomet_qe_score": 0.8879216909408569, "metricx_score": 1.730974555015564, "metricx_qe_score": 1.131259560585022, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend führen wir eine weitere Feinabstimmungsphase durch, bei der es sich um eine Zielaufgabfeinabstimmung handelt, wenn wir das Sprachmodell anhand des n-ten Zieldatensatzes feinabstimmen.", "metrics": {"bleu_score": 38.75738939089709, "chrf_score": 72.96187029372906, "xcomet_score": 0.9089250564575195, "xcomet_qe_score": 0.8868286609649658, "metricx_score": 1.6664756536483765, "metricx_qe_score": 1.4789531230926514, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der aktuelle Stand der Technik bei der Multitask-Feinanpassung, auch bekannt als leeres DNN.", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 35.53848096109748, "xcomet_score": 0.8281292915344238, "xcomet_qe_score": 0.8193965554237366, "metricx_score": 7.694552421569824, "metricx_qe_score": 7.08252477645874, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN werden die Anzahl der Aufgaben im Trainingsdatensatz beibehalten.", "metrics": {"bleu_score": 12.630268049376259, "chrf_score": 45.88020379464205, "xcomet_score": 0.9237818717956543, "xcomet_qe_score": 0.9307770729064941, "metricx_score": 7.4943389892578125, "metricx_qe_score": 3.80475115776062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainingsdatensatz. Also leeres DNN, vier Köpfe beibehalten, wie Sie auf dem Bild sehen können.", "metrics": {"bleu_score": 59.7713031281549, "chrf_score": 72.58845329034284, "xcomet_score": 0.8034113645553589, "xcomet_qe_score": 0.8133187294006348, "metricx_score": 9.188721656799316, "metricx_qe_score": 8.814733505249023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "und es wird eine zufällige Stichprobe aus dem Trainingsdatensatz entnommen.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 48.614980456277415, "xcomet_score": 0.9629402160644531, "xcomet_qe_score": 0.9505178332328796, "metricx_score": 1.8028451204299927, "metricx_qe_score": 2.2252261638641357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge beispielsweise zu Aufgaben der Einzelabsatzklassifizierung gehört, wird ein Vorwärts- und Rückwärtsdurchlauf durch den ersten Kopf ausgeführt.", "metrics": {"bleu_score": 5.538696232597744, "chrf_score": 46.15637439121977, "xcomet_score": 0.8063278198242188, "xcomet_qe_score": 0.8742893934249878, "metricx_score": 3.377264976501465, "metricx_qe_score": 2.1710593700408936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die zufällige Charge zur paarweisen Rangordnungsaufgabe gehört, wird sie in vorwärts- und rückwärtsgerichtete Weise durch den letzten Kopf geleitet.", "metrics": {"bleu_score": 6.798317193644945, "chrf_score": 46.876724263160035, "xcomet_score": 0.8140871524810791, "xcomet_qe_score": 0.8466259241104126, "metricx_score": 4.868830680847168, "metricx_qe_score": 2.422159433364868, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario wird ein tabellarischer Datensatz die Anzahl der Klassen durchlaufen.", "metrics": {"bleu_score": 20.098339913206324, "chrf_score": 67.34161172607268, "xcomet_score": 0.8413839340209961, "xcomet_qe_score": 0.8214573860168457, "metricx_score": 6.153027534484863, "metricx_qe_score": 4.58924674987793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben", "metrics": {"bleu_score": 81.87307530779823, "chrf_score": 96.21994437259447, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.050271835178136826, "metricx_qe_score": 0.436081200838089, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "mtDNN behält die Anzahl der Klassenleiter und Ausgabeebenen bei", "metrics": {"bleu_score": 4.062582855427254, "chrf_score": 32.006435658125454, "xcomet_score": 0.9039971828460693, "xcomet_qe_score": 0.9446098804473877, "metricx_score": 2.045980215072632, "metricx_qe_score": 2.085326910018921, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus muss emptyDNA neue Heads für einen neuen Datensatz mit einer neuen Aufgabe initialisieren.", "metrics": {"bleu_score": 61.000344570143675, "chrf_score": 65.97143159883467, "xcomet_score": 0.7756587266921997, "xcomet_qe_score": 0.8430285453796387, "metricx_score": 6.509905815124512, "metricx_qe_score": 7.872955799102783, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, den wir als Aufgabenreformulierung und Feinabstimmung bezeichnen, besteht darin, dass wir – anstatt mehrere Köpfe beizubehalten – jeden Datensatz in einen Satz pro Klassifikationsproblem umformulieren, bei dem es sich um Aufgaben mit zwei Klassen handelt.", "metrics": {"bleu_score": 28.050892427639997, "chrf_score": 71.79416530139827, "xcomet_score": 0.8238564133644104, "xcomet_qe_score": 0.8354817628860474, "metricx_score": 6.547427177429199, "metricx_qe_score": 3.835467576980591, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns ein Beispiel an.", "metrics": {"bleu_score": 80.91067115702207, "chrf_score": 82.06979784224109, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.035305172204971313, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Eingabe-Datensatz, der aus Entitäten, Merkmalen, Text und Klassen besteht.", "metrics": {"bleu_score": 57.56799653136483, "chrf_score": 72.36242536674152, "xcomet_score": 0.9940356016159058, "xcomet_qe_score": 0.9895455837249756, "metricx_score": 0.7309696078300476, "metricx_qe_score": 0.4386414885520935, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir reformulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zur Klassifizierung des Textes, des Abstracts und der Klasse in wahr oder falsch.", "metrics": {"bleu_score": 58.092391352823, "chrf_score": 84.93900897283935, "xcomet_score": 0.9790700674057007, "xcomet_qe_score": 0.9623187780380249, "metricx_score": 0.9712395071983337, "metricx_qe_score": 1.33269464969635, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten: Wir trainieren das Sprachmodell, um Abstraktes und Klassen zu klassifizieren, um zu abstrahieren und zu klassifizieren, wenn das Abstrakte zur Klasse gehört oder nicht.", "metrics": {"bleu_score": 30.119487183959937, "chrf_score": 62.22433059553061, "xcomet_score": 0.5399234294891357, "xcomet_qe_score": 0.5326193571090698, "metricx_score": 4.64355993270874, "metricx_qe_score": 5.057595729827881, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Label-Vektor bleibt in diesem Fall immer gleich, der besteht immer aus zwei Klassen.", "metrics": {"bleu_score": 24.79135867329687, "chrf_score": 53.794931568641445, "xcomet_score": 0.9544732570648193, "xcomet_qe_score": 0.9283021688461304, "metricx_score": 1.6594816446304321, "metricx_qe_score": 1.8994157314300537, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren neu formulierten Feinabstimmungsansatz.", "metrics": {"bleu_score": 59.00468726392806, "chrf_score": 93.23728204653821, "xcomet_score": 0.9943841695785522, "xcomet_qe_score": 0.9695727825164795, "metricx_score": 1.0241913795471191, "metricx_qe_score": 1.5420314073562622, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns also den vollständigen Rahmen an.", "metrics": {"bleu_score": 43.167001068522545, "chrf_score": 62.61096584754464, "xcomet_score": 0.9491994976997375, "xcomet_qe_score": 0.9430612921714783, "metricx_score": 0.7002825140953064, "metricx_qe_score": 0.9148326516151428, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "Das hat die Fed in Bewegung gesetzt.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 17.856900701838295, "xcomet_score": 0.11667764186859131, "xcomet_qe_score": 0.08882085233926773, "metricx_score": 10.447047233581543, "metricx_qe_score": 8.932278633117676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "und dann eine schnelle Phase zur Ausführung der Entität-Verknüpfung", "metrics": {"bleu_score": 0.0, "chrf_score": 23.29899519321099, "xcomet_score": 0.9008016586303711, "xcomet_qe_score": 0.8567006587982178, "metricx_score": 5.529020309448242, "metricx_qe_score": 6.248025894165039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensdatenbank, in diesem Beispiel den Abstract der Wikipedia-Seite.", "metrics": {"bleu_score": 42.1262979301172, "chrf_score": 79.27585002650149, "xcomet_score": 0.9855296611785889, "xcomet_qe_score": 0.9553920030593872, "metricx_score": 0.9722869396209717, "metricx_qe_score": 1.2876640558242798, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann formuliert es die Aufgabe in einen Satz pro Klassifizierungsaufgabe um.", "metrics": {"bleu_score": 26.20251007173262, "chrf_score": 64.12980829103896, "xcomet_score": 0.8490628004074097, "xcomet_qe_score": 0.8534355163574219, "metricx_score": 3.3249824047088623, "metricx_qe_score": 3.3843727111816406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "wandte das Sprachmodell auf die neue Aufgabe an und berechnete die Ausgabewahrscheinlichkeit für jede Klasse,", "metrics": {"bleu_score": 40.325042950627804, "chrf_score": 78.35104598511248, "xcomet_score": 0.9560521841049194, "xcomet_qe_score": 0.9523787498474121, "metricx_score": 0.7096999287605286, "metricx_qe_score": 1.1522482633590698, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über dem N-1-Datensatz mit einer vorläufigen Multitask-Feinabstimmung verfeinert wurde.", "metrics": {"bleu_score": 18.951629567590746, "chrf_score": 67.8569780720257, "xcomet_score": 0.9313639998435974, "xcomet_qe_score": 0.8702623844146729, "metricx_score": 1.806900978088379, "metricx_qe_score": 2.4848673343658447, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verwenden wir den Ausgabevektor des Sprachmodells als neu generiertes Merkmal in der Anzahl der Klassen.", "metrics": {"bleu_score": 41.31624154858751, "chrf_score": 74.35970905163671, "xcomet_score": 0.9304149746894836, "xcomet_qe_score": 0.9150216579437256, "metricx_score": 0.8662654757499695, "metricx_qe_score": 1.6151846647262573, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Framework zu bewerten, verwenden wir einen 17-tabellarischen Klassifikationsdatensatz, der Größe, Merkmale, Ausgewogenheit, Domäne und anfängliche Leistung überprüft.", "metrics": {"bleu_score": 18.25741858350554, "chrf_score": 57.73333322565548, "xcomet_score": 0.916776180267334, "xcomet_qe_score": 0.9369946718215942, "metricx_score": 4.176300048828125, "metricx_qe_score": 4.589050769805908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensbasis verwenden wir Wikipedia.", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 95.4310132341269, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.02063114196062088, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir gestalten unser Experiment als Live-Evaluation, indem wir es an über 16 Datensätzen trainieren und auf den 17. Datensatz anwenden.", "metrics": {"bleu_score": 52.64172193306223, "chrf_score": 70.58268646059503, "xcomet_score": 0.821165919303894, "xcomet_qe_score": 0.8446494340896606, "metricx_score": 3.181065559387207, "metricx_qe_score": 3.53497576713562, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen jeden Datensatz auch in vier Faltblätter auf und wenden eine vierfache Kreuzvalidierung an.", "metrics": {"bleu_score": 53.24221584015077, "chrf_score": 72.6223033657256, "xcomet_score": 0.8905559182167053, "xcomet_qe_score": 0.8953733444213867, "metricx_score": 4.538041114807129, "metricx_qe_score": 3.661865234375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend generieren wir das neue Merkmal und bewerten es mit fünf Bewertungs-Klassifikatoren.", "metrics": {"bleu_score": 11.121234698968381, "chrf_score": 52.18414366695713, "xcomet_score": 0.9879056215286255, "xcomet_qe_score": 0.994999885559082, "metricx_score": 1.93365478515625, "metricx_qe_score": 0.9579792022705078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine auf BERT basierende Architektur.", "metrics": {"bleu_score": 15.851165692617148, "chrf_score": 68.10168504579508, "xcomet_score": 0.9978176355361938, "xcomet_qe_score": 1.0, "metricx_score": 0.4331548810005188, "metricx_qe_score": 1.183579683303833, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 85.51131524815735, "xcomet_score": 0.9987486600875854, "xcomet_qe_score": 0.9999598264694214, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unseren Rahmen mit der Feinabstimmung auf Zieldatensätze, der Feinabstimmung auf Zielaufgaben und der vorläufigen Feinabstimmung von MTDNN vergleichen.", "metrics": {"bleu_score": 46.24914700665564, "chrf_score": 77.93500157425312, "xcomet_score": 0.9632132053375244, "xcomet_qe_score": 0.9173139333724976, "metricx_score": 1.5215749740600586, "metricx_qe_score": 2.6236214637756348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "und unsere neu formulierte Feinabstimmung erzielt das beste Ergebnis, die beste Leistung.", "metrics": {"bleu_score": 33.649324423301536, "chrf_score": 83.06560654433763, "xcomet_score": 0.9707882404327393, "xcomet_qe_score": 0.9611876010894775, "metricx_score": 0.4114375710487366, "metricx_qe_score": 0.5767695903778076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "während es bei leerem dnn eine Verbesserung von zwei Prozent gegenüber dem Zieldatensatz-Feintuning erzielte", "metrics": {"bleu_score": 6.754312828675707, "chrf_score": 53.040431627662734, "xcomet_score": 0.6992250680923462, "xcomet_qe_score": 0.7037731409072876, "metricx_score": 7.849998474121094, "metricx_qe_score": 8.854355812072754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz erzielte eine Verbesserung von 6 %.", "metrics": {"bleu_score": 14.448814886766836, "chrf_score": 40.95749393921971, "xcomet_score": 0.985198974609375, "xcomet_qe_score": 0.9885041117668152, "metricx_score": 0.14844700694084167, "metricx_qe_score": 0.2075570523738861, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns das kleine Datensatz ansieht, können wir sehen, dass die Leistung von mtDNN abnimmt und die Verbesserung der vorläufigen Multitask-Feinabstimmung auf 1,5 Prozent sinkt.", "metrics": {"bleu_score": 46.462670705355734, "chrf_score": 79.97161159963059, "xcomet_score": 0.8976041674613953, "xcomet_qe_score": 0.8759347200393677, "metricx_score": 4.091216087341309, "metricx_qe_score": 4.572832107543945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "aber unsere Leistung stieg auf 11 % im Vergleich zur Zielaufgabe Feinabstimmung allein.", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 62.325369720686375, "xcomet_score": 0.9250864386558533, "xcomet_qe_score": 0.9379920363426208, "metricx_score": 1.7029036283493042, "metricx_qe_score": 1.763443112373352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Summierung ermöglicht FAST in unserem Experiment eine Anreicherung mit nur wenigen Schüssen aus 35 Proben.", "metrics": {"bleu_score": 28.43329181530769, "chrf_score": 69.20470371899222, "xcomet_score": 0.810819149017334, "xcomet_qe_score": 0.7643914818763733, "metricx_score": 4.14592981338501, "metricx_qe_score": 4.835620880126953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze.", "metrics": {"bleu_score": 55.0695314903184, "chrf_score": 90.0929663869274, "xcomet_score": 0.9807785749435425, "xcomet_qe_score": 0.9429309368133545, "metricx_score": 1.1379332542419434, "metricx_qe_score": 1.739567518234253, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und es behält den Kopf des Modells.", "metrics": {"bleu_score": 50.000000000000014, "chrf_score": 65.65602250693576, "xcomet_score": 0.864235520362854, "xcomet_qe_score": 0.8114601373672485, "metricx_score": 3.6576592922210693, "metricx_qe_score": 5.515409469604492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "aber es fügt eine Reformulierungsphase hinzu", "metrics": {"bleu_score": 64.31870218238025, "chrf_score": 95.16413282619317, "xcomet_score": 0.9597140550613403, "xcomet_qe_score": 0.9272104501724243, "metricx_score": 0.4084157645702362, "metricx_qe_score": 2.7123401165008545, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "seinen erweiterten Zug und seine Bedürfnisse, einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell eingeben und bei jedem Klassifizierungsproblem in den Satz einfügen können.", "metrics": {"bleu_score": 40.87501331941742, "chrf_score": 63.19505059739168, "xcomet_score": 0.7927794456481934, "xcomet_qe_score": 0.7428104877471924, "metricx_score": 8.473857879638672, "metricx_qe_score": 8.267804145812988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 87.72426647426647, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
