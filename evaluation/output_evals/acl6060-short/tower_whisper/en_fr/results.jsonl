{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous, aujourd'hui je vais présenter notre travail de recherche intitulé \"Apprendre à raisonner de manière déductive, résolution de problèmes métaboliques comme extraction de régions complexes\".", "metrics": {"bleu_score": 21.41303085756264, "chrf_score": 66.93373354704443, "xcomet_score": 0.6424802541732788, "xcomet_qe_score": 0.6691655516624451, "metricx_score": 7.659124851226807, "metricx_qe_score": 8.06008243560791, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "Je suis Alan du laboratoire d'IA de ByteDance et c'est un travail conjoint avec Jerry de l'Université du Texas à Austin et Weilu de la SUTD", "metrics": {"bleu_score": 23.978869996887823, "chrf_score": 53.650352932693444, "xcomet_score": 0.685390830039978, "xcomet_qe_score": 0.6808993816375732, "metricx_score": 4.500471115112305, "metricx_qe_score": 4.1060333251953125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, j'aimerais parler de notre motivation pour raisonner", "metrics": {"bleu_score": 72.05745450576255, "chrf_score": 86.4139108066489, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.712293803691864, "metricx_qe_score": 1.0606024265289307, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple où le raisonnement en plusieurs étapes est utile", "metrics": {"bleu_score": 56.69173599743462, "chrf_score": 74.45869260409185, "xcomet_score": 0.9991846084594727, "xcomet_qe_score": 1.0, "metricx_score": 0.462637335062027, "metricx_qe_score": 1.5307927131652832, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Cette figure est tirée de l'article de Pound, où ils utilisent l'incitation pour résoudre le problème mathématique dans un scénario d'apprentissage en quelques étapes.", "metrics": {"bleu_score": 9.563134602465547, "chrf_score": 53.907818909755854, "xcomet_score": 0.20254430174827576, "xcomet_qe_score": 0.35478848218917847, "metricx_score": 8.4906587600708, "metricx_qe_score": 8.190510749816895, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, du côté gauche, nous pouvons voir que si nous donnons quelques exemples avec juste des questions et des réponses, nous ne pourrons peut-être pas obtenir les réponses correctes", "metrics": {"bleu_score": 51.59060152500551, "chrf_score": 71.88210811714764, "xcomet_score": 0.9892693758010864, "xcomet_qe_score": 0.9917166233062744, "metricx_score": 0.8129451274871826, "metricx_qe_score": 0.8418726921081543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si nous fournissons une description plus détaillée du raisonnement, le modèle est capable de prédire la description du raisonnement et de faire une prédiction correcte ici", "metrics": {"bleu_score": 43.35075973696331, "chrf_score": 71.75975921516779, "xcomet_score": 0.9491387605667114, "xcomet_qe_score": 0.9756304025650024, "metricx_score": 0.9859954118728638, "metricx_qe_score": 1.383537769317627, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Il est donc bon d'avoir un raisonnement multi-étapes interprétable comme résultat.", "metrics": {"bleu_score": 12.12428055266944, "chrf_score": 66.848370582207, "xcomet_score": 0.9998177289962769, "xcomet_qe_score": 1.0, "metricx_score": 1.3215548992156982, "metricx_qe_score": 1.875845193862915, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pensons également que le problème de méthode est une application directe pour évaluer de telles capacités de raisonnement.", "metrics": {"bleu_score": 63.67075680957933, "chrf_score": 79.67952366575398, "xcomet_score": 0.7422282099723816, "xcomet_qe_score": 0.6918374300003052, "metricx_score": 8.228606224060059, "metricx_qe_score": 6.7190046310424805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans notre problème, étant donné les questions, nous devons résoudre cette question et obtenir les réponses numériques.", "metrics": {"bleu_score": 57.96664416079147, "chrf_score": 74.56068073714678, "xcomet_score": 0.9393302202224731, "xcomet_qe_score": 0.9301223158836365, "metricx_score": 2.306046962738037, "metricx_qe_score": 2.4982619285583496, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos ensembles de données, on nous donne également l'expression mathématique, qui conduit également à cette réponse particulière.", "metrics": {"bleu_score": 31.751444361869975, "chrf_score": 75.49820948131821, "xcomet_score": 0.9657988548278809, "xcomet_qe_score": 0.9708861112594604, "metricx_score": 3.332369565963745, "metricx_qe_score": 3.735417127609253, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, certaines hypothèses s'appliquent également comme dans les travaux précédents.", "metrics": {"bleu_score": 72.92571723872932, "chrf_score": 81.74616035973521, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.85512375831604, "metricx_qe_score": 2.617657423019409, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "nous supposons que la précision des quantités est connue", "metrics": {"bleu_score": 77.25505949016376, "chrf_score": 96.10701894445121, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.9910596013069153, "metricx_qe_score": 1.4724169969558716, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous ne considérons que les opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentiation.", "metrics": {"bleu_score": 92.10589320522861, "chrf_score": 95.68299687983432, "xcomet_score": 0.969541072845459, "xcomet_qe_score": 0.9754696488380432, "metricx_score": 1.1877816915512085, "metricx_qe_score": 0.6469014883041382, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les opérateurs complexes peuvent en réalité être décomposés en ces opérateurs de base.", "metrics": {"bleu_score": 50.7196093945688, "chrf_score": 69.8708284380725, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5208061337471008, "metricx_qe_score": 0.4972343444824219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, les travaux antérieurs sur la résolution de problèmes méthodologiques peuvent en fait être classés en deux catégories : les modèles séquence-à-séquence et séquence-à-arbre.", "metrics": {"bleu_score": 10.888009381443315, "chrf_score": 60.40670099285029, "xcomet_score": 0.7883093357086182, "xcomet_qe_score": 0.7982602715492249, "metricx_score": 5.756209373474121, "metricx_qe_score": 5.988705158233643, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le modèle séquence-à-séquence traditionnel convertit l'expression en une séquence spécifique pour la génération.", "metrics": {"bleu_score": 53.32786524937508, "chrf_score": 88.4981281048073, "xcomet_score": 0.8008545637130737, "xcomet_qe_score": 0.8248609900474548, "metricx_score": 1.6161398887634277, "metricx_qe_score": 1.9006930589675903, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est assez facile à mettre en œuvre, et cela peut s'appliquer à de nombreux problèmes complexes différents.", "metrics": {"bleu_score": 40.1577332834242, "chrf_score": 70.515203013879, "xcomet_score": 0.8672163486480713, "xcomet_qe_score": 0.9492133259773254, "metricx_score": 0.9844542741775513, "metricx_qe_score": 1.1875696182250977, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les inconvénients de la performance ne sont généralement pas meilleurs que ceux du modèle structuré. Et c'est le manque d'interprétabilité pour la prédiction.", "metrics": {"bleu_score": 10.754672770161264, "chrf_score": 72.36921583762937, "xcomet_score": 0.7440571784973145, "xcomet_qe_score": 0.8254727125167847, "metricx_score": 9.017582893371582, "metricx_qe_score": 8.617385864257812, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en réalité, cette direction reste assez populaire à cause du modèle transformateur.", "metrics": {"bleu_score": 33.696998602966666, "chrf_score": 56.56064715763331, "xcomet_score": 0.8718991279602051, "xcomet_qe_score": 0.8699468970298767, "metricx_score": 4.700998306274414, "metricx_qe_score": 3.4472012519836426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans les modèles basés sur les arbres, nous structurons ces expressions sous forme d'arbre et suivons un parcours pré-ordre dans les générations d'arbres.", "metrics": {"bleu_score": 46.03909996443368, "chrf_score": 69.21813535775986, "xcomet_score": 0.8616049885749817, "xcomet_qe_score": 0.8654000163078308, "metricx_score": 4.377847194671631, "metricx_qe_score": 4.469575881958008, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous continuons à générer les opérateurs jusqu'à ce que nous atteignions les feuilles, qui sont les quantités.", "metrics": {"bleu_score": 77.59071335214406, "chrf_score": 85.02836172066701, "xcomet_score": 0.8039419651031494, "xcomet_qe_score": 0.7920256853103638, "metricx_score": 2.9332034587860107, "metricx_qe_score": 3.8475592136383057, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, le point positif est qu'il nous donne en fait cette structure d'arbre binaire. Mais en réalité, c'est assez contre-intuitif parce que nous générons d'abord l'opérateur, puis à la fin nous générons les quantités.", "metrics": {"bleu_score": 56.33309764933518, "chrf_score": 78.83525265508864, "xcomet_score": 0.9580745697021484, "xcomet_qe_score": 0.958815336227417, "metricx_score": 2.922244071960449, "metricx_qe_score": 3.8940162658691406, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose, c'est qu'il contient aussi des calculs répétitifs.", "metrics": {"bleu_score": 39.832871551569504, "chrf_score": 66.75788060680503, "xcomet_score": 0.9301498532295227, "xcomet_qe_score": 0.9874109029769897, "metricx_score": 1.8331148624420166, "metricx_qe_score": 1.3039352893829346, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ici, si nous regardons cette expression, 8 fois 3 plus 3 est en fait générée deux fois. Mais en fait, nous devrions réutiliser les résultats.", "metrics": {"bleu_score": 51.48030774310147, "chrf_score": 73.19873525898197, "xcomet_score": 0.9719972610473633, "xcomet_qe_score": 0.9751424193382263, "metricx_score": 1.3682526350021362, "metricx_qe_score": 1.5748720169067383, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre approche proposée, nous voulons résoudre ces problèmes de manière progressive et interprétable.", "metrics": {"bleu_score": 64.5536177559541, "chrf_score": 81.61876085762648, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9764289855957031, "metricx_qe_score": 0.82675701379776, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, par exemple, ici, à l'étape suivante, nous pouvons obtenir ce diviseur, qui est 27.", "metrics": {"bleu_score": 17.509131039045965, "chrf_score": 53.95660797318572, "xcomet_score": 0.8521658182144165, "xcomet_qe_score": 0.8021247386932373, "metricx_score": 2.926027536392212, "metricx_qe_score": 3.715317726135254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "nous pouvons également nous référer aux questions initiales pour trouver les contenus pertinents.", "metrics": {"bleu_score": 45.74563333993254, "chrf_score": 81.0415741595122, "xcomet_score": 0.9855179786682129, "xcomet_qe_score": 0.9902883172035217, "metricx_score": 0.7559148669242859, "metricx_qe_score": 0.722252607345581, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous obtenons les diviseurs.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9926035404205322, "xcomet_qe_score": 0.9813810586929321, "metricx_score": 2.1472244262695312, "metricx_qe_score": 2.927687406539917, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, à cette troisième étape, nous obtenons en fait le quotient.", "metrics": {"bleu_score": 61.62607099729587, "chrf_score": 77.85706986273857, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 3.076632022857666, "metricx_qe_score": 3.3022449016571045, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "Très bien, et après ces trois étapes, nous pouvons effectivement utiliser les résultats de la deuxième étape, puis obtenir les résultats de la quatrième étape. Et enfin, nous pouvons obtenir les dividendes.", "metrics": {"bleu_score": 74.45169791314018, "chrf_score": 89.20438103438188, "xcomet_score": 0.9732629060745239, "xcomet_qe_score": 0.9304863214492798, "metricx_score": 2.2987194061279297, "metricx_qe_score": 3.135930061340332, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, nous générons directement l'expression entière plutôt que de générer un seul opérateur ou une seule quantité.", "metrics": {"bleu_score": 51.92815178749843, "chrf_score": 74.30887290744747, "xcomet_score": 0.9802219867706299, "xcomet_qe_score": 0.9803208708763123, "metricx_score": 1.214451551437378, "metricx_qe_score": 1.4564714431762695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "Cela rend donc le processus plus précis.", "metrics": {"bleu_score": 59.4603557501361, "chrf_score": 87.93094020593963, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6577164530754089, "metricx_qe_score": 1.3236981630325317, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre système déductif, nous commençons d'abord avec un ensemble de quantités présentées dans les questions, et incluant également certaines constantes comme notre état initial.", "metrics": {"bleu_score": 61.809829588356614, "chrf_score": 85.43771527099457, "xcomet_score": 0.969727635383606, "xcomet_qe_score": 0.9455512762069702, "metricx_score": 2.7911558151245117, "metricx_qe_score": 4.237696647644043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "L'expression est donc représentée par EIJOP.", "metrics": {"bleu_score": 7.64649370538093, "chrf_score": 61.31749886839668, "xcomet_score": 0.9785304069519043, "xcomet_qe_score": 0.9675105810165405, "metricx_score": 1.1124985218048096, "metricx_qe_score": 1.9465159177780151, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "où nous effectuons l'opérateur de QI à QJ, et une telle expression est en fait dirigée.", "metrics": {"bleu_score": 37.43119524761466, "chrf_score": 76.75301642946071, "xcomet_score": 0.883467435836792, "xcomet_qe_score": 0.8833141922950745, "metricx_score": 5.237339019775391, "metricx_qe_score": 7.921926975250244, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc également ici une soustraction inverse pour représenter la direction opposée.", "metrics": {"bleu_score": 33.58216499387018, "chrf_score": 71.18403290670558, "xcomet_score": 0.9514408111572266, "xcomet_qe_score": 0.9520546197891235, "metricx_score": 2.4266481399536133, "metricx_qe_score": 3.5052285194396973, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "Cela ressemble beaucoup à l'extraction de relations.", "metrics": {"bleu_score": 17.20339087300932, "chrf_score": 52.28058352587631, "xcomet_score": 0.9975495338439941, "xcomet_qe_score": 0.9840716123580933, "metricx_score": 1.1622432470321655, "metricx_qe_score": 2.826047420501709, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans un système déductif formel, à l'instant t, nous appliquons l'opérateur entre la paire qi et qj, et nous obtenons alors ces nouvelles expressions.", "metrics": {"bleu_score": 27.983469084065106, "chrf_score": 60.65642637723025, "xcomet_score": 0.9600625038146973, "xcomet_qe_score": 0.977623462677002, "metricx_score": 1.6010289192199707, "metricx_qe_score": 1.8937472105026245, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "nous l'ajoutons à l'état suivant pour qu'elle devienne une nouvelle quantité.", "metrics": {"bleu_score": 53.107253497886994, "chrf_score": 81.84298885354299, "xcomet_score": 0.963492751121521, "xcomet_qe_score": 0.9482529759407043, "metricx_score": 1.6492443084716797, "metricx_qe_score": 2.6319806575775146, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, cette diapositive illustre en fait l'évolution de l'état où nous continuons d'ajouter une expression à l'état actuel.", "metrics": {"bleu_score": 37.49801651358116, "chrf_score": 69.87152605843457, "xcomet_score": 0.8421608209609985, "xcomet_qe_score": 0.7475004196166992, "metricx_score": 3.530120611190796, "metricx_qe_score": 4.79678201675415, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos implémentations de modèles, nous utilisons d'abord un modèle linguistique pré-entraîné, qui peut être Brits ou Robertas, puis nous codons une phrase, et ensuite nous obtenons ces représentations de quantités.", "metrics": {"bleu_score": 32.390651721334386, "chrf_score": 71.10720648287814, "xcomet_score": 0.6632482409477234, "xcomet_qe_score": 0.6909009218215942, "metricx_score": 7.604870796203613, "metricx_qe_score": 7.169671058654785, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, une fois que nous avons les représentations quantitatives, nous pouvons commencer à faire des inférences.", "metrics": {"bleu_score": 47.9071425065913, "chrf_score": 73.29209051544434, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.6489012241363525, "metricx_qe_score": 1.7596518993377686, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de Q1 pour obtenir la représentation de Q1 divisée par Q2, puis multipliée par Q4.", "metrics": {"bleu_score": 14.462923420152972, "chrf_score": 63.44822511011372, "xcomet_score": 0.6768770217895508, "xcomet_qe_score": 0.8393592834472656, "metricx_score": 14.350646018981934, "metricx_qe_score": 12.021917343139648, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous obtenons la représentation de la paire, qui est essentiellement la concaténation entre Q1 et Q2. Ensuite, nous appliquons un réseau de type feedforward, qui est paramétré par l'opérateur.", "metrics": {"bleu_score": 42.08534593816981, "chrf_score": 70.34972721100758, "xcomet_score": 0.8639204502105713, "xcomet_qe_score": 0.8390370607376099, "metricx_score": 4.401483058929443, "metricx_qe_score": 4.004823207855225, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, nous obtenons l'expression de représentation Q1 divisé par Q2", "metrics": {"bleu_score": 22.272147118804728, "chrf_score": 73.14891837625005, "xcomet_score": 0.8768660426139832, "xcomet_qe_score": 0.9261417388916016, "metricx_score": 4.595692157745361, "metricx_qe_score": 3.942389965057373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en fait, en pratique, à l'étape de l'inférence, nous pourrions également obtenir l'expression incorrecte.", "metrics": {"bleu_score": 36.51625019670311, "chrf_score": 72.83935184733848, "xcomet_score": 0.9874356985092163, "xcomet_qe_score": 0.998699426651001, "metricx_score": 1.531229853630066, "metricx_qe_score": 2.0957045555114746, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, toute expression possible est égale à 3 fois le nombre d'opérateurs.", "metrics": {"bleu_score": 45.93073632354733, "chrf_score": 78.43967690899628, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0420069694519043, "metricx_qe_score": 1.7638729810714722, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, le point positif ici, c'est que nous pouvons facilement ajouter des contraintes pour contrôler cet espace de recherche.", "metrics": {"bleu_score": 73.20755362899838, "chrf_score": 84.01397711139839, "xcomet_score": 0.9603631496429443, "xcomet_qe_score": 0.9588572978973389, "metricx_score": 1.2446006536483765, "metricx_qe_score": 1.389100193977356, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement la supprimer de notre espace de recherche", "metrics": {"bleu_score": 68.68616146336804, "chrf_score": 80.97255377096391, "xcomet_score": 0.9927541017532349, "xcomet_qe_score": 0.9726138114929199, "metricx_score": 0.34851160645484924, "metricx_qe_score": 0.5428516864776611, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans la deuxième étape, nous faisons la même chose, mais la seule différence est une quantité supplémentaire.", "metrics": {"bleu_score": 70.68979696284055, "chrf_score": 80.97233963561735, "xcomet_score": 0.9675962924957275, "xcomet_qe_score": 0.9521546363830566, "metricx_score": 3.447427988052368, "metricx_qe_score": 4.780954360961914, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "Cette quantité provient de l'expression calculée précédente.", "metrics": {"bleu_score": 31.708476589333063, "chrf_score": 74.09650727541442, "xcomet_score": 0.9993386268615723, "xcomet_qe_score": 0.995700478553772, "metricx_score": 0.5797427892684937, "metricx_qe_score": 0.8377796411514282, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc finalement obtenir cette expression finale Q", "metrics": {"bleu_score": 12.974640326799936, "chrf_score": 61.51229634224994, "xcomet_score": 0.2799620032310486, "xcomet_qe_score": 0.6595611572265625, "metricx_score": 11.693547248840332, "metricx_qe_score": 6.214522838592529, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "fois Q4. Et nous pouvons également voir que le nombre de toutes les expressions possibles est différent de l'étape précédente.", "metrics": {"bleu_score": 76.6119563549595, "chrf_score": 89.10529275743869, "xcomet_score": 0.45795848965644836, "xcomet_qe_score": 0.30718815326690674, "metricx_score": 7.176429271697998, "metricx_qe_score": 11.071443557739258, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, cette différence rend difficile l'application de la recherche par balayage (beam search) car la distribution de probabilité entre ces deux étapes est déséquilibrée.", "metrics": {"bleu_score": 60.65859249958907, "chrf_score": 86.65648483743163, "xcomet_score": 0.9769316911697388, "xcomet_qe_score": 0.9754986763000488, "metricx_score": 2.2770206928253174, "metricx_qe_score": 2.721470594406128, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "La procédure d'entraînement est donc similaire à celle d'un modèle de séquence à séquence, où nous optimisons la perte à chaque étape temporelle.", "metrics": {"bleu_score": 41.334350113087844, "chrf_score": 68.50660946711675, "xcomet_score": 0.6277204751968384, "xcomet_qe_score": 0.7036218643188477, "metricx_score": 3.2309412956237793, "metricx_qe_score": 3.774818181991577, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également cette tau pour indiquer quand nous devons mettre fin à ce processus de génération.", "metrics": {"bleu_score": 53.85057399615972, "chrf_score": 74.1345796873535, "xcomet_score": 0.9718739986419678, "xcomet_qe_score": 0.9985607862472534, "metricx_score": 3.3744559288024902, "metricx_qe_score": 4.067068099975586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent d'une séquence à l'autre car l'espace est différent à chaque étape temporelle, alors que dans le modèle traditionnel de séquence à séquence, c'est le nombre de vocabulaire.", "metrics": {"bleu_score": 56.63554366423205, "chrf_score": 79.46724994244126, "xcomet_score": 0.6686422824859619, "xcomet_qe_score": 0.6729731559753418, "metricx_score": 4.864861965179443, "metricx_qe_score": 5.99294900894165, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela nous permet également d'imposer certaines contraintes issues de connaissances antérieures.", "metrics": {"bleu_score": 70.4805090506219, "chrf_score": 89.24264286254328, "xcomet_score": 0.9486253261566162, "xcomet_qe_score": 0.8975114822387695, "metricx_score": 1.1430037021636963, "metricx_qe_score": 1.2097399234771729, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Nous menons donc des expériences sur les ensembles de données de problèmes de méthodes couramment utilisés MAWPS, MAT23K, MATQA et SWAMP", "metrics": {"bleu_score": 38.575777329142426, "chrf_score": 66.98741021844152, "xcomet_score": 0.6012726426124573, "xcomet_qe_score": 0.6093477010726929, "metricx_score": 6.636857032775879, "metricx_qe_score": 6.1628217697143555, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons brièvement les résultats par rapport aux approches des lots précédents.", "metrics": {"bleu_score": 47.95482798967691, "chrf_score": 62.32917019750326, "xcomet_score": 0.8272450566291809, "xcomet_qe_score": 0.8047063946723938, "metricx_score": 5.051733016967773, "metricx_qe_score": 6.060276031494141, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre variante la mieux performante est Robeta Dictative Reasoner.", "metrics": {"bleu_score": 26.20251007173262, "chrf_score": 67.8014764092542, "xcomet_score": 0.805438756942749, "xcomet_qe_score": 0.7981991767883301, "metricx_score": 5.967029571533203, "metricx_qe_score": 6.156699180603027, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "et en fait nous n'utilisons pas la recherche par faisceau contrairement aux approches évidentes qui utilisent la recherche par faisceau", "metrics": {"bleu_score": 13.18331306548015, "chrf_score": 47.751795473389535, "xcomet_score": 0.7374838590621948, "xcomet_qe_score": 0.714191198348999, "metricx_score": 4.826220512390137, "metricx_qe_score": 3.903130292892456, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, donc les meilleures approches sont souvent basées sur des modèles arborescents", "metrics": {"bleu_score": 24.029210317584685, "chrf_score": 56.47968474280333, "xcomet_score": 0.9913206100463867, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.8111321330070496, "metricx_qe_score": 0.613896906375885, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans l'ensemble, notre raisonneur est capable de surpasser de manière significative ce modèle basé sur l'arbre", "metrics": {"bleu_score": 45.98036015897533, "chrf_score": 71.27449727077133, "xcomet_score": 0.9694243669509888, "xcomet_qe_score": 0.891047477722168, "metricx_score": 4.175450325012207, "metricx_qe_score": 5.893506050109863, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons voir que le nombre absolu sur Mathqa ou SWAM n'est pas vraiment élevé.", "metrics": {"bleu_score": 25.38262477544204, "chrf_score": 66.98652936725638, "xcomet_score": 0.85767662525177, "xcomet_qe_score": 0.8622965812683105, "metricx_score": 3.0132558345794678, "metricx_qe_score": 2.940251350402832, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Nous examinons donc plus en détail les résultats sur", "metrics": {"bleu_score": 60.10525952194528, "chrf_score": 73.08247819261635, "xcomet_score": 0.32891860604286194, "xcomet_qe_score": 0.3630223274230957, "metricx_score": 6.099941253662109, "metricx_qe_score": 4.170998573303223, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "Et cet ensemble de données est difficile à traiter car l'auteur a essayé d'ajouter manuellement quelque chose pour confondre le modèle de traitement du langage naturel, comme l'ajout d'informations non pertinentes et de quantités supplémentaires", "metrics": {"bleu_score": 38.281116099287054, "chrf_score": 76.02035740696927, "xcomet_score": 0.9531809091567993, "xcomet_qe_score": 0.9412516355514526, "metricx_score": 1.9539436101913452, "metricx_qe_score": 1.4563117027282715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre prédiction, nous trouvons que certaines des valeurs intermédiaires sont en fait négatives.", "metrics": {"bleu_score": 62.685933350049744, "chrf_score": 80.99528599265699, "xcomet_score": 0.9873621463775635, "xcomet_qe_score": 1.0, "metricx_score": 1.301595687866211, "metricx_qe_score": 0.8621784448623657, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans ces questions, nous demandons combien de pommes Drake a ?", "metrics": {"bleu_score": 58.89798187818744, "chrf_score": 85.21324799129005, "xcomet_score": 0.6840114593505859, "xcomet_qe_score": 0.7154157161712646, "metricx_score": 5.585871696472168, "metricx_qe_score": 6.301672458648682, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons des informations supplémentaires, comme 17 moins de terrains de camping, et Steven a 8 terrains de camping, ce qui est totalement sans rapport", "metrics": {"bleu_score": 31.750930269397234, "chrf_score": 59.64441111662253, "xcomet_score": 0.46385329961776733, "xcomet_qe_score": 0.6386992931365967, "metricx_score": 13.531787872314453, "metricx_qe_score": 13.87809944152832, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait une prédiction de ce genre, qui produit des valeurs négatives.", "metrics": {"bleu_score": 43.85068972747104, "chrf_score": 64.59760006048438, "xcomet_score": 0.9773280620574951, "xcomet_qe_score": 0.9947031736373901, "metricx_score": 2.7790186405181885, "metricx_qe_score": 2.903749465942383, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "et nous observons ces deux expressions", "metrics": {"bleu_score": 8.558153335723478, "chrf_score": 33.74871853387019, "xcomet_score": 0.1677292436361313, "xcomet_qe_score": 0.22412756085395813, "metricx_score": 18.77903175354004, "metricx_qe_score": 18.574827194213867, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc limiter cet espace de recherche en supprimant les résultats négatifs afin de rendre la réponse correcte.", "metrics": {"bleu_score": 65.74012849085679, "chrf_score": 80.26181076311887, "xcomet_score": 0.90229332447052, "xcomet_qe_score": 0.7914157509803772, "metricx_score": 2.892577886581421, "metricx_qe_score": 3.3907418251037598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous constatons que cette contrainte améliore en réalité considérablement certains modèles.", "metrics": {"bleu_score": 44.534504264163466, "chrf_score": 64.23642263344215, "xcomet_score": 0.9910334348678589, "xcomet_qe_score": 0.9889209270477295, "metricx_score": 1.375691294670105, "metricx_qe_score": 1.698866605758667, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, pour les oiseaux, nous avons amélioré sept points. Et puis pour le modèle basé sur Robeta, nous avons en fait amélioré deux points.", "metrics": {"bleu_score": 35.40953426762724, "chrf_score": 52.73796438144894, "xcomet_score": 0.41219091415405273, "xcomet_qe_score": 0.4332660436630249, "metricx_score": 12.26500129699707, "metricx_qe_score": 10.617559432983398, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, un meilleur modèle linguistique a une meilleure capacité de compréhension du langage, de sorte que le nombre ici est plus élevé pour Robita et plus faible pour Bird.", "metrics": {"bleu_score": 28.023415713591874, "chrf_score": 49.33155440845747, "xcomet_score": 0.5263893604278564, "xcomet_qe_score": 0.6122933626174927, "metricx_score": 14.30655288696289, "metricx_qe_score": 8.485143661499023, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous essayons également d'analyser la difficulté qui se cache derrière cela", "metrics": {"bleu_score": 53.3167536340577, "chrf_score": 73.34980872261961, "xcomet_score": 0.7943838834762573, "xcomet_qe_score": 0.687947690486908, "metricx_score": 2.469646692276001, "metricx_qe_score": 5.699763298034668, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que le nombre de quantités non utilisées peut être considéré comme une information non pertinente ici.", "metrics": {"bleu_score": 58.66204912938539, "chrf_score": 90.56915947168946, "xcomet_score": 0.9996166229248047, "xcomet_qe_score": 0.9799081087112427, "metricx_score": 1.7777221202850342, "metricx_qe_score": 1.9587219953536987, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous pouvons voir ici que nous avons le pourcentage d'échantillons avec des quantités non utilisées, et le jeu de données SWAMP a la plus grande proportion.", "metrics": {"bleu_score": 42.05823861049631, "chrf_score": 78.31978213550352, "xcomet_score": 0.9184011220932007, "xcomet_qe_score": 0.9131766557693481, "metricx_score": 3.742849588394165, "metricx_qe_score": 4.41966438293457, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons également la performance globale.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9156627655029297, "metricx_qe_score": 1.2110265493392944, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "pour ces échantillons sans quantités non utilisées. Ainsi, la performance globale est en réalité supérieure à la performance globale.", "metrics": {"bleu_score": 53.66411241731205, "chrf_score": 89.08085754458833, "xcomet_score": 0.4465937614440918, "xcomet_qe_score": 0.32124224305152893, "metricx_score": 7.00049352645874, "metricx_qe_score": 8.39018726348877, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "Mais avec ces échantillons, la quantité non utilisée est en réalité bien pire que la situation déjà bien pire que", "metrics": {"bleu_score": 24.62292439135324, "chrf_score": 55.02462878085491, "xcomet_score": 0.28694427013397217, "xcomet_qe_score": 0.16049671173095703, "metricx_score": 12.935827255249023, "metricx_qe_score": 11.257362365722656, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "performance. Pour MAWPS, nous n'avons pas vraiment beaucoup de cas de disque, donc j'ignore juste cette partie.", "metrics": {"bleu_score": 41.35171000263378, "chrf_score": 63.88442361380372, "xcomet_score": 0.5069491863250732, "xcomet_qe_score": 0.4208553433418274, "metricx_score": 10.443216323852539, "metricx_qe_score": 11.4110107421875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous voulons enfin montrer l'interprétabilité à travers un exemple de crash et de perturbation.", "metrics": {"bleu_score": 32.934059711691795, "chrf_score": 68.91601462783025, "xcomet_score": 0.3596973121166229, "xcomet_qe_score": 0.7302388548851013, "metricx_score": 6.0705485343933105, "metricx_qe_score": 6.956716537475586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait en réalité une prédiction erronée dès la première étape.", "metrics": {"bleu_score": 29.13055375496153, "chrf_score": 66.21728293141985, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.9707198143005371, "metricx_qe_score": 0.7610479593276978, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc réellement établir un lien entre cette expression et la phrase ici.", "metrics": {"bleu_score": 19.022082811568303, "chrf_score": 48.542394780126834, "xcomet_score": 0.9845117330551147, "xcomet_qe_score": 1.0, "metricx_score": 1.3845510482788086, "metricx_qe_score": 1.899268627166748, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons donc que cette phrase pourrait induire le modèle en erreur et conduire à une prédiction incorrecte.", "metrics": {"bleu_score": 60.98820960308448, "chrf_score": 77.64040440972902, "xcomet_score": 0.9966170787811279, "xcomet_qe_score": 0.9823441505432129, "metricx_score": 0.770254373550415, "metricx_qe_score": 0.4123237133026123, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ici, imprimer un autre 35 fait penser au modèle qu'il devrait s'agir d'un opérateur d'addition.", "metrics": {"bleu_score": 41.15109772030928, "chrf_score": 65.3273889434249, "xcomet_score": 0.5271892547607422, "xcomet_qe_score": 0.3740482032299042, "metricx_score": 7.497614860534668, "metricx_qe_score": 5.25857400894165, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Nous essayons donc de réviser la phrase pour qu'elle ressemble à ceci : le nombre d'arbres de poire est de 55 inférieur à celui des pommiers.", "metrics": {"bleu_score": 25.59231167509251, "chrf_score": 54.814231608555644, "xcomet_score": 0.7517833709716797, "xcomet_qe_score": 0.7931287288665771, "metricx_score": 6.249271392822266, "metricx_qe_score": 6.611273288726807, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Nous procédons donc de manière à transmettre une sémantique plus précise, de sorte que le modèle puisse effectuer la prédiction correcte.", "metrics": {"bleu_score": 25.0737833894674, "chrf_score": 59.284106415388436, "xcomet_score": 0.9756402969360352, "xcomet_qe_score": 0.9686422348022461, "metricx_score": 2.0619587898254395, "metricx_qe_score": 2.2618143558502197, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, cette étude montre comment les prédictions interprétables nous aident à comprendre le comportement du modèle.", "metrics": {"bleu_score": 83.94327083733333, "chrf_score": 94.38448679358433, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.077393651008606, "metricx_qe_score": 0.783183753490448, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure notre travail, notre modèle est en fait assez efficace.", "metrics": {"bleu_score": 57.475393483140245, "chrf_score": 78.83479427187108, "xcomet_score": 0.9972312450408936, "xcomet_qe_score": 0.99419105052948, "metricx_score": 1.520257830619812, "metricx_qe_score": 1.7071630954742432, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous sommes en mesure de fournir une procédure de résolution interprétable.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0080623626708984, "metricx_qe_score": 1.129818081855774, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "et nous pouvons facilement intégrer certaines connaissances antérieures comme contrainte, ce qui peut aider à améliorer les performances", "metrics": {"bleu_score": 14.07008663653591, "chrf_score": 71.36593892190177, "xcomet_score": 0.9601818919181824, "xcomet_qe_score": 0.9397133588790894, "metricx_score": 1.1398793458938599, "metricx_qe_score": 1.4160380363464355, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et la dernière chose est que le mécanisme sous-jacent ne s'applique pas uniquement aux tâches de résolution de problèmes de Mapwork, mais aussi à d'autres tâches qui impliquent un raisonnement en plusieurs étapes.", "metrics": {"bleu_score": 57.85182910790548, "chrf_score": 84.73771201723058, "xcomet_score": 0.7636498212814331, "xcomet_qe_score": 0.7975564002990723, "metricx_score": 2.9019997119903564, "metricx_qe_score": 3.6844706535339355, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons aussi certaines limites", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 59.38480938961529, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.17647391557693481, "metricx_qe_score": 0.21984341740608215, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée.", "metrics": {"bleu_score": 94.57416090031757, "chrf_score": 98.9525445252718, "xcomet_score": 0.9851295948028564, "xcomet_qe_score": 0.9756907820701599, "metricx_score": 1.2383146286010742, "metricx_qe_score": 1.2242019176483154, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est que, comme mentionné, parce que la distribution de probabilité est déséquilibrée à différents instants, il est donc également assez difficile d'appliquer la recherche par faisceau.", "metrics": {"bleu_score": 57.560050923694334, "chrf_score": 74.97499890202474, "xcomet_score": 0.782400369644165, "xcomet_qe_score": 0.9527207612991333, "metricx_score": 2.5296640396118164, "metricx_qe_score": 2.464834451675415, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "Voilà la fin de la conférence, et les questions sont les bienvenues. Merci.", "metrics": {"bleu_score": 47.0979469721022, "chrf_score": 59.241643878041984, "xcomet_score": 0.946290135383606, "xcomet_qe_score": 0.9660265445709229, "metricx_score": 1.193157434463501, "metricx_qe_score": 0.8189818859100342, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je viens de l'Université de Maastricht.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 90.46894018144044, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.377380132675171, "metricx_qe_score": 0.664887011051178, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter mon travail réalisé avec Jerry, qui concerne un nouveau jeu de données pour la récupération d'articles légaux.", "metrics": {"bleu_score": 18.132302350830216, "chrf_score": 52.31138488933287, "xcomet_score": 0.83417147397995, "xcomet_qe_score": 0.6884852647781372, "metricx_score": 3.478181838989258, "metricx_qe_score": 2.3857836723327637, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les problèmes juridiques font partie intégrante de la vie de nombreuses personnes.", "metrics": {"bleu_score": 84.23626743789745, "chrf_score": 86.06115383670415, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6353251934051514, "metricx_qe_score": 0.46970173716545105, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "mais la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et les processus juridiques fondamentaux.", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 91.24584740555369, "xcomet_score": 0.966964602470398, "xcomet_qe_score": 0.9696496725082397, "metricx_score": 0.9958561062812805, "metricx_qe_score": 1.1265379190444946, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "En conséquence, de nombreux citoyens vulnérables qui ne peuvent pas se permettre l'assistance coûteuse d'un expert juridique se retrouvent sans protection ou, pire, exploités.", "metrics": {"bleu_score": 46.00585798331265, "chrf_score": 71.9167407662733, "xcomet_score": 0.9987257719039917, "xcomet_qe_score": 1.0, "metricx_score": 1.2121862173080444, "metricx_qe_score": 1.0803606510162354, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Notre travail vise à combler le fossé entre les gens et la loi en développant des systèmes de recherche efficaces pour les articles de loi.", "metrics": {"bleu_score": 41.229744029518166, "chrf_score": 60.50505990784158, "xcomet_score": 0.9680838584899902, "xcomet_qe_score": 0.9740520715713501, "metricx_score": 1.8112835884094238, "metricx_qe_score": 0.994146466255188, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "un tel système pourrait fournir un service d'aide juridique professionnelle gratuite pour les humains non qualifiés.", "metrics": {"bleu_score": 43.78826865860791, "chrf_score": 80.49225854746356, "xcomet_score": 0.9219261407852173, "xcomet_qe_score": 0.9153454303741455, "metricx_score": 1.4125277996063232, "metricx_qe_score": 1.2823553085327148, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de plonger dans la contribution principale de ce travail, décrivons d'abord le problème de la récupération d'articles statutaires.", "metrics": {"bleu_score": 30.91327937802876, "chrf_score": 64.2390172620644, "xcomet_score": 0.8134631514549255, "xcomet_qe_score": 0.7815635204315186, "metricx_score": 5.66942024230957, "metricx_qe_score": 4.398686408996582, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "Si l'on pose une question simple sur une question mineure, comme : « À quoi m'expose-je si je viole la confidentialité professionnelle ? »", "metrics": {"bleu_score": 36.26305461419686, "chrf_score": 58.47798410844024, "xcomet_score": 0.6989131569862366, "xcomet_qe_score": 0.548084020614624, "metricx_score": 5.970125675201416, "metricx_qe_score": 6.549294471740723, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle est nécessaire pour récupérer tous les articles légaux pertinents à partir d'un vaste ensemble de textes législatifs.", "metrics": {"bleu_score": 26.52951833482444, "chrf_score": 62.163185404422606, "xcomet_score": 0.9857714176177979, "xcomet_qe_score": 1.0, "metricx_score": 1.3628816604614258, "metricx_qe_score": 1.3164023160934448, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche de recherche d'information comporte son propre ensemble de défis.", "metrics": {"bleu_score": 57.067457770559976, "chrf_score": 73.53348574314383, "xcomet_score": 0.9810460805892944, "xcomet_qe_score": 1.0, "metricx_score": 0.9133810997009277, "metricx_qe_score": 0.4641854763031006, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, il traite de deux types de langage.", "metrics": {"bleu_score": 48.326978309062206, "chrf_score": 77.70626446580955, "xcomet_score": 0.7698017358779907, "xcomet_qe_score": 0.9778584241867065, "metricx_score": 2.369997024536133, "metricx_qe_score": 1.0847606658935547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "Un langage naturel courant pour les questions et un langage juridique complexe pour les statuts.", "metrics": {"bleu_score": 31.53554052490134, "chrf_score": 63.27213373253119, "xcomet_score": 0.7938545942306519, "xcomet_qe_score": 0.87550950050354, "metricx_score": 4.313218593597412, "metricx_qe_score": 2.758528709411621, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence dans les distributions linguistiques rend plus difficile pour un système de retrouver des candidats pertinents, car cela nécessite indirectement un système d'interprétation inhérent capable de traduire une question naturelle en une question juridique correspondant à la terminologie des statuts.", "metrics": {"bleu_score": 70.0282633046773, "chrf_score": 87.48548898469988, "xcomet_score": 0.9539227485656738, "xcomet_qe_score": 0.9813951253890991, "metricx_score": 3.8589816093444824, "metricx_qe_score": 3.374617576599121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le droit législatif n'est pas un ensemble d'articles indépendants qui peuvent être traités comme une source d'information complète en soi, contrairement aux actualités ou aux recettes, par exemple.", "metrics": {"bleu_score": 49.440093004527334, "chrf_score": 74.31156246200622, "xcomet_score": 0.9931774139404297, "xcomet_qe_score": 1.0, "metricx_score": 2.8191089630126953, "metricx_qe_score": 2.339019775390625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'agit plutôt d'un ensemble structuré de dispositions légales qui ne prennent tout leur sens que lorsqu'elles sont examinées dans leur contexte global, c'est-à-dire en tenant compte des informations complémentaires fournies par les articles voisins, des domaines et sous-domaines auxquels elles appartiennent, et de leur place dans la structure de la loi.", "metrics": {"bleu_score": 39.163018660826125, "chrf_score": 74.77226937182182, "xcomet_score": 0.9950075149536133, "xcomet_qe_score": 0.9998384714126587, "metricx_score": 0.6045260429382324, "metricx_qe_score": 0.7240393161773682, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, les articles légaux ne sont pas de petits paragraphes, qui sont généralement l'unité de récupération typique dans la plupart des travaux de récupération.", "metrics": {"bleu_score": 46.445316553607185, "chrf_score": 72.50593093111002, "xcomet_score": 0.5862963199615479, "xcomet_qe_score": 0.48276540637016296, "metricx_score": 6.346551895141602, "metricx_qe_score": 6.118258953094482, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, il y a de longs documents qui peuvent atteindre six pages", "metrics": {"bleu_score": 59.85558517362037, "chrf_score": 62.66432604571987, "xcomet_score": 0.832196831703186, "xcomet_qe_score": 0.9050927758216858, "metricx_score": 6.791609287261963, "metricx_qe_score": 7.198525428771973, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les récentes avancées en NLP ont suscité un grand intérêt pour de nombreuses tâches juridiques telles que la prédiction des jugements juridiques ou l'examen automatisé des contrats.", "metrics": {"bleu_score": 20.696205960568722, "chrf_score": 55.23751724725858, "xcomet_score": 0.8408776521682739, "xcomet_qe_score": 0.9697285890579224, "metricx_score": 2.2763099670410156, "metricx_qe_score": 2.0925209522247314, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la récupération d'articles statutaires est restée principalement intacte en raison du manque de grands ensembles de données d'étiquettes de haute qualité.", "metrics": {"bleu_score": 29.81792160679168, "chrf_score": 60.61757170748766, "xcomet_score": 0.6305027008056641, "xcomet_qe_score": 0.7519453167915344, "metricx_score": 7.122098922729492, "metricx_qe_score": 5.891180038452148, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette étude, nous présentons un nouveau jeu de données centré sur le citoyen, en langue française, afin d'étudier si un modèle de recherche peut se rapprocher de l'efficacité et de la fiabilité d'un expert juridique pour la tâche de recherche d'articles légaux.", "metrics": {"bleu_score": 38.15448012315994, "chrf_score": 65.5637171116946, "xcomet_score": 0.6432120203971863, "xcomet_qe_score": 0.6041406393051147, "metricx_score": 5.020649433135986, "metricx_qe_score": 3.205761432647705, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "Notre ensemble de données de recherche d'articles légaux belges, PSART, comprend plus de 1 100 articles juridiques", "metrics": {"bleu_score": 4.256623508027625, "chrf_score": 34.24812837912228, "xcomet_score": 0.30277860164642334, "xcomet_qe_score": 0.45853039622306824, "metricx_score": 7.360593318939209, "metricx_qe_score": 6.841599941253662, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "Ces questions couvrent un large éventail de sujets, allant de la famille, au logement, à l'argent, au travail et à la sécurité sociale.", "metrics": {"bleu_score": 67.13783850074476, "chrf_score": 84.40550138901145, "xcomet_score": 0.9989352226257324, "xcomet_qe_score": 1.0, "metricx_score": 1.2284950017929077, "metricx_qe_score": 0.4286993145942688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun d’eux a été étiqueté par des juristes expérimentés avec des références aux articles pertinents d’un corpus de plus de 22 600.", "metrics": {"bleu_score": 25.576385526731638, "chrf_score": 53.308084148635935, "xcomet_score": 0.2523057758808136, "xcomet_qe_score": 0.5103423595428467, "metricx_score": 6.202849864959717, "metricx_qe_score": 6.210411548614502, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Codes de droit belges. Parlons maintenant de la manière dont nous avons collecté ces ensembles de données.", "metrics": {"bleu_score": 34.51395513935864, "chrf_score": 74.64129449864147, "xcomet_score": 0.19371137022972107, "xcomet_qe_score": 0.17632406949996948, "metricx_score": 15.083236694335938, "metricx_qe_score": 17.663244247436523, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons commencé par constituer un vaste corpus d'articles juridiques.", "metrics": {"bleu_score": 26.70976496992394, "chrf_score": 65.29244897930707, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.1222872734069824, "metricx_qe_score": 0.7819873690605164, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons examiné 32 codes belges accessibles au public et extrait tous leurs articles ainsi que les titres de sections correspondants.", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 85.72563458801761, "xcomet_score": 0.9852142333984375, "xcomet_qe_score": 0.9972126483917236, "metricx_score": 2.4425292015075684, "metricx_qe_score": 2.6867780685424805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous avons rassemblé des questions juridiques avec des références aux lois pertinentes.", "metrics": {"bleu_score": 57.73502691896262, "chrf_score": 91.31938011871401, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.070390224456787, "metricx_qe_score": 1.3487091064453125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous collaborons avec un cabinet d'avocats belge qui reçoit chaque année environ 4 000 courriels de citoyens belges qui demandent des conseils sur une question juridique personnelle.", "metrics": {"bleu_score": 60.55223296065568, "chrf_score": 80.71378379093886, "xcomet_score": 0.9965945482254028, "xcomet_qe_score": 0.9991436004638672, "metricx_score": 0.6075301766395569, "metricx_qe_score": 0.5469942688941956, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance d'accéder à leurs sites web, où leur équipe de juristes expérimentés aborde les problèmes juridiques les plus courants en Belgique.", "metrics": {"bleu_score": 61.806599678536905, "chrf_score": 78.712791698755, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.4328558444976807, "metricx_qe_score": 1.8640111684799194, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons recueilli des milliers de questions, annotées avec des catégories, des sous-catégories et des références légales aux lois pertinentes.", "metrics": {"bleu_score": 75.22135016840222, "chrf_score": 89.88889484392803, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6943244338035583, "metricx_qe_score": 1.1060343980789185, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons analysé les références juridiques et filtré les questions dont les références n'étaient pas des articles dans l'un des codes de droit que nous avons examinés.", "metrics": {"bleu_score": 81.8982360578351, "chrf_score": 86.56367777718117, "xcomet_score": 0.9435513019561768, "xcomet_qe_score": 0.9444282054901123, "metricx_score": 2.002016067504883, "metricx_qe_score": 3.023996591567993, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "Les références restantes ont été mises en correspondance et converties en identifiants d'articles correspondants d'Ocorpus.", "metrics": {"bleu_score": 28.78787818101128, "chrf_score": 72.91320210695656, "xcomet_score": 0.8993417620658875, "xcomet_qe_score": 0.8478207588195801, "metricx_score": 3.488462448120117, "metricx_qe_score": 3.1964356899261475, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons finalement obtenu 1108 questions, chacune soigneusement étiquetée avec les identifiants des articles pertinents de", "metrics": {"bleu_score": 25.81958609586441, "chrf_score": 50.887112880857245, "xcomet_score": 0.08760257065296173, "xcomet_qe_score": 0.07515744119882584, "metricx_score": 13.06376838684082, "metricx_qe_score": 8.429040908813477, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, chaque question est accompagnée d'une catégorie principale et d'une concaténation de sous-catégories.", "metrics": {"bleu_score": 50.47325154308107, "chrf_score": 80.4082245966848, "xcomet_score": 0.954633355140686, "xcomet_qe_score": 0.9636931419372559, "metricx_score": 5.552073955535889, "metricx_qe_score": 5.55289888381958, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "et chaque article est accompagné d'une concaténation de leur titre ultérieur dans la structure de la loi.", "metrics": {"bleu_score": 37.15770152515525, "chrf_score": 48.36235163500904, "xcomet_score": 0.52467280626297, "xcomet_qe_score": 0.5493702292442322, "metricx_score": 11.582133293151855, "metricx_qe_score": 11.410711288452148, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Ces informations supplémentaires ne sont pas utilisées dans le cadre du présent travail, mais pourraient présenter un intérêt pour des recherches futures sur la recherche d'informations juridiques ou la classification fiscale juridique.", "metrics": {"bleu_score": 69.11767741252595, "chrf_score": 86.18392417271873, "xcomet_score": 0.7272887229919434, "xcomet_qe_score": 0.7092998027801514, "metricx_score": 6.02813196182251, "metricx_qe_score": 5.9463701248168945, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons certaines caractéristiques de nos ensembles de données.", "metrics": {"bleu_score": 28.422022424918996, "chrf_score": 64.65790434330656, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6294617652893066, "metricx_qe_score": 0.7357365489006042, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions font entre 5 et 44 mots, avec une médiane de 14 mots.", "metrics": {"bleu_score": 9.625807217196785, "chrf_score": 35.91236146515854, "xcomet_score": 0.9334867596626282, "xcomet_qe_score": 0.8723384141921997, "metricx_score": 1.1333669424057007, "metricx_qe_score": 0.4113321900367737, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont beaucoup plus longs, avec une longueur médiane de 77 mots, avec 142", "metrics": {"bleu_score": 29.029556598856026, "chrf_score": 44.689777998416005, "xcomet_score": 0.12871776521205902, "xcomet_qe_score": 0.3396320343017578, "metricx_score": 12.37292194366455, "metricx_qe_score": 12.80408763885498, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "excédant 1000.", "metrics": {"bleu_score": 0.0, "chrf_score": 3.979731122963449, "xcomet_score": 0.14493092894554138, "xcomet_qe_score": 0.14606595039367676, "metricx_score": 23.010377883911133, "metricx_qe_score": 23.953319549560547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "Comme mentionné précédemment, les questions couvrent un large éventail de sujets, environ 85 % d'entre elles portant sur la famille, le logement, l'argent ou la justice.", "metrics": {"bleu_score": 58.90151271587919, "chrf_score": 68.56856283449522, "xcomet_score": 0.9654093980789185, "xcomet_qe_score": 0.9935692548751831, "metricx_score": 1.0198006629943848, "metricx_qe_score": 0.7834170460700989, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que les 15 % restants concernent soit la sécurité sociale, les étrangers ou le travail.", "metrics": {"bleu_score": 58.53882755435387, "chrf_score": 74.91281311315399, "xcomet_score": 0.9629040956497192, "xcomet_qe_score": 0.9605318903923035, "metricx_score": 1.364593267440796, "metricx_qe_score": 1.333687424659729, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très divers car ils proviennent de 32 codes belges différents qui couvrent un grand nombre de sujets juridiques.", "metrics": {"bleu_score": 53.39935148604844, "chrf_score": 77.24096766464558, "xcomet_score": 0.9098352193832397, "xcomet_qe_score": 0.9818813800811768, "metricx_score": 1.1662499904632568, "metricx_qe_score": 0.8779904246330261, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles recueillis pour chacun de ces codes belges.", "metrics": {"bleu_score": 57.475393483140245, "chrf_score": 73.11152168808387, "xcomet_score": 0.9977279901504517, "xcomet_qe_score": 1.0, "metricx_score": 1.3700995445251465, "metricx_qe_score": 2.39261531829834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Sur les 22 633 articles, seuls 1 612 sont considérés comme pertinents pour au moins", "metrics": {"bleu_score": 7.777443922955584, "chrf_score": 32.65303091977474, "xcomet_score": 0.3796849548816681, "xcomet_qe_score": 0.3178598880767822, "metricx_score": 8.998380661010742, "metricx_qe_score": 4.642595291137695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "une question dans les ensembles de données. Et environ 80 % de ces articles cités proviennent soit du code civil, du code judiciaire, du code d'instruction pénale ou des codes pénaux.", "metrics": {"bleu_score": 28.387021048806446, "chrf_score": 59.06970014494195, "xcomet_score": 0.2656557857990265, "xcomet_qe_score": 0.296976774930954, "metricx_score": 11.35582447052002, "metricx_qe_score": 13.408174514770508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "Par ailleurs, 18 des 32 codes comportent moins de 5 articles jugés pertinents pour au moins une question.", "metrics": {"bleu_score": 32.004580793050366, "chrf_score": 48.66992294270185, "xcomet_score": 0.7622448205947876, "xcomet_qe_score": 0.8089028596878052, "metricx_score": 1.2999980449676514, "metricx_qe_score": 1.2391645908355713, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut s'expliquer par le fait que ces codes se concentrent moins sur les individus et leurs préoccupations.", "metrics": {"bleu_score": 75.06935728875011, "chrf_score": 91.17897668052449, "xcomet_score": 0.9976266622543335, "xcomet_qe_score": 1.0, "metricx_score": 2.756505012512207, "metricx_qe_score": 2.941240072250366, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le nombre médian de citations pour ces articles cités est de 2, et moins de 25 % d'entre eux sont", "metrics": {"bleu_score": 44.008930612863544, "chrf_score": 62.78775100349725, "xcomet_score": 0.2923576235771179, "xcomet_qe_score": 0.6427922248840332, "metricx_score": 14.149847030639648, "metricx_qe_score": 13.466174125671387, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant nos ensembles de données, nous évaluons plusieurs approches de récupération, y compris l'architecture lexicale et dense.", "metrics": {"bleu_score": 44.77845944135174, "chrf_score": 71.99726345674952, "xcomet_score": 0.6580978631973267, "xcomet_qe_score": 0.7577692866325378, "metricx_score": 4.341616630554199, "metricx_qe_score": 4.490166664123535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné une requête dans un article, un modèle lexical attribue un score à la paire requête-article en calculant la somme des poids de chacun de ces termes dans cet article.", "metrics": {"bleu_score": 63.18906586119838, "chrf_score": 80.26019254313009, "xcomet_score": 0.9258080124855042, "xcomet_qe_score": 0.9412425756454468, "metricx_score": 4.084524154663086, "metricx_qe_score": 4.412400245666504, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec les fonctions de classement standard TF-IDF et BM25.", "metrics": {"bleu_score": 66.36154805687889, "chrf_score": 90.65201472600005, "xcomet_score": 0.9941763877868652, "xcomet_qe_score": 0.9998935461044312, "metricx_score": 1.1771973371505737, "metricx_qe_score": 2.00666880607605, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème avec ces approches est qu'elles ne peuvent récupérer que les articles contenant des mots-clés présents dans la requête.", "metrics": {"bleu_score": 73.89984311706958, "chrf_score": 87.64492020072457, "xcomet_score": 0.992904782295227, "xcomet_qe_score": 1.0, "metricx_score": 0.8965938091278076, "metricx_qe_score": 0.9452088475227356, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour surmonter cette limitation, nous expérimentons une architecture basée sur les réseaux de neurones qui peut capturer les relations sémantiques entre les requêtes et les articles.", "metrics": {"bleu_score": 60.60655437708259, "chrf_score": 89.02690117056656, "xcomet_score": 0.9894617795944214, "xcomet_qe_score": 0.9636143445968628, "metricx_score": 0.7698409557342529, "metricx_qe_score": 0.8191792964935303, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle b-encoder qui associe des requêtes et des articles à des représentations vectorielles denses et calcule un score de pertinence entre une paire requête-article en fonction de la similarité de leurs intégrations.", "metrics": {"bleu_score": 34.003576652422915, "chrf_score": 71.49035460983427, "xcomet_score": 0.8751605749130249, "xcomet_qe_score": 0.8779702186584473, "metricx_score": 5.139767646789551, "metricx_qe_score": 5.505636692047119, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces intégrations résultent généralement d'une opération de pooling sur la sortie d'un modèle d'intégration de mots.", "metrics": {"bleu_score": 82.82477531331043, "chrf_score": 90.96908691044948, "xcomet_score": 0.8626084327697754, "xcomet_qe_score": 0.7329448461532593, "metricx_score": 3.66196608543396, "metricx_qe_score": 6.458038806915283, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous étudions l'efficacité des b-encodeurs de type Siamese dans un cadre d'évaluation sans apprentissage préalable, ce qui signifie que les modèles d'encodage de bois pré-entraînés sont utilisés tels quels, sans aucun réglage supplémentaire.", "metrics": {"bleu_score": 27.978365375469682, "chrf_score": 55.977194489330174, "xcomet_score": 0.43605920672416687, "xcomet_qe_score": 0.3965393602848053, "metricx_score": 8.513906478881836, "metricx_qe_score": 6.709061622619629, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec un encodeur de texte indépendant du contexte, à savoir Word2Vec et FastText, et des modèles d'intégration contextuels, à savoir Robota et plus spécifiquement Camembert, qui est un modèle Robota français.", "metrics": {"bleu_score": 42.581050851658, "chrf_score": 73.6059039814301, "xcomet_score": 0.8722585439682007, "xcomet_qe_score": 0.8459614515304565, "metricx_score": 4.1509904861450195, "metricx_qe_score": 2.928067684173584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous formons notre propre modèle basé sur Camembert au-delà des codeurs", "metrics": {"bleu_score": 22.45774725976927, "chrf_score": 52.468319639748195, "xcomet_score": 0.5137592554092407, "xcomet_qe_score": 0.5033866167068481, "metricx_score": 14.348140716552734, "metricx_qe_score": 11.942559242248535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "sur tous les ensembles de données. Notez que pour la formation, nous expérimentons avec les deux variantes de l'architecture Bianco.", "metrics": {"bleu_score": 47.79289657345159, "chrf_score": 76.97118482362471, "xcomet_score": 0.1612149327993393, "xcomet_qe_score": 0.13061067461967468, "metricx_score": 15.498441696166992, "metricx_qe_score": 16.685710906982422, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "Siamese, qui utilise un modèle unique d'encodage des mots qui mappe la requête et l'article ensemble dans un espace vectoriel dense partagé. Et Tutowa, qui utilise deux modèles d'encodage des mots indépendants qui encodent la requête et l'article séparément dans différents espaces d'encodage.", "metrics": {"bleu_score": 41.4205992430625, "chrf_score": 64.19758581135869, "xcomet_score": 0.49228766560554504, "xcomet_qe_score": 0.6919701099395752, "metricx_score": 7.389047622680664, "metricx_qe_score": 6.95085334777832, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec le pooling moyen, max et CLS, ainsi que le produit scalaire et le cosinus pour le calcul des similarités.", "metrics": {"bleu_score": 29.30802563796799, "chrf_score": 59.542195599129364, "xcomet_score": 0.6638817191123962, "xcomet_qe_score": 0.6363312005996704, "metricx_score": 6.86091423034668, "metricx_qe_score": 6.502737045288086, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre modèle de base sur l'ensemble de test.", "metrics": {"bleu_score": 17.99653127176589, "chrf_score": 67.51494470904892, "xcomet_score": 0.8246839046478271, "xcomet_qe_score": 0.7405568361282349, "metricx_score": 2.430752754211426, "metricx_qe_score": 2.385406732559204, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "avec les méthodes lexicales ci-dessus, les b-encodeurs siamois évalués en configuration zéro-shot au milieu, et les b-encodeurs affinés ci-dessous.", "metrics": {"bleu_score": 36.28369085501993, "chrf_score": 78.1680022663847, "xcomet_score": 0.43494951725006104, "xcomet_qe_score": 0.4021289050579071, "metricx_score": 7.052150726318359, "metricx_qe_score": 8.632913589477539, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le B-encodeur affiné surpasse de manière significative toutes les autres lignes de basse.", "metrics": {"bleu_score": 43.85068972747104, "chrf_score": 80.05596636929667, "xcomet_score": 0.6932966709136963, "xcomet_qe_score": 0.7138023376464844, "metricx_score": 9.918527603149414, "metricx_qe_score": 8.953042030334473, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle à deux tours est meilleur que sa variante siamoise en termes de rappel à 100, mais il obtient des résultats similaires pour les autres métriques.", "metrics": {"bleu_score": 17.592391261425668, "chrf_score": 43.58304661065002, "xcomet_score": 0.7567705512046814, "xcomet_qe_score": 0.4255092144012451, "metricx_score": 2.9716713428497314, "metricx_qe_score": 4.508361339569092, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que BM25 ait eu de moins bons résultats que Biancoda entraîné, sa performance indique qu'il s'agit toujours d'une référence solide pour la recherche spécifique à un domaine.", "metrics": {"bleu_score": 19.545984328607467, "chrf_score": 52.26060169892538, "xcomet_score": 0.6903380751609802, "xcomet_qe_score": 0.7681156396865845, "metricx_score": 9.218598365783691, "metricx_qe_score": 9.958578109741211, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation à tir zéro de Siamese biancoder, nous constatons que l'utilisation directe des embeddings d'un modèle Camembert pré-entraîné sans optimisation pour la tâche de recherche d'information donne de mauvais résultats, ce qui est cohérent avec les résultats précédents.", "metrics": {"bleu_score": 49.34676814805795, "chrf_score": 70.94126499133083, "xcomet_score": 0.4277144968509674, "xcomet_qe_score": 0.4570629298686981, "metricx_score": 9.227354049682617, "metricx_qe_score": 8.331931114196777, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous avons observé que le biancodeur basé sur Word2Vec surperformait considérablement le modèle basé sur FastText et Bird, suggérant que peut-être les représentations pré-entraînées au niveau des mots sont plus appropriées pour la tâche que les représentations au niveau des caractères ou au niveau des sous-mots lorsqu'elles sont utilisées telles quelles.", "metrics": {"bleu_score": 23.148515819578986, "chrf_score": 54.30270340988913, "xcomet_score": 0.5162918567657471, "xcomet_qe_score": 0.579884946346283, "metricx_score": 8.070087432861328, "metricx_qe_score": 7.275746822357178, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que prometteurs, ces résultats laissent entrevoir de nombreuses possibilités d'amélioration par rapport à un expert juridique qualifié qui peut finalement retrouver tous les articles pertinents à toute question et ainsi obtenir des scores parfaits.", "metrics": {"bleu_score": 58.95772766663462, "chrf_score": 76.59650681710038, "xcomet_score": 0.9966669082641602, "xcomet_qe_score": 1.0, "metricx_score": 1.387215495109558, "metricx_qe_score": 1.686208724975586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Concluons en discutant de deux limites de tous les ensembles de données.", "metrics": {"bleu_score": 52.055103630534376, "chrf_score": 83.27695935099287, "xcomet_score": 0.8470206260681152, "xcomet_qe_score": 0.8627233505249023, "metricx_score": 3.855677604675293, "metricx_qe_score": 3.0442311763763428, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, le corpus de l'article est limité à ceux recueillis à partir des 32 codes belges considérés, ce qui ne couvre pas l'ensemble du droit belge, car les articles des décrets, directives et ordonnances sont absents.", "metrics": {"bleu_score": 66.05941270308047, "chrf_score": 82.62803414945967, "xcomet_score": 0.742518961429596, "xcomet_qe_score": 0.7964967489242554, "metricx_score": 3.701970100402832, "metricx_qe_score": 3.7565767765045166, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Lors de la construction du jeu de données, toutes les références à ces articles non collectés sont ignorées, ce qui fait que certaines questions se retrouvent avec seulement une fraction du nombre initial d'articles pertinents.", "metrics": {"bleu_score": 71.05516791217374, "chrf_score": 88.51767956128744, "xcomet_score": 0.9418079853057861, "xcomet_qe_score": 0.9425033926963806, "metricx_score": 1.7379014492034912, "metricx_qe_score": 1.9648516178131104, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cette perte d'information implique que la réponse contenue dans les articles pertinents restants pourrait être incomplète, bien qu'elle soit toujours tout à fait appropriée.", "metrics": {"bleu_score": 68.87246539984304, "chrf_score": 89.37236228825259, "xcomet_score": 0.9688940644264221, "xcomet_qe_score": 0.9670678377151489, "metricx_score": 2.134427785873413, "metricx_qe_score": 1.8046678304672241, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, il convient de noter que toutes les questions juridiques ne peuvent pas être résolues uniquement avec des statuts.", "metrics": {"bleu_score": 37.62957149383418, "chrf_score": 71.71099646346713, "xcomet_score": 0.9869778156280518, "xcomet_qe_score": 1.0, "metricx_score": 3.968161106109619, "metricx_qe_score": 1.8647587299346924, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question : puis-je agir contre mes locataires s'ils font trop de bruit ?", "metrics": {"bleu_score": 64.1975224568211, "chrf_score": 78.52062856256926, "xcomet_score": 0.9887889623641968, "xcomet_qe_score": 0.9841839075088501, "metricx_score": 2.2228894233703613, "metricx_qe_score": 2.4809632301330566, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "il est possible qu'il n'existe pas de réponse détaillée dans le droit législatif qui quantifie un seuil sonore spécifique à partir duquel un expulsion est autorisée.", "metrics": {"bleu_score": 39.76353643835252, "chrf_score": 70.77661812734665, "xcomet_score": 0.9254900217056274, "xcomet_qe_score": 0.8818117380142212, "metricx_score": 3.9452943801879883, "metricx_qe_score": 4.07199239730835, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, le propriétaire devrait probablement s'appuyer davantage sur la jurisprudence et trouver des précédents similaires à sa situation actuelle.", "metrics": {"bleu_score": 88.43865924896839, "chrf_score": 96.00693419793949, "xcomet_score": 0.9974983930587769, "xcomet_qe_score": 0.9999064207077026, "metricx_score": 0.9097432494163513, "metricx_qe_score": 1.021873950958252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le locataire fait deux soirées par semaine jusqu'à 2 heures du matin", "metrics": {"bleu_score": 18.744150287621725, "chrf_score": 63.206240762001876, "xcomet_score": 0.8990412950515747, "xcomet_qe_score": 0.8446927070617676, "metricx_score": 4.040968418121338, "metricx_qe_score": 2.460139513015747, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, certaines questions sont plus adaptées que d'autres à la tâche de récupération d'articles légaux, et le domaine de celles qui sont moins adaptées reste à déterminer.", "metrics": {"bleu_score": 53.19774228122344, "chrf_score": 77.09045851095246, "xcomet_score": 0.8382522463798523, "xcomet_qe_score": 0.6524969935417175, "metricx_score": 3.9124038219451904, "metricx_qe_score": 4.181876182556152, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que tous ces travaux susciteront un intérêt pour le développement de modèles de récupération d'articles légaux pratiques et fiables.", "metrics": {"bleu_score": 19.857943409196785, "chrf_score": 66.72675501334031, "xcomet_score": 0.7973412275314331, "xcomet_qe_score": 0.7741513848304749, "metricx_score": 4.01465368270874, "metricx_qe_score": 3.569023370742798, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut contribuer à améliorer l'accès à la justice pour tous.", "metrics": {"bleu_score": 76.91605673134588, "chrf_score": 86.50202009453643, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6813316941261292, "metricx_qe_score": 0.8533360958099365, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre article, DATSET&CODE, aux liens suivants. Merci.", "metrics": {"bleu_score": 56.60979188828385, "chrf_score": 69.66113673982726, "xcomet_score": 0.945110023021698, "xcomet_qe_score": 0.9469804167747498, "metricx_score": 7.905106544494629, "metricx_qe_score": 7.841402053833008, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour ! Nous sommes heureux de vous présenter notre travail sur VAUS, une référence indépendante des tâches destinée à tester les modèles de vision et de langage avec des phénomènes linguistiques spécifiques.", "metrics": {"bleu_score": 43.83719254095279, "chrf_score": 79.69193584948215, "xcomet_score": 0.5650749802589417, "xcomet_qe_score": 0.5963598489761353, "metricx_score": 5.389585971832275, "metricx_qe_score": 5.6126508712768555, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Pourquoi avons-nous rencontré des difficultés à établir ce benchmark ?", "metrics": {"bleu_score": 6.225616866546953, "chrf_score": 37.07647700447233, "xcomet_score": 0.22066684067249298, "xcomet_qe_score": 0.47648969292640686, "metricx_score": 15.297365188598633, "metricx_qe_score": 8.449380874633789, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Eh bien, au cours des dernières années, nous avons assisté à une explosion de modèles de vision et de langage basés sur des transformateurs, pré-entraînés sur de grandes quantités de paires image-texte.", "metrics": {"bleu_score": 47.07965028787837, "chrf_score": 71.03066956570675, "xcomet_score": 0.9479119181632996, "xcomet_qe_score": 0.9887073040008545, "metricx_score": 2.1921041011810303, "metricx_qe_score": 2.430924654006958, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun de ces modèles repousse les limites de l'état de l'art en matière de tâches de vision et de langage, telles que la réponse à des questions visuelles, le raisonnement sur le sens commun visuel, la récupération d'images, l'ancrage de phrases.", "metrics": {"bleu_score": 29.91138459267709, "chrf_score": 69.91760759861242, "xcomet_score": 0.6568971872329712, "xcomet_qe_score": 0.689464271068573, "metricx_score": 4.017908573150635, "metricx_qe_score": 3.602102279663086, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc reçu un message. Les précisions sur ces points de référence spécifiques à la tâche augmentent régulièrement.", "metrics": {"bleu_score": 39.41004770986059, "chrf_score": 78.91324243980297, "xcomet_score": 0.8638429641723633, "xcomet_qe_score": 0.5701179504394531, "metricx_score": 4.687292098999023, "metricx_qe_score": 6.40407133102417, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "Mais savons-nous réellement ce que les modèles ont appris ?", "metrics": {"bleu_score": 51.69731539571708, "chrf_score": 87.01056627810956, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2264529466629028, "metricx_qe_score": 2.1026551723480225, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce qu'un transformateur de vision et de langage a compris lorsqu'il a attribué un score élevé pour que cette image et cette phrase correspondent ?", "metrics": {"bleu_score": 48.221575329820354, "chrf_score": 79.32837875334661, "xcomet_score": 0.7451979517936707, "xcomet_qe_score": 0.5714974403381348, "metricx_score": 2.6634278297424316, "metricx_qe_score": 2.7875521183013916, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "et un faible score pour celui-ci.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 44.691433223418365, "xcomet_score": 0.9077090620994568, "xcomet_qe_score": 0.9084277153015137, "metricx_score": 4.19215726852417, "metricx_qe_score": 3.0713937282562256, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur la bonne chose ?", "metrics": {"bleu_score": 32.281751885843555, "chrf_score": 68.20305147191763, "xcomet_score": 0.7724132537841797, "xcomet_qe_score": 0.7463480830192566, "metricx_score": 1.717067003250122, "metricx_qe_score": 2.1995620727539062, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "Ou se concentrent-ils sur les biais tels que démontrés par les travaux antérieurs ?", "metrics": {"bleu_score": 36.362270465000705, "chrf_score": 65.67172680024657, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9018996953964233, "metricx_qe_score": 1.1912939548492432, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour éclairer davantage cet aspect, nous proposons une approche plus indépendante des tâches et introduisons des tests qui évaluent la sensibilité des modèles de vision et de langage à des phénomènes linguistiques spécifiques qui affectent à la fois les modalités linguistiques et visuelles.", "metrics": {"bleu_score": 62.256083968521104, "chrf_score": 83.94080047415878, "xcomet_score": 0.7756016254425049, "xcomet_qe_score": 0.8446800708770752, "metricx_score": 1.983102798461914, "metricx_qe_score": 3.1365673542022705, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la référence aux entités.", "metrics": {"bleu_score": 80.03526445867712, "chrf_score": 88.50540031095565, "xcomet_score": 0.8606103658676147, "xcomet_qe_score": 0.9594275951385498, "metricx_score": 2.5848708152770996, "metricx_qe_score": 4.343854904174805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "Mais comment tester si les modèles de vision et de langage ont capturé ces phénomènes ?", "metrics": {"bleu_score": 48.10977290978806, "chrf_score": 80.9244319176873, "xcomet_score": 0.9484028220176697, "xcomet_qe_score": 0.8684145212173462, "metricx_score": 1.5279712677001953, "metricx_qe_score": 1.7546184062957764, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "en utilisant la méthode FOIL, déjà appliquée pour les modèles de vision et de langage, uniquement pour les groupes nominaux par Ravi Shekhar et ses collaborateurs, et en comptant par nous dans des travaux antérieurs.", "metrics": {"bleu_score": 38.21668498446409, "chrf_score": 64.79884435206142, "xcomet_score": 0.5434912443161011, "xcomet_qe_score": 0.5921635627746582, "metricx_score": 6.642325401306152, "metricx_qe_score": 7.446088790893555, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Le « foiling » signifie essentiellement que nous prenons la légende d'une image et produisons un « foil » en modifiant la légende de telle sorte qu'elle ne décrit plus l'image.", "metrics": {"bleu_score": 54.895488899892044, "chrf_score": 83.66011815312919, "xcomet_score": 0.9235228896141052, "xcomet_qe_score": 0.9660822749137878, "metricx_score": 2.232985258102417, "metricx_qe_score": 5.014932155609131, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous effectuons ces modifications de phrases en nous concentrant sur six éléments spécifiques, tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la référence d'entité, où chaque élément peut consister en un ou plusieurs instruments, au cas où nous trouverions plus d'une manière intéressante de créer des instances FOIL.", "metrics": {"bleu_score": 71.36146508173229, "chrf_score": 84.76833485639838, "xcomet_score": 0.7440789341926575, "xcomet_qe_score": 0.7732341289520264, "metricx_score": 3.734111785888672, "metricx_qe_score": 4.407797813415527, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans le cas de la pièce d'action, nous avons deux instruments, l'un dans lequel le verbe d'action est remplacé par une action différente et l'autre dans lequel les acteurs sont échangés.", "metrics": {"bleu_score": 58.95772766663462, "chrf_score": 77.95794216146056, "xcomet_score": 0.6045320630073547, "xcomet_qe_score": 0.6103154420852661, "metricx_score": 4.488827228546143, "metricx_qe_score": 5.553333282470703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la coréférence sont également des pièces qui nécessitent plus d'un instrument.", "metrics": {"bleu_score": 50.31747626530137, "chrf_score": 71.53026944150909, "xcomet_score": 0.7866995930671692, "xcomet_qe_score": 0.7524574398994446, "metricx_score": 4.640817165374756, "metricx_qe_score": 4.491874694824219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous créons ces faux par le fait de nous assurer qu'ils ne parviennent pas à décrire l'image, qu'ils sont des phrases grammaticales et autrement valides.", "metrics": {"bleu_score": 36.76308284763634, "chrf_score": 72.04351537589568, "xcomet_score": 0.6174365282058716, "xcomet_qe_score": 0.5003321170806885, "metricx_score": 8.3626708984375, "metricx_qe_score": 6.612709999084473, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "Ce n'est pas facile à faire, car une légende annulée peut être moins probable que la légende originale.", "metrics": {"bleu_score": 64.03113144057492, "chrf_score": 81.07791820753934, "xcomet_score": 0.8274329900741577, "xcomet_qe_score": 0.8004777431488037, "metricx_score": 6.6519317626953125, "metricx_qe_score": 5.485711097717285, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien que ce ne soit pas impossible, il est statistiquement moins probable qu'une plante coupe un homme qu'un homme coupe des plantes, et les grands modèles de vision et de langage pourraient s'en rendre compte.", "metrics": {"bleu_score": 53.61806810457202, "chrf_score": 78.13104091601005, "xcomet_score": 0.785429060459137, "xcomet_qe_score": 0.7641260027885437, "metricx_score": 2.3604583740234375, "metricx_qe_score": 2.572516918182373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour obtenir des lames valides, nous devons agir.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 88.03360259381346, "xcomet_score": 0.8294509649276733, "xcomet_qe_score": 0.8252901434898376, "metricx_score": 3.554013967514038, "metricx_qe_score": 1.5871697664260864, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous utilisons des modèles linguistiques puissants pour proposer des contre-exemples.", "metrics": {"bleu_score": 50.698033524721, "chrf_score": 71.15033555075682, "xcomet_score": 0.9572921991348267, "xcomet_qe_score": 0.9540972709655762, "metricx_score": 3.42240834236145, "metricx_qe_score": 1.019761085510254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence du langage naturel, ou NLI court, pour filtrer les faux qui pourraient encore décrire l'image, car lors de la construction des faux, nous devons nous assurer qu'ils ne parviennent pas à décrire l'image.", "metrics": {"bleu_score": 52.13881081163798, "chrf_score": 79.65465307823304, "xcomet_score": 0.6100656390190125, "xcomet_qe_score": 0.5805729627609253, "metricx_score": 11.400530815124512, "metricx_qe_score": 8.406251907348633, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Pour tester cela automatiquement, nous appliquons l'inférence du langage naturel avec la logique suivante.", "metrics": {"bleu_score": 49.025517878204084, "chrf_score": 74.21178809689445, "xcomet_score": 0.9903548955917358, "xcomet_qe_score": 0.9898281097412109, "metricx_score": 1.1603026390075684, "metricx_qe_score": 1.0455312728881836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "Nous considérons qu'une image est la prémisse et sa légende l'hypothèse qui en découle.", "metrics": {"bleu_score": 64.1386525898168, "chrf_score": 79.02472122917035, "xcomet_score": 0.9898675680160522, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.01365065574646, "metricx_qe_score": 1.1841981410980225, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous considérons la légende comme la prémisse et le FOIL comme son hypothèse.", "metrics": {"bleu_score": 50.09092657036855, "chrf_score": 72.95712067444813, "xcomet_score": 0.8292665481567383, "xcomet_qe_score": 0.5810114145278931, "metricx_score": 2.541767120361328, "metricx_qe_score": 3.918027639389038, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit que le FOIL contredit ou est neutre par rapport à la légende, nous considérons cela comme un indicateur d'un FOIL valide.", "metrics": {"bleu_score": 59.817595536558535, "chrf_score": 73.33130145135452, "xcomet_score": 0.6695801019668579, "xcomet_qe_score": 0.6926940679550171, "metricx_score": 4.631582736968994, "metricx_qe_score": 5.547378063201904, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si une NLI prédit que le FOIL est impliqué par la légende, il ne peut pas être un bon FOIL, car par transitivité, il donnera une description vraie de l'image et nous filtrons ces FOIL.", "metrics": {"bleu_score": 45.17515570981023, "chrf_score": 66.18097519847494, "xcomet_score": 0.4408789575099945, "xcomet_qe_score": 0.45154109597206116, "metricx_score": 7.994952201843262, "metricx_qe_score": 10.052233695983887, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cette procédure n'est pas parfaite, elle n'est qu'un indicateur pour les lames valides", "metrics": {"bleu_score": 44.09928765478173, "chrf_score": 69.75633048322182, "xcomet_score": 0.8246661424636841, "xcomet_qe_score": 0.7753731608390808, "metricx_score": 2.772397518157959, "metricx_qe_score": 1.7842291593551636, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, comme troisième mesure pour générer des FOI valides, nous faisons appel à des annotateurs humains pour valider les données utilisées dans VALS.", "metrics": {"bleu_score": 56.74773954614978, "chrf_score": 79.69359000965143, "xcomet_score": 0.8890717029571533, "xcomet_qe_score": 0.9222031831741333, "metricx_score": 4.7539286613464355, "metricx_qe_score": 5.181339263916016, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, après filtrage et évaluation humaine, nous avons autant d'exemples de test que ceux décrits dans ce tableau.", "metrics": {"bleu_score": 61.79396438001991, "chrf_score": 80.00454727922742, "xcomet_score": 0.9657013416290283, "xcomet_qe_score": 0.9653283357620239, "metricx_score": 1.9923498630523682, "metricx_qe_score": 2.553736686706543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que VALS ne fournit aucune donnée d'entraînement, mais uniquement des données de test.", "metrics": {"bleu_score": 28.304895944141947, "chrf_score": 59.02979244846107, "xcomet_score": 0.8620109558105469, "xcomet_qe_score": 0.9544814825057983, "metricx_score": 2.7719790935516357, "metricx_qe_score": 4.382838249206543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "car il s'agit uniquement d'un indicateur de référence pour les tests sans entraînement préalable. Il est conçu pour exploiter les capacités existantes des modèles de vision et de langage après l'entraînement préalable.", "metrics": {"bleu_score": 34.13986626409399, "chrf_score": 63.839801608252635, "xcomet_score": 0.7546280026435852, "xcomet_qe_score": 0.606458306312561, "metricx_score": 2.550536870956421, "metricx_qe_score": 3.1549882888793945, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "Le réglage fin ne permettrait qu'aux modèles d'exploiter des artefacts ou des biais statistiques dans les données.", "metrics": {"bleu_score": 65.91096049931349, "chrf_score": 79.46468247380966, "xcomet_score": 0.9497354030609131, "xcomet_qe_score": 0.9627677798271179, "metricx_score": 1.871721625328064, "metricx_qe_score": 2.2211921215057373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998902082443237, "xcomet_qe_score": 1.0, "metricx_score": 1.3476738929748535, "metricx_qe_score": 2.4462342262268066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme nous l’avons dit, nous sommes intéressés à évaluer les capacités des modèles de vision et de langage après l’entraînement préalable.", "metrics": {"bleu_score": 25.924945760983757, "chrf_score": 63.70402980579604, "xcomet_score": 0.9813010692596436, "xcomet_qe_score": 1.0, "metricx_score": 1.392293930053711, "metricx_qe_score": 1.5556659698486328, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec cinq modèles de vision et de langage sur les voyelles, à savoir CLIP, LXMIRT, VILBERT, VILBERT12IN1 et VISUALBERT.", "metrics": {"bleu_score": 25.59667597084103, "chrf_score": 56.413687745986586, "xcomet_score": 0.49490588903427124, "xcomet_qe_score": 0.5163530111312866, "metricx_score": 6.820377826690674, "metricx_qe_score": 6.31925106048584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos métriques d'évaluation les plus importantes sont la précision des modèles dans la classification des paires image-phrase en légendes et en faux.", "metrics": {"bleu_score": 42.027169897839464, "chrf_score": 76.70689267736044, "xcomet_score": 0.5875847339630127, "xcomet_qe_score": 0.6296790242195129, "metricx_score": 6.120433807373047, "metricx_qe_score": 5.036433696746826, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "Peut-être plus pertinent pour cette vidéo, nous allons présenter notre métrique plus permissive, la précision par paire, qui mesure si le score d'alignement de la phrase d'image est plus élevé pour la paire de texte d'image correcte que pour sa paire contrefaite.", "metrics": {"bleu_score": 54.00953186762318, "chrf_score": 71.47867918987662, "xcomet_score": 0.5515322089195251, "xcomet_qe_score": 0.5272539854049683, "metricx_score": 5.791715621948242, "metricx_qe_score": 4.884999752044678, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "Pour plus de mesures et de résultats à leur sujet, consultez notre article.", "metrics": {"bleu_score": 36.15855225145533, "chrf_score": 71.81765130966649, "xcomet_score": 0.9703108072280884, "xcomet_qe_score": 0.9889576435089111, "metricx_score": 2.0646443367004395, "metricx_qe_score": 1.7676552534103394, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats en termes de précision par paire sont présentés ici et ils sont cohérents avec les résultats obtenus avec les autres métriques. Il s'avère que la meilleure performance sans entraînement préalable est réalisée par Wilbert 12 in 1, suivi de Wilbert, Alexmert, Klip et enfin Visualbert.", "metrics": {"bleu_score": 25.13181466105028, "chrf_score": 55.69666491956955, "xcomet_score": 0.4228200316429138, "xcomet_qe_score": 0.41375985741615295, "metricx_score": 6.273594856262207, "metricx_qe_score": 6.799524307250977, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est remarquable de constater que les instruments centrés sur les objets individuels tels que l'existence et les phrases nominales sont presque résolus par Wilbert 12 in 1, soulignant que les modèles sont capables d'identifier les objets nommés et leur présence dans les images.", "metrics": {"bleu_score": 63.236255537502736, "chrf_score": 82.42024904994742, "xcomet_score": 0.6044531464576721, "xcomet_qe_score": 0.5154335498809814, "metricx_score": 5.656928539276123, "metricx_qe_score": 5.624240875244141, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucune des pièces restantes ne peut être résolue de manière fiable dans nos paramètres d'opposition contradictoire.", "metrics": {"bleu_score": 34.14088641890569, "chrf_score": 65.70281354435463, "xcomet_score": 0.6875821352005005, "xcomet_qe_score": 0.686808705329895, "metricx_score": 6.405132293701172, "metricx_qe_score": 4.488535404205322, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "On constate, à travers les instruments de pluralité et de comptage, que les modèles de vision et de langage ont du mal à distinguer les références à des objets uniques par rapport à des objets multiples ou à les compter dans une image.", "metrics": {"bleu_score": 61.138341409253506, "chrf_score": 78.14079516190719, "xcomet_score": 0.9557181596755981, "xcomet_qe_score": 0.9260027408599854, "metricx_score": 2.130384922027588, "metricx_qe_score": 2.7258458137512207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "La pièce de relation montre qu'ils ont des difficultés à classer correctement une relation spatiale nommée entre des objets dans une image.", "metrics": {"bleu_score": 90.67110266941049, "chrf_score": 92.93299474142468, "xcomet_score": 0.7587360143661499, "xcomet_qe_score": 0.6939899921417236, "metricx_score": 5.114096641540527, "metricx_qe_score": 5.364658355712891, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "Ils ont également du mal à distinguer les actions et à identifier leurs participants, même si cela est soutenu par des biais de plausibilité, comme nous le voyons dans la section sur les actions.", "metrics": {"bleu_score": 60.41292073836065, "chrf_score": 82.67908818556016, "xcomet_score": 0.8716142773628235, "xcomet_qe_score": 0.8994886875152588, "metricx_score": 2.0253262519836426, "metricx_qe_score": 2.4873149394989014, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "D'après le fragment de référence, nous apprenons que le fait de retracer plusieurs références au même objet dans une image en utilisant des pronoms est également difficile pour les modèles de vision et de langage.", "metrics": {"bleu_score": 56.36036032217381, "chrf_score": 76.69819438898242, "xcomet_score": 0.7740180492401123, "xcomet_qe_score": 0.839564323425293, "metricx_score": 3.6925642490386963, "metricx_qe_score": 4.417716026306152, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "À titre de vérification de cohérence, et parce que c'est une expérience intéressante, nous évaluons également deux modèles basés uniquement sur le texte, GPT-1 et GPT-2, pour déterminer si VALS est résoluble par ces modèles unimodaux en calculant la perplexité de la légende correcte et de la légende contrefaite, et en prédisant l'entrée présentant la plus faible perplexité.", "metrics": {"bleu_score": 41.38852314216148, "chrf_score": 67.26084055401729, "xcomet_score": 0.7465903759002686, "xcomet_qe_score": 0.8761101961135864, "metricx_score": 5.369786262512207, "metricx_qe_score": 5.233417510986328, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "Si la perplexité est plus élevée pour le FOIL, nous considérons cela comme une indication que la légende FOILée peut souffrir d'un biais de plausibilité ou d'autres biais linguistiques.", "metrics": {"bleu_score": 67.32460357124411, "chrf_score": 84.07233120657503, "xcomet_score": 0.6547378301620483, "xcomet_qe_score": 0.6321390271186829, "metricx_score": 6.640031337738037, "metricx_qe_score": 8.66455364227295, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est intéressant de constater que, dans certains cas, les modèles GPT basés uniquement sur le texte ont mieux capturé la plausibilité du monde que les modèles de vision et de langage.", "metrics": {"bleu_score": 46.21080293282983, "chrf_score": 73.93207081518625, "xcomet_score": 0.9918035268783569, "xcomet_qe_score": 0.9621990919113159, "metricx_score": 2.8297908306121826, "metricx_qe_score": 3.2190215587615967, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, VALS est une référence qui utilise la lentille des constructions linguistiques pour aider la communauté à améliorer les modèles de vision et de langage en testant rigoureusement leurs capacités d'ancrage visuel.", "metrics": {"bleu_score": 38.15659884752199, "chrf_score": 70.18956064686155, "xcomet_score": 0.4304350018501282, "xcomet_qe_score": 0.5119962096214294, "metricx_score": 6.641483306884766, "metricx_qe_score": 6.716378211975098, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que les modèles de vision et de langage identifient bien les objets nommés et leur présence dans les images, comme le montre l'existence de la pièce, mais ont du mal à ancrer leur interdépendance et leurs relations dans des scènes visuelles lorsqu'ils sont contraints de respecter les indicateurs linguistiques.", "metrics": {"bleu_score": 61.62248193050929, "chrf_score": 85.16709755967733, "xcomet_score": 0.7198151350021362, "xcomet_qe_score": 0.728679895401001, "metricx_score": 5.248769283294678, "metricx_qe_score": 5.253415107727051, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions vraiment encourager la communauté à utiliser VALS pour mesurer les progrès réalisés dans le domaine de l'ancrage linguistique avec des modèles de vision et de langage.", "metrics": {"bleu_score": 44.348492631401015, "chrf_score": 75.9744984713992, "xcomet_score": 0.7336684465408325, "xcomet_qe_score": 0.7814145088195801, "metricx_score": 5.039430618286133, "metricx_qe_score": 6.06243896484375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, VALS pourrait être utilisé comme une évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou le réglage fin pour voir si un ensemble de données aide les modèles à s'améliorer sur l'un des aspects testés par VALS.", "metrics": {"bleu_score": 47.47587535373449, "chrf_score": 76.56243809051459, "xcomet_score": 0.937193751335144, "xcomet_qe_score": 0.9829366207122803, "metricx_score": 2.7621421813964844, "metricx_qe_score": 3.4751830101013184, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "Si cela vous intéresse, consultez les données VALS sur GitHub et si vous avez des questions, n'hésitez pas à nous contacter.", "metrics": {"bleu_score": 63.19430791985466, "chrf_score": 83.45536793061025, "xcomet_score": 0.9007070064544678, "xcomet_qe_score": 0.9060479402542114, "metricx_score": 2.228633165359497, "metricx_qe_score": 2.800727367401123, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kami Zerua de l'Université de Tokyo.", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 85.8385869806183, "xcomet_score": 0.6272016167640686, "xcomet_qe_score": 0.5381074547767639, "metricx_score": 3.4331846237182617, "metricx_qe_score": 4.228899002075195, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai une communication intitulée RNSUM, un ensemble de données à grande échelle pour la noturation automatique de listes via la synthèse des journaux de commits.", "metrics": {"bleu_score": 34.72136453672462, "chrf_score": 61.84390941039146, "xcomet_score": 0.7001919746398926, "xcomet_qe_score": 0.7885264158248901, "metricx_score": 6.847248554229736, "metricx_qe_score": 6.142768859863281, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais expliquer dans cet ordre.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 82.67586467120438, "xcomet_score": 0.9803920984268188, "xcomet_qe_score": 1.0, "metricx_score": 0.5986242294311523, "metricx_qe_score": 0.8819785118103027, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je vais présenter l'alerte automatique de risque sur laquelle nous travaillons dans cette recherche.", "metrics": {"bleu_score": 57.24429659479037, "chrf_score": 76.98850104850199, "xcomet_score": 0.6682689785957336, "xcomet_qe_score": 0.6917861104011536, "metricx_score": 2.5818278789520264, "metricx_qe_score": 2.4796550273895264, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "ReleaseNode est un document technique qui résume les modifications distribuées avec chaque version d'un produit logiciel.", "metrics": {"bleu_score": 63.911674912072804, "chrf_score": 83.34746815097289, "xcomet_score": 0.7802062034606934, "xcomet_qe_score": 0.7483896017074585, "metricx_score": 9.185649871826172, "metricx_qe_score": 8.518582344055176, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'image montre les notes de version pour la version 2.6.1.", "metrics": {"bleu_score": 20.161413772504737, "chrf_score": 42.32178442220441, "xcomet_score": 0.18041980266571045, "xcomet_qe_score": 0.19091099500656128, "metricx_score": 4.22187614440918, "metricx_qe_score": 6.824519634246826, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Cela ne joue pas un rôle important dans le développement open source, mais ils prennent beaucoup de temps à préparer manuellement.", "metrics": {"bleu_score": 43.72055558976597, "chrf_score": 62.29668307043911, "xcomet_score": 0.28999876976013184, "xcomet_qe_score": 0.17771092057228088, "metricx_score": 9.571675300598145, "metricx_qe_score": 9.97844123840332, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Il serait donc très utile de pouvoir générer automatiquement des notes de version de haute qualité.", "metrics": {"bleu_score": 72.83860464220109, "chrf_score": 83.3655136180521, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6620479822158813, "metricx_qe_score": 0.7192174196243286, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais me référer à deux recherches antérieures sur la génération automatique d'auditeurs.", "metrics": {"bleu_score": 47.13585889212891, "chrf_score": 68.15743063899804, "xcomet_score": 0.5158745050430298, "xcomet_qe_score": 0.5142368078231812, "metricx_score": 9.064114570617676, "metricx_qe_score": 10.660517692565918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier est un système appelé Arena, sorti en 2014.", "metrics": {"bleu_score": 26.20251007173262, "chrf_score": 45.50403463476553, "xcomet_score": 0.3176872134208679, "xcomet_qe_score": 0.7537177801132202, "metricx_score": 1.080009937286377, "metricx_qe_score": 1.1859829425811768, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il adopte une approche basée sur des règles, par exemple, en utilisant l'extracteur de modifications pour extraire les différences fondamentales, les modifications de bibliothèque et les modifications de documents à partir des différences entre les versions, et en les combinant finalement.", "metrics": {"bleu_score": 56.90171995912943, "chrf_score": 75.27991179441693, "xcomet_score": 0.880473256111145, "xcomet_qe_score": 0.9429032802581787, "metricx_score": 2.1288886070251465, "metricx_qe_score": 1.8356684446334839, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus notable de ce système est l'extracteur de problèmes dans le coin supérieur droit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.8251105546951294, "xcomet_qe_score": 0.8080521821975708, "metricx_score": 3.1561570167541504, "metricx_qe_score": 3.8789119720458984, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "qui doit être lié à Jira, le système de gestion des problèmes, et ne peut être appliqué qu'aux projets qui utilisent Jira.", "metrics": {"bleu_score": 54.02963813314917, "chrf_score": 79.86286578275238, "xcomet_score": 0.7140092849731445, "xcomet_qe_score": 0.7303370237350464, "metricx_score": 4.299831867218018, "metricx_qe_score": 3.629873037338257, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, il ne peut pas être utilisé pour de nombreux projets sur GitHub.", "metrics": {"bleu_score": 84.82198619370465, "chrf_score": 91.46112044357582, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5660356283187866, "metricx_qe_score": 0.6357637643814087, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "Le deuxième est GRIF. Récemment annoncé en 2020,", "metrics": {"bleu_score": 5.934202609760488, "chrf_score": 37.812250765357525, "xcomet_score": 0.2070692479610443, "xcomet_qe_score": 0.3037557303905487, "metricx_score": 8.283858299255371, "metricx_qe_score": 6.0540008544921875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "Il est disponible sur Internet et peut être stocké via PIP.", "metrics": {"bleu_score": 22.781556051062047, "chrf_score": 59.40457871592192, "xcomet_score": 0.6234923601150513, "xcomet_qe_score": 0.8746084570884705, "metricx_score": 6.34021520614624, "metricx_qe_score": 5.257358551025391, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système dispose d'un simple module de classification de texte basé sur l'apprentissage et génère l'une des cinq variables, telles que les fonctionnalités ou les corrections de bogues, pour chaque message de commit d'entrée.", "metrics": {"bleu_score": 32.12167242090694, "chrf_score": 67.7481492909949, "xcomet_score": 0.7155923843383789, "xcomet_qe_score": 0.7805266380310059, "metricx_score": 3.3940906524658203, "metricx_qe_score": 3.041569232940674, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un exemple d'utilisation qui renvoie une étiquette de correction ou de correction de bogues.", "metrics": {"bleu_score": 68.89656775362826, "chrf_score": 83.36354877308032, "xcomet_score": 0.7354081273078918, "xcomet_qe_score": 0.7204704284667969, "metricx_score": 3.480973243713379, "metricx_qe_score": 3.5427937507629395, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "Les données d'entraînement de Goyafet sont assez limitées, environ 5000, et seront présentées dans les expériences décrites ci-dessous.", "metrics": {"bleu_score": 32.6868132730374, "chrf_score": 63.45479664755304, "xcomet_score": 0.4321601986885071, "xcomet_qe_score": 0.4588862359523773, "metricx_score": 9.188090324401855, "metricx_qe_score": 9.585617065429688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "les performances du modèle de classification de texte ne sont pas élevées.", "metrics": {"bleu_score": 91.21679090703874, "chrf_score": 98.34578851210975, "xcomet_score": 0.9871468544006348, "xcomet_qe_score": 0.9648545384407043, "metricx_score": 0.7311195731163025, "metricx_qe_score": 0.9105969667434692, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches connexes, mais il y avait des problèmes d'applicabilité limitée et de ressources de données rares.", "metrics": {"bleu_score": 48.45766087853282, "chrf_score": 81.87829776115237, "xcomet_score": 0.9446797370910645, "xcomet_qe_score": 0.9100715517997742, "metricx_score": 1.4788610935211182, "metricx_qe_score": 1.5011966228485107, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des nœuds de libération de haute qualité.", "metrics": {"bleu_score": 70.85876411943929, "chrf_score": 86.41210578117375, "xcomet_score": 0.7086522579193115, "xcomet_qe_score": 0.7240821123123169, "metricx_score": 5.404891014099121, "metricx_qe_score": 5.432879447937012, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le programme d'applicabilité limitée, nous proposons une méthode de résumé de classificateur de haute qualité utilisant uniquement le message de commit comme entrée.", "metrics": {"bleu_score": 34.01185071799047, "chrf_score": 62.94100527973363, "xcomet_score": 0.680007815361023, "xcomet_qe_score": 0.6809642910957336, "metricx_score": 8.653600692749023, "metricx_qe_score": 8.86544132232666, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée pour toutes les bibliothèques anglaises.", "metrics": {"bleu_score": 54.91004867761124, "chrf_score": 74.34819229705005, "xcomet_score": 0.8684433698654175, "xcomet_qe_score": 1.0, "metricx_score": 4.022363185882568, "metricx_qe_score": 3.5499415397644043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème des ressources de données limitées, nous avons créé un ensemble de données RNSUM composé d'environ 82 000 données en collectant des données à partir de dépôts publics GitHub en utilisant l'API GitHub.", "metrics": {"bleu_score": 42.038506304181816, "chrf_score": 66.46666895283664, "xcomet_score": 0.90369713306427, "xcomet_qe_score": 0.9604983329772949, "metricx_score": 3.289186716079712, "metricx_qe_score": 3.0547432899475098, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décris comment ils s'assoient.", "metrics": {"bleu_score": 22.089591134157878, "chrf_score": 39.362454921708824, "xcomet_score": 0.21321873366832733, "xcomet_qe_score": 0.21510377526283264, "metricx_score": 7.939977645874023, "metricx_qe_score": 9.721546173095703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de données.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998996257781982, "xcomet_qe_score": 0.9993472099304199, "metricx_score": 0.5450457334518433, "metricx_qe_score": 0.6231614351272583, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche est le message de commit, et le côté droit est la note de version.", "metrics": {"bleu_score": 33.48865558065726, "chrf_score": 56.76268484121787, "xcomet_score": 0.8198015093803406, "xcomet_qe_score": 0.7523123025894165, "metricx_score": 3.5386037826538086, "metricx_qe_score": 4.0007219314575195, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de version sont étiquetées comme des améliorations, des lieux de travail, etc.", "metrics": {"bleu_score": 43.85068972747104, "chrf_score": 72.77768943390683, "xcomet_score": 0.6320219039916992, "xcomet_qe_score": 0.6290271282196045, "metricx_score": 8.987825393676758, "metricx_qe_score": 9.33829402923584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons configuré une tâche qui prend les messages engagés en entrée et produit les nœuds de pièces câblés brute.", "metrics": {"bleu_score": 25.319096689413083, "chrf_score": 40.065145388333974, "xcomet_score": 0.15343979001045227, "xcomet_qe_score": 0.2808859646320343, "metricx_score": 16.45292091369629, "metricx_qe_score": 15.802337646484375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de résumé.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 80.28616903243483, "xcomet_score": 0.9564080238342285, "xcomet_qe_score": 0.9850058555603027, "metricx_score": 1.28573477268219, "metricx_qe_score": 0.8809378743171692, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons prédéfini quatre niveaux. Fonctionnalités, améliorations, corrections de bogues, dépréciations, suppressions et changements incompatibles.", "metrics": {"bleu_score": 31.35651449525274, "chrf_score": 64.97783321525557, "xcomet_score": 0.4605873227119446, "xcomet_qe_score": 0.545653760433197, "metricx_score": 7.694762229919434, "metricx_qe_score": 6.732927322387695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces affirmations étaient basées sur des recherches antérieures et d'autres facteurs.", "metrics": {"bleu_score": 17.45832536535669, "chrf_score": 54.115668616440374, "xcomet_score": 0.8885179758071899, "xcomet_qe_score": 0.850012481212616, "metricx_score": 2.708129644393921, "metricx_qe_score": 3.5541319847106934, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de la couronne en bas à droite sont extraites des notes de la couronne affichées en bas à gauche.", "metrics": {"bleu_score": 30.09429889037876, "chrf_score": 51.437906842415046, "xcomet_score": 0.349771112203598, "xcomet_qe_score": 0.4749182164669037, "metricx_score": 9.413695335388184, "metricx_qe_score": 7.801814556121826, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce stade, il est nécessaire de détecter les quatre niveaux qui ont été définis au préalable.", "metrics": {"bleu_score": 56.4581524229928, "chrf_score": 62.703393086341805, "xcomet_score": 0.8510393500328064, "xcomet_qe_score": 0.8890587091445923, "metricx_score": 4.434687614440918, "metricx_qe_score": 3.521883964538574, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "mais les niveaux ne sont pas toujours cohérents d'une bibliothèque à l'autre.", "metrics": {"bleu_score": 21.401603033752977, "chrf_score": 47.683077160784066, "xcomet_score": 0.5159385204315186, "xcomet_qe_score": 0.5356714129447937, "metricx_score": 5.714294910430908, "metricx_qe_score": 4.306755542755127, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le niveau d'amélioration comprend les améliorations, les perfectionnements, les optimisations, etc.", "metrics": {"bleu_score": 23.682079130839753, "chrf_score": 71.48145887394594, "xcomet_score": 0.8967965841293335, "xcomet_qe_score": 0.8641353845596313, "metricx_score": 1.9239022731781006, "metricx_qe_score": 1.8320070505142212, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste de vocabulaire pour chaque niveau d'étude de chacune de ces variations notationnelles.", "metrics": {"bleu_score": 49.502425668334865, "chrf_score": 70.54147653044534, "xcomet_score": 0.5037322044372559, "xcomet_qe_score": 0.61518394947052, "metricx_score": 6.485915184020996, "metricx_qe_score": 8.256209373474121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez-le pour détecter la classe de note de version et corriger le texte de la liste qui suit en tant que phrase de note de version pour la classe.", "metrics": {"bleu_score": 69.75603674379987, "chrf_score": 76.74804123351552, "xcomet_score": 0.4771033525466919, "xcomet_qe_score": 0.33993154764175415, "metricx_score": 8.744789123535156, "metricx_qe_score": 11.129803657531738, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, il y a un message de commit.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 68.6805532750581, "xcomet_score": 0.8390024900436401, "xcomet_qe_score": 0.9567588567733765, "metricx_score": 4.6736555099487305, "metricx_qe_score": 4.267538070678711, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de connexion ne sont pas liés à chaque liste.", "metrics": {"bleu_score": 54.52469119630866, "chrf_score": 67.86613622781142, "xcomet_score": 0.5933517217636108, "xcomet_qe_score": 0.5802716016769409, "metricx_score": 10.546843528747559, "metricx_qe_score": 9.376301765441895, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "Comme le montre l'image ci-dessous, si la liste actuelle est la version 2.5 à 19, nous devons identifier", "metrics": {"bleu_score": 28.528271647502013, "chrf_score": 48.27781246897469, "xcomet_score": 0.06266790628433228, "xcomet_qe_score": 0.11727236211299896, "metricx_score": 20.37971305847168, "metricx_qe_score": 17.769439697265625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "la version de sortie précédente, 2.5.18, et allez au fond des choses. C'est un peu fastidieux, et ce n'est pas suffisant de simplement obtenir une liste des sorties et de regarder le avant et le après.", "metrics": {"bleu_score": 10.09083540416532, "chrf_score": 60.63538775705241, "xcomet_score": 0.35977664589881897, "xcomet_qe_score": 0.16863906383514404, "metricx_score": 19.547863006591797, "metricx_qe_score": 18.753984451293945, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons créé une règle d'appariement heuristique pour obtenir les versions précédente et suivante.", "metrics": {"bleu_score": 48.176104471900615, "chrf_score": 68.34057322108093, "xcomet_score": 0.8760169744491577, "xcomet_qe_score": 0.8845483660697937, "metricx_score": 1.014144778251648, "metricx_qe_score": 0.9547683000564575, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "Ceci est Tanarsis.", "metrics": {"bleu_score": 15.97357760615681, "chrf_score": 10.587823207234749, "xcomet_score": 0.13256151974201202, "xcomet_qe_score": 0.11238433420658112, "metricx_score": 4.668356418609619, "metricx_qe_score": 8.57442855834961, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "Au final, 7200 dépôts.", "metrics": {"bleu_score": 1.0358715463283363, "chrf_score": 6.9315244870094075, "xcomet_score": 0.13895849883556366, "xcomet_qe_score": 0.14635924994945526, "metricx_score": 20.842731475830078, "metricx_qe_score": 20.550737380981445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de jetons de nœud de sortie est de 63, ce qui est assez élevé pour une tâche de résumé.", "metrics": {"bleu_score": 50.64962285182339, "chrf_score": 52.848255656352286, "xcomet_score": 0.3901221752166748, "xcomet_qe_score": 0.44159695506095886, "metricx_score": 7.735586166381836, "metricx_qe_score": 7.03493595123291, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre de jetons uniques est assez élevé, avec 8 830 000.", "metrics": {"bleu_score": 17.89117353466845, "chrf_score": 34.7602655734697, "xcomet_score": 0.7724733948707581, "xcomet_qe_score": 0.9406945705413818, "metricx_score": 4.365232467651367, "metricx_qe_score": 2.080101251602173, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "en raison du grand nombre de noms de classes et de méthodes uniques trouvés dans le dépôt.", "metrics": {"bleu_score": 26.896741624879542, "chrf_score": 61.47313536184683, "xcomet_score": 0.6752432584762573, "xcomet_qe_score": 0.6439417600631714, "metricx_score": 2.400895595550537, "metricx_qe_score": 1.5289374589920044, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, j'expliquerai la méthode proposée.", "metrics": {"bleu_score": 36.74145494215666, "chrf_score": 75.59105076499984, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26971232891082764, "metricx_qe_score": 0.1778177171945572, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de résumé extractif puis abstrayctif par classe consiste en deux modules neuronaux.", "metrics": {"bleu_score": 25.470014226549075, "chrf_score": 60.824691291327056, "xcomet_score": 0.961758553981781, "xcomet_qe_score": 0.9587306976318359, "metricx_score": 2.784808874130249, "metricx_qe_score": 2.4105398654937744, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "un classificateur utilisant BERT ou CodeBert, et un générateur utilisant BERT.", "metrics": {"bleu_score": 39.832871551569504, "chrf_score": 86.40642850852215, "xcomet_score": 0.9728261232376099, "xcomet_qe_score": 0.9710761308670044, "metricx_score": 6.193147659301758, "metricx_qe_score": 5.322481155395508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, CAS utilise un classificateur pour classer chaque message de commit en cinq catégories de notes de version. Nous choisissons les catégories suivantes : implémentations, corrections de bugs, dépréciations, ajouts et autres.", "metrics": {"bleu_score": 31.280763439438303, "chrf_score": 65.01116666341953, "xcomet_score": 0.5250294804573059, "xcomet_qe_score": 0.45704033970832825, "metricx_score": 7.263857841491699, "metricx_qe_score": 7.321592807769775, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de commit classés comme autres sont ignorés.", "metrics": {"bleu_score": 39.281465090051285, "chrf_score": 62.6891654486944, "xcomet_score": 0.888575553894043, "xcomet_qe_score": 0.9439843893051147, "metricx_score": 4.75583553314209, "metricx_qe_score": 4.91592264175415, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, CES applique le générateur aux quatre documents d'étiquette indépendamment et génère des nœuds de libération pour chaque classe.", "metrics": {"bleu_score": 48.82066497822451, "chrf_score": 80.48761092789583, "xcomet_score": 0.33728474378585815, "xcomet_qe_score": 0.34409773349761963, "metricx_score": 10.810461044311523, "metricx_qe_score": 9.78341293334961, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages de commit et les nœuds lus ne sont pas connues.", "metrics": {"bleu_score": 65.71079383543572, "chrf_score": 75.36021740277073, "xcomet_score": 0.7093414068222046, "xcomet_qe_score": 0.671369194984436, "metricx_score": 6.533944129943848, "metricx_qe_score": 6.978617191314697, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour entraîner le classificateur, nous attribuons des étiquettes sudo à chaque message de commit d'entrée en utilisant les 10 premiers caractères de chaque message de commit.", "metrics": {"bleu_score": 40.55107818771749, "chrf_score": 63.71706316844241, "xcomet_score": 0.5898247957229614, "xcomet_qe_score": 0.8284162282943726, "metricx_score": 9.446296691894531, "metricx_qe_score": 9.18695068359375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons la résumé abstrayant par classe à travers notre approche par deux méthodes différentes.", "metrics": {"bleu_score": 31.53554052490134, "chrf_score": 63.687259372241066, "xcomet_score": 0.4359402656555176, "xcomet_qe_score": 0.48506414890289307, "metricx_score": 8.826221466064453, "metricx_qe_score": 10.123907089233398, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons cssingle, se compose d'un seul réseau de sexe à sexe et génère un seul nœud de texte de pièce longue, étant donné une concaténation de messages de commit d'entrée.", "metrics": {"bleu_score": 33.20585776558894, "chrf_score": 56.57089003917907, "xcomet_score": 0.06403423100709915, "xcomet_qe_score": 0.14485907554626465, "metricx_score": 18.554258346557617, "metricx_qe_score": 17.29306411743164, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte de sortie peut être divisé en segments spécifiques à la classe en fonction de symboles de point de terminaison spécifiques à la classe.", "metrics": {"bleu_score": 27.85481825766967, "chrf_score": 57.67823622390041, "xcomet_score": 0.9549108743667603, "xcomet_qe_score": 0.9578454494476318, "metricx_score": 1.0889379978179932, "metricx_qe_score": 1.2358571290969849, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons fusion CAS, consiste en quatre réseaux différents de seconde à seconde, chacun correspondant à l'une des classes les moins connues.", "metrics": {"bleu_score": 23.772018834023733, "chrf_score": 58.9596832568147, "xcomet_score": 0.07527773082256317, "xcomet_qe_score": 0.10901331901550293, "metricx_score": 14.173327445983887, "metricx_qe_score": 13.265830993652344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, laissez-moi expliquer l'expérience.", "metrics": {"bleu_score": 6.4790667469036025, "chrf_score": 47.210365058958445, "xcomet_score": 0.9313861131668091, "xcomet_qe_score": 0.9775118827819824, "metricx_score": 1.1269221305847168, "metricx_qe_score": 0.8525193333625793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été comparées : CAS, CS simple, fusion CS, regroupement et deuil de l'étude précédente.", "metrics": {"bleu_score": 31.222258402876665, "chrf_score": 55.340455233379885, "xcomet_score": 0.2851995825767517, "xcomet_qe_score": 0.2741665840148926, "metricx_score": 15.419900894165039, "metricx_qe_score": 15.376218795776367, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation, dans certains cas, ces nœuds sont présentés dans plusieurs phrases.", "metrics": {"bleu_score": 53.948230957280764, "chrf_score": 70.53432203319608, "xcomet_score": 0.7155654430389404, "xcomet_qe_score": 0.5149511694908142, "metricx_score": 5.769745349884033, "metricx_qe_score": 7.044692039489746, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Puisqu'il est difficile de calculer le nombre de phrases, elles sont combinées avec des espaces et traitées comme une seule phrase longue.", "metrics": {"bleu_score": 81.99776825057587, "chrf_score": 86.8692516403163, "xcomet_score": 0.9987102746963501, "xcomet_qe_score": 1.0, "metricx_score": 1.1074215173721313, "metricx_qe_score": 2.048152446746826, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "Le bleu est en panneaux, lorsque le système affiche une phrase courte.", "metrics": {"bleu_score": 27.379285619165262, "chrf_score": 54.201409560776845, "xcomet_score": 0.7598378658294678, "xcomet_qe_score": 0.7396101355552673, "metricx_score": 11.31235122680664, "metricx_qe_score": 11.802055358886719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité entraîne une valeur bleue inférieure dans les résultats expérimentaux décrits ci-après.", "metrics": {"bleu_score": 20.50102460820911, "chrf_score": 59.87673254039435, "xcomet_score": 0.9775080680847168, "xcomet_qe_score": 0.9677661657333374, "metricx_score": 2.449563503265381, "metricx_qe_score": 3.910029411315918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous calculons également la spécificité, car le rouge et le bleu ne peuvent pas être calculés si les nœuds de libération sont vides.", "metrics": {"bleu_score": 49.17995026927894, "chrf_score": 74.5779269758236, "xcomet_score": 0.5634252429008484, "xcomet_qe_score": 0.63100665807724, "metricx_score": 6.141030788421631, "metricx_qe_score": 3.994363307952881, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une spécificité élevée signifie que le modèle produit correctement un texte vide dans les cas où les nœuds de sortie supposent vide.", "metrics": {"bleu_score": 59.36019329182504, "chrf_score": 74.09794614237185, "xcomet_score": 0.7567209005355835, "xcomet_qe_score": 0.8528612852096558, "metricx_score": 5.03196907043457, "metricx_qe_score": 5.230812072753906, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats.", "metrics": {"bleu_score": 11.521590992286539, "chrf_score": 34.57828622839441, "xcomet_score": 0.7604808807373047, "xcomet_qe_score": 1.0, "metricx_score": 0.15108263492584229, "metricx_qe_score": 0.03296280279755592, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que l'ensemble de données contient des adresses e-mail, des valeurs de hachage, etc., nous avons également évalué l'ensemble de données nettoyé, qui les exclut.", "metrics": {"bleu_score": 39.35363517155281, "chrf_score": 69.89270185705901, "xcomet_score": 0.9013433456420898, "xcomet_qe_score": 0.9044867157936096, "metricx_score": 2.382300853729248, "metricx_qe_score": 2.635183811187744, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "Les scores L approximatifs obtenus par le CEAS et le CAS étaient de plus de 10 points supérieurs aux valeurs de référence.", "metrics": {"bleu_score": 17.729842264695016, "chrf_score": 49.70727411286808, "xcomet_score": 0.6100465059280396, "xcomet_qe_score": 0.6845628023147583, "metricx_score": 8.27709674835205, "metricx_qe_score": 7.987768173217773, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur l'ensemble de test propre, l'écart de score entre les méthodes proposées et la base a bondi à plus de 20 points.", "metrics": {"bleu_score": 52.639640335444795, "chrf_score": 73.44008367764113, "xcomet_score": 0.7419014573097229, "xcomet_qe_score": 0.6798508167266846, "metricx_score": 5.794129848480225, "metricx_qe_score": 6.747098445892334, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent que le CES et le GS sont significativement efficaces.", "metrics": {"bleu_score": 35.416987661440594, "chrf_score": 55.19335691842152, "xcomet_score": 0.18175438046455383, "xcomet_qe_score": 0.21222606301307678, "metricx_score": 15.467076301574707, "metricx_qe_score": 13.658897399902344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "Le CAS a obtenu un meilleur score de défaillance des racines que le CAS, ce qui suggère que la combinaison d'un classificateur et d'un générateur est efficace pour entraîner le classificateur en utilisant des pseudo-doubles.", "metrics": {"bleu_score": 59.52275333096198, "chrf_score": 76.31158327506354, "xcomet_score": 0.1776410937309265, "xcomet_qe_score": 0.15415190160274506, "metricx_score": 14.555362701416016, "metricx_qe_score": 16.517921447753906, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "La couverture élevée du CAS peut être atteinte probablement parce que le classificateur peut se concentrer sur la sélection des messages de commit pertinents pour chaque classe.", "metrics": {"bleu_score": 56.08477095443868, "chrf_score": 79.93458742611409, "xcomet_score": 0.6742423176765442, "xcomet_qe_score": 0.5972076058387756, "metricx_score": 6.828530788421631, "metricx_qe_score": 6.4878973960876465, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Le couplage CAS tend à donner de meilleurs résultats que le CAS simple.", "metrics": {"bleu_score": 13.508625657351418, "chrf_score": 26.938873279554404, "xcomet_score": 0.8966646194458008, "xcomet_qe_score": 0.9267946481704712, "metricx_score": 6.512783527374268, "metricx_qe_score": 8.499098777770996, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "ce qui suggère qu'il est également efficace de développer de manière indépendante des modèles de résumé à absorption différente pour chaque classe de nœud de diffusion.", "metrics": {"bleu_score": 31.600229153053032, "chrf_score": 60.9124534070559, "xcomet_score": 0.37170058488845825, "xcomet_qe_score": 0.3352833092212677, "metricx_score": 7.972757816314697, "metricx_qe_score": 7.4842529296875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "Analyse des héros et des erreurs", "metrics": {"bleu_score": 0.0, "chrf_score": 36.56619019158502, "xcomet_score": 0.15556032955646515, "xcomet_qe_score": 0.15514278411865234, "metricx_score": 9.42391300201416, "metricx_qe_score": 14.02401065826416, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes de CS ont tendance à produire des phrases plus courtes que les phrases de référence humaines.", "metrics": {"bleu_score": 80.86627571031983, "chrf_score": 94.66279885743036, "xcomet_score": 0.7905377149581909, "xcomet_qe_score": 0.7156859636306763, "metricx_score": 4.612730026245117, "metricx_qe_score": 4.678327560424805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure à droite, la phrase de référence comporte 3 ou 4 phrases, tandis que le CAS n'en comporte qu'une seule.", "metrics": {"bleu_score": 48.850982922826084, "chrf_score": 71.20425174570032, "xcomet_score": 0.9483757019042969, "xcomet_qe_score": 0.6871975660324097, "metricx_score": 2.57464337348938, "metricx_qe_score": 6.246801376342773, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette réticence du modèle est que dans les données d'entraînement, seules 33 % des phrases sont présentes dans l'étiquette des caractéristiques et 40 % dans l'étiquette des améliorations.", "metrics": {"bleu_score": 41.59422474868443, "chrf_score": 65.7192895994116, "xcomet_score": 0.8388247489929199, "xcomet_qe_score": 0.8780544996261597, "metricx_score": 2.780648946762085, "metricx_qe_score": 2.400660991668701, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes CES ne peuvent pas générer des VsNode précis sans informations supplémentaires.", "metrics": {"bleu_score": 38.18418689062094, "chrf_score": 70.95067370843495, "xcomet_score": 0.5179803371429443, "xcomet_qe_score": 0.5380455255508423, "metricx_score": 12.367424964904785, "metricx_qe_score": 12.637140274047852, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple en haut à droite est un exemple de message de commentaire très désordonné, et la phrase complète ne peut pas être générée sans référence à la demande de pull ou au problème correspondant.", "metrics": {"bleu_score": 74.7331156753343, "chrf_score": 83.02696467409987, "xcomet_score": 0.7303330898284912, "xcomet_qe_score": 0.6178860664367676, "metricx_score": 6.4369378089904785, "metricx_qe_score": 6.528649806976318, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous montre que les deux messages de commit dans l'entrée sont liés et devraient être combinés en une seule phrase, mais il ne parvient pas à le faire.", "metrics": {"bleu_score": 39.0944313761396, "chrf_score": 69.35618355922927, "xcomet_score": 0.8577835559844971, "xcomet_qe_score": 0.9136546850204468, "metricx_score": 5.396671772003174, "metricx_qe_score": 5.279102325439453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, une conclusion.", "metrics": {"bleu_score": 20.252884954471366, "chrf_score": 51.7870301786907, "xcomet_score": 0.9809033870697021, "xcomet_qe_score": 1.0, "metricx_score": 1.8073315620422363, "metricx_qe_score": 2.418452262878418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons construit un nouveau jeu de modèles pour la notarisation automatique des cas.", "metrics": {"bleu_score": 13.834368456410946, "chrf_score": 55.89679487704085, "xcomet_score": 0.4572843015193939, "xcomet_qe_score": 0.5134568214416504, "metricx_score": 7.447384834289551, "metricx_qe_score": 4.921706676483154, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également élaboré la tâche de saisie des messages de commit et de leur résumé afin qu'elle soit applicable à tous les projets rédigés en anglais.", "metrics": {"bleu_score": 18.878340668029022, "chrf_score": 53.984472281027706, "xcomet_score": 0.8386588096618652, "xcomet_qe_score": 0.9222943186759949, "metricx_score": 4.6131744384765625, "metricx_qe_score": 4.39619255065918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Notre expérience montre que la méthode proposée a généré des pistes de notes moins bruyantes à une couverture plus élevée que les méthodes de référence.", "metrics": {"bleu_score": 42.567920066474585, "chrf_score": 69.74429224829025, "xcomet_score": 0.6351505517959595, "xcomet_qe_score": 0.6352353096008301, "metricx_score": 6.2362213134765625, "metricx_qe_score": 5.573803424835205, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez vérifier le code pour l'onglet de vérification du désert.", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 24.331204377504562, "xcomet_score": 0.12038497626781464, "xcomet_qe_score": 0.11564488708972931, "metricx_score": 12.690327644348145, "metricx_qe_score": 15.679023742675781, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10382990539073944, "metricx_qe_score": 0.4022793173789978, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Asaf Harari.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 83.1845583109951, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14045611023902893, "metricx_qe_score": 0.1951381266117096, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "et je vais présenter notre article intitulé « Enrichissement de données tabulaires en quelques étapes à l’aide d’architectures de transformateurs affinés ».", "metrics": {"bleu_score": 25.481620920647202, "chrf_score": 76.57647605414721, "xcomet_score": 0.8956191539764404, "xcomet_qe_score": 0.9363110661506653, "metricx_score": 3.4483399391174316, "metricx_qe_score": 4.467342376708984, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "C'est ainsi que les scientifiques analysent les données et se concentrent principalement sur la manipulation des caractéristiques existantes des données.", "metrics": {"bleu_score": 65.77160909911663, "chrf_score": 87.5476856033268, "xcomet_score": 0.7937742471694946, "xcomet_qe_score": 0.850911021232605, "metricx_score": 3.186272382736206, "metricx_qe_score": 3.85183048248291, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "mais parfois ces fonctionnalités sont limitées.", "metrics": {"bleu_score": 24.0785655451027, "chrf_score": 76.94819920746691, "xcomet_score": 0.9686001539230347, "xcomet_qe_score": 0.9744012951850891, "metricx_score": 0.21747228503227234, "metricx_qe_score": 0.22584828734397888, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "La génération de caractéristiques à l'aide d'une autre source de données peut ajouter des informations substantielles.", "metrics": {"bleu_score": 63.019085559238604, "chrf_score": 78.13911569774599, "xcomet_score": 0.9807618856430054, "xcomet_qe_score": 1.0, "metricx_score": 1.872923493385315, "metricx_qe_score": 1.3984712362289429, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique des données tabulaires à l'aide de sources externes en texte libre.", "metrics": {"bleu_score": 43.200373340115924, "chrf_score": 80.324139365827, "xcomet_score": 0.9968491792678833, "xcomet_qe_score": 1.0, "metricx_score": 0.6752551794052124, "metricx_qe_score": 0.977837860584259, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Supposons que nous ayons un ensemble de données tabulaires et une base de connaissances.", "metrics": {"bleu_score": 64.75445426291287, "chrf_score": 89.73182752598848, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7479367256164551, "metricx_qe_score": 0.9663262367248535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique qui implique le couplage d'entités et l'analyse de texte pour extraire de nouvelles fonctionnalités à partir du texte libre de la base de connaissances.", "metrics": {"bleu_score": 72.03362668653467, "chrf_score": 90.36522301974841, "xcomet_score": 0.9489810466766357, "xcomet_qe_score": 0.8966528177261353, "metricx_score": 1.5525987148284912, "metricx_qe_score": 1.4353814125061035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre est d'abord exactement ce processus automatique.", "metrics": {"bleu_score": 53.07712171072444, "chrf_score": 79.53167817792153, "xcomet_score": 0.6487555503845215, "xcomet_qe_score": 0.6181809902191162, "metricx_score": 7.233702659606934, "metricx_qe_score": 11.051931381225586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple dans des ensembles de données fournis à FAST.", "metrics": {"bleu_score": 24.384183193426086, "chrf_score": 47.85496385147542, "xcomet_score": 0.47450515627861023, "xcomet_qe_score": 0.6535142660140991, "metricx_score": 6.535367012023926, "metricx_qe_score": 7.133109092712402, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le jeu de données est un jeu de données universitaire.", "metrics": {"bleu_score": 18.92240568795936, "chrf_score": 71.44394706558398, "xcomet_score": 0.9318212270736694, "xcomet_qe_score": 0.8916794657707214, "metricx_score": 0.7501013278961182, "metricx_qe_score": 0.731359601020813, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "lorsqu'il s'agit de classer les universités en universités de faible rang et en universités de haut rang.", "metrics": {"bleu_score": 67.73401400577126, "chrf_score": 76.18647639058622, "xcomet_score": 0.9777740240097046, "xcomet_qe_score": 0.972602367401123, "metricx_score": 1.2917836904525757, "metricx_qe_score": 1.7408027648925781, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons Wikipedia comme base de connaissances.", "metrics": {"bleu_score": 16.0529461904344, "chrf_score": 68.12699120128313, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.24026861786842346, "metricx_qe_score": 0.1657801866531372, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase de FAST est le couplage d'entités.", "metrics": {"bleu_score": 32.46679154750989, "chrf_score": 62.10213810894469, "xcomet_score": 0.589958906173706, "xcomet_qe_score": 0.7011847496032715, "metricx_score": 6.508577346801758, "metricx_qe_score": 6.512113094329834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque chaque entité, dans cet exemple le nom de l'université, est liée à une entité dans la base de connaissances.", "metrics": {"bleu_score": 66.02281207883463, "chrf_score": 86.54911603522221, "xcomet_score": 0.9638090133666992, "xcomet_qe_score": 0.9413872361183167, "metricx_score": 0.7510913014411926, "metricx_qe_score": 1.10117769241333, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte des entités de la base de connaissances est extrait et ajouté au jeu de données.", "metrics": {"bleu_score": 67.36041912625802, "chrf_score": 89.91782906832555, "xcomet_score": 0.9177287220954895, "xcomet_qe_score": 0.9149763584136963, "metricx_score": 1.626519799232483, "metricx_qe_score": 1.662952184677124, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le texte est le résumé de la page Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5573669075965881, "metricx_qe_score": 0.8606062531471252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Nous devons maintenant générer ou extraire des caractéristiques du texte récupéré.", "metrics": {"bleu_score": 21.099261895175324, "chrf_score": 54.32807460126669, "xcomet_score": 0.9790385961532593, "xcomet_qe_score": 1.0, "metricx_score": 1.7824831008911133, "metricx_qe_score": 1.277591586112976, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'une phase d'extraction des caractéristiques qui inclut l'analyse de texte.", "metrics": {"bleu_score": 26.11938211208066, "chrf_score": 60.24981298457971, "xcomet_score": 0.9887895584106445, "xcomet_qe_score": 0.9697056412696838, "metricx_score": 4.042403221130371, "metricx_qe_score": 4.140544414520264, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "et c'est la principale nouveauté de cet article et j'y plongerai plus avant dans les diapositives suivantes", "metrics": {"bleu_score": 35.17559811415742, "chrf_score": 58.37607782418478, "xcomet_score": 0.6610403060913086, "xcomet_qe_score": 0.5218707323074341, "metricx_score": 4.427551746368408, "metricx_qe_score": 3.540029287338257, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction des caractéristiques, il y a une phase de génération des caractéristiques lorsque nous utilisons les caractéristiques extraites pour générer un petit nombre de nouvelles caractéristiques.", "metrics": {"bleu_score": 63.224657395432004, "chrf_score": 72.98475010364008, "xcomet_score": 0.9610253572463989, "xcomet_qe_score": 0.994035005569458, "metricx_score": 2.269667387008667, "metricx_qe_score": 1.3787375688552856, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "Générez d'abord des caractéristiques en fonction du nombre de classes du jeu de données original.", "metrics": {"bleu_score": 12.874330508144842, "chrf_score": 60.88071616150887, "xcomet_score": 0.8214989900588989, "xcomet_qe_score": 0.6484176516532898, "metricx_score": 4.416718006134033, "metricx_qe_score": 3.0543644428253174, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données original comporte deux classes.", "metrics": {"bleu_score": 31.702331385234313, "chrf_score": 65.64216837325874, "xcomet_score": 0.9993909597396851, "xcomet_qe_score": 1.0, "metricx_score": 1.1682051420211792, "metricx_qe_score": 1.6217488050460815, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, FAST génère deux nouvelles fonctionnalités.", "metrics": {"bleu_score": 27.054113452696992, "chrf_score": 77.53824420453357, "xcomet_score": 0.7529754638671875, "xcomet_qe_score": 0.7606123685836792, "metricx_score": 5.917479991912842, "metricx_qe_score": 6.713468551635742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si le jeu de données a cinq classes, générez d'abord cinq nouvelles caractéristiques.", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 51.45364818969542, "xcomet_score": 0.3609280586242676, "xcomet_qe_score": 0.34650829434394836, "metricx_score": 8.792834281921387, "metricx_qe_score": 7.768510818481445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque caractéristique représente la probabilité pour chaque classe.", "metrics": {"bleu_score": 75.06238537503395, "chrf_score": 78.89231057183392, "xcomet_score": 0.9665066003799438, "xcomet_qe_score": 1.0, "metricx_score": 1.271324634552002, "metricx_qe_score": 1.2625250816345215, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état de l'art actuel de l'analyse de texte, à savoir les modèles de langage basés sur les transformateurs tels que BERT, GPT, XNL, etc.", "metrics": {"bleu_score": 29.007992125659705, "chrf_score": 60.63529177669057, "xcomet_score": 0.7446289658546448, "xcomet_qe_score": 0.8009472489356995, "metricx_score": 2.822582960128784, "metricx_qe_score": 1.9734249114990234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "mais il est peu probable que nous puissions entraîner un modèle linguistique en utilisant les ensembles de données d'entrée.", "metrics": {"bleu_score": 38.27673535697133, "chrf_score": 66.83118310632673, "xcomet_score": 0.8606722354888916, "xcomet_qe_score": 0.9204162359237671, "metricx_score": 2.7731752395629883, "metricx_qe_score": 2.222773551940918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, une approche naïve consisterait à affiner la tâche cible.", "metrics": {"bleu_score": 48.86103195703452, "chrf_score": 67.95142514785971, "xcomet_score": 0.9104291796684265, "xcomet_qe_score": 0.8309173583984375, "metricx_score": 1.807779312133789, "metricx_qe_score": 2.9226772785186768, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, lors de la phase d'extraction future, nous pouvons télécharger le modèle de langage peritrain, ajuster finement le modèle de langage sur l'ensemble de données cible,", "metrics": {"bleu_score": 15.337871109155067, "chrf_score": 59.14975825093028, "xcomet_score": 0.5846664905548096, "xcomet_qe_score": 0.6243675947189331, "metricx_score": 8.540552139282227, "metricx_qe_score": 7.7755303382873535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, pour affiner le modèle linguistique, classer le texte en catégories, abstraire en catégories, basses ou élevées,", "metrics": {"bleu_score": 32.59889346257789, "chrf_score": 60.076763232952715, "xcomet_score": 0.5835933685302734, "xcomet_qe_score": 0.6725826859474182, "metricx_score": 4.714752674102783, "metricx_qe_score": 6.554224967956543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "recevoir la sortie du modèle linguistique, qui est la probabilité pour chaque classe, et l'utiliser comme nouvelles caractéristiques.", "metrics": {"bleu_score": 23.675470690860738, "chrf_score": 62.940360300208965, "xcomet_score": 0.8784862756729126, "xcomet_qe_score": 0.8894109129905701, "metricx_score": 4.667048931121826, "metricx_qe_score": 4.282763957977295, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que le jeu de données peut avoir peu d'étiquettes d'entités distinctes.", "metrics": {"bleu_score": 31.770554524092265, "chrf_score": 73.9905834287689, "xcomet_score": 0.7281299233436584, "xcomet_qe_score": 0.7619214057922363, "metricx_score": 4.332690715789795, "metricx_qe_score": 4.621841907501221, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, près de la moitié des ensembles de données contiennent moins de 400 échantillons et le plus petit ensemble de données contient 35 échantillons dans son ensemble d'entraînement.", "metrics": {"bleu_score": 38.72265129515214, "chrf_score": 70.81645873719165, "xcomet_score": 0.9226170778274536, "xcomet_qe_score": 0.9303825497627258, "metricx_score": 1.4895226955413818, "metricx_qe_score": 1.292279601097107, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, affiner un modèle linguistique sur ce jeu de données sera inefficace.", "metrics": {"bleu_score": 8.280453072947422, "chrf_score": 57.057220280494036, "xcomet_score": 0.9580610990524292, "xcomet_qe_score": 0.9682168960571289, "metricx_score": 1.2482987642288208, "metricx_qe_score": 1.2583656311035156, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "mais nous pouvons utiliser des connaissances antérieures sur des ensembles de données pré-analysés,", "metrics": {"bleu_score": 31.61487584488944, "chrf_score": 73.85689588606037, "xcomet_score": 0.9782816171646118, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.2325886487960815, "metricx_qe_score": 1.079128384590149, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "car nous appliquons FAST à plusieurs ensembles de données, nous pouvons utiliser les N moins un ensembles de données pour recueillir des informations sur les N moins un ensembles de données et utiliser ces informations lorsque nous analysons le N-ième ensemble de données.", "metrics": {"bleu_score": 35.91683871959397, "chrf_score": 73.07737130070606, "xcomet_score": 0.6421940922737122, "xcomet_qe_score": 0.6155818700790405, "metricx_score": 5.011462688446045, "metricx_qe_score": 5.277864456176758, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "Ce que nous suggérons, c'est d'ajouter une autre phase d'affinage,", "metrics": {"bleu_score": 74.25271143743538, "chrf_score": 82.7757459593426, "xcomet_score": 0.8789403438568115, "xcomet_qe_score": 0.8220337629318237, "metricx_score": 2.262819528579712, "metricx_qe_score": 1.9055191278457642, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "une phase de réglage fin multitâche préliminaire.", "metrics": {"bleu_score": 25.848657697858535, "chrf_score": 70.65001504137368, "xcomet_score": 0.9047296643257141, "xcomet_qe_score": 0.8776587247848511, "metricx_score": 4.938012599945068, "metricx_qe_score": 6.571381568908691, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque vous affinez le modèle linguistique sur des ensembles de données N-1,", "metrics": {"bleu_score": 7.52885143038073, "chrf_score": 55.380369299615516, "xcomet_score": 0.9353525042533875, "xcomet_qe_score": 0.9657876491546631, "metricx_score": 2.533616542816162, "metricx_qe_score": 2.209845542907715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "et ensuite nous exécutons une autre phase d'affinage qui est un affinage de tâche cible lorsque nous affinons le modèle linguistique sur le n-ième ensemble de données cible.", "metrics": {"bleu_score": 22.7160528277135, "chrf_score": 65.59440791283035, "xcomet_score": 0.7350824475288391, "xcomet_qe_score": 0.6783567667007446, "metricx_score": 2.718363046646118, "metricx_qe_score": 4.460340976715088, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "l'état de l'art en matière d'affinage multitâche appelé DNN vide.", "metrics": {"bleu_score": 5.300156689756295, "chrf_score": 41.7045926360552, "xcomet_score": 0.32954955101013184, "xcomet_qe_score": 0.3027676045894623, "metricx_score": 10.68700122833252, "metricx_qe_score": 11.064013481140137, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "Dans MTDNN, MTDNN maintient le nombre de tâches dans l'ensemble d'entraînement.", "metrics": {"bleu_score": 37.79635286696043, "chrf_score": 65.43305217429275, "xcomet_score": 0.4117808938026428, "xcomet_qe_score": 0.7222834825515747, "metricx_score": 8.814841270446777, "metricx_qe_score": 7.233624458312988, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans cet exemple, il y a quatre tâches dans l'ensemble d'entraînement. Donc, DNN vide, maintenir quatre têtes, comme vous pouvez le voir sur l'image.", "metrics": {"bleu_score": 59.410688139696376, "chrf_score": 73.24179273306761, "xcomet_score": 0.4816541373729706, "xcomet_qe_score": 0.42866799235343933, "metricx_score": 13.018667221069336, "metricx_qe_score": 14.096426963806152, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "et il prélève un échantillon aléatoire de l'ensemble d'entraînement.", "metrics": {"bleu_score": 16.807407519804237, "chrf_score": 59.080133128743874, "xcomet_score": 0.7465322017669678, "xcomet_qe_score": 0.7612265348434448, "metricx_score": 2.302901029586792, "metricx_qe_score": 3.192049980163574, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot aléatoire appartient, par exemple, à des tâches de classification de phrase unique, il est exécuté en passant en avant et en arrière à travers la première tête.", "metrics": {"bleu_score": 28.253893006668058, "chrf_score": 59.84944476487011, "xcomet_score": 0.6848497986793518, "xcomet_qe_score": 0.6102072596549988, "metricx_score": 5.812906742095947, "metricx_qe_score": 5.562397480010986, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Si le lot aléatoire appartient à la tâche de classement par paires, son attitude consiste à passer avant et après la dernière tête.", "metrics": {"bleu_score": 45.56701532024825, "chrf_score": 64.98795948743424, "xcomet_score": 0.5937248468399048, "xcomet_qe_score": 0.524391770362854, "metricx_score": 5.697211265563965, "metricx_qe_score": 5.98866605758667, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, un ensemble de données tabulaires déterminera le nombre de classes.", "metrics": {"bleu_score": 44.80304273880272, "chrf_score": 72.37139831287968, "xcomet_score": 0.8757402896881104, "xcomet_qe_score": 0.8839563727378845, "metricx_score": 4.594229221343994, "metricx_qe_score": 5.853786945343018, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a donc beaucoup de tâches", "metrics": {"bleu_score": 86.6877899750182, "chrf_score": 96.39149075818747, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6686975955963135, "metricx_qe_score": 0.7007427215576172, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "mtDNN conserve le nombre de chefs de classes, de couches de sortie,", "metrics": {"bleu_score": 34.47847620414246, "chrf_score": 58.53361807697641, "xcomet_score": 0.5780292749404907, "xcomet_qe_score": 0.549095094203949, "metricx_score": 7.74463415145874, "metricx_qe_score": 5.942177772521973, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, emptyDNA doit initialiser de nouvelles têtes pour un nouveau jeu de données avec une nouvelle tâche.", "metrics": {"bleu_score": 49.030470692026626, "chrf_score": 70.86673744230802, "xcomet_score": 0.4971635043621063, "xcomet_qe_score": 0.4540475308895111, "metricx_score": 8.346831321716309, "metricx_qe_score": 10.817550659179688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche, appelée affinage de la reformulation de tâche, consiste, au lieu de maintenir plusieurs têtes, à reformuler chaque ensemble de données en une phrase par problème de classification, ce qui correspond à des tâches à deux classes.", "metrics": {"bleu_score": 36.980298006293886, "chrf_score": 61.818685843581925, "xcomet_score": 0.5350120663642883, "xcomet_qe_score": 0.48992395401000977, "metricx_score": 4.094470024108887, "metricx_qe_score": 5.952033042907715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple.", "metrics": {"bleu_score": 46.30777161991026, "chrf_score": 48.32474847235818, "xcomet_score": 0.9386066198348999, "xcomet_qe_score": 0.9773107767105103, "metricx_score": 0.2514381408691406, "metricx_qe_score": 0.34026220440864563, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre ensemble de données d'entrée, qui se compose d'entités, de caractéristiques, de texte et de classes.", "metrics": {"bleu_score": 38.75407750115177, "chrf_score": 64.16015151771236, "xcomet_score": 0.9720182418823242, "xcomet_qe_score": 0.9976086616516113, "metricx_score": 2.0105767250061035, "metricx_qe_score": 2.757319211959839, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous reformulons la tâche en passant de la classification du texte en faible et élevé à la classification du texte, de l'abstrait et de la classe en vrai ou faux.", "metrics": {"bleu_score": 37.58610313819115, "chrf_score": 60.65191551633093, "xcomet_score": 0.7092766761779785, "xcomet_qe_score": 0.7382036447525024, "metricx_score": 4.530405044555664, "metricx_qe_score": 3.9608101844787598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous entraînons le modèle de langage à classer l'abstrait et la classe, à distinguer si l'abstrait appartient ou non à la classe.", "metrics": {"bleu_score": 10.213409499230604, "chrf_score": 43.643671895312714, "xcomet_score": 0.5705271363258362, "xcomet_qe_score": 0.4652705490589142, "metricx_score": 5.190657138824463, "metricx_qe_score": 6.660048007965088, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le vecteur d'étiquette dans ce cas reste toujours, ce qui consiste toujours en deux classes.", "metrics": {"bleu_score": 44.47608928410893, "chrf_score": 80.98778871701694, "xcomet_score": 0.6679500341415405, "xcomet_qe_score": 0.7693915367126465, "metricx_score": 7.381757736206055, "metricx_qe_score": 9.212035179138184, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici l'algorithme de notre approche de réglage fine reformulée.", "metrics": {"bleu_score": 9.596928383261213, "chrf_score": 49.637499888750064, "xcomet_score": 0.9114736318588257, "xcomet_qe_score": 0.9390148520469666, "metricx_score": 4.629692554473877, "metricx_qe_score": 5.227245807647705, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons donc le cadre complet.", "metrics": {"bleu_score": 53.7284965911771, "chrf_score": 81.9759249161167, "xcomet_score": 0.9789191484451294, "xcomet_qe_score": 0.9587022066116333, "metricx_score": 1.1847355365753174, "metricx_qe_score": 3.205934524536133, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "Cela a mis la Fed en mode accéléré.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 8.462977874335953, "xcomet_score": 0.11581284552812576, "xcomet_qe_score": 0.08922512829303741, "metricx_score": 10.610702514648438, "metricx_qe_score": 13.365667343139648, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "et ensuite une phase rapide d'exécution de liaison d'entités", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 55.2095160550375, "xcomet_score": 0.43560829758644104, "xcomet_qe_score": 0.7251561880111694, "metricx_score": 9.813994407653809, "metricx_qe_score": 9.133158683776855, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "il extrait le texte de la base de connaissances, qui dans cet exemple est le résumé de la page Wikipédia.", "metrics": {"bleu_score": 95.10699415570296, "chrf_score": 98.8018938583582, "xcomet_score": 0.9654701948165894, "xcomet_qe_score": 0.9213699698448181, "metricx_score": 2.0358121395111084, "metricx_qe_score": 3.023637056350708, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "puis il reformule la tâche en une phrase par tâche de classification.", "metrics": {"bleu_score": 22.478349658423234, "chrf_score": 59.12130485001478, "xcomet_score": 0.37433281540870667, "xcomet_qe_score": 0.5180696249008179, "metricx_score": 10.956801414489746, "metricx_qe_score": 9.692585945129395, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "a appliqué le modèle linguistique à la nouvelle tâche et a évalué la probabilité de sortie pour chaque classe,", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 82.48819951403448, "xcomet_score": 0.5610817670822144, "xcomet_qe_score": 0.5746177434921265, "metricx_score": 3.228255271911621, "metricx_qe_score": 4.418120384216309, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que le modèle linguistique est déjà affiné sur un ensemble de données N-1 en utilisant un affinage préalable multitâche.", "metrics": {"bleu_score": 10.545401236865166, "chrf_score": 49.512453949070526, "xcomet_score": 0.8337100744247437, "xcomet_qe_score": 0.748691201210022, "metricx_score": 2.7783138751983643, "metricx_qe_score": 2.4905920028686523, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous utilisons le vecteur de sortie du modèle linguistique comme une nouvelle caractéristique générée dans le nombre de classes.", "metrics": {"bleu_score": 67.40705509899853, "chrf_score": 77.82797724718824, "xcomet_score": 0.891135573387146, "xcomet_qe_score": 0.9339526891708374, "metricx_score": 3.8746848106384277, "metricx_qe_score": 5.268843650817871, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un ensemble de données de classification tabulaire de 17 éléments, qui vérifie la taille, les caractéristiques, l'équilibre, le domaine et la performance initiale.", "metrics": {"bleu_score": 27.042049185058644, "chrf_score": 71.08361545413405, "xcomet_score": 0.6198565363883972, "xcomet_qe_score": 0.5548546314239502, "metricx_score": 4.120384693145752, "metricx_qe_score": 4.653648376464844, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme base de connaissances, nous utilisons Wikipédia.", "metrics": {"bleu_score": 64.069143843707, "chrf_score": 82.77936370702274, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.31506168842315674, "metricx_qe_score": 0.3690527379512787, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concevons notre expérience comme une évaluation en temps réel lorsque nous entraînons rapidement plus de 16 ensembles de données et l'appliquons au 17e ensemble de données.", "metrics": {"bleu_score": 26.16747576701775, "chrf_score": 62.22997806497945, "xcomet_score": 0.22795984148979187, "xcomet_qe_score": 0.20231756567955017, "metricx_score": 7.93344783782959, "metricx_qe_score": 8.030418395996094, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "Nous divisons également chaque ensemble de données en quatre plis et appliquons une validation croisée à quatre plis.", "metrics": {"bleu_score": 57.77966168512882, "chrf_score": 89.25561868345505, "xcomet_score": 0.7914178371429443, "xcomet_qe_score": 0.6754323244094849, "metricx_score": 1.72420072555542, "metricx_qe_score": 3.224687337875366, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous générons la nouvelle fonctionnalité et les évaluons à l'aide de cinq classificateurs d'évaluation.", "metrics": {"bleu_score": 35.23089031737454, "chrf_score": 74.96907095996136, "xcomet_score": 0.92185378074646, "xcomet_qe_score": 0.9126148819923401, "metricx_score": 2.8427164554595947, "metricx_qe_score": 4.1992387771606445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons dans notre expérience une architecture basée sur BERT.", "metrics": {"bleu_score": 8.68851996125416, "chrf_score": 36.028224074283024, "xcomet_score": 0.5403529405593872, "xcomet_qe_score": 0.8989875912666321, "metricx_score": 4.682814121246338, "metricx_qe_score": 1.7337007522583008, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre expérience.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 82.16212638893361, "xcomet_score": 0.9823514223098755, "xcomet_qe_score": 0.9937252998352051, "metricx_score": 0.3568568527698517, "metricx_qe_score": 0.5269936919212341, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "On peut voir que nous comparons notre cadre au réglage fin du jeu de données cible, au réglage fin de la tâche cible et au réglage fin préliminaire de MTDNN.", "metrics": {"bleu_score": 33.10670933889895, "chrf_score": 58.59802994501505, "xcomet_score": 0.6430913805961609, "xcomet_qe_score": 0.5884895324707031, "metricx_score": 5.366126537322998, "metricx_qe_score": 4.627584934234619, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "et notre affinage reformulé atteint le meilleur résultat, la meilleure performance.", "metrics": {"bleu_score": 50.934984129906766, "chrf_score": 79.40545916480679, "xcomet_score": 0.8262925148010254, "xcomet_qe_score": 0.7969803810119629, "metricx_score": 2.7652535438537598, "metricx_qe_score": 3.3960323333740234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que, dans le cas de dnn vide, on a obtenu une amélioration de deux pour cent par rapport à l'ensemble de données cible affiné", "metrics": {"bleu_score": 35.31598970614653, "chrf_score": 65.63610707677964, "xcomet_score": 0.30595359206199646, "xcomet_qe_score": 0.3283410966396332, "metricx_score": 10.213419914245605, "metricx_qe_score": 11.151920318603516, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "notre approche a permis une amélioration de 6 %.", "metrics": {"bleu_score": 18.60045401920258, "chrf_score": 58.189967586979705, "xcomet_score": 0.9715737104415894, "xcomet_qe_score": 0.9753538966178894, "metricx_score": 1.3482437133789062, "metricx_qe_score": 1.7589399814605713, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous examinons le petit ensemble de données, nous pouvons voir que la performance de mtDNN diminue et que l'amélioration de la phase de réglage fin multitâche préliminaire diminue à 1,5 pour cent.", "metrics": {"bleu_score": 39.76353643835252, "chrf_score": 70.36713606653761, "xcomet_score": 0.852898359298706, "xcomet_qe_score": 0.8513376712799072, "metricx_score": 5.313658714294434, "metricx_qe_score": 5.979616165161133, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "mais notre performance a augmenté à 11 % par rapport au seul affinage de la tâche cible.", "metrics": {"bleu_score": 25.890790939055332, "chrf_score": 55.39555197222247, "xcomet_score": 0.7835106253623962, "xcomet_qe_score": 0.7245611548423767, "metricx_score": 3.1599531173706055, "metricx_qe_score": 5.664343357086182, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "Pour la sommation, FAST permet une enrichissement en quelques essais à partir de 35 échantillons dans notre expérience.", "metrics": {"bleu_score": 15.071676257541073, "chrf_score": 62.74066096924822, "xcomet_score": 0.3322412669658661, "xcomet_qe_score": 0.3528877794742584, "metricx_score": 9.668227195739746, "metricx_qe_score": 8.856069564819336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "Il utilise une architecture pour tous les ensembles de données de tâches.", "metrics": {"bleu_score": 33.495318896976464, "chrf_score": 75.42593815170618, "xcomet_score": 0.9868813753128052, "xcomet_qe_score": 0.9803872108459473, "metricx_score": 3.605736017227173, "metricx_qe_score": 3.802783966064453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela conserve la tête du modèle.", "metrics": {"bleu_score": 54.10822690539397, "chrf_score": 63.79769019519902, "xcomet_score": 0.7745968103408813, "xcomet_qe_score": 0.6426060199737549, "metricx_score": 4.83475399017334, "metricx_qe_score": 6.767157554626465, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "mais cela ajoute une phase de reformulation", "metrics": {"bleu_score": 70.1396726799769, "chrf_score": 94.88889520966822, "xcomet_score": 0.9718477725982666, "xcomet_qe_score": 0.9564205408096313, "metricx_score": 1.4273874759674072, "metricx_qe_score": 2.744992256164551, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "son ensemble de trains augmenté et ses besoins, une valeur cible avec un sens sémantique afin que nous puissions l'introduire dans le modèle linguistique et l'utiliser dans la phrase par problème de classification.", "metrics": {"bleu_score": 44.66071519296394, "chrf_score": 75.33237448983226, "xcomet_score": 0.3986411988735199, "xcomet_qe_score": 0.42348039150238037, "metricx_score": 15.052923202514648, "metricx_qe_score": 13.758234977722168, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Merci.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10382990539073944, "metricx_qe_score": 0.4022793173789978, "linguapy_score": [1, "ITALIAN"]}}
