{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous, aujourd'hui je vais présenter notre travail de recherche sur l'apprentissage du raisonnement déductif, la résolution de problèmes matériels et l'extraction de raisonnements complexes.", "metrics": {"bleu_score": 15.930980477936155, "chrf_score": 58.47423570859356, "xcomet_score": 0.7828032970428467, "xcomet_qe_score": 0.8225246667861938, "metricx_score": 6.577470779418945, "metricx_qe_score": 5.735951900482178, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "je suis Alan du laboratoire d'aéronautique de Bython et c'est un travail conjoint avec Cheri de l'université du Texas à Austin et Weido de SDD", "metrics": {"bleu_score": 15.27794067264744, "chrf_score": 46.51269692898189, "xcomet_score": 0.17821699380874634, "xcomet_qe_score": 0.11246082186698914, "metricx_score": 18.835153579711914, "metricx_qe_score": 17.650033950805664, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, j'aimerais parler de notre motivation pour raisonner", "metrics": {"bleu_score": 72.05745450576255, "chrf_score": 86.4139108066489, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.712293803691864, "metricx_qe_score": 1.0606024265289307, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Nous vous montrerons des exemples où l'aliment de base est sain.", "metrics": {"bleu_score": 3.1934960455974277, "chrf_score": 29.175399830347214, "xcomet_score": 0.1352425366640091, "xcomet_qe_score": 0.13450372219085693, "metricx_score": 19.70151138305664, "metricx_qe_score": 22.48011016845703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Cette figure est tirée de l'article dans lequel ils utilisent l'incitation pour résoudre le problème mathématique dans un scénario d'apprentissage futur.", "metrics": {"bleu_score": 8.429386858583033, "chrf_score": 52.19655858569582, "xcomet_score": 0.32306066155433655, "xcomet_qe_score": 0.3661308288574219, "metricx_score": 8.649094581604004, "metricx_qe_score": 7.281710624694824, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, sur le site du stylo à encre, nous pouvons voir si nous donnons quelques exemples avec juste des réponses correctes et dans d'autres cas, nous ne parvenons pas à obtenir les bonnes réponses.", "metrics": {"bleu_score": 28.397110626034333, "chrf_score": 60.718345237246105, "xcomet_score": 0.25682273507118225, "xcomet_qe_score": 0.19588615000247955, "metricx_score": 10.930651664733887, "metricx_qe_score": 8.932116508483887, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "mais si nous fournissons une description plus détaillée du raisonnement, le modèle est capable de prédire la description du raisonnement et de faire la bonne prédiction ici", "metrics": {"bleu_score": 39.362191501483814, "chrf_score": 66.90424904468522, "xcomet_score": 0.8709535598754883, "xcomet_qe_score": 0.9229820966720581, "metricx_score": 1.27455735206604, "metricx_qe_score": 1.3975235223770142, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Il est donc bon d'avoir un raisonnement en plusieurs étapes interchangeable.", "metrics": {"bleu_score": 11.809094681011398, "chrf_score": 58.269757025482626, "xcomet_score": 0.8730226159095764, "xcomet_qe_score": 0.8858155012130737, "metricx_score": 5.5735650062561035, "metricx_qe_score": 5.541025638580322, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pensons également que le problème de méthode est une application directe pour évaluer de telles capacités de raisonnement.", "metrics": {"bleu_score": 63.67075680957933, "chrf_score": 79.67952366575398, "xcomet_score": 0.7422282099723816, "xcomet_qe_score": 0.6918374300003052, "metricx_score": 8.228606224060059, "metricx_qe_score": 6.7190046310424805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans notre problème, étant donné les questions, nous devons résoudre cette question et obtenir les réponses numériques.", "metrics": {"bleu_score": 57.96664416079147, "chrf_score": 74.56068073714678, "xcomet_score": 0.9393302202224731, "xcomet_qe_score": 0.9301223158836365, "metricx_score": 2.306046962738037, "metricx_qe_score": 2.4982619285583496, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos ensembles de données, on nous donne également l'expression mathématique qui conduit à cette réponse particulière.", "metrics": {"bleu_score": 49.24584878270649, "chrf_score": 81.1413696475458, "xcomet_score": 0.9820101261138916, "xcomet_qe_score": 0.9784786701202393, "metricx_score": 2.7192282676696777, "metricx_qe_score": 3.3011441230773926, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, certaines hypothèses s'appliquent également comme dans les travaux précédents.", "metrics": {"bleu_score": 72.92571723872932, "chrf_score": 81.74616035973521, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.85512375831604, "metricx_qe_score": 2.617657423019409, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "nous supposons la précision des quantités connues", "metrics": {"bleu_score": 28.319415510892387, "chrf_score": 74.33447434545333, "xcomet_score": 0.9367649555206299, "xcomet_qe_score": 0.9686828851699829, "metricx_score": 6.344260215759277, "metricx_qe_score": 5.324505805969238, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous ne considérons que les opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentiation.", "metrics": {"bleu_score": 92.10589320522861, "chrf_score": 95.68299687983432, "xcomet_score": 0.969541072845459, "xcomet_qe_score": 0.9754696488380432, "metricx_score": 1.1877816915512085, "metricx_qe_score": 0.6469014883041382, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les opérateurs complexes peuvent en réalité être décomposés en ces opérateurs de base.", "metrics": {"bleu_score": 50.7196093945688, "chrf_score": 69.8708284380725, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5208061337471008, "metricx_qe_score": 0.4972343444824219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, les travaux antérieurs en résolution de problèmes mathématiques peuvent en fait être classés en modèles séquence-à-séquence et séquence-à-arbre.", "metrics": {"bleu_score": 6.9065068793497, "chrf_score": 66.49995238992645, "xcomet_score": 0.9226276874542236, "xcomet_qe_score": 0.8387330770492554, "metricx_score": 4.080077648162842, "metricx_qe_score": 4.20098876953125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle séquence-à-séquence traditionnel convertit l'expression en une séquence spécifique pour la génération", "metrics": {"bleu_score": 46.040771186435805, "chrf_score": 87.72740835072203, "xcomet_score": 0.7515407204627991, "xcomet_qe_score": 0.7969427704811096, "metricx_score": 1.5479321479797363, "metricx_qe_score": 1.9081381559371948, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "et il est assez facile à mettre en œuvre et il peut s'appliquer à de nombreux problèmes complexes différents", "metrics": {"bleu_score": 51.84341074271373, "chrf_score": 72.68010833621229, "xcomet_score": 0.9418843388557434, "xcomet_qe_score": 0.9575933814048767, "metricx_score": 1.2983368635177612, "metricx_qe_score": 1.632769227027893, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "mais les inconvénients de la performance ne sont en réalité généralement pas meilleurs que ceux du modèle structurel et il manque d'interprétabilité pour la prédiction", "metrics": {"bleu_score": 6.802254824715724, "chrf_score": 69.43068403948199, "xcomet_score": 0.742263674736023, "xcomet_qe_score": 0.7766136527061462, "metricx_score": 9.898415565490723, "metricx_qe_score": 8.472192764282227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en réalité, cette direction reste assez populaire à cause du modèle transformateur.", "metrics": {"bleu_score": 33.696998602966666, "chrf_score": 56.56064715763331, "xcomet_score": 0.8718991279602051, "xcomet_qe_score": 0.8699468970298767, "metricx_score": 4.700998306274414, "metricx_qe_score": 3.4472012519836426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans les modèles basés sur les arbres, nous structurons ces expressions sous forme d'arbre et suivons un parcours d'ordre prédéfini dans les générations d'arbres.", "metrics": {"bleu_score": 45.97006398721532, "chrf_score": 68.87740109892079, "xcomet_score": 0.8861666917800903, "xcomet_qe_score": 0.877417802810669, "metricx_score": 2.4029417037963867, "metricx_qe_score": 2.5876073837280273, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous continuons à générer les opérateurs jusqu'à ce que nous atteignions les quantités à gauche", "metrics": {"bleu_score": 43.87464321792805, "chrf_score": 67.04778473573485, "xcomet_score": 0.5630744695663452, "xcomet_qe_score": 0.41944727301597595, "metricx_score": 5.147191524505615, "metricx_qe_score": 5.967554092407227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, la bonne chose, c'est qu'elle nous donne en fait cette structure d'arbre binaire et c'est en fait assez contingent car nous générons d'abord l'opérateur et ensuite, à la fin, nous générons les quantités", "metrics": {"bleu_score": 51.29225811923655, "chrf_score": 74.17546425163832, "xcomet_score": 0.7596465349197388, "xcomet_qe_score": 0.7071704864501953, "metricx_score": 9.30423355102539, "metricx_qe_score": 11.873550415039062, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "et la deuxième chose est qu'il contient également quelques commutations répétitives", "metrics": {"bleu_score": 23.26303536297059, "chrf_score": 66.00402898726159, "xcomet_score": 0.906600832939148, "xcomet_qe_score": 0.9386098980903625, "metricx_score": 6.4217095375061035, "metricx_qe_score": 5.817844390869141, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ici, si nous regardons cette expression, les atomes trois plus trois sont en fait générés deux fois, mais en réalité, nous devrions utiliser les résultats", "metrics": {"bleu_score": 58.82661820461596, "chrf_score": 83.94874034795592, "xcomet_score": 0.7453447580337524, "xcomet_qe_score": 0.750243604183197, "metricx_score": 8.154577255249023, "metricx_qe_score": 9.334636688232422, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre approche proposée, nous voulons résoudre ces problèmes de manière progressive et interprétable.", "metrics": {"bleu_score": 64.5536177559541, "chrf_score": 81.61876085762648, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9764289855957031, "metricx_qe_score": 0.82675701379776, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, par exemple, ici, à l'étape suivante, nous pouvons obtenir ces diviseurs, qui est 27.", "metrics": {"bleu_score": 29.945160623183913, "chrf_score": 59.24377266711897, "xcomet_score": 0.7647606730461121, "xcomet_qe_score": 0.7860821485519409, "metricx_score": 4.133042812347412, "metricx_qe_score": 6.590356826782227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons également nous référer aux questions initiales pour trouver les contenus pertinents.", "metrics": {"bleu_score": 37.73213566354408, "chrf_score": 79.82893313414947, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6789897680282593, "metricx_qe_score": 0.6728734970092773, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous obtenons les diviseurs.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9926035404205322, "xcomet_qe_score": 0.9813810586929321, "metricx_score": 2.1472244262695312, "metricx_qe_score": 2.927687406539917, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, et ensuite, à cette troisième étape, nous obtenons réellement le quotient", "metrics": {"bleu_score": 52.025568808075846, "chrf_score": 73.7561313380471, "xcomet_score": 0.8927319049835205, "xcomet_qe_score": 0.9691197872161865, "metricx_score": 3.989567279815674, "metricx_qe_score": 3.665109157562256, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "Et après ces trois étapes, nous pouvons en fait réduire les résultats de la deuxième étape, puis obtenir les résultats de la quatrième étape, et enfin, nous pouvons obtenir les dividendes.", "metrics": {"bleu_score": 82.07124605935064, "chrf_score": 86.59827267234625, "xcomet_score": 0.7890783548355103, "xcomet_qe_score": 0.8012666702270508, "metricx_score": 7.424045562744141, "metricx_qe_score": 7.442018032073975, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, nous générons directement l'expression entière, plutôt que de générer un seul opérateur ou une seule quantité.", "metrics": {"bleu_score": 51.79597484328195, "chrf_score": 74.01954768643873, "xcomet_score": 0.9826120138168335, "xcomet_qe_score": 0.9817992448806763, "metricx_score": 1.2079737186431885, "metricx_qe_score": 1.4430291652679443, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "cela rend donc le processus plus précis", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 81.41181438781946, "xcomet_score": 0.9546758532524109, "xcomet_qe_score": 0.938508152961731, "metricx_score": 0.7022737860679626, "metricx_qe_score": 1.5196199417114258, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre système didactique, nous commençons par un ensemble de quantités présentées dans les questions, et incluant également certaines constantes sous forme d'abréviations.", "metrics": {"bleu_score": 37.25742310754032, "chrf_score": 68.70048427728132, "xcomet_score": 0.5449703335762024, "xcomet_qe_score": 0.5120992660522461, "metricx_score": 8.34173583984375, "metricx_qe_score": 7.732661247253418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "L'expression est donc représentée par E.I.J.O.P.", "metrics": {"bleu_score": 6.250381527944883, "chrf_score": 60.06130091607861, "xcomet_score": 0.9106243252754211, "xcomet_qe_score": 0.8104403018951416, "metricx_score": 1.6752607822418213, "metricx_qe_score": 2.1528167724609375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "où nous effectuons des opérations de QI à QJ, et une telle expression est en fait dirigée.", "metrics": {"bleu_score": 29.040304905772032, "chrf_score": 64.12429469694716, "xcomet_score": 0.8907957077026367, "xcomet_qe_score": 0.8854594230651855, "metricx_score": 4.776418685913086, "metricx_qe_score": 5.704414367675781, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc également la soustraction avec des mots ici pour représenter la direction opposée.", "metrics": {"bleu_score": 52.95361149563325, "chrf_score": 82.43396304938267, "xcomet_score": 0.9831878542900085, "xcomet_qe_score": 0.9324163198471069, "metricx_score": 1.1433124542236328, "metricx_qe_score": 1.5855202674865723, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "Cela ressemble beaucoup à l'extraction rhodésienne.", "metrics": {"bleu_score": 9.469167282754096, "chrf_score": 33.622410830151274, "xcomet_score": 0.6866604089736938, "xcomet_qe_score": 0.7440251111984253, "metricx_score": 5.905089378356934, "metricx_qe_score": 6.961878299713135, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans un système déductif formel, à l'instant t, nous appliquons l'opérateur entre q et qjp ici, puis nous obtenons cette nouvelle expression", "metrics": {"bleu_score": 26.583600695446645, "chrf_score": 61.45328470365195, "xcomet_score": 0.8681076169013977, "xcomet_qe_score": 0.9022713303565979, "metricx_score": 6.825935363769531, "metricx_qe_score": 7.3223466873168945, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "nous l'ajoutons à l'état suivant pour devenir une nouvelle quantité", "metrics": {"bleu_score": 79.6358031503278, "chrf_score": 96.799899842816, "xcomet_score": 0.9557915925979614, "xcomet_qe_score": 0.9293824434280396, "metricx_score": 2.1312947273254395, "metricx_qe_score": 3.570648193359375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, cette diapositive illustre l'évolution des états, où nous continuons d'ajouter des expressions aux états actuels.", "metrics": {"bleu_score": 9.27755128237612, "chrf_score": 57.85286837324624, "xcomet_score": 0.9016977548599243, "xcomet_qe_score": 0.9098700284957886, "metricx_score": 5.080285549163818, "metricx_qe_score": 4.468928337097168, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos implémentations de modèles, nous utilisons d'abord un modèle linguistique pré-entraîné qui peut être des oiseaux ou des robots, puis nous codons les phrases, et ensuite nous obtenons ces représentations quantitatives.", "metrics": {"bleu_score": 30.394778395171432, "chrf_score": 65.68533663303803, "xcomet_score": 0.6197330951690674, "xcomet_qe_score": 0.6666855812072754, "metricx_score": 8.636544227600098, "metricx_qe_score": 8.239738464355469, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, une fois que nous avons les représentations quantitatives, nous pouvons commencer à faire des inférences.", "metrics": {"bleu_score": 47.9071425065913, "chrf_score": 73.29209051544434, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.6489012241363525, "metricx_qe_score": 1.7596518993377686, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de Q1 pour obtenir la représentation de Q1 divisée par Q2, puis multipliée par Q4", "metrics": {"bleu_score": 13.900672249666965, "chrf_score": 63.40800535623605, "xcomet_score": 0.5241179466247559, "xcomet_qe_score": 0.6967358589172363, "metricx_score": 15.702738761901855, "metricx_qe_score": 9.102961540222168, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Nous obtenons d'abord la représentation de la paire, qui est essentiellement la concaténation entre Q1 et Q2, puis nous appliquons un réseau de type feed-forward, paramétré par l'opérateur.", "metrics": {"bleu_score": 28.635894269450535, "chrf_score": 65.42210770663755, "xcomet_score": 0.8205839395523071, "xcomet_qe_score": 0.9054242968559265, "metricx_score": 4.2394185066223145, "metricx_qe_score": 4.144954681396484, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, nous obtenons l'expression de représentation Q1 divisé par Q2", "metrics": {"bleu_score": 22.272147118804728, "chrf_score": 73.14891837625005, "xcomet_score": 0.8768660426139832, "xcomet_qe_score": 0.9261417388916016, "metricx_score": 4.595692157745361, "metricx_qe_score": 3.942389965057373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "mais en pratique, à un stade précoce, nous pourrions également obtenir l'expression incorrecte", "metrics": {"bleu_score": 20.73607464953792, "chrf_score": 62.30341888467623, "xcomet_score": 0.7792469263076782, "xcomet_qe_score": 0.8113048076629639, "metricx_score": 3.7783169746398926, "metricx_qe_score": 3.674351215362549, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, toutes les expressions possibles sont égales à trois fois le nombre d'opérateurs.", "metrics": {"bleu_score": 38.53856918030314, "chrf_score": 73.77771861326676, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8023084998130798, "metricx_qe_score": 1.5921916961669922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "l'avantage ici est que nous pouvons facilement ajouter des contraintes pour contrôler cette recherche", "metrics": {"bleu_score": 33.65344213568372, "chrf_score": 71.65289277738596, "xcomet_score": 0.9008587598800659, "xcomet_qe_score": 0.9098492860794067, "metricx_score": 2.266669273376465, "metricx_qe_score": 4.881729602813721, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement la supprimer de notre espace de recherche.", "metrics": {"bleu_score": 73.62853809865184, "chrf_score": 81.71776209831928, "xcomet_score": 0.9951730966567993, "xcomet_qe_score": 0.9794670343399048, "metricx_score": 0.37088721990585327, "metricx_qe_score": 0.45243895053863525, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans la deuxième étape, nous faisons la même chose, mais la seule différence est qu'il y a une quantité supplémentaire.", "metrics": {"bleu_score": 71.03600666390408, "chrf_score": 81.83922662836126, "xcomet_score": 0.9617201089859009, "xcomet_qe_score": 0.9233575463294983, "metricx_score": 3.420553207397461, "metricx_qe_score": 4.673766613006592, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "Cette quantité provient de l'expression calculée précédente.", "metrics": {"bleu_score": 31.708476589333063, "chrf_score": 74.09650727541442, "xcomet_score": 0.9993386268615723, "xcomet_qe_score": 0.995700478553772, "metricx_score": 0.5797427892684937, "metricx_qe_score": 0.8377796411514282, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc finalement obtenir cette expression finale,", "metrics": {"bleu_score": 13.579714487002688, "chrf_score": 61.76180097666113, "xcomet_score": 0.7007339000701904, "xcomet_qe_score": 0.8739519119262695, "metricx_score": 9.313029289245605, "metricx_qe_score": 6.133010387420654, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "fois Q4 et nous pouvons également voir que le nombre de toutes les expressions possibles est différent de l'étape précédente", "metrics": {"bleu_score": 78.28785637123033, "chrf_score": 88.11985378308339, "xcomet_score": 0.4734105169773102, "xcomet_qe_score": 0.28487178683280945, "metricx_score": 9.237905502319336, "metricx_qe_score": 12.586121559143066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ces différences rendent difficile l'application de la recherche par balayage car la distribution de probabilité entre ces deux étapes est déséquilibrée.", "metrics": {"bleu_score": 59.70228993860436, "chrf_score": 79.38499570066668, "xcomet_score": 0.9071063995361328, "xcomet_qe_score": 0.8976969122886658, "metricx_score": 1.9480876922607422, "metricx_qe_score": 1.4965810775756836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, la procédure d'entraînement est similaire à celle d'un modèle de séquence à séquence où nous optimisons les lois à chaque étape temporelle.", "metrics": {"bleu_score": 26.015538360004697, "chrf_score": 59.76504680217432, "xcomet_score": 0.4957393407821655, "xcomet_qe_score": 0.5624402761459351, "metricx_score": 6.254640579223633, "metricx_qe_score": 6.994204044342041, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également cela pour représenter quand nous devrions mettre fin à ce processus de génération.", "metrics": {"bleu_score": 62.53394459096071, "chrf_score": 83.83589956935903, "xcomet_score": 0.9329532384872437, "xcomet_qe_score": 0.9630377888679504, "metricx_score": 3.0812788009643555, "metricx_qe_score": 2.8756563663482666, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent d'une séquence à l'autre, car l'espace est différent à chaque étape temporelle, alors que dans le modèle traditionnel séquence à séquence, c'est le nombre de vocabulaire.", "metrics": {"bleu_score": 53.53937540083666, "chrf_score": 78.18893982555943, "xcomet_score": 0.6812957525253296, "xcomet_qe_score": 0.6885342597961426, "metricx_score": 5.166402339935303, "metricx_qe_score": 6.197297096252441, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "et cela nous permet également d'imposer certaines contraintes issues de connaissances antérieures", "metrics": {"bleu_score": 53.67088830805399, "chrf_score": 87.1012244338996, "xcomet_score": 0.9756678342819214, "xcomet_qe_score": 0.9525270462036133, "metricx_score": 1.1871709823608398, "metricx_qe_score": 1.2616071701049805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc mené des expériences sur les ensembles de données couramment utilisés pour le problème de la métropole, MAWPS, Math23k, MathQA et swamp", "metrics": {"bleu_score": 18.05915447393609, "chrf_score": 60.49330227890377, "xcomet_score": 0.4114932715892792, "xcomet_qe_score": 0.4692288935184479, "metricx_score": 11.12415885925293, "metricx_qe_score": 11.092216491699219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "et ici, nous présentons brièvement les résultats par rapport aux meilleures approches précédentes", "metrics": {"bleu_score": 24.09683061844592, "chrf_score": 66.11742233044014, "xcomet_score": 0.9620018601417542, "xcomet_qe_score": 0.9205403327941895, "metricx_score": 1.2905515432357788, "metricx_qe_score": 1.331632137298584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre arme la plus performante est le raisonnement détective de Robert.", "metrics": {"bleu_score": 21.97281387499715, "chrf_score": 51.97834998214008, "xcomet_score": 0.5089704394340515, "xcomet_qe_score": 0.5113440155982971, "metricx_score": 8.334932327270508, "metricx_qe_score": 6.938713550567627, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "Et en fait, nous n'utilisons pas la recherche par faisceau, contrairement aux approches évidentes qui utilisent la recherche par faisceau.", "metrics": {"bleu_score": 21.233470585998816, "chrf_score": 47.93178368886847, "xcomet_score": 0.7595174312591553, "xcomet_qe_score": 0.7836669683456421, "metricx_score": 4.765428066253662, "metricx_qe_score": 3.6660337448120117, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord. Ainsi, les meilleures approches sont souvent des modèles basés sur des arbres.", "metrics": {"bleu_score": 45.608395453519385, "chrf_score": 67.72389408541993, "xcomet_score": 0.9898309707641602, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.9991783499717712, "metricx_qe_score": 1.0493299961090088, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans l'ensemble, notre raisonneur est capable de surpasser de manière significative ce modèle à trois bases.", "metrics": {"bleu_score": 48.130446616982546, "chrf_score": 70.6748151909175, "xcomet_score": 0.7297717332839966, "xcomet_qe_score": 0.9091421365737915, "metricx_score": 8.096476554870605, "metricx_qe_score": 7.690991401672363, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "mais nous pouvons voir que le nombre absolu sur les quais de maths ou swam n'est pas vraiment élevé", "metrics": {"bleu_score": 16.67955161379731, "chrf_score": 61.03230902713387, "xcomet_score": 0.3385637700557709, "xcomet_qe_score": 0.17001973092556, "metricx_score": 9.684791564941406, "metricx_qe_score": 9.351964950561523, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Nous examinons donc plus en détail les résultats sur", "metrics": {"bleu_score": 60.10525952194528, "chrf_score": 73.08247819261635, "xcomet_score": 0.32891860604286194, "xcomet_qe_score": 0.3630223274230957, "metricx_score": 6.099941253662109, "metricx_qe_score": 4.170998573303223, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "Et cet ensemble de données est difficile à traiter car l'auteur a essayé d'ajouter manuellement quelque chose pour confondre le modèle NLB, comme l'ajout d'informations environnementales et de quantités supplémentaires.", "metrics": {"bleu_score": 34.25019872373427, "chrf_score": 65.20896573605324, "xcomet_score": 0.6590303778648376, "xcomet_qe_score": 0.8388296365737915, "metricx_score": 5.7297539710998535, "metricx_qe_score": 5.574820518493652, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre prédiction, nous trouvons que certaines des valeurs intermédiaires sont en fait négatives.", "metrics": {"bleu_score": 62.685933350049744, "chrf_score": 80.99528599265699, "xcomet_score": 0.9873621463775635, "xcomet_qe_score": 1.0, "metricx_score": 1.301595687866211, "metricx_qe_score": 0.8621784448623657, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans ces questions, nous demandons combien de pommes Jake a ?", "metrics": {"bleu_score": 59.92267879576601, "chrf_score": 86.56577014501036, "xcomet_score": 0.9971505403518677, "xcomet_qe_score": 0.9892210960388184, "metricx_score": 1.8740465641021729, "metricx_qe_score": 2.735065460205078, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "mais nous avons des informations supplémentaires comme dix-sept terrains de camping et Steven a huit terrains ce qui est totalement sans rapport", "metrics": {"bleu_score": 26.038248909028304, "chrf_score": 65.44441408321123, "xcomet_score": 0.38024988770484924, "xcomet_qe_score": 0.35985925793647766, "metricx_score": 14.549832344055176, "metricx_qe_score": 15.972536087036133, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait certaines prédictions de ce type, qui produisent des valeurs négatives.", "metrics": {"bleu_score": 29.48993986902436, "chrf_score": 58.20291400828608, "xcomet_score": 0.9857156276702881, "xcomet_qe_score": 1.0, "metricx_score": 1.808215618133545, "metricx_qe_score": 1.313873052597046, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous observons ces deux expressions", "metrics": {"bleu_score": 10.014525608798039, "chrf_score": 35.16689671066389, "xcomet_score": 0.1863933950662613, "xcomet_qe_score": 0.26318830251693726, "metricx_score": 18.502872467041016, "metricx_qe_score": 18.035531997680664, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc limiter cet espace de recherche en supprimant les résultats négatifs, afin de pouvoir rendre la réponse correcte.", "metrics": {"bleu_score": 61.39776196756082, "chrf_score": 78.09341300369286, "xcomet_score": 0.9241632223129272, "xcomet_qe_score": 0.8042563199996948, "metricx_score": 2.8505499362945557, "metricx_qe_score": 3.597954750061035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Nous constatons donc que cette contrainte améliore en réalité considérablement certains modèles", "metrics": {"bleu_score": 49.5958668188253, "chrf_score": 71.23085685685066, "xcomet_score": 0.9862899780273438, "xcomet_qe_score": 0.9750595092773438, "metricx_score": 1.8571336269378662, "metricx_qe_score": 1.6527204513549805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, pour les oiseaux, nous améliorons sept points, et puis pour le modèle de base du robot, nous améliorons en fait deux points.", "metrics": {"bleu_score": 45.17367344753633, "chrf_score": 52.518862122059005, "xcomet_score": 0.4702240228652954, "xcomet_qe_score": 0.5056766271591187, "metricx_score": 11.798585891723633, "metricx_qe_score": 10.830892562866211, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Un meilleur modèle linguistique possède une meilleure capacité de compréhension du langage, de sorte que le nombre ici est plus élevé pour le robot et plus faible pour le robot", "metrics": {"bleu_score": 27.093730640055156, "chrf_score": 48.273008434776585, "xcomet_score": 0.36234337091445923, "xcomet_qe_score": 0.4838048815727234, "metricx_score": 16.18670654296875, "metricx_qe_score": 6.268874168395996, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous essayons également d'analyser la difficulté derrière ce #ahB.", "metrics": {"bleu_score": 63.15552371794033, "chrf_score": 78.06792114124332, "xcomet_score": 0.5807936787605286, "xcomet_qe_score": 0.5470401048660278, "metricx_score": 11.223054885864258, "metricx_qe_score": 15.073957443237305, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que le nombre de quantités non utilisées peut être considéré comme une information non pertinente ici", "metrics": {"bleu_score": 61.29719199531818, "chrf_score": 90.58839063581655, "xcomet_score": 0.9839489459991455, "xcomet_qe_score": 0.9697611927986145, "metricx_score": 2.0377936363220215, "metricx_qe_score": 2.2616875171661377, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous pouvons voir ici que nous avons le pourcentage d'échantillons avec des quantités non utilisées et que le jeu de données Swamp représente la plus grande partie.", "metrics": {"bleu_score": 47.689559976337705, "chrf_score": 77.23081077388858, "xcomet_score": 0.9039543867111206, "xcomet_qe_score": 0.8618485331535339, "metricx_score": 5.291669845581055, "metricx_qe_score": 6.064111709594727, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons également la performance globale", "metrics": {"bleu_score": 89.483931681437, "chrf_score": 98.23149044069322, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8484746217727661, "metricx_qe_score": 1.3591183423995972, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "pour ces échantillons sans quantités d'utilisation, donc la performance globale est en réalité supérieure à la performance globale.", "metrics": {"bleu_score": 56.79161104357995, "chrf_score": 84.46766282691004, "xcomet_score": 0.43565675616264343, "xcomet_qe_score": 0.22832193970680237, "metricx_score": 8.477686882019043, "metricx_qe_score": 10.868298530578613, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "mais avec ces échantillons, la qualité non utilisée est en réalité bien pire que celle qui vient, euh, bien pire que celle qui vient", "metrics": {"bleu_score": 9.615094003919301, "chrf_score": 48.24023182240301, "xcomet_score": 0.32106083631515503, "xcomet_qe_score": 0.4361775517463684, "metricx_score": 11.770848274230957, "metricx_qe_score": 10.991377830505371, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "pour M.W.P.S., nous n'avons pas vraiment de données sur le nombre de cas, donc je n'arrive pas à comprendre cela.", "metrics": {"bleu_score": 14.614031921776125, "chrf_score": 39.72440398223181, "xcomet_score": 0.6814123392105103, "xcomet_qe_score": 0.6398378610610962, "metricx_score": 8.232169151306152, "metricx_qe_score": 7.150945663452148, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Nous voulons donc finalement montrer l'interprétabilité à travers un exemple d'accident et de participation", "metrics": {"bleu_score": 19.03837857221325, "chrf_score": 61.636463645933446, "xcomet_score": 0.21474677324295044, "xcomet_qe_score": 0.43331021070480347, "metricx_score": 9.66262149810791, "metricx_qe_score": 8.617053985595703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait en réalité la mauvaise prédiction à la première étape.", "metrics": {"bleu_score": 33.82657819986719, "chrf_score": 52.33997433657534, "xcomet_score": 0.9093289971351624, "xcomet_qe_score": 0.8995984196662903, "metricx_score": 1.6090798377990723, "metricx_qe_score": 1.4886221885681152, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc effectivement établir un lien entre cette expression et la phrase ici, n'est-ce pas ?", "metrics": {"bleu_score": 11.306082351602983, "chrf_score": 55.945158768942505, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.595879316329956, "metricx_qe_score": 1.2400789260864258, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons donc que ces indicateurs pourraient induire le modèle en erreur et conduire à une prédiction incorrecte.", "metrics": {"bleu_score": 32.59481888833584, "chrf_score": 64.71040928764529, "xcomet_score": 0.820649266242981, "xcomet_qe_score": 0.7128008604049683, "metricx_score": 2.7853293418884277, "metricx_qe_score": 3.024902820587158, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, l'ajout de trente-cinq autres caractères amène le modèle à penser qu'il s'agit d'un opérateur d'addition.", "metrics": {"bleu_score": 11.64394847706997, "chrf_score": 54.24537503945569, "xcomet_score": 0.8476347923278809, "xcomet_qe_score": 0.7078900933265686, "metricx_score": 1.9947118759155273, "metricx_qe_score": 2.0294671058654785, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc essayé de réviser la phrase pour qu'elle ressemble à ceci : le nombre d'arbres de poire est trente-cinq de moins que celui des pommiers.", "metrics": {"bleu_score": 20.535052985621373, "chrf_score": 54.42259979938386, "xcomet_score": 0.9296228885650635, "xcomet_qe_score": 0.9521712064743042, "metricx_score": 5.388927936553955, "metricx_qe_score": 4.992667198181152, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Nous l'avons donc conçu pour qu'il dispose d'une sémantique plus précise, de sorte que le modèle puisse effectuer la prédiction correcte.", "metrics": {"bleu_score": 12.962472880491877, "chrf_score": 49.32886515442457, "xcomet_score": 0.9466332197189331, "xcomet_qe_score": 0.9544602632522583, "metricx_score": 1.6653825044631958, "metricx_qe_score": 1.5413858890533447, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, cette étude montre comment les prédictions interprétables nous aident à comprendre le comportement du modèle", "metrics": {"bleu_score": 78.09325628873462, "chrf_score": 93.5589127896898, "xcomet_score": 0.9978306293487549, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.1429829597473145, "metricx_qe_score": 0.8980576395988464, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure notre travail, notre modèle est en fait assez efficace.", "metrics": {"bleu_score": 57.475393483140245, "chrf_score": 78.83479427187108, "xcomet_score": 0.9972312450408936, "xcomet_qe_score": 0.99419105052948, "metricx_score": 1.520257830619812, "metricx_qe_score": 1.7071630954742432, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "et nous sommes en mesure de fournir des procédures d'épargne interprétables", "metrics": {"bleu_score": 38.49742634318482, "chrf_score": 68.39644585808482, "xcomet_score": 0.5329389572143555, "xcomet_qe_score": 0.5474931001663208, "metricx_score": 10.246443748474121, "metricx_qe_score": 8.88819694519043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "et nous pouvons facilement intégrer certaines connaissances antérieures comme contrainte, ce qui peut aider à améliorer les performances", "metrics": {"bleu_score": 14.07008663653591, "chrf_score": 71.36593892190177, "xcomet_score": 0.9601818919181824, "xcomet_qe_score": 0.9397133588790894, "metricx_score": 1.1398793458938599, "metricx_qe_score": 1.4160380363464355, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et la dernière chose est que le mécanisme sous-jacent ne s'applique pas uniquement aux tâches de résolution de problèmes de réseau, mais aussi à d'autres tâches qui impliquent un raisonnement en plusieurs étapes.", "metrics": {"bleu_score": 65.58477295367683, "chrf_score": 89.46776250237585, "xcomet_score": 0.9958618879318237, "xcomet_qe_score": 1.0, "metricx_score": 0.5809659957885742, "metricx_qe_score": 0.7670202255249023, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "mais nous avons également certaines limitations", "metrics": {"bleu_score": 30.213753973567677, "chrf_score": 84.48939323977612, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3532283902168274, "metricx_qe_score": 0.34171804785728455, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée", "metrics": {"bleu_score": 89.42867789154981, "chrf_score": 98.11062135430721, "xcomet_score": 0.9855943918228149, "xcomet_qe_score": 0.9759100675582886, "metricx_score": 1.21998929977417, "metricx_qe_score": 1.2785372734069824, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est que, comme mentionné, parce que la distribution de probabilité est déséquilibrée entre les différentes étapes temporelles, il est également assez difficile d'appliquer des recherches par faisceau.", "metrics": {"bleu_score": 58.38659307501705, "chrf_score": 79.83252527427013, "xcomet_score": 0.8883031606674194, "xcomet_qe_score": 0.9391007423400879, "metricx_score": 2.870096445083618, "metricx_qe_score": 2.9317517280578613, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "Voilà la fin de la conférence et les questions sont les bienvenues. Merci.", "metrics": {"bleu_score": 44.64009548104569, "chrf_score": 58.7103502028591, "xcomet_score": 0.9393696188926697, "xcomet_qe_score": 0.9623950719833374, "metricx_score": 1.2034980058670044, "metricx_qe_score": 0.9499146938323975, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je viens de l'Université de Maastricht.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 90.46894018144044, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.377380132675171, "metricx_qe_score": 0.664887011051178, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter mon travail sur John avec Jerry, qui porte sur un nouveau jeu de données pour la récupération d'articles légaux.", "metrics": {"bleu_score": 29.85114496930219, "chrf_score": 58.828020197010744, "xcomet_score": 0.3006289005279541, "xcomet_qe_score": 0.23721103370189667, "metricx_score": 9.438787460327148, "metricx_qe_score": 9.411137580871582, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les problèmes juridiques font partie intégrante de la vie de nombreuses personnes.", "metrics": {"bleu_score": 84.23626743789745, "chrf_score": 86.06115383670415, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6353251934051514, "metricx_qe_score": 0.46970173716545105, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "mais la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et les processus juridiques fondamentaux", "metrics": {"bleu_score": 56.85488870277223, "chrf_score": 90.40177843143653, "xcomet_score": 0.9693612456321716, "xcomet_qe_score": 0.9778475761413574, "metricx_score": 1.1581387519836426, "metricx_qe_score": 1.1340991258621216, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "En conséquence, de nombreux citoyens vulnérables qui ne peuvent pas se permettre l'assistance coûteuse d'un expert juridique se retrouvent sans protection ou, pire, exploités", "metrics": {"bleu_score": 43.67533980746584, "chrf_score": 71.34914850823908, "xcomet_score": 0.9963549375534058, "xcomet_qe_score": 1.0, "metricx_score": 1.535309076309204, "metricx_qe_score": 1.311374545097351, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Notre travail vise à combler le fossé entre les gens et la loi en développant des systèmes de recherche efficaces pour les articles de loi.", "metrics": {"bleu_score": 41.229744029518166, "chrf_score": 60.50505990784158, "xcomet_score": 0.9680838584899902, "xcomet_qe_score": 0.9740520715713501, "metricx_score": 1.8112835884094238, "metricx_qe_score": 0.994146466255188, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "un tel système pourrait fournir un service d'aide juridique professionnelle gratuit pour les humains non qualifiés", "metrics": {"bleu_score": 46.825687910244035, "chrf_score": 80.31596386138877, "xcomet_score": 0.907966136932373, "xcomet_qe_score": 0.9009053111076355, "metricx_score": 1.6917344331741333, "metricx_qe_score": 1.2145031690597534, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant d'aborder la contribution principale de ce travail, décrivons d'abord le problème de la récupération des articles statutaires", "metrics": {"bleu_score": 15.95705857160047, "chrf_score": 57.893342834770955, "xcomet_score": 0.8379805088043213, "xcomet_qe_score": 0.8765908479690552, "metricx_score": 4.654324054718018, "metricx_qe_score": 2.8761298656463623, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "Une question simple sur une question réelle, par exemple : « À quoi m'expose-je si je viole la confidentialité professionnelle ? »", "metrics": {"bleu_score": 36.343365059404576, "chrf_score": 58.79785454090928, "xcomet_score": 0.737095832824707, "xcomet_qe_score": 0.7058523893356323, "metricx_score": 4.637036323547363, "metricx_qe_score": 5.233200550079346, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "un modèle est nécessaire pour récupérer tous les articles légaux pertinents à partir d'un vaste ensemble de textes législatifs", "metrics": {"bleu_score": 20.038908500140973, "chrf_score": 61.03284957481661, "xcomet_score": 0.9898223876953125, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.5776760578155518, "metricx_qe_score": 1.3315895795822144, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche de recherche d'information comporte son propre ensemble de défis", "metrics": {"bleu_score": 47.41797560818527, "chrf_score": 72.25327282833648, "xcomet_score": 0.9678698778152466, "xcomet_qe_score": 1.0, "metricx_score": 0.8779728412628174, "metricx_qe_score": 0.48467493057250977, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, il traite de deux types de langage", "metrics": {"bleu_score": 47.53852732567741, "chrf_score": 77.29172724666428, "xcomet_score": 0.7586780786514282, "xcomet_qe_score": 0.9729639291763306, "metricx_score": 2.1670761108398438, "metricx_qe_score": 0.8968414664268494, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "langage naturel courant pour les questions et langage juridique complexe pour les statuts", "metrics": {"bleu_score": 30.706596465808243, "chrf_score": 65.23718606590457, "xcomet_score": 0.8450164794921875, "xcomet_qe_score": 0.9040846824645996, "metricx_score": 4.28001594543457, "metricx_qe_score": 3.125528573989868, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence dans les distributions linguistiques rend plus difficile pour un système de retrouver des candidats pertinents, car cela nécessite indirectement un système d'interprétation inhérent capable de traduire une question naturelle en une question juridique correspondant à la terminologie des statuts.", "metrics": {"bleu_score": 70.0282633046773, "chrf_score": 87.48548898469988, "xcomet_score": 0.9539227485656738, "xcomet_qe_score": 0.9813951253890991, "metricx_score": 3.8589816093444824, "metricx_qe_score": 3.374617576599121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "en outre, le droit législatif n'est pas un ensemble d'articles indépendants qui peuvent être traités comme une source d'information complète à eux seuls, contrairement aux actualités ou aux recettes, par exemple", "metrics": {"bleu_score": 49.440093004527334, "chrf_score": 77.20943581760181, "xcomet_score": 0.9496737718582153, "xcomet_qe_score": 0.9732977151870728, "metricx_score": 3.1811025142669678, "metricx_qe_score": 2.3904130458831787, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'agit plutôt d'une collection de dispositions légales qui ne prennent tout leur sens que lorsqu'elles sont examinées dans leur contexte global, c'est-à-dire en tenant compte des informations supplémentaires fournies par les articles voisins, des domaines et sous-domaines auxquels elles appartiennent et de leur place dans la structure de la loi.", "metrics": {"bleu_score": 37.480016178815724, "chrf_score": 72.17713457941127, "xcomet_score": 0.9803476333618164, "xcomet_qe_score": 0.992394208908081, "metricx_score": 0.8610740900039673, "metricx_qe_score": 0.991195559501648, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, les articles légaux sont présentés en petits paragraphes, qui constituent généralement l'unité de récupération typique dans la plupart des travaux de récupération.", "metrics": {"bleu_score": 33.12514805912847, "chrf_score": 69.47363368373962, "xcomet_score": 0.37270301580429077, "xcomet_qe_score": 0.48450011014938354, "metricx_score": 10.182977676391602, "metricx_qe_score": 10.74853229522705, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "ici, ce sont de longs documents qui peuvent atteindre six pages", "metrics": {"bleu_score": 24.70918283591955, "chrf_score": 50.63538168792441, "xcomet_score": 0.8966727256774902, "xcomet_qe_score": 0.848960280418396, "metricx_score": 7.049027442932129, "metricx_qe_score": 6.93743896484375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les récentes avancées en matière de traitement du langage naturel ont suscité un intérêt considérable pour de nombreuses tâches juridiques, telles que la prédiction des jugements juridiques ou l'examen automatisé des contrats.", "metrics": {"bleu_score": 40.45683511534812, "chrf_score": 69.35157418077465, "xcomet_score": 0.9298486709594727, "xcomet_qe_score": 0.9756604433059692, "metricx_score": 1.1736202239990234, "metricx_qe_score": 0.7892859578132629, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la récupération d'articles légaux est restée principalement en suspens en raison du manque de grands ensembles de données étiquetées de haute qualité.", "metrics": {"bleu_score": 37.87865612579482, "chrf_score": 62.5064002322048, "xcomet_score": 0.6308994293212891, "xcomet_qe_score": 0.7076961994171143, "metricx_score": 5.4709672927856445, "metricx_qe_score": 3.946582317352295, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette étude, nous présentons un nouveau jeu de données centré sur les citoyens français natifs afin d'étudier si un modèle de recherche peut s'approcher de l'efficacité et de la fiabilité d'un expert juridique pour la tâche de recherche d'articles légaux.", "metrics": {"bleu_score": 32.28414137011352, "chrf_score": 64.02136048705283, "xcomet_score": 0.8161593079566956, "xcomet_qe_score": 0.8408983945846558, "metricx_score": 5.719383239746094, "metricx_qe_score": 4.778692245483398, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "ou l'ensemble de données d'extraction d'articles légaux belges z. comprend plus de mille cent.", "metrics": {"bleu_score": 12.22123867456877, "chrf_score": 41.44006202283444, "xcomet_score": 0.14149127900600433, "xcomet_qe_score": 0.1414717584848404, "metricx_score": 20.479768753051758, "metricx_qe_score": 22.60132598876953, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "ces questions couvrent un large éventail de sujets, allant du logement familial et de l'argent au travail et à la sécurité sociale", "metrics": {"bleu_score": 31.822083427452363, "chrf_score": 69.82901545744414, "xcomet_score": 0.930309534072876, "xcomet_qe_score": 0.9394793510437012, "metricx_score": 2.3786134719848633, "metricx_qe_score": 1.464342474937439, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "chacun d’eux a été étiqueté par des juristes expérimentés avec des références aux articles pertinents d’un corpus de plus de vingt-deux mille six cents", "metrics": {"bleu_score": 38.020578118350976, "chrf_score": 65.12443576066576, "xcomet_score": 0.43629688024520874, "xcomet_qe_score": 0.5053203105926514, "metricx_score": 10.34770393371582, "metricx_qe_score": 9.345327377319336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Codes de droit belges. Ne parlons pas de la manière dont nous avons collecté ces ensembles de données.", "metrics": {"bleu_score": 22.97523682812302, "chrf_score": 56.26377618326893, "xcomet_score": 0.1569221019744873, "xcomet_qe_score": 0.1468527615070343, "metricx_score": 21.86835289001465, "metricx_qe_score": 22.762836456298828, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons commencé par constituer un vaste corpus d'articles juridiques", "metrics": {"bleu_score": 18.30054742374001, "chrf_score": 64.03664408425941, "xcomet_score": 0.9861669540405273, "xcomet_qe_score": 1.0, "metricx_score": 1.1236646175384521, "metricx_qe_score": 0.8396791219711304, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons examiné trente-deux codes belges accessibles au public et extrait tous leurs articles ainsi que les titres de sections correspondants", "metrics": {"bleu_score": 73.62853809865184, "chrf_score": 94.62054490935675, "xcomet_score": 0.9949190616607666, "xcomet_qe_score": 0.9953182935714722, "metricx_score": 1.9097084999084473, "metricx_qe_score": 1.717905044555664, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "ensuite, nous avons rassemblé des questions juridiques avec des références aux lois pertinentes", "metrics": {"bleu_score": 40.73224091836954, "chrf_score": 89.08279094069914, "xcomet_score": 0.9868036508560181, "xcomet_qe_score": 0.9807731509208679, "metricx_score": 1.2869144678115845, "metricx_qe_score": 1.4529129266738892, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous collaborons avec un cabinet d'avocats belge qui reçoit chaque année environ quatre mille courriels de citoyens belges qui demandent des conseils sur une question juridique personnelle.", "metrics": {"bleu_score": 72.98926162113918, "chrf_score": 87.18777751759065, "xcomet_score": 0.9973171949386597, "xcomet_qe_score": 1.0, "metricx_score": 0.5833123922348022, "metricx_qe_score": 0.5474573969841003, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance d'accéder à leurs sites web où leur équipe de juristes expérimentés aborde les problèmes juridiques les plus courants en Belgique.", "metrics": {"bleu_score": 50.70283593483281, "chrf_score": 76.13768280568026, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.439666509628296, "metricx_qe_score": 1.8814411163330078, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons collecté des milliers de questions annotées avec des catégories, des sous-catégories et des références légales aux statuts pertinents.", "metrics": {"bleu_score": 65.97618889159988, "chrf_score": 77.44932833305067, "xcomet_score": 0.9902164936065674, "xcomet_qe_score": 1.0, "metricx_score": 2.922173023223877, "metricx_qe_score": 1.541303277015686, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons passé en revue les références légales et éliminé les questions dont les références n'étaient pas des articles dans l'un des codes de droit que nous avions considérés.", "metrics": {"bleu_score": 63.37609478527905, "chrf_score": 80.23434252253915, "xcomet_score": 0.9467479586601257, "xcomet_qe_score": 0.9429582357406616, "metricx_score": 1.5866190195083618, "metricx_qe_score": 1.973999261856079, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "les références restantes ont été mises en correspondance et converties en les identifiants d'article correspondants du corpus O", "metrics": {"bleu_score": 22.250253290431033, "chrf_score": 73.45791674205046, "xcomet_score": 0.8608300685882568, "xcomet_qe_score": 0.8633929491043091, "metricx_score": 4.104899883270264, "metricx_qe_score": 1.63235604763031, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "nous avons finalement obtenu mille cent huit questions, chacune soigneusement étiquetée avec les idées des articles pertinents de", "metrics": {"bleu_score": 28.94576198953866, "chrf_score": 52.06397859575236, "xcomet_score": 0.24489665031433105, "xcomet_qe_score": 0.2504957616329193, "metricx_score": 16.596967697143555, "metricx_qe_score": 14.037785530090332, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "en outre, chaque question est accompagnée d'une catégorie principale et d'une concaténation de sous-catégories", "metrics": {"bleu_score": 31.645000185694006, "chrf_score": 73.51177885347087, "xcomet_score": 0.9270904064178467, "xcomet_qe_score": 0.9376360177993774, "metricx_score": 5.827066421508789, "metricx_qe_score": 5.959730625152588, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "et chaque article est accompagné d'une concaténation de leur sous-titre dans la structure de la loi", "metrics": {"bleu_score": 30.798976455759156, "chrf_score": 50.326943562935654, "xcomet_score": 0.6548892259597778, "xcomet_qe_score": 0.7609901428222656, "metricx_score": 8.430442810058594, "metricx_qe_score": 8.00194263458252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "ces informations supplémentaires ne sont pas utilisées dans le présent travail, mais pourraient être d'intérêt pour des recherches futures sur la recherche d'informations juridiques ou la classification de textes juridiques", "metrics": {"bleu_score": 69.74704001812898, "chrf_score": 86.98373307526415, "xcomet_score": 0.9802793264389038, "xcomet_qe_score": 0.983550488948822, "metricx_score": 1.375548243522644, "metricx_qe_score": 0.6682063341140747, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons certaines caractéristiques de tous les ensembles de données", "metrics": {"bleu_score": 15.270725349716185, "chrf_score": 59.854880734478535, "xcomet_score": 0.566673755645752, "xcomet_qe_score": 0.8337976932525635, "metricx_score": 5.433248043060303, "metricx_qe_score": 5.823047161102295, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "le questionnaire entre cinq et quarante-quatre mots de long avec une médiane de quarante", "metrics": {"bleu_score": 29.43543418414033, "chrf_score": 58.396513394165105, "xcomet_score": 0.3436095118522644, "xcomet_qe_score": 0.5255682468414307, "metricx_score": 15.692755699157715, "metricx_qe_score": 14.327571868896484, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont beaucoup plus longs, avec une longueur médiane de 77 mots, pour 140", "metrics": {"bleu_score": 27.18657914941594, "chrf_score": 42.96531636593385, "xcomet_score": 0.21484839916229248, "xcomet_qe_score": 0.2580130100250244, "metricx_score": 11.779375076293945, "metricx_qe_score": 7.170562744140625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "deux d'entre eux, dépassant un pouce.", "metrics": {"bleu_score": 3.3495035708457803, "chrf_score": 11.717508127995412, "xcomet_score": 0.1300317943096161, "xcomet_qe_score": 0.117982879281044, "metricx_score": 25.0, "metricx_qe_score": 24.13766098022461, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "comme mentionné précédemment, la question portait sur un large éventail de sujets, dont environ quatre-vingt-cinq pour cent concernaient soit le logement familial, soit l'argent ou la justice", "metrics": {"bleu_score": 38.22359359857401, "chrf_score": 72.64343068785622, "xcomet_score": 0.727336049079895, "xcomet_qe_score": 0.7716317176818848, "metricx_score": 5.571679592132568, "metricx_qe_score": 5.612520217895508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que les quinze pour cent restants concernent soit la sécurité sociale, les étrangers ou le travail", "metrics": {"bleu_score": 77.7811122305422, "chrf_score": 91.19075780992256, "xcomet_score": 0.9626003503799438, "xcomet_qe_score": 0.9567838907241821, "metricx_score": 1.3187015056610107, "metricx_qe_score": 2.080857038497925, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très divers, car ils proviennent de 32 codes belges différents qui couvrent un grand nombre de sujets juridiques.", "metrics": {"bleu_score": 51.02002548573252, "chrf_score": 77.11398468633138, "xcomet_score": 0.9291741847991943, "xcomet_qe_score": 0.9881991147994995, "metricx_score": 1.239342212677002, "metricx_qe_score": 0.9468382000923157, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles collectés pour chacun de ces codes belges", "metrics": {"bleu_score": 57.23320664346175, "chrf_score": 83.10664416091994, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2891660928726196, "metricx_qe_score": 2.0431833267211914, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "sur les vingt-deux mille six cent trente-trois articles, seulement mille six cent douze sont considérés comme pertinents pour au moins", "metrics": {"bleu_score": 41.930517167115454, "chrf_score": 71.40068067041912, "xcomet_score": 0.40827852487564087, "xcomet_qe_score": 0.6615285277366638, "metricx_score": 9.899620056152344, "metricx_qe_score": 6.70725679397583, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "Une question dans l'ensemble de données, et environ quatre-vingts pour cent de ces articles cités proviennent soit des tribunaux civils, des tribunaux judiciaires, des tribunaux d'instruction pénale ou des tribunaux pénaux.", "metrics": {"bleu_score": 30.747623446144537, "chrf_score": 61.72355608855911, "xcomet_score": 0.28053635358810425, "xcomet_qe_score": 0.2624058127403259, "metricx_score": 13.383772850036621, "metricx_qe_score": 14.760987281799316, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "par ailleurs, dix-huit des trente-deux codes ont moins de cinq articles mentionnés comme pertinents pour au moins une question", "metrics": {"bleu_score": 80.66357446243076, "chrf_score": 88.30313201895734, "xcomet_score": 0.9566419124603271, "xcomet_qe_score": 0.9530729651451111, "metricx_score": 1.2535614967346191, "metricx_qe_score": 2.219611406326294, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "ce qui peut s'expliquer par le fait que le code se concentre moins sur les individus et leurs préoccupations", "metrics": {"bleu_score": 59.509221134368715, "chrf_score": 83.30099723450921, "xcomet_score": 0.8741345405578613, "xcomet_qe_score": 0.7524124383926392, "metricx_score": 3.864744186401367, "metricx_qe_score": 3.4795899391174316, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "globalement, le nombre médian de citations pour ces articles cités est de deux et moins de 25 % d'entre eux sont", "metrics": {"bleu_score": 35.984513069397295, "chrf_score": 56.03887966854925, "xcomet_score": 0.4573037028312683, "xcomet_qe_score": 0.6038770079612732, "metricx_score": 14.989883422851562, "metricx_qe_score": 14.68468189239502, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "À l'aide de nos ensembles de données, nous évaluons plusieurs approches de récupération, y compris l'architecture lexicale et dense", "metrics": {"bleu_score": 36.651343611373036, "chrf_score": 64.99191826390346, "xcomet_score": 0.7090654373168945, "xcomet_qe_score": 0.80159592628479, "metricx_score": 4.149477481842041, "metricx_qe_score": 5.593871593475342, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "étant donné une requête dans un article, un modèle lexical attribue un score à la paire requête-article en calculant la somme des poids de chacun de ces termes dans cet article", "metrics": {"bleu_score": 57.63286428014349, "chrf_score": 79.12940681334608, "xcomet_score": 0.8559203147888184, "xcomet_qe_score": 0.8341212272644043, "metricx_score": 4.1775712966918945, "metricx_qe_score": 4.406031608581543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons les fonctions de classement standard tf-idf et bm vingt-cinq", "metrics": {"bleu_score": 27.376780981812882, "chrf_score": 66.08071739115921, "xcomet_score": 0.7258385419845581, "xcomet_qe_score": 0.7572401762008667, "metricx_score": 4.804607391357422, "metricx_qe_score": 5.727284908294678, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème avec ces approches est qu'elles ne peuvent récupérer que les articles contenant des mots-clés présents dans la requête", "metrics": {"bleu_score": 69.05652100281736, "chrf_score": 86.93307876343806, "xcomet_score": 0.9932156801223755, "xcomet_qe_score": 1.0, "metricx_score": 0.9509255886077881, "metricx_qe_score": 0.957878053188324, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour surmonter cette limitation, nous expérimentons une architecture basée sur les réseaux de neurones qui peut capturer les relations sémantiques entre les requêtes et les articles", "metrics": {"bleu_score": 62.18522253057098, "chrf_score": 89.0372820627135, "xcomet_score": 0.9831080436706543, "xcomet_qe_score": 0.9624001383781433, "metricx_score": 0.8435445427894592, "metricx_qe_score": 1.1996687650680542, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle de type biancode qui associe des requêtes et des articles à des représentations vectorielles denses et calcule un score de pertinence entre une paire de requêtes et d'articles en fonction de la similarité de leurs intégrations.", "metrics": {"bleu_score": 29.988225847344523, "chrf_score": 72.05696567781479, "xcomet_score": 0.747123658657074, "xcomet_qe_score": 0.7933956384658813, "metricx_score": 6.977556228637695, "metricx_qe_score": 6.9608073234558105, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces intégrations résultent généralement d'une opération de pooling sur la sortie d'un modèle d'intégration de mots", "metrics": {"bleu_score": 76.59552353576204, "chrf_score": 90.12101760430171, "xcomet_score": 0.8640254735946655, "xcomet_qe_score": 0.7474201917648315, "metricx_score": 3.410921096801758, "metricx_qe_score": 6.701174259185791, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous étudions l'efficacité des codeurs binaires de type Siamese dans un cadre d'évaluation sans apprentissage préalable, ce qui signifie que les modèles d'intégration de Wood pré-entraînés sont appliqués tels quels, sans aucun réglage fin supplémentaire.", "metrics": {"bleu_score": 29.588994069727793, "chrf_score": 62.42094585887499, "xcomet_score": 0.6715598106384277, "xcomet_qe_score": 0.7331336736679077, "metricx_score": 5.115425109863281, "metricx_qe_score": 4.205368518829346, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec un encodeur de texte indépendant du contexte, à savoir Word2Vec et FastText, et des modèles d'intégration dépendants du contexte, à savoir Roberta et plus spécifiquement Camembert, qui est un modèle Roberta français.", "metrics": {"bleu_score": 67.05803488125281, "chrf_score": 85.15360702499262, "xcomet_score": 0.9830435514450073, "xcomet_qe_score": 0.986862063407898, "metricx_score": 3.132143020629883, "metricx_qe_score": 2.7048158645629883, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous formons notre propre modèle basé sur le camembert au-delà des codeurs.", "metrics": {"bleu_score": 23.39447254031161, "chrf_score": 48.714818859262884, "xcomet_score": 0.46372416615486145, "xcomet_qe_score": 0.3163881301879883, "metricx_score": 14.067811965942383, "metricx_qe_score": 12.657811164855957, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "Sur tous les ensembles de données, notez que pour l'entraînement, nous expérimentons avec les deux variantes de l'architecture Biancoro", "metrics": {"bleu_score": 27.653555158457866, "chrf_score": 63.12968678752121, "xcomet_score": 0.3030892312526703, "xcomet_qe_score": 0.35103413462638855, "metricx_score": 9.476529121398926, "metricx_qe_score": 9.348594665527344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "siaméen qui utilise un modèle unique d'encodage des mots qui mappe la requête et l'article ensemble dans un espace vectoriel dense partagé, et two tower qui utilise deux modèles d'encodage des mots indépendants qui encodent la requête et l'article séparément dans différents espaces d'encodage", "metrics": {"bleu_score": 40.186413426165274, "chrf_score": 64.81307329815839, "xcomet_score": 0.4732433259487152, "xcomet_qe_score": 0.561267614364624, "metricx_score": 6.508950710296631, "metricx_qe_score": 6.025548458099365, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec le pooling de moyenne, de maximum et de cls, ainsi qu'avec le produit scalaire et le cosinus pour calculer les similarités", "metrics": {"bleu_score": 15.288008279464082, "chrf_score": 60.40171737005495, "xcomet_score": 0.5816935300827026, "xcomet_qe_score": 0.5793683528900146, "metricx_score": 6.660017967224121, "metricx_qe_score": 6.6758646965026855, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre modèle de base sur l'ensemble de test.", "metrics": {"bleu_score": 17.99653127176589, "chrf_score": 67.51494470904892, "xcomet_score": 0.8246839046478271, "xcomet_qe_score": 0.7405568361282349, "metricx_score": 2.430752754211426, "metricx_qe_score": 2.385406732559204, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "Avec les méthodes lexicales ci-dessus, les codeurs de balises siamois ont été évalués dans un cadre zéro-shot au milieu, et les codeurs de balises affinés ci-dessous.", "metrics": {"bleu_score": 36.20300046351118, "chrf_score": 68.672880221259, "xcomet_score": 0.430449903011322, "xcomet_qe_score": 0.5367016792297363, "metricx_score": 6.199380397796631, "metricx_qe_score": 7.9641618728637695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, les bianchors finement réglés surpassent de manière significative toutes les autres lignes de basse.", "metrics": {"bleu_score": 34.57913759237496, "chrf_score": 67.25271342835455, "xcomet_score": 0.5875217914581299, "xcomet_qe_score": 0.47856518626213074, "metricx_score": 11.13812255859375, "metricx_qe_score": 10.240055084228516, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "le modèle à deux tours est meilleur que sa variante siamoise en termes de rappel à cent, mais il a des performances similaires sur les autres métriques", "metrics": {"bleu_score": 24.688533095200516, "chrf_score": 48.8549568157033, "xcomet_score": 0.6643694639205933, "xcomet_qe_score": 0.35547977685928345, "metricx_score": 3.371462345123291, "metricx_qe_score": 5.769833087921143, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que B M twenty five ait eu des performances inférieures à celles du train de manière significative, ses performances indiquent qu'il s'agit toujours d'une référence solide pour la récupération spécifique au domaine.", "metrics": {"bleu_score": 39.209056551646675, "chrf_score": 71.14290082612882, "xcomet_score": 0.4903203248977661, "xcomet_qe_score": 0.38223686814308167, "metricx_score": 9.345216751098633, "metricx_qe_score": 9.345762252807617, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation sans entraînement préalable du Siamese Bian Coder, nous constatons que l'utilisation directe des intégrations d'un modèle Camambert pré-entraîné sans optimisation pour la tâche de recherche d'information donne de mauvais résultats, ce qui est conforme aux résultats précédents.", "metrics": {"bleu_score": 46.43980473762534, "chrf_score": 69.56395318597215, "xcomet_score": 0.7727220058441162, "xcomet_qe_score": 0.7055943012237549, "metricx_score": 5.278829574584961, "metricx_qe_score": 5.647521018981934, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "en outre, nous observons que le modèle basé sur les mots biancoder a largement surpassé le modèle rapide basé sur les mots et les verbes, ce qui suggère que les représentations de mots pré-entraînées sont peut-être plus appropriées pour la tâche que les représentations de caractères ou de sous-mots lorsqu'elles sont utilisées telles quelles", "metrics": {"bleu_score": 23.551249700272884, "chrf_score": 49.718288238229825, "xcomet_score": 0.1895487755537033, "xcomet_qe_score": 0.2433718740940094, "metricx_score": 12.209071159362793, "metricx_qe_score": 11.544166564941406, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que prometteurs, ces résultats laissent entrevoir de nombreuses possibilités d'amélioration par rapport à un expert qualifié qui peut, en fin de compte, retrouver tous les articles pertinents à toute question et ainsi obtenir des scores parfaits.", "metrics": {"bleu_score": 45.65548562636216, "chrf_score": 71.43883147309968, "xcomet_score": 0.9943903684616089, "xcomet_qe_score": 1.0, "metricx_score": 1.6244733333587646, "metricx_qe_score": 2.02797794342041, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Concluons en discutant de deux limites de tous les ensembles de données", "metrics": {"bleu_score": 53.3167536340577, "chrf_score": 81.47317091670662, "xcomet_score": 0.8274081945419312, "xcomet_qe_score": 0.8341712355613708, "metricx_score": 4.016845226287842, "metricx_qe_score": 2.419203042984009, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, le corpus de l'article est limité à ceux recueillis à partir des trente-deux codes belges considérés, ce qui ne couvre pas l'ensemble du droit belge, car les articles des décrets, directives et ordonnances sont absents.", "metrics": {"bleu_score": 68.76332928842052, "chrf_score": 83.23868987304269, "xcomet_score": 0.7443678975105286, "xcomet_qe_score": 0.7788827419281006, "metricx_score": 3.7591283321380615, "metricx_qe_score": 3.719470977783203, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Lors de la construction du jeu de données, toutes les références à ces articles non collectés sont ignorées, ce qui fait que certaines questions se retrouvent avec seulement une fraction de leur nombre initial d'articles pertinents.", "metrics": {"bleu_score": 63.17797103753847, "chrf_score": 87.24270827227943, "xcomet_score": 0.9381119012832642, "xcomet_qe_score": 0.9454561471939087, "metricx_score": 2.5592041015625, "metricx_qe_score": 2.8172450065612793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cette perte d'information implique que la réponse contenue dans les articles pertinents restants pourrait être incomplète, bien qu'elle soit toujours tout à fait appropriée.", "metrics": {"bleu_score": 68.87246539984304, "chrf_score": 89.37236228825259, "xcomet_score": 0.9688940644264221, "xcomet_qe_score": 0.9670678377151489, "metricx_score": 2.134427785873413, "metricx_qe_score": 1.8046678304672241, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, il convient de noter que toutes les questions juridiques ne peuvent pas être résolues uniquement avec des textes de loi.", "metrics": {"bleu_score": 34.1191474032336, "chrf_score": 71.79084061552231, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2710362672805786, "metricx_qe_score": 1.6332476139068604, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question peut-on expulser mes locataires s'ils font trop de bruit", "metrics": {"bleu_score": 63.160377007081344, "chrf_score": 83.59018732066032, "xcomet_score": 0.9058246612548828, "xcomet_qe_score": 0.9150723218917847, "metricx_score": 4.625942707061768, "metricx_qe_score": 4.151607513427734, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "il se peut qu'il n'existe pas de réponse détaillée dans le droit statutaire qui quantifie un seuil sonore spécifique à partir duquel un expulsion est autorisée", "metrics": {"bleu_score": 39.392661757434155, "chrf_score": 72.25873712217775, "xcomet_score": 0.9207472801208496, "xcomet_qe_score": 0.8817139267921448, "metricx_score": 4.406521797180176, "metricx_qe_score": 5.036386013031006, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "À la place, le propriétaire devrait probablement s'appuyer davantage sur la jurisprudence et trouver des précédents similaires à sa situation actuelle.", "metrics": {"bleu_score": 70.64427343447376, "chrf_score": 88.51798276250118, "xcomet_score": 0.999651312828064, "xcomet_qe_score": 0.9977333545684814, "metricx_score": 1.5504958629608154, "metricx_qe_score": 1.708451271057129, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le locataire fait deux soirées par semaine jusqu'à 2 heures du matin.", "metrics": {"bleu_score": 25.57291360727664, "chrf_score": 64.40602718995356, "xcomet_score": 0.914985179901123, "xcomet_qe_score": 0.8527895212173462, "metricx_score": 4.229057788848877, "metricx_qe_score": 2.0371150970458984, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "certaines questions sont donc plus adaptées que d'autres à la tâche de récupération d'articles légaux et le domaine de celles qui sont moins adaptées reste à déterminer", "metrics": {"bleu_score": 37.427025622964365, "chrf_score": 68.52135626789958, "xcomet_score": 0.8457965850830078, "xcomet_qe_score": 0.6063638925552368, "metricx_score": 4.103796005249023, "metricx_qe_score": 4.1393723487854, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que tous les travaux susciteront un intérêt pour le développement de modèles de récupération d'articles légaux pratiques et fiables", "metrics": {"bleu_score": 14.962848372546674, "chrf_score": 65.98503613939639, "xcomet_score": 0.733212411403656, "xcomet_qe_score": 0.7117365002632141, "metricx_score": 6.345523834228516, "metricx_qe_score": 5.966114521026611, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "qui peuvent contribuer à améliorer l'accès à la justice fold", "metrics": {"bleu_score": 42.326181966045375, "chrf_score": 62.209083237500536, "xcomet_score": 0.18639492988586426, "xcomet_qe_score": 0.1693081259727478, "metricx_score": 13.604455947875977, "metricx_qe_score": 5.985690593719482, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "vous pouvez consulter notre article qui est encodée aux liens suivants merci", "metrics": {"bleu_score": 20.213298080616212, "chrf_score": 64.29536794368553, "xcomet_score": 0.6652390956878662, "xcomet_qe_score": 0.6096569299697876, "metricx_score": 8.137829780578613, "metricx_qe_score": 9.54688549041748, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "bonjour nous sommes heureux de présenter notre travail sur les voyelles une tâche de référence indépendante destinée à tester la vision et les modèles de langage avec des phénomènes linguistiques spécifiques", "metrics": {"bleu_score": 28.464631967058317, "chrf_score": 74.8628934982051, "xcomet_score": 0.5659687519073486, "xcomet_qe_score": 0.513198733329773, "metricx_score": 8.39102554321289, "metricx_qe_score": 8.129833221435547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "pourquoi avons-nous rencontré des difficultés à établir ce benchmark", "metrics": {"bleu_score": 2.7354882120611315, "chrf_score": 35.56836524296906, "xcomet_score": 0.2688888609409332, "xcomet_qe_score": 0.47849032282829285, "metricx_score": 16.815105438232422, "metricx_qe_score": 8.71906852722168, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Ces dernières années, nous avons assisté à une explosion de modèles de vision et de langage basés sur des transformateurs, pré-entraînés sur de grandes quantités de paires d'images et de textes.", "metrics": {"bleu_score": 30.09813629232826, "chrf_score": 68.35200434682959, "xcomet_score": 0.9579936265945435, "xcomet_qe_score": 0.9881632328033447, "metricx_score": 2.60237979888916, "metricx_qe_score": 2.3988282680511475, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "chacun de ces modèles repousse l'état de l'art sur les tâches de vision et de langage telles que la réponse à des questions visuelles, le raisonnement de bon sens visuel, la récupération d'images et l'ancrage de phrases", "metrics": {"bleu_score": 44.01481296079652, "chrf_score": 72.89362814909418, "xcomet_score": 0.4561558961868286, "xcomet_qe_score": 0.5893778800964355, "metricx_score": 5.36284875869751, "metricx_qe_score": 5.074800968170166, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "nous avons donc reçu un message indiquant que les précisions sur ces références spécifiques aux tâches augmentent régulièrement", "metrics": {"bleu_score": 32.31584890499715, "chrf_score": 77.38032848671665, "xcomet_score": 0.9061344861984253, "xcomet_qe_score": 0.7114476561546326, "metricx_score": 5.974836349487305, "metricx_qe_score": 6.928281307220459, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "mais savons-nous ce que les modèles ont réellement appris", "metrics": {"bleu_score": 77.25505949016376, "chrf_score": 96.18954000118175, "xcomet_score": 0.951722264289856, "xcomet_qe_score": 0.9632534384727478, "metricx_score": 1.656081199645996, "metricx_qe_score": 2.0039584636688232, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "qu'est-ce qu'un transformateur de vision et de langage a compris lorsqu'il a attribué un score élevé à cette image et à cette phrase pour qu'elles correspondent", "metrics": {"bleu_score": 10.754672770161264, "chrf_score": 69.16427628147541, "xcomet_score": 0.7864087820053101, "xcomet_qe_score": 0.6370932459831238, "metricx_score": 2.822453022003174, "metricx_qe_score": 3.347696304321289, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "et un faible score pour celui-ci", "metrics": {"bleu_score": 8.170609724417774, "chrf_score": 45.070626534737606, "xcomet_score": 0.9186477065086365, "xcomet_qe_score": 0.9125261306762695, "metricx_score": 3.923271656036377, "metricx_qe_score": 2.801985740661621, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur la bonne chose ?", "metrics": {"bleu_score": 32.281751885843555, "chrf_score": 68.20305147191763, "xcomet_score": 0.7724132537841797, "xcomet_qe_score": 0.7463480830192566, "metricx_score": 1.717067003250122, "metricx_qe_score": 2.1995620727539062, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "ou se concentrent-ils sur les biais tels que démontrés par les travaux antérieurs", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 64.2430880206323, "xcomet_score": 0.9794167280197144, "xcomet_qe_score": 0.9763724207878113, "metricx_score": 1.2386243343353271, "metricx_qe_score": 1.473004698753357, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour éclairer davantage cet aspect, nous proposons une approche plus indépendante de la tâche et introduisons des voyelles qui testent la sensibilité de la vision et des modèles linguistiques à des phénomènes linguistiques spécifiques qui affectent à la fois les modalités linguistiques et visuelles.", "metrics": {"bleu_score": 48.19751102251434, "chrf_score": 80.18083805508081, "xcomet_score": 0.559384822845459, "xcomet_qe_score": 0.626939058303833, "metricx_score": 6.360577583312988, "metricx_qe_score": 5.7070746421813965, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la référence aux entités.", "metrics": {"bleu_score": 80.03526445867712, "chrf_score": 88.50540031095565, "xcomet_score": 0.8606103658676147, "xcomet_qe_score": 0.9594275951385498, "metricx_score": 2.5848708152770996, "metricx_qe_score": 4.343854904174805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "mais comment testons-nous si les modèles de vision et de langage ont capturé ces phénomènes", "metrics": {"bleu_score": 23.014755887080998, "chrf_score": 71.8348139470834, "xcomet_score": 0.9210010170936584, "xcomet_qe_score": 0.9094798564910889, "metricx_score": 2.0803096294403076, "metricx_qe_score": 2.4167065620422363, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "en déjouant une méthode précédemment appliquée uniquement aux modèles de vision et de langage pour les phrases nominales par Ravi Shekar et ses collaborateurs, et sur le comptage par nous dans des travaux antérieurs", "metrics": {"bleu_score": 20.486922663504735, "chrf_score": 66.68989403708147, "xcomet_score": 0.6952779293060303, "xcomet_qe_score": 0.7851017713546753, "metricx_score": 4.809170722961426, "metricx_qe_score": 4.374537944793701, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Le \"foiling\" signifie essentiellement que l'on prend la légende d'une image et produit une fausse légende en modifiant la légende de manière à ce qu'elle ne décrit plus l'image.", "metrics": {"bleu_score": 30.935276471311436, "chrf_score": 68.65402351109383, "xcomet_score": 0.8872847557067871, "xcomet_qe_score": 0.9456135630607605, "metricx_score": 3.7844791412353516, "metricx_qe_score": 3.650496482849121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous effectuons ces modifications de phrases en nous concentrant sur six éléments spécifiques tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la coréférence d'entité, où chaque élément peut consister en un ou plusieurs instruments au cas où nous trouverions plus d'une manière intéressante de créer des instances de contre-exemple.", "metrics": {"bleu_score": 72.913961244714, "chrf_score": 86.08446847609174, "xcomet_score": 0.6250752210617065, "xcomet_qe_score": 0.5483437776565552, "metricx_score": 4.998831748962402, "metricx_qe_score": 4.318718910217285, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "par exemple, dans le cas de la pièce d'action, nous avons deux instruments, l'un dans lequel le verbe d'action est remplacé par une action différente et l'autre dans lequel les actants sont échangés", "metrics": {"bleu_score": 45.555046063640305, "chrf_score": 73.81615841685041, "xcomet_score": 0.5410177707672119, "xcomet_qe_score": 0.5002923011779785, "metricx_score": 5.25455379486084, "metricx_qe_score": 5.489218711853027, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la coréférence sont également des pièces qui comportent plus d'un instrument", "metrics": {"bleu_score": 52.960749334062214, "chrf_score": 71.47708400398481, "xcomet_score": 0.7564407587051392, "xcomet_qe_score": 0.7376058101654053, "metricx_score": 4.6887359619140625, "metricx_qe_score": 4.6524658203125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "et nous créons ces faux par le fait de nous assurer qu'ils ne parviennent pas à décrire l'image qu'ils sont des phrases grammaticalement et autrement valides", "metrics": {"bleu_score": 14.474615329145799, "chrf_score": 67.54471036624113, "xcomet_score": 0.5161283612251282, "xcomet_qe_score": 0.40197888016700745, "metricx_score": 9.717602729797363, "metricx_qe_score": 8.098342895507812, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "ce n'est pas facile à faire parce qu'une légende annulée est peut-être moins probable que la légende originale", "metrics": {"bleu_score": 38.139930563272145, "chrf_score": 72.94472515876382, "xcomet_score": 0.763564944267273, "xcomet_qe_score": 0.6664490699768066, "metricx_score": 6.590104103088379, "metricx_qe_score": 6.797117233276367, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien que ce ne soit pas impossible, il est statistiquement moins probable qu'une plante coupe un homme qu'un homme coupe des plantes, et les grands modèles de vision et de langage pourraient s'en rendre compte.", "metrics": {"bleu_score": 53.61806810457202, "chrf_score": 78.13104091601005, "xcomet_score": 0.785429060459137, "xcomet_qe_score": 0.7641260027885437, "metricx_score": 2.3604583740234375, "metricx_qe_score": 2.572516918182373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour obtenir des lames valides, nous devons agir", "metrics": {"bleu_score": 67.61304462994481, "chrf_score": 86.48569415586867, "xcomet_score": 0.7903537750244141, "xcomet_qe_score": 0.8168827891349792, "metricx_score": 3.2311086654663086, "metricx_qe_score": 2.746509552001953, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous utilisons des modèles linguistiques puissants pour proposer des contre-exemples", "metrics": {"bleu_score": 49.588554702454445, "chrf_score": 70.89046956573085, "xcomet_score": 0.95198655128479, "xcomet_qe_score": 0.9464902877807617, "metricx_score": 3.319312810897827, "metricx_qe_score": 0.9303455352783203, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence en langage naturel ou NLI court pour filtrer les folios qui pourraient encore décrire l'image, car lors de la construction des folios, nous devons nous assurer qu'ils ne parviennent pas à décrire l'image.", "metrics": {"bleu_score": 54.78081726007865, "chrf_score": 81.06470255961152, "xcomet_score": 0.6563316583633423, "xcomet_qe_score": 0.7070000171661377, "metricx_score": 10.191572189331055, "metricx_qe_score": 10.527076721191406, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Pour tester cela automatiquement, nous appliquons une inférence de langage naturel avec la logique suivante", "metrics": {"bleu_score": 40.70672072665171, "chrf_score": 71.45870135326136, "xcomet_score": 0.988895058631897, "xcomet_qe_score": 0.9941092729568481, "metricx_score": 1.636151671409607, "metricx_qe_score": 1.1987577676773071, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "Nous considérons une image comme la prémisse et sa légende comme son hypothèse impliquée", "metrics": {"bleu_score": 34.98761149110957, "chrf_score": 75.1372175298362, "xcomet_score": 0.9952458143234253, "xcomet_qe_score": 0.995004415512085, "metricx_score": 1.393205165863037, "metricx_qe_score": 1.5000396966934204, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "en outre, nous considérons que la légende est la prémisse et le feuil est son hypothèse", "metrics": {"bleu_score": 25.632730096634397, "chrf_score": 73.10787783340682, "xcomet_score": 0.679011344909668, "xcomet_qe_score": 0.4184677302837372, "metricx_score": 6.749786376953125, "metricx_qe_score": 7.70982027053833, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit qu'une contre-exemple contredit ou est neutre par rapport à la légende, nous considérons cela comme un indicateur d'un contre-exemple valide.", "metrics": {"bleu_score": 57.71027831205723, "chrf_score": 71.9430721956007, "xcomet_score": 0.6134360432624817, "xcomet_qe_score": 0.5158161520957947, "metricx_score": 10.705031394958496, "metricx_qe_score": 7.760312557220459, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si une NLI prédit que le contre-exemple est impliqué par la légende, il ne peut pas être un bon contre-exemple, car par transitivité, il donnera une description vraie de l'image et nous filtrons ces contre-exemples.", "metrics": {"bleu_score": 45.17515570981023, "chrf_score": 65.6726015063789, "xcomet_score": 0.45713990926742554, "xcomet_qe_score": 0.5067688822746277, "metricx_score": 7.510293483734131, "metricx_qe_score": 6.461162090301514, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "mais cette procédure n'est pas parfaite, elle n'est qu'un indicateur pour les lames valides", "metrics": {"bleu_score": 37.03014567724628, "chrf_score": 68.7422419662794, "xcomet_score": 0.7759346961975098, "xcomet_qe_score": 0.7083078026771545, "metricx_score": 2.8183064460754395, "metricx_qe_score": 1.8816170692443848, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, comme troisième mesure pour générer des contre-exemples valides, nous faisons appel à des annotateurs humains pour valider les données utilisées dans les voyelles.", "metrics": {"bleu_score": 54.60241725418134, "chrf_score": 75.781364382126, "xcomet_score": 0.5373491048812866, "xcomet_qe_score": 0.579553484916687, "metricx_score": 7.085204601287842, "metricx_qe_score": 5.4838786125183105, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, après le filtrage et l'évaluation humaine, nous avons autant d'exemples de test que ceux décrits dans ce tableau", "metrics": {"bleu_score": 31.967153441331142, "chrf_score": 72.89838433196935, "xcomet_score": 0.9571149349212646, "xcomet_qe_score": 0.9622690677642822, "metricx_score": 2.083864688873291, "metricx_qe_score": 2.3642635345458984, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que Valve ne fournit aucune donnée d'entraînement, mais uniquement des données de test", "metrics": {"bleu_score": 20.036355246442355, "chrf_score": 53.78967687893681, "xcomet_score": 0.7339755892753601, "xcomet_qe_score": 0.752728283405304, "metricx_score": 3.155829906463623, "metricx_qe_score": 1.782869577407837, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "puisqu'il s'agit d'une référence de test sans apprentissage spécifique, elle est conçue pour exploiter les capacités existantes des modèles de vision et de langage après l'entraînement préalable", "metrics": {"bleu_score": 17.871607387254866, "chrf_score": 53.417545046367366, "xcomet_score": 0.7646594047546387, "xcomet_qe_score": 0.7919260263442993, "metricx_score": 2.822996139526367, "metricx_qe_score": 2.21726131439209, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "un réglage fin ne permettrait qu'aux modèles d'exploiter des artefacts ou des biais statistiques dans les données", "metrics": {"bleu_score": 62.36362995619313, "chrf_score": 77.95582773966524, "xcomet_score": 0.927108883857727, "xcomet_qe_score": 0.9530594348907471, "metricx_score": 2.1700596809387207, "metricx_qe_score": 2.0477793216705322, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998902082443237, "xcomet_qe_score": 1.0, "metricx_score": 1.3476738929748535, "metricx_qe_score": 2.4462342262268066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme nous l’avons dit, nous sommes intéressés à évaluer les capacités des modèles de vision et de langage après l’entraînement préalable.", "metrics": {"bleu_score": 25.924945760983757, "chrf_score": 63.70402980579604, "xcomet_score": 0.9813010692596436, "xcomet_qe_score": 1.0, "metricx_score": 1.392293930053711, "metricx_qe_score": 1.5556659698486328, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec cinq modèles de vision et de langage sur les voyelles, à savoir avec Clip, AlexMERT, WilBERT, WilBERT Twelve in One et Visual Bird", "metrics": {"bleu_score": 28.468243684377647, "chrf_score": 56.51865104473568, "xcomet_score": 0.27417871356010437, "xcomet_qe_score": 0.3426121473312378, "metricx_score": 9.200658798217773, "metricx_qe_score": 7.093530178070068, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "deux de nos métriques d'évaluation les plus importantes sont la précision des modèles dans la classification des paires d'images et de phrases en légendes et en faux-semblants", "metrics": {"bleu_score": 39.13516286480063, "chrf_score": 78.10681900465546, "xcomet_score": 0.6173093318939209, "xcomet_qe_score": 0.6316581964492798, "metricx_score": 4.988622188568115, "metricx_qe_score": 3.3653337955474854, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "peut-être plus pertinent pour cette vidéo, nous allons présenter notre métrique plus primitive, la précision par paire, qui mesure si le score d'alignement de la phrase d'image est plus élevé pour la paire de texte d'image correcte que pour sa paire contrefaite", "metrics": {"bleu_score": 51.35115006816825, "chrf_score": 68.49540539714174, "xcomet_score": 0.4370405673980713, "xcomet_qe_score": 0.4343551695346832, "metricx_score": 6.487547874450684, "metricx_qe_score": 5.304690837860107, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "pour plus de mesures et de résultats à ce sujet, consultez notre article", "metrics": {"bleu_score": 26.58483576665878, "chrf_score": 67.75950512651615, "xcomet_score": 0.9609638452529907, "xcomet_qe_score": 0.9471564292907715, "metricx_score": 2.1744284629821777, "metricx_qe_score": 1.9938949346542358, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "les résultats avec la précision par paire sont présentés ici et ils sont cohérents avec les résultats obtenus avec les autres métriques : la meilleure performance en zéro coup est réalisée par wilbert twelve in one, suivie de wilbert alexmer clip et enfin de visual bird", "metrics": {"bleu_score": 23.05048168431422, "chrf_score": 54.24473388126781, "xcomet_score": 0.4121640920639038, "xcomet_qe_score": 0.3213083744049072, "metricx_score": 13.238442420959473, "metricx_qe_score": 13.164185523986816, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est remarquable de constater que les instruments centrés sur les objets individuels comme l'existence et les phrases nominales sont presque résolus par Wilbert douze en un, soulignant que les modèles sont capables d'identifier les objets nommés et leur présence dans les images.", "metrics": {"bleu_score": 74.27773076445125, "chrf_score": 87.69486235259428, "xcomet_score": 0.5725775957107544, "xcomet_qe_score": 0.5676668882369995, "metricx_score": 5.855764865875244, "metricx_qe_score": 6.434696674346924, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucune des pièces restantes ne peut être résolue de manière fiable dans nos paramètres d'opposition et de contrefaçon.", "metrics": {"bleu_score": 32.88580454955831, "chrf_score": 66.05133480068005, "xcomet_score": 0.6132556200027466, "xcomet_qe_score": 0.6369569301605225, "metricx_score": 7.842738628387451, "metricx_qe_score": 5.771073818206787, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "on peut le voir à travers les instruments de pluralité et de comptage, les modèles de vision et de langage ont du mal à distinguer les références à un seul objet par rapport à plusieurs objets ou à les compter dans une image", "metrics": {"bleu_score": 49.70729452943474, "chrf_score": 73.8602684048882, "xcomet_score": 0.8674517273902893, "xcomet_qe_score": 0.7767153382301331, "metricx_score": 2.687882900238037, "metricx_qe_score": 3.832899570465088, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "La relation p' montre qu'ils ont des difficultés à classer correctement une relation spatiale nommée entre des objets dans une image", "metrics": {"bleu_score": 81.7248067463409, "chrf_score": 89.1271234565857, "xcomet_score": 0.8054953813552856, "xcomet_qe_score": 0.7590494155883789, "metricx_score": 5.029858589172363, "metricx_qe_score": 5.640016555786133, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "ils ont également du mal à distinguer les actions et à identifier leurs participants, même s'ils sont soutenus par des biais de plausibilité comme nous le voyons dans la pièce d'action", "metrics": {"bleu_score": 86.86624666729523, "chrf_score": 91.8833950979305, "xcomet_score": 0.6828639507293701, "xcomet_qe_score": 0.7029553651809692, "metricx_score": 5.03433084487915, "metricx_qe_score": 5.975349426269531, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "D'après le texte de référence, nous apprenons que le fait de retracer plusieurs références au même objet dans une image en utilisant des pronoms est également difficile pour les modèles de vision et de langage.", "metrics": {"bleu_score": 56.36036032217381, "chrf_score": 75.7979039619159, "xcomet_score": 0.8011447191238403, "xcomet_qe_score": 0.9335064888000488, "metricx_score": 2.782806873321533, "metricx_qe_score": 3.3588175773620605, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "Pour vérifier la cohérence et parce que c'est une expérience intéressante, nous évaluons également deux modèles textuels, GPT1 et GPT2, afin de déterminer si la valve peut être résolue par ces unimodes en calculant la perplexité des légendes correctes et incorrectes.", "metrics": {"bleu_score": 19.577483465171714, "chrf_score": 52.14620554457806, "xcomet_score": 0.3746293783187866, "xcomet_qe_score": 0.5058947205543518, "metricx_score": 13.24189281463623, "metricx_qe_score": 12.184698104858398, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "si la perplexité est plus élevée pour la feuille, nous considérons cela comme une indication que la légende masquée peut souffrir d'un biais de plausibilité ou d'autres biais linguistiques", "metrics": {"bleu_score": 57.77871410454277, "chrf_score": 83.0161327891766, "xcomet_score": 0.4764399230480194, "xcomet_qe_score": 0.4761005640029907, "metricx_score": 8.485663414001465, "metricx_qe_score": 7.219925880432129, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est intéressant de constater que, dans certains cas, les modèles basés uniquement sur le texte ont mieux capturé la plausibilité du monde que les modèles de vision et de langage.", "metrics": {"bleu_score": 44.29683759031999, "chrf_score": 72.09587745783787, "xcomet_score": 0.9725971221923828, "xcomet_qe_score": 0.9376675486564636, "metricx_score": 3.104053497314453, "metricx_qe_score": 3.426854133605957, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, Waltz est une référence qui utilise la lentille des constructions linguistiques pour aider la communauté à améliorer les modèles de vision et de langage en testant rigoureusement leurs capacités d'ancrage visuel.", "metrics": {"bleu_score": 38.15659884752199, "chrf_score": 69.03495396930613, "xcomet_score": 0.2918208837509155, "xcomet_qe_score": 0.3292723596096039, "metricx_score": 10.642854690551758, "metricx_qe_score": 10.443548202514648, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que les modèles de langage identifient bien les objets nommés et leur présence dans les images, comme en témoigne l'existence des espaces, mais ont du mal à ancrer leur interdépendance et leurs relations dans des scènes visuelles lorsqu'ils sont contraints de respecter les indicateurs linguistiques.", "metrics": {"bleu_score": 60.80258007852506, "chrf_score": 81.2839578298952, "xcomet_score": 0.6412516832351685, "xcomet_qe_score": 0.61756831407547, "metricx_score": 6.413404941558838, "metricx_qe_score": 6.463237762451172, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions vraiment encourager la communauté à utiliser des vœux pour mesurer les progrès réalisés dans l'ancrage linguistique avec des modèles de vision et de langage.", "metrics": {"bleu_score": 45.53525282455363, "chrf_score": 73.63549002573625, "xcomet_score": 0.4980154037475586, "xcomet_qe_score": 0.5116486549377441, "metricx_score": 12.350504875183105, "metricx_qe_score": 12.910576820373535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "et encore plus de valves pourraient être utilisées comme évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou le réglage fin pour voir si un ensemble de données aide les modèles à s'améliorer sur l'un des aspects testés par les valves", "metrics": {"bleu_score": 36.74843411383715, "chrf_score": 70.20507217754158, "xcomet_score": 0.5070621371269226, "xcomet_qe_score": 0.5350419878959656, "metricx_score": 13.042905807495117, "metricx_qe_score": 11.656538963317871, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "Si cela vous intéresse, consultez les données factices sur GitHub et si vous avez des questions, n'hésitez pas à nous contacter.", "metrics": {"bleu_score": 63.19430791985466, "chrf_score": 79.43404639559915, "xcomet_score": 0.7861030101776123, "xcomet_qe_score": 0.792373776435852, "metricx_score": 5.124847412109375, "metricx_qe_score": 4.599099159240723, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kamizera de l'Université de Tokyo", "metrics": {"bleu_score": 53.417359568998464, "chrf_score": 84.75844798850319, "xcomet_score": 0.834774374961853, "xcomet_qe_score": 0.70368891954422, "metricx_score": 3.676551580429077, "metricx_qe_score": 4.769583702087402, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai une communication intitulée «  L'N-Sum : une thèse à grande échelle pour une renaissance automatique par la synthèse de résumés  ».", "metrics": {"bleu_score": 10.614554817431985, "chrf_score": 42.69941328074158, "xcomet_score": 0.1001317948102951, "xcomet_qe_score": 0.2927356958389282, "metricx_score": 15.583605766296387, "metricx_qe_score": 13.87657356262207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais expliquer dans cet ordre.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 82.67586467120438, "xcomet_score": 0.9803920984268188, "xcomet_qe_score": 1.0, "metricx_score": 0.5986242294311523, "metricx_qe_score": 0.8819785118103027, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je vais présenter la génération automatique de signalement dont nous travaillons dans cette recherche.", "metrics": {"bleu_score": 57.24429659479037, "chrf_score": 77.47190320318805, "xcomet_score": 0.7308642864227295, "xcomet_qe_score": 0.7374117374420166, "metricx_score": 8.408979415893555, "metricx_qe_score": 8.528368949890137, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "La note de version est un document technique qui résume les changements distribués avec chaque version d'un produit logiciel.", "metrics": {"bleu_score": 69.3395566222006, "chrf_score": 79.83676813459488, "xcomet_score": 0.9961577653884888, "xcomet_qe_score": 0.975024938583374, "metricx_score": 0.33922040462493896, "metricx_qe_score": 0.409065842628479, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'e-mail montre une note de version pour le budget 2.6", "metrics": {"bleu_score": 21.018559929939123, "chrf_score": 35.986800750707594, "xcomet_score": 0.1317526251077652, "xcomet_qe_score": 0.1338890641927719, "metricx_score": 17.138782501220703, "metricx_qe_score": 23.07185935974121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Ces notes jouent un rôle important dans le développement open source, mais elles prennent beaucoup de temps à préparer manuellement.", "metrics": {"bleu_score": 53.737428729508345, "chrf_score": 72.19534154118932, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9145327806472778, "metricx_qe_score": 1.5295531749725342, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Il serait donc très utile de pouvoir générer automatiquement des notes de location de haute qualité.", "metrics": {"bleu_score": 57.07222437877795, "chrf_score": 76.25594304506754, "xcomet_score": 0.7775670289993286, "xcomet_qe_score": 0.8085315823554993, "metricx_score": 6.132070064544678, "metricx_qe_score": 5.204495906829834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "J'ai fait référence à deux recherches antérieures sur la génération automatique sans risque.", "metrics": {"bleu_score": 45.91050315190768, "chrf_score": 65.74021027228784, "xcomet_score": 0.29219046235084534, "xcomet_qe_score": 0.40897631645202637, "metricx_score": 13.407258033752441, "metricx_qe_score": 11.923279762268066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier est un système appelé Array, sorti en 2014.", "metrics": {"bleu_score": 26.20251007173262, "chrf_score": 45.211631094793056, "xcomet_score": 0.15937644243240356, "xcomet_qe_score": 0.16309455037117004, "metricx_score": 6.546071529388428, "metricx_qe_score": 7.393444538116455, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il adopte une approche basée sur des règles, par exemple, en utilisant l'extrait de modification pour extraire les différences fondamentales, les modifications de bibliothèque et les modifications de document à partir des différences entre les versions, puis en les combinant.", "metrics": {"bleu_score": 56.53553210890054, "chrf_score": 71.83292949517683, "xcomet_score": 0.7656132578849792, "xcomet_qe_score": 0.7515679597854614, "metricx_score": 3.7299845218658447, "metricx_qe_score": 3.2594120502471924, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus notable de ce système est l'affichage de la structure dans le coin supérieur droit", "metrics": {"bleu_score": 66.54377827941899, "chrf_score": 75.6669631356726, "xcomet_score": 0.5745301246643066, "xcomet_qe_score": 0.34367483854293823, "metricx_score": 5.9666924476623535, "metricx_qe_score": 7.266589164733887, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "qui doit être lié à zéro, au cycle de publication, et ne peut être appliqué qu'aux produits qui utilisent zéro.", "metrics": {"bleu_score": 24.006978356462586, "chrf_score": 52.970254578358265, "xcomet_score": 0.18874607980251312, "xcomet_qe_score": 0.2362249195575714, "metricx_score": 20.889541625976562, "metricx_qe_score": 21.63028335571289, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, il ne peut pas être utilisé pour de nombreux projets sur la guitare.", "metrics": {"bleu_score": 68.53234406569368, "chrf_score": 81.31423432893868, "xcomet_score": 0.45181694626808167, "xcomet_qe_score": 0.37306463718414307, "metricx_score": 9.333427429199219, "metricx_qe_score": 9.08963394165039, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "le second est le deuil récemment annoncé dans vingt", "metrics": {"bleu_score": 5.0735520042259505, "chrf_score": 47.33294211993254, "xcomet_score": 0.14350862801074982, "xcomet_qe_score": 0.1731976866722107, "metricx_score": 19.330175399780273, "metricx_qe_score": 17.41228675842285, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "Il est disponible sur Internet et peut être stocké via pip.", "metrics": {"bleu_score": 28.73539322585947, "chrf_score": 65.98541218198787, "xcomet_score": 0.6498608589172363, "xcomet_qe_score": 0.8685106039047241, "metricx_score": 6.345839023590088, "metricx_qe_score": 5.665617942810059, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système dispose d'un modèle de classification simple basé sur l'exécution et génère l'un des cinq labels, tels que les fonctionnalités ou les corrections de bogues, pour chaque message de commit d'entrée.", "metrics": {"bleu_score": 14.963473452375604, "chrf_score": 57.22842454173724, "xcomet_score": 0.5743719339370728, "xcomet_qe_score": 0.6300554871559143, "metricx_score": 4.201862812042236, "metricx_qe_score": 4.176080226898193, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un exemple d'utilisation qui renvoie une étiquette corrective ou de correction de bogues.", "metrics": {"bleu_score": 53.24221584015077, "chrf_score": 77.48638853862401, "xcomet_score": 0.8117958307266235, "xcomet_qe_score": 0.8878514170646667, "metricx_score": 2.4345853328704834, "metricx_qe_score": 3.024054527282715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "Les données d'entraînement de Griffith sont assez limitées, environ cinq mille, et seront présentées dans les expériences décrites ci-dessous.", "metrics": {"bleu_score": 51.43894472390287, "chrf_score": 72.09961988350071, "xcomet_score": 0.8540327548980713, "xcomet_qe_score": 0.960543155670166, "metricx_score": 6.470199108123779, "metricx_qe_score": 6.404419422149658, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "les performances du modèle de classification de texte ne sont pas élevées", "metrics": {"bleu_score": 83.1353976469103, "chrf_score": 97.01253105387613, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7696065306663513, "metricx_qe_score": 0.9399595856666565, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches connexes, mais il y avait des problèmes d'applicabilité limitée et de ressources de données rares.", "metrics": {"bleu_score": 48.45766087853282, "chrf_score": 81.87829776115237, "xcomet_score": 0.9446797370910645, "xcomet_qe_score": 0.9100715517997742, "metricx_score": 1.4788610935211182, "metricx_qe_score": 1.5011966228485107, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des auditeurs de haute qualité.", "metrics": {"bleu_score": 70.0418991088418, "chrf_score": 83.72907494640633, "xcomet_score": 0.6909562349319458, "xcomet_qe_score": 0.6622534990310669, "metricx_score": 12.133160591125488, "metricx_qe_score": 10.499191284179688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le problème d'applicabilité limitée, nous proposons une méthode de sommation de classification de haute qualité, utilisant uniquement le message du comité comme entrée.", "metrics": {"bleu_score": 38.20749987385285, "chrf_score": 67.46559547317054, "xcomet_score": 0.6212804317474365, "xcomet_qe_score": 0.6763388514518738, "metricx_score": 9.159870147705078, "metricx_qe_score": 7.281243801116943, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée par tous les anglophones.", "metrics": {"bleu_score": 48.83499409416458, "chrf_score": 69.14849830867354, "xcomet_score": 0.6052995920181274, "xcomet_qe_score": 0.6068578362464905, "metricx_score": 4.356797695159912, "metricx_qe_score": 6.538144588470459, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème des ressources de données limitées, nous avons créé notre propre ensemble d'enzymes composé d'environ 82 000 données en collectant des données à partir de dépôts publics GitHub en utilisant l'API GitHub.", "metrics": {"bleu_score": 40.74453003570758, "chrf_score": 63.59618919024131, "xcomet_score": 0.5712713003158569, "xcomet_qe_score": 0.720285177230835, "metricx_score": 5.366589546203613, "metricx_qe_score": 5.270592212677002, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décris notre désert.", "metrics": {"bleu_score": 22.772101321113862, "chrf_score": 41.252730026822185, "xcomet_score": 0.3890964388847351, "xcomet_qe_score": 0.4221149682998657, "metricx_score": 12.627046585083008, "metricx_qe_score": 13.441385269165039, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de données.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998996257781982, "xcomet_qe_score": 0.9993472099304199, "metricx_score": 0.5450457334518433, "metricx_qe_score": 0.6231614351272583, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche est le message de validation et le côté droit est la note de lecture.", "metrics": {"bleu_score": 48.59373818796306, "chrf_score": 64.62706443400353, "xcomet_score": 0.7542882561683655, "xcomet_qe_score": 0.6185668706893921, "metricx_score": 3.892714023590088, "metricx_qe_score": 2.5128636360168457, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "Les Risonnes sont considérées comme des améliorations par les physiciens, etc.", "metrics": {"bleu_score": 14.211672443220438, "chrf_score": 41.20598972778132, "xcomet_score": 0.1257295161485672, "xcomet_qe_score": 0.12359467148780823, "metricx_score": 18.943147659301758, "metricx_qe_score": 15.309920310974121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons configuré une tâche qui prend les messages de commit comme entrée et produit une sortie qui n'est pas autorisée.", "metrics": {"bleu_score": 29.88685861808017, "chrf_score": 45.727193428665956, "xcomet_score": 0.29153257608413696, "xcomet_qe_score": 0.5482776165008545, "metricx_score": 13.248984336853027, "metricx_qe_score": 13.446632385253906, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de synthèse.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3962705135345459, "metricx_qe_score": 0.495924174785614, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons prédéfini quatre niveaux : Fonctionnalités, Améliorations, Corrections de bogues, Dépréciations, Retrait et Changements de rupture.", "metrics": {"bleu_score": 18.255858453725565, "chrf_score": 56.7411730835596, "xcomet_score": 0.5552555322647095, "xcomet_qe_score": 0.49503087997436523, "metricx_score": 5.603970050811768, "metricx_qe_score": 4.928639888763428, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces projets de loi sont basés sur des recherches antérieures et d'autres facteurs.", "metrics": {"bleu_score": 18.3186413935951, "chrf_score": 52.18018499415318, "xcomet_score": 0.7055150270462036, "xcomet_qe_score": 0.6862375736236572, "metricx_score": 9.457988739013672, "metricx_qe_score": 9.166168212890625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "il n'y en a pas en bas à droite et extrait lorsqu'il n'y en a pas en bas à gauche", "metrics": {"bleu_score": 23.972125922151484, "chrf_score": 43.71932585416325, "xcomet_score": 0.14748242497444153, "xcomet_qe_score": 0.15315274894237518, "metricx_score": 18.964445114135742, "metricx_qe_score": 17.429885864257812, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce stade, il est nécessaire de détecter les quatre ruines qui ont été préalablement installées", "metrics": {"bleu_score": 55.04474074331649, "chrf_score": 65.31228909215689, "xcomet_score": 0.584033727645874, "xcomet_qe_score": 0.6028900146484375, "metricx_score": 10.96677017211914, "metricx_qe_score": 11.242948532104492, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "mais les tarifs ne sont pas toujours cohérents d'une liposuccion à l'autre", "metrics": {"bleu_score": 22.416933501922287, "chrf_score": 48.17290195665806, "xcomet_score": 0.22972935438156128, "xcomet_qe_score": 0.1255725771188736, "metricx_score": 8.214982032775879, "metricx_qe_score": 7.951716423034668, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le niveau d'amélioration comprend les améliorations, les perfectionnements, les optimisations, etc.", "metrics": {"bleu_score": 23.682079130839753, "chrf_score": 71.48145887394594, "xcomet_score": 0.8967965841293335, "xcomet_qe_score": 0.8641353845596313, "metricx_score": 1.9239022731781006, "metricx_qe_score": 1.8320070505142212, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste de vocabulaire de trente mots pour chacune de ces variations notationnelles.", "metrics": {"bleu_score": 55.22027108670325, "chrf_score": 73.85417407781323, "xcomet_score": 0.9421722888946533, "xcomet_qe_score": 0.958442211151123, "metricx_score": 3.3697080612182617, "metricx_qe_score": 3.0358922481536865, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez-le pour détecter la clause rationnelle et corriger le texte du reste qui suit en tant que phrase rationnelle pour la clause.", "metrics": {"bleu_score": 19.068149416460535, "chrf_score": 46.28717972790318, "xcomet_score": 0.18928517401218414, "xcomet_qe_score": 0.13165119290351868, "metricx_score": 15.785863876342773, "metricx_qe_score": 13.815712928771973, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, il y a un message de commit.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 68.6805532750581, "xcomet_score": 0.8390024900436401, "xcomet_qe_score": 0.9567588567733765, "metricx_score": 4.6736555099487305, "metricx_qe_score": 4.267538070678711, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages engagés ne sont pas liés à chaque pièce.", "metrics": {"bleu_score": 48.83499409416458, "chrf_score": 57.36333933537159, "xcomet_score": 0.4115440249443054, "xcomet_qe_score": 0.4813094437122345, "metricx_score": 9.110607147216797, "metricx_qe_score": 9.38209056854248, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "comme le montre l'image ci-dessous, si la version actuelle est de 2.5 à 19, nous devons identifier", "metrics": {"bleu_score": 27.022168735185037, "chrf_score": 48.05141185126228, "xcomet_score": 0.18968592584133148, "xcomet_qe_score": 0.12019228935241699, "metricx_score": 19.071483612060547, "metricx_qe_score": 18.400238037109375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "C'est un peu fastidieux et ce n'est pas suffisant de simplement obtenir une liste de versions et de regarder le avant et le après.", "metrics": {"bleu_score": 39.24259174695315, "chrf_score": 75.3997099899719, "xcomet_score": 0.9357062578201294, "xcomet_qe_score": 0.8649739623069763, "metricx_score": 1.5485191345214844, "metricx_qe_score": 1.845418095588684, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Il a créé une règle d'appariement heuristique pour obtenir les versions précédente et suivante.", "metrics": {"bleu_score": 32.54777991021598, "chrf_score": 59.25435205941098, "xcomet_score": 0.5946651697158813, "xcomet_qe_score": 0.5207870006561279, "metricx_score": 3.556406259536743, "metricx_qe_score": 3.444131374359131, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "On appelle cela une \"sentencedécouverte\".", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 12.343069183513242, "xcomet_score": 0.1400471329689026, "xcomet_qe_score": 0.13364161550998688, "metricx_score": 14.913731575012207, "metricx_qe_score": 13.620220184326172, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "Au final, 7 200 dépôts", "metrics": {"bleu_score": 0.936015604744713, "chrf_score": 6.531934850050329, "xcomet_score": 0.14978055655956268, "xcomet_qe_score": 0.14707252383232117, "metricx_score": 23.23417854309082, "metricx_qe_score": 19.438711166381836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de jetons libérés est de soixante-trois, ce qui est assez élevé pour les tâches de simulation.", "metrics": {"bleu_score": 47.761152007880774, "chrf_score": 60.69196663314277, "xcomet_score": 0.5425864458084106, "xcomet_qe_score": 0.5774518251419067, "metricx_score": 9.89378547668457, "metricx_qe_score": 7.531492710113525, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre de jetons uniques est assez élevé, avec 8 830 000.", "metrics": {"bleu_score": 17.89117353466845, "chrf_score": 34.7602655734697, "xcomet_score": 0.7724733948707581, "xcomet_qe_score": 0.9406945705413818, "metricx_score": 4.365232467651367, "metricx_qe_score": 2.080101251602173, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "En raison du grand nombre de noms de classes et de méthodes uniques trouvés dans le laboratoire.", "metrics": {"bleu_score": 26.896741624879542, "chrf_score": 61.57982448882522, "xcomet_score": 0.6467502117156982, "xcomet_qe_score": 0.6241660714149475, "metricx_score": 5.753298282623291, "metricx_qe_score": 4.499656677246094, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, j'expliquerai la méthode proposée.", "metrics": {"bleu_score": 36.74145494215666, "chrf_score": 75.59105076499984, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26971232891082764, "metricx_qe_score": 0.1778177171945572, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle d'extraction transversale puis de sommation abstraite se compose de deux modules neutres.", "metrics": {"bleu_score": 28.939523428407796, "chrf_score": 56.62619563179627, "xcomet_score": 0.2727002203464508, "xcomet_qe_score": 0.40998905897140503, "metricx_score": 7.788758754730225, "metricx_qe_score": 6.4619927406311035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "un classificateur utilisant un embout ou un embout de code et un générateur utilisant un embout", "metrics": {"bleu_score": 18.92240568795936, "chrf_score": 64.67698927674502, "xcomet_score": 0.16599084436893463, "xcomet_qe_score": 0.1495516002178192, "metricx_score": 13.963545799255371, "metricx_qe_score": 14.4005708694458, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, CAS utilise un classificateur pour classer chaque message envoyé dans cinq catégories distinctes : fonctionnalités, améliorations, corrections de bugs, applications plus et autres.", "metrics": {"bleu_score": 23.625012787704538, "chrf_score": 57.7770434658077, "xcomet_score": 0.41173312067985535, "xcomet_qe_score": 0.30635011196136475, "metricx_score": 8.367688179016113, "metricx_qe_score": 8.401049613952637, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de commit classés comme autres sont écartés", "metrics": {"bleu_score": 38.62752974508188, "chrf_score": 61.354937830698155, "xcomet_score": 0.8350085020065308, "xcomet_qe_score": 0.9043673276901245, "metricx_score": 4.894278526306152, "metricx_qe_score": 4.982367515563965, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, GAS applique le générateur aux documents à quatre rangées de manière indépendante et génère des énigmes pour chaque classe.", "metrics": {"bleu_score": 30.09429889037877, "chrf_score": 64.59587713757054, "xcomet_score": 0.18453547358512878, "xcomet_qe_score": 0.21194835007190704, "metricx_score": 13.548371315002441, "metricx_qe_score": 11.979025840759277, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages du comité et le raisonnement ne sont pas connues.", "metrics": {"bleu_score": 58.69740862506178, "chrf_score": 74.2214314000575, "xcomet_score": 0.6110730171203613, "xcomet_qe_score": 0.5786795616149902, "metricx_score": 10.319321632385254, "metricx_qe_score": 9.554679870605469, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour entraîner le classificateur, nous attribuons des sous-niveaux à chaque message de commentaire d'entrée en utilisant les dix premiers caractères de chaque message de commentaire", "metrics": {"bleu_score": 50.35649624275154, "chrf_score": 66.03942778654525, "xcomet_score": 0.5715348720550537, "xcomet_qe_score": 0.6787218451499939, "metricx_score": 6.3949666023254395, "metricx_qe_score": 5.723333835601807, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons l'approche de résumé classificateur obstructive par deux méthodes différentes.", "metrics": {"bleu_score": 21.099261895175324, "chrf_score": 58.17293089133734, "xcomet_score": 0.6048793792724609, "xcomet_qe_score": 0.4262945353984833, "metricx_score": 10.296335220336914, "metricx_qe_score": 7.869671821594238, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons GAS single, se compose d'un seul réseau de six à six et génère une seule pièce sans texte étant donné une concaténation de messages de commit d'entrée.", "metrics": {"bleu_score": 35.973870394187955, "chrf_score": 57.925396870714984, "xcomet_score": 0.10477862507104874, "xcomet_qe_score": 0.18953900039196014, "metricx_score": 12.960107803344727, "metricx_qe_score": 11.57165241241455, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Les balises de sortie peuvent être divisées en segments transversaux en fonction de symboles de points de terminaison spécifiques à chaque traversée.", "metrics": {"bleu_score": 16.616655023283982, "chrf_score": 54.351550348370814, "xcomet_score": 0.42233529686927795, "xcomet_qe_score": 0.5967767238616943, "metricx_score": 6.813031196594238, "metricx_qe_score": 5.97860050201416, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons GSmart, consiste en quatre réseaux différents de seconde à seconde, chacun correspondant à l'une des trois non-classes.", "metrics": {"bleu_score": 19.07230218496638, "chrf_score": 56.14797485347057, "xcomet_score": 0.16110163927078247, "xcomet_qe_score": 0.05328928306698799, "metricx_score": 16.919031143188477, "metricx_qe_score": 15.352982521057129, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, laissez-moi expliquer l'expérience.", "metrics": {"bleu_score": 6.4790667469036025, "chrf_score": 47.210365058958445, "xcomet_score": 0.9313861131668091, "xcomet_qe_score": 0.9775118827819824, "metricx_score": 1.1269221305847168, "metricx_qe_score": 0.8525193333625793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été comparées : acclamations, acclamations individuelles, acclamations de marche, lutte et deuils d'études antérieures.", "metrics": {"bleu_score": 26.035572673286655, "chrf_score": 43.50685096902866, "xcomet_score": 0.14874820411205292, "xcomet_qe_score": 0.014704432338476181, "metricx_score": 24.800065994262695, "metricx_qe_score": 23.424636840820312, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'aberration, dans certains cas, ces notes sont produites en plusieurs phrases.", "metrics": {"bleu_score": 54.85113740772977, "chrf_score": 77.27603630388694, "xcomet_score": 0.30860215425491333, "xcomet_qe_score": 0.2810898423194885, "metricx_score": 7.397716522216797, "metricx_qe_score": 8.39199447631836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Puisqu'il est difficile de corriger le nombre de phrases à zéro, elles sont combinées avec des espaces et traitées comme une seule phrase longue.", "metrics": {"bleu_score": 71.51826245402509, "chrf_score": 80.53444113949222, "xcomet_score": 0.5629584789276123, "xcomet_qe_score": 0.5218449234962463, "metricx_score": 8.270576477050781, "metricx_qe_score": 9.575096130371094, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "Le bureau est pénalisé lorsque le système produit une phrase courte", "metrics": {"bleu_score": 73.69231628533761, "chrf_score": 87.47365090737897, "xcomet_score": 0.623521089553833, "xcomet_qe_score": 0.5936251282691956, "metricx_score": 8.32716178894043, "metricx_qe_score": 8.611756324768066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité entraîne une valeur réelle inférieure dans les résultats de l'expérience décrits ci-après.", "metrics": {"bleu_score": 43.06092978232365, "chrf_score": 71.96135474969752, "xcomet_score": 0.8364756107330322, "xcomet_qe_score": 0.8236405849456787, "metricx_score": 6.915243148803711, "metricx_qe_score": 7.769864082336426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "finalement, nous calculons également la spécificité car le bleu et le bleu ne peuvent pas être calculés si les bobines ne sont pas vides", "metrics": {"bleu_score": 48.15092081725061, "chrf_score": 66.5139537689225, "xcomet_score": 0.30380409955978394, "xcomet_qe_score": 0.32287535071372986, "metricx_score": 13.789619445800781, "metricx_qe_score": 13.860068321228027, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une spécificité élevée signifie que le modèle génère correctement du texte vide, dans les cas où les leads ne supposent pas le vide.", "metrics": {"bleu_score": 32.22074553137884, "chrf_score": 60.338620653696914, "xcomet_score": 0.7045416235923767, "xcomet_qe_score": 0.7631319761276245, "metricx_score": 7.265655517578125, "metricx_qe_score": 6.910705089569092, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le troisième.", "metrics": {"bleu_score": 9.688464563433238, "chrf_score": 7.29016100538023, "xcomet_score": 0.14605870842933655, "xcomet_qe_score": 0.17445208132266998, "metricx_score": 9.650201797485352, "metricx_qe_score": 6.097742080688477, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que le jeu de données contient des adresses e-mail, des valeurs de hachage, etc., nous gérons également un jeu de données imprimé, qui les exclut.", "metrics": {"bleu_score": 27.093695289987522, "chrf_score": 58.843813167928175, "xcomet_score": 0.5611644983291626, "xcomet_qe_score": 0.5896505117416382, "metricx_score": 9.828645706176758, "metricx_qe_score": 9.627533912658691, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "Le C.E.A.S. et le C.E.A.S. ont obtenu des scores R.U.S. de plus de dix points supérieurs aux valeurs de référence.", "metrics": {"bleu_score": 17.200767571780613, "chrf_score": 54.03891079645562, "xcomet_score": 0.2308146357536316, "xcomet_qe_score": 0.19562020897865295, "metricx_score": 11.012115478515625, "metricx_qe_score": 11.626388549804688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur l'ensemble de test de décaissement, l'écart de score entre la méthode proposée et la méthode de référence a bondi à plus de vingt points.", "metrics": {"bleu_score": 57.37618401341797, "chrf_score": 76.52906870619755, "xcomet_score": 0.6521461606025696, "xcomet_qe_score": 0.6062738299369812, "metricx_score": 6.88824462890625, "metricx_qe_score": 6.434419631958008, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent qu'elle est et qu'elle est significativement efficaces.", "metrics": {"bleu_score": 13.215955651112736, "chrf_score": 42.690852904528846, "xcomet_score": 0.13479627668857574, "xcomet_qe_score": 0.1489936113357544, "metricx_score": 20.594900131225586, "metricx_qe_score": 19.138687133789062, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "GAS a obtenu un meilleur score de passage de racine que GAS, suggérant que la combinaison d'un classificateur et d'un générateur est efficace et que l'entraînement du classificateur à l'aide de sous-routines est bénéfique.", "metrics": {"bleu_score": 42.416092104229875, "chrf_score": 66.63448589705712, "xcomet_score": 0.16144923865795135, "xcomet_qe_score": 0.1347627192735672, "metricx_score": 16.665435791015625, "metricx_qe_score": 17.046173095703125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "Une couverture élevée de CS peut être obtenue correctement car le classificateur peut se concentrer sur la sélection des messages de commit pertinents pour chaque classe.", "metrics": {"bleu_score": 64.32343886784393, "chrf_score": 82.09112590093696, "xcomet_score": 0.6115323305130005, "xcomet_qe_score": 0.6438822150230408, "metricx_score": 9.605039596557617, "metricx_qe_score": 9.24354362487793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Elle a tendance à être beaucoup mieux payée qu'elle ne l'est en étant célibataire.", "metrics": {"bleu_score": 3.1251907639724417, "chrf_score": 15.859574805786405, "xcomet_score": 0.1333170384168625, "xcomet_qe_score": 0.13479015231132507, "metricx_score": 25.0, "metricx_qe_score": 23.64565086364746, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "ce qui suggère qu'il est également efficace de développer de manière indépendante des modèles de sommation abstraits différents pour chaque classe de note", "metrics": {"bleu_score": 40.19329987592565, "chrf_score": 64.16146373735936, "xcomet_score": 0.6874815225601196, "xcomet_qe_score": 0.537064790725708, "metricx_score": 4.051594257354736, "metricx_qe_score": 2.8092103004455566, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "héros et éronasis", "metrics": {"bleu_score": 0.0, "chrf_score": 7.5784344036629685, "xcomet_score": 0.1119341105222702, "xcomet_qe_score": 0.11423603445291519, "metricx_score": 22.262346267700195, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes de Shear ont tendance à produire des phrases plus courtes que les phrases de référence humaines.", "metrics": {"bleu_score": 80.86627571031983, "chrf_score": 92.84553458313619, "xcomet_score": 0.5996298789978027, "xcomet_qe_score": 0.4292909801006317, "metricx_score": 9.963709831237793, "metricx_qe_score": 12.313870429992676, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure à droite, la phrase de référence a trois ou quatre phrases tandis que l'autre n'en a qu'une.", "metrics": {"bleu_score": 60.82130354523255, "chrf_score": 83.10378085188161, "xcomet_score": 0.6615635752677917, "xcomet_qe_score": 0.5788705348968506, "metricx_score": 4.80557107925415, "metricx_qe_score": 4.9802350997924805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "la raison de cette moindre réticence est que dans les données d'entraînement, seulement trente-trois pour cent des phrases sont présentes au niveau des fonctionnalités et quarante pour cent au niveau de la mise en œuvre", "metrics": {"bleu_score": 40.86640112620186, "chrf_score": 63.59899701136634, "xcomet_score": 0.28516191244125366, "xcomet_qe_score": 0.2961052656173706, "metricx_score": 7.067549228668213, "metricx_qe_score": 6.84612512588501, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes de Cia ne peuvent pas générer de notes de lecture précises sans informations supplémentaires.", "metrics": {"bleu_score": 38.36841681691308, "chrf_score": 74.72625740832899, "xcomet_score": 0.5370133519172668, "xcomet_qe_score": 0.5767340660095215, "metricx_score": 7.4231276512146, "metricx_qe_score": 7.2088727951049805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple en haut à droite est un exemple de message commutatif très confus, et la phrase complète ne peut pas être générée sans référence au prologue ou au problème correspondant.", "metrics": {"bleu_score": 60.70506830454063, "chrf_score": 74.29665144560927, "xcomet_score": 0.690570592880249, "xcomet_qe_score": 0.5891927480697632, "metricx_score": 6.021831035614014, "metricx_qe_score": 4.949734687805176, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous montre que les deux messages engagés dans l'entrée sont liés et devraient être combinés en une seule phrase, mais il ne parvient pas à le faire", "metrics": {"bleu_score": 37.368363717256074, "chrf_score": 67.88408528088623, "xcomet_score": 0.7274754047393799, "xcomet_qe_score": 0.6928473114967346, "metricx_score": 6.052641868591309, "metricx_qe_score": 5.705169677734375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin une conclusion.", "metrics": {"bleu_score": 16.70067963244422, "chrf_score": 47.84397202861422, "xcomet_score": 0.9810041189193726, "xcomet_qe_score": 1.0, "metricx_score": 1.931408166885376, "metricx_qe_score": 1.9700369834899902, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "nous avons créé un nouvel ensemble d'indicateurs pour la génération automatique", "metrics": {"bleu_score": 17.24541906163268, "chrf_score": 52.821050724692384, "xcomet_score": 0.39819514751434326, "xcomet_qe_score": 0.5295909643173218, "metricx_score": 9.981559753417969, "metricx_qe_score": 7.662578105926514, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également pour mission d'entrer des messages de commit et de les résumer de manière à ce qu'ils soient applicables à tous les projets écrits en anglais.", "metrics": {"bleu_score": 46.95966835778608, "chrf_score": 65.88120195763958, "xcomet_score": 0.8599263429641724, "xcomet_qe_score": 0.8266247510910034, "metricx_score": 5.47643518447876, "metricx_qe_score": 5.655139923095703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que la méthode proposée génère moins de bruit et pas à une couverture plus élevée que les méthodes de référence.", "metrics": {"bleu_score": 54.89938756679379, "chrf_score": 72.89963386007412, "xcomet_score": 0.5793324708938599, "xcomet_qe_score": 0.5583073496818542, "metricx_score": 10.097743034362793, "metricx_qe_score": 9.984208106994629, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Consultez le set sur GitHub !", "metrics": {"bleu_score": 13.741272855400096, "chrf_score": 37.92909063209614, "xcomet_score": 0.7519000768661499, "xcomet_qe_score": 0.7302998304367065, "metricx_score": 4.909231185913086, "metricx_qe_score": 3.6468513011932373, "linguapy_score": [1, "XHOSA"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10382990539073944, "metricx_qe_score": 0.4022793173789978, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, c'est Mizzou Ferrari.", "metrics": {"bleu_score": 8.170609724417774, "chrf_score": 27.583872301707046, "xcomet_score": 0.11613722145557404, "xcomet_qe_score": 0.11524996906518936, "metricx_score": 19.078306198120117, "metricx_qe_score": 13.738678932189941, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "Et je vais présenter notre article, « Future Tabular Data Enrichment using FineTuner Transformers architectures ».", "metrics": {"bleu_score": 11.189133509740282, "chrf_score": 42.79927340189251, "xcomet_score": 0.6035745143890381, "xcomet_qe_score": 0.7096006274223328, "metricx_score": 9.879673957824707, "metricx_qe_score": 8.828717231750488, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "Un scientifique analyse-t-il des données et se concentre-t-il principalement sur la manipulation des caractéristiques existantes des données ?", "metrics": {"bleu_score": 33.08548466798255, "chrf_score": 75.6539232347687, "xcomet_score": 0.6046949028968811, "xcomet_qe_score": 0.5326617956161499, "metricx_score": 5.3943305015563965, "metricx_qe_score": 6.755790710449219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "Mais parfois, ces fonctionnalités sont limitées.", "metrics": {"bleu_score": 50.000000000000014, "chrf_score": 89.38312351623203, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1626409888267517, "metricx_qe_score": 0.21877840161323547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "Une future génération utilisant une autre source de données pourrait ajouter des informations substantielles", "metrics": {"bleu_score": 43.94900482337444, "chrf_score": 79.0925433801559, "xcomet_score": 0.8196097612380981, "xcomet_qe_score": 0.8139390349388123, "metricx_score": 3.559178352355957, "metricx_qe_score": 4.9347453117370605, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique des données tabulaires à l'aide de sources externes en texte libre.", "metrics": {"bleu_score": 43.200373340115924, "chrf_score": 80.324139365827, "xcomet_score": 0.9968491792678833, "xcomet_qe_score": 1.0, "metricx_score": 0.6752551794052124, "metricx_qe_score": 0.977837860584259, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, nous disposons d'un ensemble de données tabulaires et d'une base de connaissances.", "metrics": {"bleu_score": 22.894156860669913, "chrf_score": 67.05617759068754, "xcomet_score": 0.6175140142440796, "xcomet_qe_score": 0.7726614475250244, "metricx_score": 1.8485691547393799, "metricx_qe_score": 1.6264519691467285, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique, qui implique la liaison d'entités et l'analyse de texte, pour extraire de nouvelles fonctionnalités à partir du texte libre de la base de connaissances.", "metrics": {"bleu_score": 68.4058267541103, "chrf_score": 92.62523360961293, "xcomet_score": 0.9621356725692749, "xcomet_qe_score": 0.893651008605957, "metricx_score": 0.8383896350860596, "metricx_qe_score": 1.0766279697418213, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre, d'abord, est exactement ce processus automatique.", "metrics": {"bleu_score": 51.93071778680675, "chrf_score": 83.0239016113388, "xcomet_score": 0.6430084109306335, "xcomet_qe_score": 0.5870615243911743, "metricx_score": 9.331979751586914, "metricx_qe_score": 14.827659606933594, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple. Dans un ensemble de données introduit dans le premier.", "metrics": {"bleu_score": 7.474875887495341, "chrf_score": 51.88529989150897, "xcomet_score": 0.4122784435749054, "xcomet_qe_score": 0.4446430504322052, "metricx_score": 7.068302154541016, "metricx_qe_score": 8.850099563598633, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le jeu de données est un jeu de données universitaire", "metrics": {"bleu_score": 19.67497981115564, "chrf_score": 71.4120105415968, "xcomet_score": 0.9365238547325134, "xcomet_qe_score": 0.8853856325149536, "metricx_score": 0.934334933757782, "metricx_qe_score": 0.7698537111282349, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsqu'il s'agit de classer les universités en universités de faible rang et en universités de haut rang.", "metrics": {"bleu_score": 67.73401400577126, "chrf_score": 76.18647639058622, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9557015895843506, "metricx_qe_score": 1.4649243354797363, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons Wikipedia comme base de connaissances.", "metrics": {"bleu_score": 16.0529461904344, "chrf_score": 68.12699120128313, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.24026861786842346, "metricx_qe_score": 0.1657801866531372, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase de Fest est le couplage d'entités.", "metrics": {"bleu_score": 32.46679154750989, "chrf_score": 63.37069678603995, "xcomet_score": 0.6424108743667603, "xcomet_qe_score": 0.7598719596862793, "metricx_score": 6.167429447174072, "metricx_qe_score": 6.8516526222229, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque chaque entité, dans cet exemple le nom de l'université, est liée à une entité au sein de la base de connaissances", "metrics": {"bleu_score": 81.36749447931932, "chrf_score": 94.82244170291543, "xcomet_score": 0.9754917621612549, "xcomet_qe_score": 0.9546369314193726, "metricx_score": 0.77728670835495, "metricx_qe_score": 1.0908942222595215, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte des entités de la base de connaissances est extrait et ajouté au jeu de données.", "metrics": {"bleu_score": 67.36041912625802, "chrf_score": 89.91782906832555, "xcomet_score": 0.9177287220954895, "xcomet_qe_score": 0.9149763584136963, "metricx_score": 1.626519799232483, "metricx_qe_score": 1.662952184677124, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le texte est le résumé de la page Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5573669075965881, "metricx_qe_score": 0.8606062531471252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Nous devons maintenant générer ou extraire des caractéristiques du texte récupéré.", "metrics": {"bleu_score": 21.099261895175324, "chrf_score": 54.32807460126669, "xcomet_score": 0.9790385961532593, "xcomet_qe_score": 1.0, "metricx_score": 1.7824831008911133, "metricx_qe_score": 1.277591586112976, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc besoin d'une phase d'extraction des caractéristiques qui inclut l'analyse de texte.", "metrics": {"bleu_score": 38.70605144677149, "chrf_score": 67.7450657326771, "xcomet_score": 0.9889019727706909, "xcomet_qe_score": 0.9709123969078064, "metricx_score": 3.97355055809021, "metricx_qe_score": 3.969383716583252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "et c'est la principale nouveauté de cet article et j'y plongerai plus avant dans la diapositive suivante", "metrics": {"bleu_score": 32.009382054351796, "chrf_score": 54.7882004976996, "xcomet_score": 0.6380062103271484, "xcomet_qe_score": 0.6165598630905151, "metricx_score": 4.5810136795043945, "metricx_qe_score": 3.640766143798828, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction des caractéristiques, il y a une phase de génération de caractéristiques, où nous utilisons les caractéristiques extraites pour générer un petit nombre de nouvelles caractéristiques.", "metrics": {"bleu_score": 61.14887872946488, "chrf_score": 69.47474763992429, "xcomet_score": 0.9686183929443359, "xcomet_qe_score": 0.9990984201431274, "metricx_score": 2.1400275230407715, "metricx_qe_score": 0.9856359958648682, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, générez des caractéristiques en fonction du nombre de classes du jeu de données original.", "metrics": {"bleu_score": 9.880782578056978, "chrf_score": 56.06289422475845, "xcomet_score": 0.8874317407608032, "xcomet_qe_score": 0.6921939849853516, "metricx_score": 4.3469767570495605, "metricx_qe_score": 3.1474545001983643, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données original comporte deux classes", "metrics": {"bleu_score": 28.997844147152072, "chrf_score": 63.86111269607918, "xcomet_score": 0.9943541288375854, "xcomet_qe_score": 0.9959211349487305, "metricx_score": 1.0562043190002441, "metricx_qe_score": 0.8206802010536194, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, commencez par générer deux nouvelles caractéristiques", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 36.32765939744477, "xcomet_score": 0.16338780522346497, "xcomet_qe_score": 0.20181745290756226, "metricx_score": 9.26601505279541, "metricx_qe_score": 8.604156494140625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "mais si le jeu de données a cinq classes, générez d'abord cinq nouvelles caractéristiques", "metrics": {"bleu_score": 13.380161378318954, "chrf_score": 49.5650294365833, "xcomet_score": 0.43834346532821655, "xcomet_qe_score": 0.39181971549987793, "metricx_score": 8.909337043762207, "metricx_qe_score": 10.4036865234375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque caractéristique représente la probabilité pour chaque classe", "metrics": {"bleu_score": 62.401954419369176, "chrf_score": 77.29172625963454, "xcomet_score": 0.9508228302001953, "xcomet_qe_score": 1.0, "metricx_score": 1.1118911504745483, "metricx_qe_score": 1.2251700162887573, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état actuel de l'art en matière d'analyse de texte, à savoir les modèles de langage basés sur les transformateurs, l'accentuation des lettres S B G P T, etc.", "metrics": {"bleu_score": 21.47702958962869, "chrf_score": 55.46444615963876, "xcomet_score": 0.1948554813861847, "xcomet_qe_score": 0.28785240650177, "metricx_score": 8.892285346984863, "metricx_qe_score": 9.50072193145752, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "Mais il est peu probable que nous puissions entraîner un modèle linguistique en utilisant les ensembles de données d'entrée.", "metrics": {"bleu_score": 44.129945550173765, "chrf_score": 67.93411192596676, "xcomet_score": 0.9211719036102295, "xcomet_qe_score": 0.9688928127288818, "metricx_score": 2.4642231464385986, "metricx_qe_score": 2.0305304527282715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, une approche naïve consistera à affiner la tâche cible", "metrics": {"bleu_score": 39.12360608928473, "chrf_score": 66.78642123781225, "xcomet_score": 0.9345026016235352, "xcomet_qe_score": 0.8129268884658813, "metricx_score": 1.872546672821045, "metricx_qe_score": 5.321902275085449, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, lors de la phase d'extraction future, nous pourrons télécharger un modèle linguistique par tendance, ajuster finement le modèle linguistique sur l'ensemble de données cible", "metrics": {"bleu_score": 8.359764098433711, "chrf_score": 52.0143673754137, "xcomet_score": 0.5426486730575562, "xcomet_qe_score": 0.658912181854248, "metricx_score": 8.939303398132324, "metricx_qe_score": 8.781038284301758, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, pour affiner le modèle linguistique afin de classer le texte en classes, abstraire en classes basses ou hautes", "metrics": {"bleu_score": 39.32517147695012, "chrf_score": 71.5648635001154, "xcomet_score": 0.668070912361145, "xcomet_qe_score": 0.7242175340652466, "metricx_score": 4.426498889923096, "metricx_qe_score": 5.327155113220215, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "recevoir la sortie du modèle linguistique, qui est la probabilité pour chaque classe, et utiliser comme nouvelles caractéristiques", "metrics": {"bleu_score": 26.316318117663407, "chrf_score": 62.52951429244449, "xcomet_score": 0.8263906240463257, "xcomet_qe_score": 0.824944257736206, "metricx_score": 4.999495983123779, "metricx_qe_score": 6.303506374359131, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que les ensembles de données peuvent avoir peu d'étiquettes d'entités distinctes.", "metrics": {"bleu_score": 44.80640212080463, "chrf_score": 79.69004356320814, "xcomet_score": 0.8347338438034058, "xcomet_qe_score": 0.8528017997741699, "metricx_score": 4.422610759735107, "metricx_qe_score": 4.827484130859375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, presque la moitié des ensembles de données contiennent moins de 400 échantillons et le plus petit ensemble de données contient 35 échantillons dans son ensemble d'entraînement.", "metrics": {"bleu_score": 23.517613599813988, "chrf_score": 68.30235571659166, "xcomet_score": 0.9238623380661011, "xcomet_qe_score": 0.9460887312889099, "metricx_score": 1.424108862876892, "metricx_qe_score": 1.255797266960144, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, affiner un modèle linguistique sur ce jeu de données sera inefficace.", "metrics": {"bleu_score": 8.280453072947422, "chrf_score": 57.057220280494036, "xcomet_score": 0.9580610990524292, "xcomet_qe_score": 0.9682168960571289, "metricx_score": 1.2482987642288208, "metricx_qe_score": 1.2583656311035156, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons utiliser des connaissances antérieures sur des données pré-analysées.", "metrics": {"bleu_score": 54.52469119630866, "chrf_score": 82.16182445792182, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.904136061668396, "metricx_qe_score": 0.9393673539161682, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "Puisque nous pouvons utiliser plusieurs ensembles de données, nous pouvons utiliser les ensembles de données N-moins-un pour recueillir des informations sur les ensembles de données N-moins-un et utiliser ces informations lorsque nous analysons l'ensemble de données N.", "metrics": {"bleu_score": 38.46208555567544, "chrf_score": 69.57410501363063, "xcomet_score": 0.6358075141906738, "xcomet_qe_score": 0.6118869185447693, "metricx_score": 6.760074615478516, "metricx_qe_score": 6.804723262786865, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "Ce que nous suggérons, c'est d'ajouter une autre phase d'affinage.", "metrics": {"bleu_score": 76.04321823471474, "chrf_score": 83.05632979523111, "xcomet_score": 0.9060847759246826, "xcomet_qe_score": 0.8419142961502075, "metricx_score": 1.8232682943344116, "metricx_qe_score": 1.9570674896240234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "et phase de réglage préliminaire du multitâche.", "metrics": {"bleu_score": 13.888095170058955, "chrf_score": 58.96231048220631, "xcomet_score": 0.8322896957397461, "xcomet_qe_score": 0.7391952276229858, "metricx_score": 4.439968109130859, "metricx_qe_score": 3.9711380004882812, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous trouvons le modèle linguistique sur les ensembles de données NMS1,", "metrics": {"bleu_score": 9.30514025247622, "chrf_score": 44.89351310254435, "xcomet_score": 0.35792744159698486, "xcomet_qe_score": 0.3203294277191162, "metricx_score": 9.12950325012207, "metricx_qe_score": 8.570671081542969, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "Puis nous exécutons une autre phase d'affinage, qui est un affinage ciblé, lorsque nous trouvons le modèle linguistique sur l'ensemble de données cible final.", "metrics": {"bleu_score": 21.766420438940976, "chrf_score": 54.86958596276262, "xcomet_score": 0.6014094352722168, "xcomet_qe_score": 0.6122368574142456, "metricx_score": 6.966753959655762, "metricx_qe_score": 6.336033821105957, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "L'état de l'art en matière d'optimisation fine multitâche appelée MDDN.", "metrics": {"bleu_score": 4.9323515694897075, "chrf_score": 40.928048234433284, "xcomet_score": 0.7012015581130981, "xcomet_qe_score": 0.9033902883529663, "metricx_score": 5.654489040374756, "metricx_qe_score": 4.794094085693359, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "Dans MTDN, MTDN conserve le nombre de tâches dans l'ensemble d'entraînement.", "metrics": {"bleu_score": 33.913176178439, "chrf_score": 51.914653413024915, "xcomet_score": 0.3901282846927643, "xcomet_qe_score": 0.4832744002342224, "metricx_score": 13.31881332397461, "metricx_qe_score": 10.76392650604248, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans cet exemple, il y a quatre tâches dans l'ensemble d'entraînement, donc empty&nbsp; DNA maintient quatre têtes comme vous pouvez le voir sur l'image", "metrics": {"bleu_score": 61.29419859056384, "chrf_score": 74.53691584742509, "xcomet_score": 0.6229375004768372, "xcomet_qe_score": 0.5438814163208008, "metricx_score": 10.25631046295166, "metricx_qe_score": 12.320625305175781, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "et il sélectionne un badge aléatoire de l'ensemble d'entraînement.", "metrics": {"bleu_score": 16.807407519804237, "chrf_score": 51.323784942238746, "xcomet_score": 0.40739119052886963, "xcomet_qe_score": 0.3071308135986328, "metricx_score": 6.658060073852539, "metricx_qe_score": 6.670732021331787, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "et si le badge aléatoire appartient par exemple aux tâches de classification de phrases chantées, il exécute des passes avant et arrière à travers la première tête", "metrics": {"bleu_score": 27.26116625131945, "chrf_score": 60.393475000584196, "xcomet_score": 0.3001067042350769, "xcomet_qe_score": 0.2975442707538605, "metricx_score": 13.555924415588379, "metricx_qe_score": 14.60695743560791, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot aléatoire doit être capable de se classer, la tâche consiste à aller et venir à travers la dernière tête.", "metrics": {"bleu_score": 26.66066053854725, "chrf_score": 48.22116452302927, "xcomet_score": 0.6142539978027344, "xcomet_qe_score": 0.5808571577072144, "metricx_score": 8.175971031188965, "metricx_qe_score": 9.441250801086426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, table, dataset et row sont le nombre de classes.", "metrics": {"bleu_score": 41.211837513230265, "chrf_score": 55.241418757945816, "xcomet_score": 0.504143238067627, "xcomet_qe_score": 0.6483372449874878, "metricx_score": 17.44199562072754, "metricx_qe_score": 19.182640075683594, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a donc beaucoup de tâches.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7176141738891602, "metricx_qe_score": 0.8257766962051392, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "Le MTDN maintient un certain nombre de classes de têtes, de couches de sortie.", "metrics": {"bleu_score": 34.20788649214953, "chrf_score": 68.96431341173623, "xcomet_score": 0.5131513476371765, "xcomet_qe_score": 0.6823283433914185, "metricx_score": 5.675413131713867, "metricx_qe_score": 7.012145042419434, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, MTDN doit initier de nouvelles têtes pour un nouvel ensemble de données avec une nouvelle tâche.", "metrics": {"bleu_score": 38.27673535697133, "chrf_score": 68.59077906615504, "xcomet_score": 0.7645642757415771, "xcomet_qe_score": 0.701545000076294, "metricx_score": 5.821863651275635, "metricx_qe_score": 7.0779852867126465, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche s'appelle le réglage fin par reformulation de tâche. Au lieu de maintenir plusieurs têtes, nous reformulons chaque ensemble de données en une phrase par problème de classification, ce qui représente deux classes de tâches.", "metrics": {"bleu_score": 40.20253813997583, "chrf_score": 65.03183192987075, "xcomet_score": 0.6413624286651611, "xcomet_qe_score": 0.5955250859260559, "metricx_score": 6.136776924133301, "metricx_qe_score": 6.011192321777344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple.", "metrics": {"bleu_score": 46.30777161991026, "chrf_score": 48.32474847235818, "xcomet_score": 0.9386066198348999, "xcomet_qe_score": 0.9773107767105103, "metricx_score": 0.2514381408691406, "metricx_qe_score": 0.34026220440864563, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Ceci est notre ensemble de données d'entrée, qui se compose d'entités, de caractéristiques, de texte et de classes.", "metrics": {"bleu_score": 36.227557436010244, "chrf_score": 59.85552584207397, "xcomet_score": 0.9707057476043701, "xcomet_qe_score": 1.0, "metricx_score": 2.173395872116089, "metricx_qe_score": 2.464421510696411, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous reformulons la tâche en passant de la classification du texte en faible et élevé à la classification du texte, de l'abstrait et de la classe en vrai ou faux.", "metrics": {"bleu_score": 37.58610313819115, "chrf_score": 60.65191551633093, "xcomet_score": 0.7092766761779785, "xcomet_qe_score": 0.7382036447525024, "metricx_score": 4.530405044555664, "metricx_qe_score": 3.9608101844787598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous entraînons le modèle linguistique à classer un résumé et une classe, pour déterminer si le résumé appartient ou non à la classe.", "metrics": {"bleu_score": 29.847078751184814, "chrf_score": 58.63919463855566, "xcomet_score": 0.628190279006958, "xcomet_qe_score": 0.4726601541042328, "metricx_score": 4.607903003692627, "metricx_qe_score": 6.744867324829102, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Le vecteur d'étiquette dans ce cas est donc toujours un vecteur qui se compose toujours de deux classes", "metrics": {"bleu_score": 12.149176141753365, "chrf_score": 62.594116582871585, "xcomet_score": 0.8882119655609131, "xcomet_qe_score": 0.8487310409545898, "metricx_score": 6.062142372131348, "metricx_qe_score": 6.83856725692749, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici l'algorithme de notre approche d'affinage affiné.", "metrics": {"bleu_score": 4.2812704196691245, "chrf_score": 37.71735034681219, "xcomet_score": 0.800084114074707, "xcomet_qe_score": 0.8036738634109497, "metricx_score": 9.388811111450195, "metricx_qe_score": 9.28021240234375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons donc le cadre complet", "metrics": {"bleu_score": 42.72870063962342, "chrf_score": 77.55145226720425, "xcomet_score": 0.9724986553192139, "xcomet_qe_score": 0.9444727897644043, "metricx_score": 1.2925015687942505, "metricx_qe_score": 4.63204288482666, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "Le jeu de données est vraiment rapide.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 24.12159320273335, "xcomet_score": 0.11193486303091049, "xcomet_qe_score": 0.09718917310237885, "metricx_score": 12.921589851379395, "metricx_qe_score": 13.026897430419922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "et ensuite exécuter d'abord la phase de liaison.", "metrics": {"bleu_score": 31.55984539112946, "chrf_score": 51.529339500347646, "xcomet_score": 0.2796754539012909, "xcomet_qe_score": 0.3246113955974579, "metricx_score": 13.410215377807617, "metricx_qe_score": 14.975767135620117, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "extraire le texte de la base de connaissances qui, dans cet exemple, est le résumé de la page Wikipédia.", "metrics": {"bleu_score": 65.54353481249281, "chrf_score": 83.86763582452794, "xcomet_score": 0.8108745217323303, "xcomet_qe_score": 0.7755404710769653, "metricx_score": 5.147960186004639, "metricx_qe_score": 5.499853134155273, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "Puis il reformule la tâche en une tâche de classification par phrase", "metrics": {"bleu_score": 36.19893509456547, "chrf_score": 63.38946263043134, "xcomet_score": 0.705071210861206, "xcomet_qe_score": 0.9099298715591431, "metricx_score": 4.6591362953186035, "metricx_qe_score": 3.8838202953338623, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "a appliqué le modèle linguistique à la nouvelle tâche et a produit une probabilité pour chaque classe", "metrics": {"bleu_score": 36.7305422064342, "chrf_score": 70.6290802919031, "xcomet_score": 0.6432178020477295, "xcomet_qe_score": 0.5556126832962036, "metricx_score": 2.9639222621917725, "metricx_qe_score": 3.032011032104492, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que le modèle linguistique est déjà affiné sur un ensemble de données N moins 1 en utilisant un affinage préalable multitâche.", "metrics": {"bleu_score": 10.71370184351315, "chrf_score": 50.977727224505855, "xcomet_score": 0.9478821754455566, "xcomet_qe_score": 0.8648095726966858, "metricx_score": 1.674241304397583, "metricx_qe_score": 1.7783619165420532, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous utilisons le vecteur de sortie du modèle linguistique comme une nouvelle caractéristique générée dans le nombre de classes.", "metrics": {"bleu_score": 67.40705509899853, "chrf_score": 77.82797724718824, "xcomet_score": 0.891135573387146, "xcomet_qe_score": 0.9339526891708374, "metricx_score": 3.8746848106384277, "metricx_qe_score": 5.268843650817871, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un ensemble de données de classification tabulaire de 17, qui varie en taille, en caractéristiques, en équilibre, en domaine et en performance initiale.", "metrics": {"bleu_score": 29.75928234249098, "chrf_score": 75.0303132832461, "xcomet_score": 0.6418814063072205, "xcomet_qe_score": 0.6005914807319641, "metricx_score": 5.864129543304443, "metricx_qe_score": 5.92758846282959, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "et comme bases de connaissances, nous utilisons Wikipédia", "metrics": {"bleu_score": 42.0886844306855, "chrf_score": 75.43517724375056, "xcomet_score": 0.9737377166748047, "xcomet_qe_score": 0.9875475168228149, "metricx_score": 1.0669723749160767, "metricx_qe_score": 0.7938600778579712, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concevons notre expérience comme une évaluation en temps réel lorsque nous entraînons rapidement plus de 16 ensembles de données et l'appliquons au 17e ensemble de données.", "metrics": {"bleu_score": 26.16747576701775, "chrf_score": 62.22997806497945, "xcomet_score": 0.22795984148979187, "xcomet_qe_score": 0.20231756567955017, "metricx_score": 7.93344783782959, "metricx_qe_score": 8.030418395996094, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "Nous divisons également ces données en quatre plis et appliquons une validation croisée à quatre plis.", "metrics": {"bleu_score": 57.30574043798692, "chrf_score": 84.06890839186627, "xcomet_score": 0.7834388017654419, "xcomet_qe_score": 0.6861882209777832, "metricx_score": 1.5496222972869873, "metricx_qe_score": 3.1983895301818848, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "ensuite, nous générons la nouvelle fonctionnalité et les évaluons à l'aide de cinq classificateurs d'évaluation", "metrics": {"bleu_score": 20.751552684616424, "chrf_score": 73.18392231816247, "xcomet_score": 0.8985248804092407, "xcomet_qe_score": 0.8877973556518555, "metricx_score": 2.8690338134765625, "metricx_qe_score": 4.763443470001221, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons dans notre expérience une architecture basée sur la naissance", "metrics": {"bleu_score": 8.085578894348709, "chrf_score": 37.30609394316352, "xcomet_score": 0.18977485597133636, "xcomet_qe_score": 0.2687254846096039, "metricx_score": 17.30238151550293, "metricx_qe_score": 6.252300262451172, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre expérience.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 82.16212638893361, "xcomet_score": 0.9823514223098755, "xcomet_qe_score": 0.9937252998352051, "metricx_score": 0.3568568527698517, "metricx_qe_score": 0.5269936919212341, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "On peut voir que nous comparons notre cadre au réglage fin ciblé sur l'ensemble de données et au réglage fin préliminaire de MTDN.", "metrics": {"bleu_score": 24.680222803952923, "chrf_score": 46.470585141991876, "xcomet_score": 0.6938854455947876, "xcomet_qe_score": 0.739503026008606, "metricx_score": 8.044255256652832, "metricx_qe_score": 8.566000938415527, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "Et notre réglage fin reformulé atteint le meilleur résultat, la meilleure performance.", "metrics": {"bleu_score": 48.41524713034602, "chrf_score": 79.23183244006825, "xcomet_score": 0.9562221765518188, "xcomet_qe_score": 0.9813209772109985, "metricx_score": 2.4601736068725586, "metricx_qe_score": 3.9929871559143066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "Alors que MTDNN a obtenu une amélioration de 2 % par rapport à l'ajustement fin du jeu de données cible,", "metrics": {"bleu_score": 28.32038438962848, "chrf_score": 63.699887323941184, "xcomet_score": 0.49184107780456543, "xcomet_qe_score": 0.4542117416858673, "metricx_score": 4.415670394897461, "metricx_qe_score": 3.5175728797912598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "notre rendement a augmenté de six pour cent", "metrics": {"bleu_score": 25.124218547395092, "chrf_score": 33.61460911816791, "xcomet_score": 0.35008570551872253, "xcomet_qe_score": 0.7149021625518799, "metricx_score": 5.185108184814453, "metricx_qe_score": 5.218907833099365, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous examinons le petit ensemble de données, nous pouvons voir que la performance du MTDN diminue et que l'amélioration de la phase de réglage fin préliminaire en multitâche diminue à 1,5 %.", "metrics": {"bleu_score": 37.838485456537555, "chrf_score": 66.7022673628152, "xcomet_score": 0.7527703642845154, "xcomet_qe_score": 0.7533489465713501, "metricx_score": 5.453276634216309, "metricx_qe_score": 6.2990641593933105, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "mais notre performance a augmenté à 11 % par rapport au réglage fin de la tâche cible seul", "metrics": {"bleu_score": 28.43329181530769, "chrf_score": 57.287885830485784, "xcomet_score": 0.7885410189628601, "xcomet_qe_score": 0.7575943470001221, "metricx_score": 5.8627214431762695, "metricx_qe_score": 7.4291205406188965, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "car la sommation rapide permet d'enrichir rapidement une trentaine d'échantillons dans notre expérience", "metrics": {"bleu_score": 2.315472233965254, "chrf_score": 43.005990393657356, "xcomet_score": 0.2823650538921356, "xcomet_qe_score": 0.22898021340370178, "metricx_score": 9.86465072631836, "metricx_qe_score": 10.866997718811035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "Il utilise une architecture pour tous les ensembles de données de tâches.", "metrics": {"bleu_score": 33.495318896976464, "chrf_score": 75.42593815170618, "xcomet_score": 0.9868813753128052, "xcomet_qe_score": 0.9803872108459473, "metricx_score": 3.605736017227173, "metricx_qe_score": 3.802783966064453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela conserve la tête du modèle.", "metrics": {"bleu_score": 54.10822690539397, "chrf_score": 63.79769019519902, "xcomet_score": 0.7745968103408813, "xcomet_qe_score": 0.6426060199737549, "metricx_score": 4.83475399017334, "metricx_qe_score": 6.767157554626465, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cela ajoute une phase de reformulation", "metrics": {"bleu_score": 86.6877899750182, "chrf_score": 97.72841502916877, "xcomet_score": 0.9976011514663696, "xcomet_qe_score": 1.0, "metricx_score": 1.414311408996582, "metricx_qe_score": 2.79911732673645, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'appelle le « Train Set » et il a besoin d'une valeur cible avec un sens sémantique afin que nous puissions l'intégrer dans le modèle linguistique et l'utiliser dans la phrase par problème de classification.", "metrics": {"bleu_score": 45.5174872968905, "chrf_score": 68.80996798050793, "xcomet_score": 0.46027812361717224, "xcomet_qe_score": 0.5642503499984741, "metricx_score": 8.329988479614258, "metricx_qe_score": 7.600739002227783, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Merci.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10382990539073944, "metricx_qe_score": 0.4022793173789978, "linguapy_score": [1, "ITALIAN"]}}
