{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous. Aujourd'hui, je vais présenter notre travail de recherche intitulé \"Apprentissage de la résolution de problèmes complexes par extraction de motifs déductibles\".", "metrics": {"bleu_score": 26.2160865379125, "chrf_score": 59.92315035219317, "xcomet_score": 0.7299898862838745, "xcomet_qe_score": 0.7773187160491943, "metricx_score": 5.405702590942383, "metricx_qe_score": 5.45206356048584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "Je suis Alan du laboratoire d'IA de Biden et c'est un travail conjoint avec Thierry de l'Université du Texas à Austin et Wayloo de SUDD.", "metrics": {"bleu_score": 23.59508424124588, "chrf_score": 47.062262372839555, "xcomet_score": 0.20373575389385223, "xcomet_qe_score": 0.13852229714393616, "metricx_score": 13.28803825378418, "metricx_qe_score": 12.977485656738281, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, j'aimerais parler de notre motivation à raisonner.", "metrics": {"bleu_score": 63.8194179668201, "chrf_score": 80.84181753080621, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.6123785972595215, "metricx_qe_score": 1.4586447477340698, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Voici des exemples où le raisonnement en plusieurs étapes est utile.", "metrics": {"bleu_score": 50.895162958220745, "chrf_score": 68.88613062472307, "xcomet_score": 0.9631788730621338, "xcomet_qe_score": 1.0, "metricx_score": 0.308756947517395, "metricx_qe_score": 0.4712192416191101, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Cette figure est tirée du document PALM où ils effectuent des incitations pour résoudre le problème mathématique dans un scénario d'apprentissage fusionné.", "metrics": {"bleu_score": 8.277097518978794, "chrf_score": 48.10239694708436, "xcomet_score": 0.30231595039367676, "xcomet_qe_score": 0.479228138923645, "metricx_score": 8.84371280670166, "metricx_qe_score": 7.354315280914307, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, du côté gauche du réseau, nous pouvons voir que si nous donnons quelques exemples avec juste des questions et des réponses, nous ne pourrons peut-être pas obtenir les réponses correctes.", "metrics": {"bleu_score": 47.91502886391992, "chrf_score": 70.43869969898807, "xcomet_score": 0.8667975664138794, "xcomet_qe_score": 0.8354254364967346, "metricx_score": 2.007106304168701, "metricx_qe_score": 1.9582312107086182, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si nous fournissons une description plus détaillée du raisonnement, le modèle est capable de prédire la description du raisonnement et de faire une prédiction correcte ici.", "metrics": {"bleu_score": 43.7742810290776, "chrf_score": 71.77345369389295, "xcomet_score": 0.9670566320419312, "xcomet_qe_score": 0.9935109615325928, "metricx_score": 0.9623212218284607, "metricx_qe_score": 1.4001814126968384, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Il est donc bon d'avoir un raisonnement multi-étapes interprétable comme résultat.", "metrics": {"bleu_score": 12.12428055266944, "chrf_score": 66.848370582207, "xcomet_score": 0.9998177289962769, "xcomet_qe_score": 1.0, "metricx_score": 1.3215548992156982, "metricx_qe_score": 1.875845193862915, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pensons également que Mathwork Problem est une application simple à utiliser pour évaluer de telles capacités de raisonnement.", "metrics": {"bleu_score": 50.54215146508146, "chrf_score": 68.3690318663571, "xcomet_score": 0.8399680852890015, "xcomet_qe_score": 0.8728749752044678, "metricx_score": 5.011134147644043, "metricx_qe_score": 5.052440166473389, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans notre problème, étant donné les questions, nous devons résoudre cette question et obtenir les réponses numériques.", "metrics": {"bleu_score": 57.96664416079147, "chrf_score": 74.56068073714678, "xcomet_score": 0.9393302202224731, "xcomet_qe_score": 0.9301223158836365, "metricx_score": 2.306046962738037, "metricx_qe_score": 2.4982619285583496, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos ensembles de données, on nous donne également l'expression mathématique qui conduit à cette réponse particulière.", "metrics": {"bleu_score": 49.24584878270649, "chrf_score": 81.1413696475458, "xcomet_score": 0.9820101261138916, "xcomet_qe_score": 0.9784786701202393, "metricx_score": 2.7192282676696777, "metricx_qe_score": 3.3011441230773926, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, certaines hypothèses s'appliquent également comme dans les travaux précédents.", "metrics": {"bleu_score": 72.92571723872932, "chrf_score": 81.74616035973521, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.85512375831604, "metricx_qe_score": 2.617657423019409, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que la précision des quantités est connue.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.0283783674240112, "metricx_qe_score": 1.3673415184020996, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous ne considérons que les opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentiation.", "metrics": {"bleu_score": 92.10589320522861, "chrf_score": 95.68299687983432, "xcomet_score": 0.969541072845459, "xcomet_qe_score": 0.9754696488380432, "metricx_score": 1.1877816915512085, "metricx_qe_score": 0.6469014883041382, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les opérateurs complexes peuvent en réalité être décomposés en ces opérateurs de base.", "metrics": {"bleu_score": 50.7196093945688, "chrf_score": 69.8708284380725, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5208061337471008, "metricx_qe_score": 0.4972343444824219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, les travaux antérieurs sur la résolution de problèmes méthodologiques peuvent en fait être classés en deux catégories : la séquence à séquence et la séquence à modèle d'arbre.", "metrics": {"bleu_score": 19.189570068047395, "chrf_score": 61.903567105915556, "xcomet_score": 0.5680650472640991, "xcomet_qe_score": 0.5731474161148071, "metricx_score": 6.795536041259766, "metricx_qe_score": 6.934214115142822, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le modèle séquence à séquence traditionnel convertit l'expression en une séquence spécifique pour la génération.", "metrics": {"bleu_score": 71.60350546947924, "chrf_score": 92.22330207239987, "xcomet_score": 0.8261331915855408, "xcomet_qe_score": 0.8099256753921509, "metricx_score": 1.6664644479751587, "metricx_qe_score": 1.9003328084945679, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est assez facile à mettre en œuvre et il peut s'appliquer à de nombreux problèmes complexes différents.", "metrics": {"bleu_score": 51.086369427314914, "chrf_score": 73.64656194763059, "xcomet_score": 0.9600332975387573, "xcomet_qe_score": 0.9602320194244385, "metricx_score": 0.876373291015625, "metricx_qe_score": 1.27777099609375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les inconvénients sont que les performances ne sont généralement pas meilleures que celles du modèle de structure et il manque d'interprétabilité pour la prédiction.", "metrics": {"bleu_score": 19.359517339258716, "chrf_score": 72.83453339924034, "xcomet_score": 0.8435922265052795, "xcomet_qe_score": 0.8216019868850708, "metricx_score": 4.642195224761963, "metricx_qe_score": 2.9490444660186768, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en réalité, cette direction est toujours très populaire à cause du modèle transformateur.", "metrics": {"bleu_score": 43.014140034028145, "chrf_score": 62.17738735529107, "xcomet_score": 0.8671234846115112, "xcomet_qe_score": 0.8596389293670654, "metricx_score": 5.030663967132568, "metricx_qe_score": 3.930050849914551, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans les modèles basés sur les arbres, nous structurons ces expressions sous forme d'arbre et suivons un parcours pré-ordre dans les générations d'arbres.", "metrics": {"bleu_score": 46.03909996443368, "chrf_score": 69.21813535775986, "xcomet_score": 0.8616049885749817, "xcomet_qe_score": 0.8654000163078308, "metricx_score": 4.377847194671631, "metricx_qe_score": 4.469575881958008, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous continuons à générer les opérateurs jusqu'à ce que nous atteignions les feuilles qui sont les quantités.", "metrics": {"bleu_score": 64.03113144057492, "chrf_score": 81.6579497532831, "xcomet_score": 0.8244457244873047, "xcomet_qe_score": 0.8049533367156982, "metricx_score": 3.169347047805786, "metricx_qe_score": 4.009009838104248, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, le point positif est qu'il nous donne en fait cette structure d'arbre binaire. Mais en réalité, c'est assez contre-intuitif parce que nous générons d'abord l'opérateur, puis, à la fin, nous générons les quantités.", "metrics": {"bleu_score": 65.107829146704, "chrf_score": 80.86499269566244, "xcomet_score": 0.9582846164703369, "xcomet_qe_score": 0.9610418081283569, "metricx_score": 2.851792812347412, "metricx_qe_score": 3.83496356010437, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose, c'est qu'il contient aussi des calculs répétitifs.", "metrics": {"bleu_score": 39.832871551569504, "chrf_score": 66.75788060680503, "xcomet_score": 0.9301498532295227, "xcomet_qe_score": 0.9874109029769897, "metricx_score": 1.8331148624420166, "metricx_qe_score": 1.3039352893829346, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ici, si nous regardons cette expression huit fois trois plus trois, elle est en fait générée deux fois. Mais en fait, nous devrions réutiliser les résultats", "metrics": {"bleu_score": 55.53306012617849, "chrf_score": 83.29106193510147, "xcomet_score": 0.9979590177536011, "xcomet_qe_score": 0.986733078956604, "metricx_score": 1.553030014038086, "metricx_qe_score": 1.634340763092041, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre approche de proposition, nous voulons résoudre ces problèmes de manière progressive et interprétable.", "metrics": {"bleu_score": 48.12700337596407, "chrf_score": 74.84424466230308, "xcomet_score": 0.869775652885437, "xcomet_qe_score": 0.8567571640014648, "metricx_score": 4.50308895111084, "metricx_qe_score": 4.337860107421875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, par exemple, ici, à l'étape suivante, nous pouvons obtenir ce diviseur, qui est 27.", "metrics": {"bleu_score": 17.509131039045965, "chrf_score": 53.95660797318572, "xcomet_score": 0.8521658182144165, "xcomet_qe_score": 0.8021247386932373, "metricx_score": 2.926027536392212, "metricx_qe_score": 3.715317726135254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons également nous référer aux questions initiales pour trouver les contenus pertinents.", "metrics": {"bleu_score": 37.73213566354408, "chrf_score": 79.82893313414947, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6789897680282593, "metricx_qe_score": 0.6728734970092773, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous obtenons les diviseurs.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9926035404205322, "xcomet_qe_score": 0.9813810586929321, "metricx_score": 2.1472244262695312, "metricx_qe_score": 2.927687406539917, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, et ensuite, à cette troisième étape, nous obtenons en fait le quotient.", "metrics": {"bleu_score": 49.62822700197381, "chrf_score": 76.14592650536532, "xcomet_score": 0.9503658413887024, "xcomet_qe_score": 0.9733055233955383, "metricx_score": 4.220550060272217, "metricx_qe_score": 3.7411417961120605, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "Très bien. Et après ces trois étapes, nous pouvons en fait réutiliser les résultats de la deuxième étape, puis obtenir les résultats de la quatrième étape. Et enfin, nous pouvons obtenir les dividendes.", "metrics": {"bleu_score": 80.87405797366502, "chrf_score": 92.8567055827106, "xcomet_score": 0.9759167432785034, "xcomet_qe_score": 0.9760475158691406, "metricx_score": 1.8390755653381348, "metricx_qe_score": 3.2240777015686035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, nous générons directement l'expression entière plutôt que de générer des opérateurs ou des quantités individuelles.", "metrics": {"bleu_score": 18.784850100336804, "chrf_score": 58.32819811336884, "xcomet_score": 0.9835344552993774, "xcomet_qe_score": 0.9786281585693359, "metricx_score": 1.3183159828186035, "metricx_qe_score": 1.4463578462600708, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "Cela rend donc le processus plus précis.", "metrics": {"bleu_score": 59.4603557501361, "chrf_score": 87.93094020593963, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6577164530754089, "metricx_qe_score": 1.3236981630325317, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre système déductif, nous commençons d'abord avec un ensemble de quantités présentées dans les questions et incluant également certaines constantes comme notre état initial.", "metrics": {"bleu_score": 68.22315659383885, "chrf_score": 86.94471897304034, "xcomet_score": 0.9688185453414917, "xcomet_qe_score": 0.9449247717857361, "metricx_score": 2.827584981918335, "metricx_qe_score": 4.195785045623779, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "L'expression est donc représentée par EIJOP.", "metrics": {"bleu_score": 7.64649370538093, "chrf_score": 61.31749886839668, "xcomet_score": 0.9785304069519043, "xcomet_qe_score": 0.9675105810165405, "metricx_score": 1.1124985218048096, "metricx_qe_score": 1.9465159177780151, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "où nous effectuons les opérateurs de Qi à Qj et une telle expression est en fait dirigée.", "metrics": {"bleu_score": 27.278200342554264, "chrf_score": 69.17839540196617, "xcomet_score": 0.8755490183830261, "xcomet_qe_score": 0.8881582021713257, "metricx_score": 4.841419219970703, "metricx_qe_score": 7.830530643463135, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc également des mots de soustraction ici pour représenter la direction opposée.", "metrics": {"bleu_score": 35.268462829911606, "chrf_score": 72.96205516114084, "xcomet_score": 0.862683892250061, "xcomet_qe_score": 0.852669894695282, "metricx_score": 2.5268640518188477, "metricx_qe_score": 2.7128725051879883, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "Cela ressemble beaucoup à l'extraction de rayonnement.", "metrics": {"bleu_score": 17.20339087300932, "chrf_score": 39.34147492893672, "xcomet_score": 0.68043452501297, "xcomet_qe_score": 0.6198866367340088, "metricx_score": 6.907865524291992, "metricx_qe_score": 8.075563430786133, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans un système déductif formel, à l'instant t, nous appliquons l'opérateur entre la paire Qi et Qj, et nous obtenons alors ces nouvelles expressions.", "metrics": {"bleu_score": 27.983469084065106, "chrf_score": 59.33451615661426, "xcomet_score": 0.9281133413314819, "xcomet_qe_score": 0.955558180809021, "metricx_score": 1.5872273445129395, "metricx_qe_score": 1.569282054901123, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "nous l'ajoutons à l'état suivant pour qu'elle devienne une nouvelle quantité.", "metrics": {"bleu_score": 53.107253497886994, "chrf_score": 81.84298885354299, "xcomet_score": 0.963492751121521, "xcomet_qe_score": 0.9482529759407043, "metricx_score": 1.6492443084716797, "metricx_qe_score": 2.6319806575775146, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, cette diapositive illustre en fait l'évolution de l'état où nous continuons d'ajouter une expression à l'état actuel.", "metrics": {"bleu_score": 37.49801651358116, "chrf_score": 69.87152605843457, "xcomet_score": 0.8421608209609985, "xcomet_qe_score": 0.7475004196166992, "metricx_score": 3.530120611190796, "metricx_qe_score": 4.79678201675415, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos implémentations de modèles, nous utilisons d'abord un modèle linguistique pré-entraîné qui peut être des oiseaux ou des robots, puis nous codons une phrase et nous obtenons ces représentations de quantité.", "metrics": {"bleu_score": 39.68427844730258, "chrf_score": 68.39559059147831, "xcomet_score": 0.6082268953323364, "xcomet_qe_score": 0.6534150242805481, "metricx_score": 9.224485397338867, "metricx_qe_score": 9.390118598937988, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, une fois que nous avons les représentations quantitatives, nous pouvons commencer à faire des inférences.", "metrics": {"bleu_score": 47.9071425065913, "chrf_score": 73.29209051544434, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.6489012241363525, "metricx_qe_score": 1.7596518993377686, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "Nous montrons ici un exemple de Q un pour obtenir la représentation de Q un. Ils seront divisés par Q deux, puis multipliés par Q quatre.", "metrics": {"bleu_score": 25.723962032456946, "chrf_score": 65.55991412955271, "xcomet_score": 0.3797014653682709, "xcomet_qe_score": 0.4309949576854706, "metricx_score": 16.427669525146484, "metricx_qe_score": 14.31481647491455, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous obtenons la représentation de la paire, qui est essentiellement la concaténation entre Q1 et Q2. Ensuite, nous appliquons un réseau de type feedforward, qui est paramétré par l'opérateur.", "metrics": {"bleu_score": 42.08534593816981, "chrf_score": 70.34972721100758, "xcomet_score": 0.8639204502105713, "xcomet_qe_score": 0.8390370607376099, "metricx_score": 4.401483058929443, "metricx_qe_score": 4.004823207855225, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, nous obtenons l'expression de représentation Q1 divisé par Q2.", "metrics": {"bleu_score": 23.4092311684103, "chrf_score": 73.42824969334688, "xcomet_score": 0.8791177868843079, "xcomet_qe_score": 0.9309722185134888, "metricx_score": 4.598386764526367, "metricx_qe_score": 3.873321771621704, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en fait, en pratique, à l'étape de l'inférence, nous pourrions également obtenir l'expression incorrecte.", "metrics": {"bleu_score": 36.51625019670311, "chrf_score": 72.83935184733848, "xcomet_score": 0.9874356985092163, "xcomet_qe_score": 0.998699426651001, "metricx_score": 1.531229853630066, "metricx_qe_score": 2.0957045555114746, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, toute expression possible est égale à trois fois le nombre d'opérateurs.", "metrics": {"bleu_score": 67.39047062564734, "chrf_score": 87.93342635597244, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 1.0156081914901733, "metricx_qe_score": 1.9174286127090454, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, le point positif ici, c'est que nous pouvons facilement ajouter des contraintes pour contrôler cet espace de recherche.", "metrics": {"bleu_score": 73.20755362899838, "chrf_score": 84.01397711139839, "xcomet_score": 0.9603631496429443, "xcomet_qe_score": 0.9588572978973389, "metricx_score": 1.2446006536483765, "metricx_qe_score": 1.389100193977356, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement la supprimer de notre espace de recherche.", "metrics": {"bleu_score": 73.62853809865184, "chrf_score": 81.71776209831928, "xcomet_score": 0.9951730966567993, "xcomet_qe_score": 0.9794670343399048, "metricx_score": 0.37088721990585327, "metricx_qe_score": 0.45243895053863525, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans la deuxième étape, nous faisons la même chose, mais la seule différence est qu'il y a une quantité supplémentaire.", "metrics": {"bleu_score": 71.03600666390408, "chrf_score": 81.83922662836126, "xcomet_score": 0.9617201089859009, "xcomet_qe_score": 0.9233575463294983, "metricx_score": 3.420553207397461, "metricx_qe_score": 4.673766613006592, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "Cette quantité provient de l'expression calculée précédente.", "metrics": {"bleu_score": 31.708476589333063, "chrf_score": 74.09650727541442, "xcomet_score": 0.9993386268615723, "xcomet_qe_score": 0.995700478553772, "metricx_score": 0.5797427892684937, "metricx_qe_score": 0.8377796411514282, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc finalement obtenir cette expression finale Q treize.", "metrics": {"bleu_score": 15.048958015468578, "chrf_score": 61.425901634950876, "xcomet_score": 0.5862443447113037, "xcomet_qe_score": 0.7167104482650757, "metricx_score": 12.573606491088867, "metricx_qe_score": 13.988037109375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "trois fois Q quatre. Et nous pouvons également voir que le nombre de toutes les expressions possibles est différent de l'étape précédente.", "metrics": {"bleu_score": 69.78429290017012, "chrf_score": 88.15015635334538, "xcomet_score": 0.3129046559333801, "xcomet_qe_score": 0.39131292700767517, "metricx_score": 13.356603622436523, "metricx_qe_score": 17.14028549194336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ces différences rendent difficile l'application de la recherche par balayage car la distribution de probabilité entre ces deux étapes est déséquilibrée.", "metrics": {"bleu_score": 59.70228993860436, "chrf_score": 79.38499570066668, "xcomet_score": 0.9071063995361328, "xcomet_qe_score": 0.8976969122886658, "metricx_score": 1.9480876922607422, "metricx_qe_score": 1.4965810775756836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, la procédure d'entraînement est similaire à l'entraînement d'un modèle de séquence à séquence où nous optimisons la perte à chaque étape temporelle.", "metrics": {"bleu_score": 42.573206097101476, "chrf_score": 65.37292637276566, "xcomet_score": 0.6996498107910156, "xcomet_qe_score": 0.6016267538070679, "metricx_score": 3.096698045730591, "metricx_qe_score": 3.6439054012298584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également cette tau pour indiquer quand nous devons mettre fin à ce processus de génération.", "metrics": {"bleu_score": 53.85057399615972, "chrf_score": 74.1345796873535, "xcomet_score": 0.9718739986419678, "xcomet_qe_score": 0.9985607862472534, "metricx_score": 3.3744559288024902, "metricx_qe_score": 4.067068099975586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent d'une séquence à l'autre parce que l'espace est différent à chaque fois, alors que dans le modèle traditionnel séquence à séquence, c'est le nombre de vocabulaire.", "metrics": {"bleu_score": 53.13396226205312, "chrf_score": 78.67842995455607, "xcomet_score": 0.5056706070899963, "xcomet_qe_score": 0.5755391120910645, "metricx_score": 7.279797554016113, "metricx_qe_score": 7.9450764656066895, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela nous permet également d'imposer certaines contraintes issues de connaissances antérieures.", "metrics": {"bleu_score": 70.4805090506219, "chrf_score": 89.24264286254328, "xcomet_score": 0.9486253261566162, "xcomet_qe_score": 0.8975114822387695, "metricx_score": 1.1430037021636963, "metricx_qe_score": 1.2097399234771729, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Nous menons donc des expériences sur les ensembles de données de problèmes de méthodes couramment utilisés, MAWPS, Math 23K, MathQA et SWAM.", "metrics": {"bleu_score": 41.95311940818068, "chrf_score": 77.28118938807789, "xcomet_score": 0.604103147983551, "xcomet_qe_score": 0.6381773352622986, "metricx_score": 6.138031959533691, "metricx_qe_score": 6.1848931312561035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons brièvement les résultats par rapport aux meilleures approches précédentes.", "metrics": {"bleu_score": 58.282339541526554, "chrf_score": 76.15969047688054, "xcomet_score": 0.9925990104675293, "xcomet_qe_score": 0.9682251214981079, "metricx_score": 0.8979421257972717, "metricx_qe_score": 1.1303930282592773, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre variante la mieux performante est Roberta Dedative Reasoner.", "metrics": {"bleu_score": 26.20251007173262, "chrf_score": 71.68864158518006, "xcomet_score": 0.9439064264297485, "xcomet_qe_score": 0.9423720836639404, "metricx_score": 3.312037229537964, "metricx_qe_score": 3.2534072399139404, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "Et en fait, nous n'utilisons pas la recherche par balayage contrairement aux approches évidentes qui utilisent la recherche par balayage.", "metrics": {"bleu_score": 20.82460369035394, "chrf_score": 47.866591113749216, "xcomet_score": 0.7327896356582642, "xcomet_qe_score": 0.7702772617340088, "metricx_score": 4.277575492858887, "metricx_qe_score": 3.4673869609832764, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "Très bien. Donc, les meilleures approches sont souvent un modèle basé sur un arbre.", "metrics": {"bleu_score": 50.7196093945688, "chrf_score": 76.00571570550348, "xcomet_score": 0.9874438643455505, "xcomet_qe_score": 0.9742785692214966, "metricx_score": 0.9383713006973267, "metricx_qe_score": 1.1348261833190918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans l'ensemble, notre raisonneur est capable de surpasser de manière significative ce modèle basé sur l'arbre.", "metrics": {"bleu_score": 44.44183736091338, "chrf_score": 72.20424970156427, "xcomet_score": 0.9738843441009521, "xcomet_qe_score": 0.8917350769042969, "metricx_score": 3.854893445968628, "metricx_qe_score": 6.143208980560303, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons voir que le nombre absolu sur math QA ou SWAM n'est pas vraiment élevé.", "metrics": {"bleu_score": 25.28116869739494, "chrf_score": 68.31523511894049, "xcomet_score": 0.77500319480896, "xcomet_qe_score": 0.8063709735870361, "metricx_score": 4.271331310272217, "metricx_qe_score": 4.419055938720703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Nous enquêtons donc davantage sur les résultats sur place.", "metrics": {"bleu_score": 16.807407519804237, "chrf_score": 46.157729353558736, "xcomet_score": 0.5118492841720581, "xcomet_qe_score": 0.7569839954376221, "metricx_score": 3.287675380706787, "metricx_qe_score": 5.206596374511719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "marécage. Et cet ensemble de données est difficile à traiter car l'auteur a essayé d'ajouter manuellement quelque chose pour dérouter le modèle de traitement du langage naturel, comme ajouter des informations non pertinentes et des quantités supplémentaires.", "metrics": {"bleu_score": 47.57039898102752, "chrf_score": 76.34349692251139, "xcomet_score": 0.5864580869674683, "xcomet_qe_score": 0.4117647111415863, "metricx_score": 6.8626298904418945, "metricx_qe_score": 7.400638580322266, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre prédiction, nous constatons que certaines des valeurs intermédiaires sont en fait négatives.", "metrics": {"bleu_score": 46.24892603869296, "chrf_score": 73.46335092792414, "xcomet_score": 0.9883226156234741, "xcomet_qe_score": 1.0, "metricx_score": 1.16629159450531, "metricx_qe_score": 0.7037749886512756, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans cette question, nous demandons combien de pommes Jake a ?", "metrics": {"bleu_score": 28.414069717309758, "chrf_score": 74.70011218761906, "xcomet_score": 0.9324591159820557, "xcomet_qe_score": 0.9739420413970947, "metricx_score": 1.7954164743423462, "metricx_qe_score": 2.2183971405029297, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons des informations supplémentaires comme dix-sept moins de terrains de camping et Stephen a huit terrains de camping, ce qui est totalement sans rapport.", "metrics": {"bleu_score": 35.64808109225033, "chrf_score": 65.57584573367754, "xcomet_score": 0.4822614789009094, "xcomet_qe_score": 0.5209096670150757, "metricx_score": 16.062803268432617, "metricx_qe_score": 14.643091201782227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait une prédiction de ce genre, qui produit des valeurs négatives.", "metrics": {"bleu_score": 43.85068972747104, "chrf_score": 64.59760006048438, "xcomet_score": 0.9773280620574951, "xcomet_qe_score": 0.9947031736373901, "metricx_score": 2.7790186405181885, "metricx_qe_score": 2.903749465942383, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous observons ces deux expressions.", "metrics": {"bleu_score": 11.835764736093042, "chrf_score": 35.591235893124356, "xcomet_score": 0.2292582094669342, "xcomet_qe_score": 0.3586346507072449, "metricx_score": 16.36252784729004, "metricx_qe_score": 20.465259552001953, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc limiter cet espace de recherche en supprimant les résultats négatifs afin de pouvoir obtenir la bonne réponse.", "metrics": {"bleu_score": 51.96509820132598, "chrf_score": 68.27932923807907, "xcomet_score": 0.9296836853027344, "xcomet_qe_score": 0.87006676197052, "metricx_score": 2.1241626739501953, "metricx_qe_score": 3.1458418369293213, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous constatons que cette contrainte améliore en réalité considérablement certains modèles.", "metrics": {"bleu_score": 44.534504264163466, "chrf_score": 64.23642263344215, "xcomet_score": 0.9910334348678589, "xcomet_qe_score": 0.9889209270477295, "metricx_score": 1.375691294670105, "metricx_qe_score": 1.698866605758667, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, pour les oiseaux, nous avons amélioré sept points. Et puis pour le modèle de base Roberta, nous avons en fait amélioré deux points.", "metrics": {"bleu_score": 52.90994522895342, "chrf_score": 58.795781707007166, "xcomet_score": 0.5394577980041504, "xcomet_qe_score": 0.530353844165802, "metricx_score": 11.703166961669922, "metricx_qe_score": 10.600186347961426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, un meilleur modèle linguistique possède de meilleures capacités de compréhension du langage, de sorte que le nombre ici est plus élevé pour Roberta et plus faible pour Bertha.", "metrics": {"bleu_score": 41.73837838283501, "chrf_score": 55.52991586073417, "xcomet_score": 0.6600983142852783, "xcomet_qe_score": 0.9021599292755127, "metricx_score": 13.144623756408691, "metricx_qe_score": 5.66492223739624, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous essayons également d'analyser la difficulté derrière ce BPP.", "metrics": {"bleu_score": 63.8194179668201, "chrf_score": 78.30709318643578, "xcomet_score": 0.47298750281333923, "xcomet_qe_score": 0.46636196970939636, "metricx_score": 8.955744743347168, "metricx_qe_score": 12.996600151062012, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que le nombre de quantités non utilisées peut être considéré comme une information non pertinente ici.", "metrics": {"bleu_score": 58.66204912938539, "chrf_score": 90.56915947168946, "xcomet_score": 0.9996166229248047, "xcomet_qe_score": 0.9799081087112427, "metricx_score": 1.7777221202850342, "metricx_qe_score": 1.9587219953536987, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous pouvons voir ici que nous avons le pourcentage d'échantillons avec des quantités non utilisées et que le jeu de données du marais a la plus grande part.", "metrics": {"bleu_score": 39.40107785584635, "chrf_score": 75.45303542715608, "xcomet_score": 0.6507145166397095, "xcomet_qe_score": 0.636690616607666, "metricx_score": 8.166191101074219, "metricx_qe_score": 8.101656913757324, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons également la performance globale.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9156627655029297, "metricx_qe_score": 1.2110265493392944, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ces échantillons sans quantités non utilisées, la performance globale est donc en réalité supérieure à la performance réelle.", "metrics": {"bleu_score": 50.27960083292187, "chrf_score": 89.78252800501673, "xcomet_score": 0.7048153877258301, "xcomet_qe_score": 0.4980754852294922, "metricx_score": 4.468963146209717, "metricx_qe_score": 5.36093282699585, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "Mais avec ces échantillons et cette quantité non utilisée, c'est en fait bien pire que, euh, bien pire que.", "metrics": {"bleu_score": 37.25748409395151, "chrf_score": 65.79800254649216, "xcomet_score": 0.6514689922332764, "xcomet_qe_score": 0.6430328488349915, "metricx_score": 12.918479919433594, "metricx_qe_score": 12.863781929016113, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "Mauvaise performance. Pour MAWPS, nous n'avons pas vraiment beaucoup de dossiers de bureau, donc j'ignore simplement cette partie.", "metrics": {"bleu_score": 45.001473167434995, "chrf_score": 70.54712586545044, "xcomet_score": 0.1804124116897583, "xcomet_qe_score": 0.40536031126976013, "metricx_score": 8.988037109375, "metricx_qe_score": 10.62214183807373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous voulons enfin montrer l'interprétabilité à travers un exemple de participation à une question.", "metrics": {"bleu_score": 32.22538601891173, "chrf_score": 66.34850015658256, "xcomet_score": 0.3082582950592041, "xcomet_qe_score": 0.6261140704154968, "metricx_score": 7.507795810699463, "metricx_qe_score": 8.925887107849121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, notre modèle fait en réalité une prédiction erronée dès la première étape.", "metrics": {"bleu_score": 36.00565854285029, "chrf_score": 67.84706434636945, "xcomet_score": 0.99074387550354, "xcomet_qe_score": 0.9882351756095886, "metricx_score": 0.9161722660064697, "metricx_qe_score": 0.7885745763778687, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc effectivement établir un lien entre cette expression et la phrase ici, d'accord ?", "metrics": {"bleu_score": 12.03921753741131, "chrf_score": 56.383096936037646, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.4143627882003784, "metricx_qe_score": 1.2234656810760498, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons donc que cette phrase pourrait induire le modèle en erreur et conduire à une prédiction incorrecte.", "metrics": {"bleu_score": 60.98820960308448, "chrf_score": 77.64040440972902, "xcomet_score": 0.9966170787811279, "xcomet_qe_score": 0.9823441505432129, "metricx_score": 0.770254373550415, "metricx_qe_score": 0.4123237133026123, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, planter une trentaine de nouveaux arbres amène le modèle à penser qu'il devrait s'agir d'une addition d'opérateurs.", "metrics": {"bleu_score": 5.983278752571241, "chrf_score": 48.418987042577264, "xcomet_score": 0.6521936655044556, "xcomet_qe_score": 0.48597145080566406, "metricx_score": 5.421957492828369, "metricx_qe_score": 3.8490490913391113, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Nous essayons donc de réviser la phrase pour qu'elle ressemble à ceci : le nombre d'arbres de poire est de cinquante-cinq de moins que celui des pommiers.", "metrics": {"bleu_score": 21.232142217308585, "chrf_score": 55.982995837134965, "xcomet_score": 0.8909066915512085, "xcomet_qe_score": 0.9505681991577148, "metricx_score": 5.138160228729248, "metricx_qe_score": 4.300900936126709, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Nous procédons donc de manière à transmettre une sémantique plus précise, de sorte que le modèle puisse effectuer la prédiction correcte.", "metrics": {"bleu_score": 25.0737833894674, "chrf_score": 59.284106415388436, "xcomet_score": 0.9756402969360352, "xcomet_qe_score": 0.9686422348022461, "metricx_score": 2.0619587898254395, "metricx_qe_score": 2.2618143558502197, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, cette étude montre comment les prédictions interprétables nous aident à comprendre le comportement du modèle.", "metrics": {"bleu_score": 83.94327083733333, "chrf_score": 94.38448679358433, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.077393651008606, "metricx_qe_score": 0.783183753490448, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure notre travail, notre modèle est en fait assez efficace.", "metrics": {"bleu_score": 57.475393483140245, "chrf_score": 78.83479427187108, "xcomet_score": 0.9972312450408936, "xcomet_qe_score": 0.99419105052948, "metricx_score": 1.520257830619812, "metricx_qe_score": 1.7071630954742432, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "et nous sommes en mesure de fournir une procédure de résolution interprétable.", "metrics": {"bleu_score": 91.21679090703874, "chrf_score": 98.44852413664101, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.1259446144104004, "metricx_qe_score": 1.2876532077789307, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pouvons facilement intégrer certaines connaissances antérieures comme contrainte, ce qui peut aider à améliorer les performances.", "metrics": {"bleu_score": 20.313747122261766, "chrf_score": 72.24079035104036, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9544926881790161, "metricx_qe_score": 1.140217900276184, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et la dernière chose est que le mécanisme sous-jacent ne s'applique pas uniquement aux tâches de résolution de problèmes de réseau, mais aussi à d'autres tâches qui impliquent un raisonnement en plusieurs étapes.", "metrics": {"bleu_score": 65.58477295367683, "chrf_score": 89.46776250237585, "xcomet_score": 0.9958618879318237, "xcomet_qe_score": 1.0, "metricx_score": 0.5809659957885742, "metricx_qe_score": 0.7670202255249023, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons aussi certaines limites.", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 62.10666488002826, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13551399111747742, "metricx_qe_score": 0.2110535204410553, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "Si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0386240482330322, "metricx_qe_score": 1.0148998498916626, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est que, comme mentionné, parce que la distribution de probabilité est déséquilibrée entre les différents instants, il est donc également assez difficile d'appliquer des recherches par faisceau.", "metrics": {"bleu_score": 60.46764878181794, "chrf_score": 79.18965332793, "xcomet_score": 0.7970190048217773, "xcomet_qe_score": 0.8804186582565308, "metricx_score": 3.30690336227417, "metricx_qe_score": 3.1692256927490234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "Voilà la fin de la conférence et les questions sont les bienvenues. Merci.", "metrics": {"bleu_score": 44.64009548104569, "chrf_score": 58.7103502028591, "xcomet_score": 0.9393696188926697, "xcomet_qe_score": 0.9623950719833374, "metricx_score": 1.2034980058670044, "metricx_qe_score": 0.9499146938323975, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je viens de l'Université de Maastricht.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 90.46894018144044, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.377380132675171, "metricx_qe_score": 0.664887011051178, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter mon travail sur John avec Jerry, qui porte sur un nouveau jeu de données pour la récupération d'articles légaux.", "metrics": {"bleu_score": 29.85114496930219, "chrf_score": 58.828020197010744, "xcomet_score": 0.3006289005279541, "xcomet_qe_score": 0.23721103370189667, "metricx_score": 9.438787460327148, "metricx_qe_score": 9.411137580871582, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les problèmes juridiques font partie intégrante de la vie de nombreuses personnes.", "metrics": {"bleu_score": 84.23626743789745, "chrf_score": 86.06115383670415, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6353251934051514, "metricx_qe_score": 0.46970173716545105, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et les processus juridiques fondamentaux.", "metrics": {"bleu_score": 65.14613449066714, "chrf_score": 92.27603232952652, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8223639726638794, "metricx_qe_score": 1.0039916038513184, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "En conséquence, de nombreux citoyens vulnérables qui ne peuvent pas se permettre l'assistance coûteuse d'un expert juridique se retrouvent sans protection ou, pire, exploités.", "metrics": {"bleu_score": 46.00585798331265, "chrf_score": 71.9167407662733, "xcomet_score": 0.9987257719039917, "xcomet_qe_score": 1.0, "metricx_score": 1.2121862173080444, "metricx_qe_score": 1.0803606510162354, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Notre travail vise à combler le fossé entre les gens et la loi en développant un système de recherche efficace pour les articles de loi.", "metrics": {"bleu_score": 54.119533608948146, "chrf_score": 66.19103737577086, "xcomet_score": 0.9550344944000244, "xcomet_qe_score": 0.9732358455657959, "metricx_score": 1.7471688985824585, "metricx_qe_score": 0.994164764881134, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "Un tel système pourrait fournir un service d'aide juridique professionnelle gratuit pour les humains non qualifiés.", "metrics": {"bleu_score": 51.54458901398172, "chrf_score": 81.54241491506178, "xcomet_score": 0.9426836967468262, "xcomet_qe_score": 0.9523552656173706, "metricx_score": 1.3478590250015259, "metricx_qe_score": 1.1983811855316162, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de plonger dans la contribution principale de ce travail, décrivons d'abord le problème de la récupération d'articles statutaires.", "metrics": {"bleu_score": 30.91327937802876, "chrf_score": 64.2390172620644, "xcomet_score": 0.8134631514549255, "xcomet_qe_score": 0.7815635204315186, "metricx_score": 5.66942024230957, "metricx_qe_score": 4.398686408996582, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "Une question simple sur une question juridique, par exemple : « À quoi m'expose-je si je viole le secret professionnel ? »", "metrics": {"bleu_score": 17.35505412321786, "chrf_score": 48.78925205851355, "xcomet_score": 0.9485353231430054, "xcomet_qe_score": 0.9461861848831177, "metricx_score": 2.9061169624328613, "metricx_qe_score": 2.698859691619873, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle est nécessaire pour récupérer tous les articles légaux pertinents d'un vaste corpus législatif.", "metrics": {"bleu_score": 38.00427070295603, "chrf_score": 70.81987205865413, "xcomet_score": 0.977972149848938, "xcomet_qe_score": 1.0, "metricx_score": 1.6713135242462158, "metricx_qe_score": 2.0001349449157715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche de recherche d'information comporte son propre ensemble de défis.", "metrics": {"bleu_score": 57.067457770559976, "chrf_score": 73.53348574314383, "xcomet_score": 0.9810460805892944, "xcomet_qe_score": 1.0, "metricx_score": 0.9133810997009277, "metricx_qe_score": 0.4641854763031006, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, il traite de deux types de langage.", "metrics": {"bleu_score": 48.326978309062206, "chrf_score": 77.70626446580955, "xcomet_score": 0.7698017358779907, "xcomet_qe_score": 0.9778584241867065, "metricx_score": 2.369997024536133, "metricx_qe_score": 1.0847606658935547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "langage naturel courant pour les questions et langage illégal complexe pour les statuts.", "metrics": {"bleu_score": 23.045806594604677, "chrf_score": 54.57604388822218, "xcomet_score": 0.4864496886730194, "xcomet_qe_score": 0.47405457496643066, "metricx_score": 11.552338600158691, "metricx_qe_score": 9.227747917175293, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence dans les distributions linguistiques rend plus difficile pour un système de retrouver des candidats pertinents, car cela nécessite indirectement un système d'interprétation inhérent capable de traduire une question naturelle en une question juridique correspondant à la terminologie des statuts.", "metrics": {"bleu_score": 70.0282633046773, "chrf_score": 87.48548898469988, "xcomet_score": 0.9539227485656738, "xcomet_qe_score": 0.9813951253890991, "metricx_score": 3.8589816093444824, "metricx_qe_score": 3.374617576599121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le droit législatif n'est pas un ensemble d'articles indépendants qui peuvent être traités comme une source d'information complète à eux seuls, comme les actualités ou les recettes, par exemple.", "metrics": {"bleu_score": 38.98938932918354, "chrf_score": 66.37443371308119, "xcomet_score": 0.9912017583847046, "xcomet_qe_score": 1.0, "metricx_score": 3.1405246257781982, "metricx_qe_score": 2.3246498107910156, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'agit plutôt d'une collection de dispositions légales qui ne prennent tout leur sens que lorsqu'elles sont examinées dans le contexte global, c'est-à-dire en tenant compte des informations complémentaires des articles voisins, des domaines et sous-domaines auxquels elles appartiennent, et de leur place dans la structure de la loi.", "metrics": {"bleu_score": 41.46697523650318, "chrf_score": 71.91323958906717, "xcomet_score": 0.9793093204498291, "xcomet_qe_score": 0.990835428237915, "metricx_score": 0.9364532232284546, "metricx_qe_score": 1.0551321506500244, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, les articles légaux sont présentés en petits paragraphes, ce qui est généralement l'unité de récupération typique dans la plupart des travaux de récupération.", "metrics": {"bleu_score": 31.823566221963034, "chrf_score": 66.153843060246, "xcomet_score": 0.44365623593330383, "xcomet_qe_score": 0.46536606550216675, "metricx_score": 10.163451194763184, "metricx_qe_score": 10.461272239685059, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, il y a de longs documents qui peuvent avoir jusqu'à soixante ans.", "metrics": {"bleu_score": 61.32167468990615, "chrf_score": 71.99555210368385, "xcomet_score": 0.5427898168563843, "xcomet_qe_score": 0.5875195264816284, "metricx_score": 17.11236572265625, "metricx_qe_score": 18.68604278564453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les récentes avancées en traitement du langage naturel ont suscité un grand intérêt pour de nombreuses tâches juridiques, telles que la prédiction des jugements juridiques ou l'examen automatisé des contrats.", "metrics": {"bleu_score": 39.85108691803096, "chrf_score": 67.03204960572256, "xcomet_score": 0.9344421625137329, "xcomet_qe_score": 0.9691270589828491, "metricx_score": 1.2116280794143677, "metricx_qe_score": 0.832463800907135, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la récupération d'articles légaux est restée principalement intacte en raison du manque de grands ensembles de données étiquetées de haute qualité.", "metrics": {"bleu_score": 39.64513253420688, "chrf_score": 65.42076703207333, "xcomet_score": 0.6811076402664185, "xcomet_qe_score": 0.6856245398521423, "metricx_score": 4.38454008102417, "metricx_qe_score": 3.8532185554504395, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette étude, nous présentons un nouveau jeu de données centré sur les citoyens français natifs afin d'étudier si un modèle de recherche peut s'approcher de l'efficacité et de la fiabilité d'un expert juridique pour la tâche de recherche d'articles légaux.", "metrics": {"bleu_score": 32.28414137011352, "chrf_score": 64.02136048705283, "xcomet_score": 0.8161593079566956, "xcomet_qe_score": 0.8408983945846558, "metricx_score": 5.719383239746094, "metricx_qe_score": 4.778692245483398, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "Nos ensembles de données de récupération d'articles statutaires belges comprennent plus de mille cent un litres.", "metrics": {"bleu_score": 11.926516773207473, "chrf_score": 38.31589100700092, "xcomet_score": 0.17657367885112762, "xcomet_qe_score": 0.25317221879959106, "metricx_score": 23.390195846557617, "metricx_qe_score": 24.586421966552734, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "Ces questions couvrent un large éventail de sujets, allant de la famille, au logement, à l'argent, au travail et à la sécurité sociale.", "metrics": {"bleu_score": 67.13783850074476, "chrf_score": 84.40550138901145, "xcomet_score": 0.9989352226257324, "xcomet_qe_score": 1.0, "metricx_score": 1.2284950017929077, "metricx_qe_score": 0.4286993145942688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun d'eux a été étiqueté par des juristes expérimentés avec des références aux articles pertinents d'un corpus de plus de vingt-deux mille six cents mille.", "metrics": {"bleu_score": 47.00588075359484, "chrf_score": 68.58674672123261, "xcomet_score": 0.47206422686576843, "xcomet_qe_score": 0.5322556495666504, "metricx_score": 13.291336059570312, "metricx_qe_score": 11.953255653381348, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Codes de droit belges. Parlons maintenant de la manière dont nous avons collecté ces ensembles de données.", "metrics": {"bleu_score": 34.51395513935864, "chrf_score": 74.64129449864147, "xcomet_score": 0.19371137022972107, "xcomet_qe_score": 0.17632406949996948, "metricx_score": 15.083236694335938, "metricx_qe_score": 17.663244247436523, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons commencé par constituer un vaste corpus d'articles juridiques.", "metrics": {"bleu_score": 26.70976496992394, "chrf_score": 65.29244897930707, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.1222872734069824, "metricx_qe_score": 0.7819873690605164, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons examiné trente-deux codes belges accessibles au public et extrait tous leurs articles ainsi que les titres de sections correspondants.", "metrics": {"bleu_score": 75.52498655792417, "chrf_score": 95.29582169762642, "xcomet_score": 0.9977248907089233, "xcomet_qe_score": 0.9982707500457764, "metricx_score": 1.9588056802749634, "metricx_qe_score": 1.7774975299835205, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous avons rassemblé des questions juridiques avec des références aux lois pertinentes.", "metrics": {"bleu_score": 57.73502691896262, "chrf_score": 91.31938011871401, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.070390224456787, "metricx_qe_score": 1.3487091064453125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous collaborons avec un cabinet d'avocats belge qui reçoit chaque année environ quatre mille e-mails de citoyens belges qui demandent des conseils sur une question juridique personnelle.", "metrics": {"bleu_score": 63.928043209292426, "chrf_score": 82.41784736347158, "xcomet_score": 0.9970988035202026, "xcomet_qe_score": 1.0, "metricx_score": 1.0202044248580933, "metricx_qe_score": 0.7030019760131836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance d'accéder à leurs sites web, où leur équipe de juristes expérimentés aborde les problèmes juridiques les plus courants en Belgique.", "metrics": {"bleu_score": 61.806599678536905, "chrf_score": 78.712791698755, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.4328558444976807, "metricx_qe_score": 1.8640111684799194, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons recueilli des milliers de questions, annotées avec des catégories, des sous-catégories et des références légales aux lois pertinentes.", "metrics": {"bleu_score": 75.22135016840222, "chrf_score": 89.88889484392803, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6943244338035583, "metricx_qe_score": 1.1060343980789185, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons passé en revue les références légales et éliminé les questions dont les références n'étaient pas des articles d'un des codes de droit que nous avions considérés.", "metrics": {"bleu_score": 52.221222004846055, "chrf_score": 76.66515485506046, "xcomet_score": 0.9480488896369934, "xcomet_qe_score": 0.9542509913444519, "metricx_score": 1.5225305557250977, "metricx_qe_score": 1.4639837741851807, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "Les références restantes ont été mises en correspondance et converties en identifiants d'articles correspondants du Corpus O.", "metrics": {"bleu_score": 25.28116869739494, "chrf_score": 71.73166196149799, "xcomet_score": 0.9126094579696655, "xcomet_qe_score": 0.9411814212799072, "metricx_score": 3.2220396995544434, "metricx_qe_score": 3.2546310424804688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons finalement obtenu mille cent huit questions, chacune soigneusement étiquetée avec les identifiants des articles pertinents du livre.", "metrics": {"bleu_score": 36.14712301829135, "chrf_score": 57.376578726469894, "xcomet_score": 0.6468964219093323, "xcomet_qe_score": 0.6170446276664734, "metricx_score": 6.938375473022461, "metricx_qe_score": 11.465877532958984, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, chaque question est accompagnée d'une catégorie principale et d'une concaténation de sous-catégories.", "metrics": {"bleu_score": 50.47325154308107, "chrf_score": 80.4082245966848, "xcomet_score": 0.954633355140686, "xcomet_qe_score": 0.9636931419372559, "metricx_score": 5.552073955535889, "metricx_qe_score": 5.55289888381958, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "et chaque article est accompagné d'une concaténation de leur en-tête ultérieur dans la structure de la loi.", "metrics": {"bleu_score": 37.15770152515525, "chrf_score": 48.902885567596435, "xcomet_score": 0.512299656867981, "xcomet_qe_score": 0.5059865117073059, "metricx_score": 11.146661758422852, "metricx_qe_score": 11.405854225158691, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Ces informations supplémentaires n'ont pas été utilisées dans le cadre du présent travail, mais elles pourraient présenter un intérêt pour des recherches futures sur la recherche d'informations juridiques ou la classification de textes juridiques.", "metrics": {"bleu_score": 57.64273414147167, "chrf_score": 87.14236721058664, "xcomet_score": 0.9832991361618042, "xcomet_qe_score": 1.0, "metricx_score": 0.8194847702980042, "metricx_qe_score": 0.380544513463974, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons certaines caractéristiques de nos ensembles de données.", "metrics": {"bleu_score": 28.422022424918996, "chrf_score": 64.65790434330656, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6294617652893066, "metricx_qe_score": 0.7357365489006042, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions font entre cinq et quarante-quatre mots, avec une médiane de quarante mots.", "metrics": {"bleu_score": 32.774568052975916, "chrf_score": 68.57617850717509, "xcomet_score": 0.9504197835922241, "xcomet_qe_score": 0.9764963984489441, "metricx_score": 8.835371017456055, "metricx_qe_score": 7.539668083190918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont beaucoup plus longs, avec une longueur médiane de soixante-dix-sept mots, pour cent quarante grammes.", "metrics": {"bleu_score": 36.55319487070358, "chrf_score": 65.12577117416694, "xcomet_score": 0.46036437153816223, "xcomet_qe_score": 0.2664636969566345, "metricx_score": 16.566673278808594, "metricx_qe_score": 19.9311466217041, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "deux d'entre eux dépassant le millier.", "metrics": {"bleu_score": 3.2149545730574576, "chrf_score": 13.5639272856789, "xcomet_score": 0.14939561486244202, "xcomet_qe_score": 0.14572429656982422, "metricx_score": 15.761676788330078, "metricx_qe_score": 17.193519592285156, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "Comme mentionné précédemment, la question portait sur un large éventail de sujets, dont environ quatre-vingt-cinq pour cent concernaient soit la famille, le logement, l'argent ou la justice, ou", "metrics": {"bleu_score": 55.15685261379873, "chrf_score": 80.1680011815379, "xcomet_score": 0.4409826695919037, "xcomet_qe_score": 0.47909560799598694, "metricx_score": 5.247429370880127, "metricx_qe_score": 3.7034502029418945, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que les quinze pour cent restants concernent soit la sécurité sociale, les étrangers ou le travail.", "metrics": {"bleu_score": 79.12619863720215, "chrf_score": 92.17046861850113, "xcomet_score": 0.9578806161880493, "xcomet_qe_score": 0.955264687538147, "metricx_score": 1.4480602741241455, "metricx_qe_score": 1.3010170459747314, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très divers car ils proviennent de trente-deux codes belges différents qui couvrent un grand nombre de sujets juridiques.", "metrics": {"bleu_score": 62.00657885072486, "chrf_score": 86.56811499116591, "xcomet_score": 0.9407737255096436, "xcomet_qe_score": 0.9949125051498413, "metricx_score": 1.1666806936264038, "metricx_qe_score": 0.7383172512054443, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles recueillis pour chacun de ces codes belges.", "metrics": {"bleu_score": 57.475393483140245, "chrf_score": 73.11152168808387, "xcomet_score": 0.9977279901504517, "xcomet_qe_score": 1.0, "metricx_score": 1.3700995445251465, "metricx_qe_score": 2.39261531829834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Sur les vingt-deux mille six cent trente-trois articles, seulement mille six cent douze sont considérés comme pertinents pour au moins l'un des", "metrics": {"bleu_score": 46.63835297818445, "chrf_score": 72.5609104777451, "xcomet_score": 0.5793332457542419, "xcomet_qe_score": 0.48403826355934143, "metricx_score": 7.458807945251465, "metricx_qe_score": 7.944127082824707, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "au moins une question dans les ensembles de données. Et environ quatre-vingts pour cent de ces articles cités proviennent soit du code civil, du code judiciaire, du code d'instruction pénale ou du code pénal.", "metrics": {"bleu_score": 30.98068900440638, "chrf_score": 65.1842592366464, "xcomet_score": 0.30569082498550415, "xcomet_qe_score": 0.317332923412323, "metricx_score": 11.963136672973633, "metricx_qe_score": 13.41003131866455, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "Entre-temps, dix-huit des trente-deux codes ont moins de cinq articles mentionnés comme pertinents pour au moins une question.", "metrics": {"bleu_score": 85.57423956196074, "chrf_score": 92.88440555807628, "xcomet_score": 0.9699159860610962, "xcomet_qe_score": 0.967171311378479, "metricx_score": 1.4313979148864746, "metricx_qe_score": 1.7736402750015259, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut s'expliquer par le fait que ces codes se concentrent moins sur les individus et leurs préoccupations.", "metrics": {"bleu_score": 75.06935728875011, "chrf_score": 91.17897668052449, "xcomet_score": 0.9976266622543335, "xcomet_qe_score": 1.0, "metricx_score": 2.756505012512207, "metricx_qe_score": 2.941240072250366, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le nombre médian de citations pour ces articles cités est de deux, et moins de vingt-cinq pour cent d'entre eux sont cités.", "metrics": {"bleu_score": 74.8094576186385, "chrf_score": 86.17150303077865, "xcomet_score": 0.5886613726615906, "xcomet_qe_score": 0.6084270477294922, "metricx_score": 11.808004379272461, "metricx_qe_score": 7.999258041381836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant nos ensembles de données, nous évaluons plusieurs approches de récupération, y compris l'architecture lexicale et dense.", "metrics": {"bleu_score": 44.77845944135174, "chrf_score": 71.99726345674952, "xcomet_score": 0.6580978631973267, "xcomet_qe_score": 0.7577692866325378, "metricx_score": 4.341616630554199, "metricx_qe_score": 4.490166664123535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné une requête dans un article, un modèle lexical attribue un score à la paire requête-article en calculant la somme des termes de la requête des poids de chacun de ces termes dans cet article.", "metrics": {"bleu_score": 68.20763123887689, "chrf_score": 86.40901037483053, "xcomet_score": 0.7772088050842285, "xcomet_qe_score": 0.7380669116973877, "metricx_score": 5.55536413192749, "metricx_qe_score": 6.5072126388549805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec les fonctions de classement standard TFIDF et BM vingt-cinq.", "metrics": {"bleu_score": 51.424016050282624, "chrf_score": 81.98200049527931, "xcomet_score": 0.752313494682312, "xcomet_qe_score": 0.787118673324585, "metricx_score": 3.4902048110961914, "metricx_qe_score": 4.225115776062012, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème avec ces approches est qu'elles ne peuvent récupérer que les articles contenant des mots-clés présents dans la requête.", "metrics": {"bleu_score": 73.89984311706958, "chrf_score": 87.64492020072457, "xcomet_score": 0.992904782295227, "xcomet_qe_score": 1.0, "metricx_score": 0.8965938091278076, "metricx_qe_score": 0.9452088475227356, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour surmonter cette limitation, nous expérimentons une architecture basée sur les réseaux de neurones qui peut capturer les relations sémantiques entre les requêtes et les articles.", "metrics": {"bleu_score": 60.60655437708259, "chrf_score": 89.02690117056656, "xcomet_score": 0.9894617795944214, "xcomet_qe_score": 0.9636143445968628, "metricx_score": 0.7698409557342529, "metricx_qe_score": 0.8191792964935303, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle de codeur BE qui associe des requêtes et des articles à des représentations vectorielles denses et calcule un score de pertinence entre une paire de requêtes et d'articles en fonction de la similarité de leurs intégrations.", "metrics": {"bleu_score": 29.988225847344523, "chrf_score": 72.5178299054068, "xcomet_score": 0.7768819332122803, "xcomet_qe_score": 0.8216056823730469, "metricx_score": 4.881414890289307, "metricx_qe_score": 5.209221839904785, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces intégrations résultent généralement d'une opération de pooling sur la sortie d'un modèle d'intégration de mots.", "metrics": {"bleu_score": 82.82477531331043, "chrf_score": 90.96908691044948, "xcomet_score": 0.8626084327697754, "xcomet_qe_score": 0.7329448461532593, "metricx_score": 3.66196608543396, "metricx_qe_score": 6.458038806915283, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous étudions l'efficacité des biancodes de type Siamese dans un cadre d'évaluation sans apprentissage préalable, ce qui signifie que les modèles d'intégration de mots pré-entraînés sont utilisés tels quels, sans aucun ajustement supplémentaire.", "metrics": {"bleu_score": 33.257620756314545, "chrf_score": 63.60499241262707, "xcomet_score": 0.6763198971748352, "xcomet_qe_score": 0.7824141979217529, "metricx_score": 6.744044780731201, "metricx_qe_score": 4.407885551452637, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec un encodeur de texte indépendant du contexte, à savoir Word to Vec et FastText, et des modèles d'ancrage dépendants du contexte, à savoir Roberta et plus spécifiquement Camembert, qui est un modèle français de Roberta.", "metrics": {"bleu_score": 49.105825864714916, "chrf_score": 76.46229222652295, "xcomet_score": 0.7827126979827881, "xcomet_qe_score": 0.7983745336532593, "metricx_score": 4.360196590423584, "metricx_qe_score": 3.5043020248413086, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous formons notre propre modèle basé sur le camembert. Au-delà des quoters,", "metrics": {"bleu_score": 23.287896954139942, "chrf_score": 44.19703257569657, "xcomet_score": 0.1562959849834442, "xcomet_qe_score": 0.15235477685928345, "metricx_score": 16.425151824951172, "metricx_qe_score": 15.252561569213867, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "utilisations sur tous les ensembles de données. Notez que pour la formation, nous expérimentons avec les deux variantes de l'architecture Bianco.", "metrics": {"bleu_score": 45.663378549673126, "chrf_score": 74.96848139151965, "xcomet_score": 0.11335393786430359, "xcomet_qe_score": 0.18340887129306793, "metricx_score": 15.850931167602539, "metricx_qe_score": 17.00620460510254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "Siamese, qui utilise un modèle unique d'encodage des mots qui mappe la requête et l'article ensemble dans un espace vectoriel dense partagé, et Tutor, qui utilise deux modèles d'encodage des mots indépendants qui encodent la requête et l'article séparément dans différents espaces d'encodage.", "metrics": {"bleu_score": 44.9752924739172, "chrf_score": 65.25629471249381, "xcomet_score": 0.5948728322982788, "xcomet_qe_score": 0.6613106727600098, "metricx_score": 9.917073249816895, "metricx_qe_score": 10.013805389404297, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons expérimenté le pooling de moyenne, de maximum et de CLS ainsi que le produit scalaire et le cosinus pour le calcul des similarités.", "metrics": {"bleu_score": 13.254512146117515, "chrf_score": 54.73171782720795, "xcomet_score": 0.7057108879089355, "xcomet_qe_score": 0.7179418802261353, "metricx_score": 5.0804572105407715, "metricx_qe_score": 5.370893478393555, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre ligne de base sur les ensembles de test.", "metrics": {"bleu_score": 49.132705481444226, "chrf_score": 81.70338888284992, "xcomet_score": 0.764010488986969, "xcomet_qe_score": 0.7451876401901245, "metricx_score": 4.734680652618408, "metricx_qe_score": 5.280911445617676, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "avec les méthodes lexicales ci-dessus, les encodeurs B siamois évalués en configuration zéro-shot au milieu, et les encodeurs B affinés ci-dessous.", "metrics": {"bleu_score": 36.33280760532487, "chrf_score": 73.63154716665575, "xcomet_score": 0.47316089272499084, "xcomet_qe_score": 0.5329757928848267, "metricx_score": 8.357137680053711, "metricx_qe_score": 8.225618362426758, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le Biancore affiné surpasse de loin toutes les autres lignes de basse.", "metrics": {"bleu_score": 23.578316044531807, "chrf_score": 51.52374768523816, "xcomet_score": 0.5562192797660828, "xcomet_qe_score": 0.4112626016139984, "metricx_score": 15.145719528198242, "metricx_qe_score": 14.223793983459473, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle à deux tours est supérieur à sa variante siamoise en termes de rappel à cent, mais obtient des résultats similaires pour les autres métriques.", "metrics": {"bleu_score": 27.495837173447466, "chrf_score": 48.31161135983807, "xcomet_score": 0.8666315078735352, "xcomet_qe_score": 0.5409875512123108, "metricx_score": 2.821800708770752, "metricx_qe_score": 4.851880073547363, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que BM twenty five ait eu de moins bons résultats que Biancoda entraîné de manière significative, sa performance a indiqué qu'il s'agit toujours d'une référence solide pour la récupération spécifique à un domaine.", "metrics": {"bleu_score": 16.8955474850733, "chrf_score": 61.180916632564006, "xcomet_score": 0.39911791682243347, "xcomet_qe_score": 0.5069999694824219, "metricx_score": 10.70361328125, "metricx_qe_score": 12.250017166137695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation à tir zéro de Siamese Biancoder, nous constatons que l'utilisation directe des embeddings d'un modèle Kamembert pré-entraîné sans optimisation pour la tâche de recherche d'information donne de mauvais résultats, ce qui est cohérent avec les résultats précédents.", "metrics": {"bleu_score": 49.34676814805795, "chrf_score": 69.60199784557662, "xcomet_score": 0.4789724051952362, "xcomet_qe_score": 0.48302242159843445, "metricx_score": 9.698568344116211, "metricx_qe_score": 8.190723419189453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous observons que le modèle basé sur les vecteurs de mots de Biancoder surpasse considérablement les modèles Vastex et basés sur les oiseaux, ce qui suggère que peut-être les représentations de mots pré-entraînées sont plus appropriées pour la tâche que les représentations au niveau des caractères ou au niveau des sous-mots lorsqu'elles sont utilisées telles quelles.", "metrics": {"bleu_score": 24.946955135328583, "chrf_score": 52.36469846046139, "xcomet_score": 0.1308414340019226, "xcomet_qe_score": 0.163730189204216, "metricx_score": 13.88375186920166, "metricx_qe_score": 13.01659107208252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que prometteurs, ces résultats laissent entrevoir de nombreuses possibilités d'amélioration par rapport à un expert juridique qualifié qui peut finalement retrouver tous les articles pertinents à toute question et ainsi obtenir des scores parfaits.", "metrics": {"bleu_score": 58.95772766663462, "chrf_score": 76.59650681710038, "xcomet_score": 0.9966669082641602, "xcomet_qe_score": 1.0, "metricx_score": 1.387215495109558, "metricx_qe_score": 1.686208724975586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Concluons en discutant de deux limites de tous les ensembles de données.", "metrics": {"bleu_score": 52.055103630534376, "chrf_score": 83.27695935099287, "xcomet_score": 0.8470206260681152, "xcomet_qe_score": 0.8627233505249023, "metricx_score": 3.855677604675293, "metricx_qe_score": 3.0442311763763428, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, le corpus d'articles est limité à ceux recueillis dans les 32 codes belges considérés, ce qui ne couvre pas l'ensemble du droit belge, car les articles des décrets, directives et ordonnances sont absents.", "metrics": {"bleu_score": 66.13185239584297, "chrf_score": 79.22659871078014, "xcomet_score": 0.9732961654663086, "xcomet_qe_score": 0.9941197633743286, "metricx_score": 1.613213062286377, "metricx_qe_score": 1.5988606214523315, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Lors de la construction du jeu de données, toutes les références à ces articles non collectés sont ignorées, ce qui fait que certaines questions se retrouvent avec seulement une fraction du nombre initial d'articles pertinents.", "metrics": {"bleu_score": 71.05516791217374, "chrf_score": 88.51767956128744, "xcomet_score": 0.9418079853057861, "xcomet_qe_score": 0.9425033926963806, "metricx_score": 1.7379014492034912, "metricx_qe_score": 1.9648516178131104, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cette perte d'information implique que la réponse contenue dans les articles pertinents restants pourrait être incomplète, bien qu'elle soit toujours tout à fait appropriée.", "metrics": {"bleu_score": 68.87246539984304, "chrf_score": 89.37236228825259, "xcomet_score": 0.9688940644264221, "xcomet_qe_score": 0.9670678377151489, "metricx_score": 2.134427785873413, "metricx_qe_score": 1.8046678304672241, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, il convient de noter que toutes les questions juridiques ne peuvent pas être résolues uniquement avec des statuts.", "metrics": {"bleu_score": 37.62957149383418, "chrf_score": 71.71099646346713, "xcomet_score": 0.9869778156280518, "xcomet_qe_score": 1.0, "metricx_score": 3.968161106109619, "metricx_qe_score": 1.8647587299346924, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question « Puis-je expulser mes locataires s'ils font trop de bruit ? »", "metrics": {"bleu_score": 82.82477531331043, "chrf_score": 94.90053815176721, "xcomet_score": 0.9947274923324585, "xcomet_qe_score": 0.9843442440032959, "metricx_score": 0.7744530439376831, "metricx_qe_score": 1.2120697498321533, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "Il est possible qu'il n'existe pas de réponse détaillée dans le droit législatif qui quantifie un seuil spécifique de bruit à partir duquel un expulsion est autorisée.", "metrics": {"bleu_score": 36.07215127026265, "chrf_score": 71.4386318330313, "xcomet_score": 0.956017255783081, "xcomet_qe_score": 0.8952250480651855, "metricx_score": 3.8966264724731445, "metricx_qe_score": 3.851480007171631, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, le propriétaire devrait probablement s'appuyer davantage sur la jurisprudence et trouver des précédents similaires à sa situation actuelle.", "metrics": {"bleu_score": 88.43865924896839, "chrf_score": 96.00693419793949, "xcomet_score": 0.9974983930587769, "xcomet_qe_score": 0.9999064207077026, "metricx_score": 0.9097432494163513, "metricx_qe_score": 1.021873950958252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le locataire fait deux soirées par semaine jusqu'à deux heures.", "metrics": {"bleu_score": 28.253017719977493, "chrf_score": 63.539242673304194, "xcomet_score": 0.6822769641876221, "xcomet_qe_score": 0.6436605453491211, "metricx_score": 8.860527992248535, "metricx_qe_score": 6.0874342918396, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, certaines questions sont plus adaptées que d'autres à la tâche de récupération d'articles légaux, et le domaine de celles qui sont moins adaptées reste à déterminer.", "metrics": {"bleu_score": 53.19774228122344, "chrf_score": 77.09045851095246, "xcomet_score": 0.8382522463798523, "xcomet_qe_score": 0.6524969935417175, "metricx_score": 3.9124038219451904, "metricx_qe_score": 4.181876182556152, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que tous les travaux susciteront un intérêt pour le développement de modèles de récupération d'articles légaux pratiques et fiables.", "metrics": {"bleu_score": 19.857943409196785, "chrf_score": 66.72675501334031, "xcomet_score": 0.7358902096748352, "xcomet_qe_score": 0.719183087348938, "metricx_score": 6.301000118255615, "metricx_qe_score": 5.845658302307129, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "qui peuvent contribuer à améliorer l'accès à la justice pour tous.", "metrics": {"bleu_score": 71.02992180127417, "chrf_score": 77.08331303994608, "xcomet_score": 0.6458194255828857, "xcomet_qe_score": 0.6206544041633606, "metricx_score": 4.428874969482422, "metricx_qe_score": 2.8825368881225586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre article, le paramètre et le code aux liens suivants. Merci.", "metrics": {"bleu_score": 64.1975224568211, "chrf_score": 77.17022491482014, "xcomet_score": 0.7838582992553711, "xcomet_qe_score": 0.7489025592803955, "metricx_score": 4.8766279220581055, "metricx_qe_score": 5.346469879150391, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, nous sommes heureux de vous présenter notre travail sur Vowls, une référence de tâche indépendante destinée à tester les modèles de vision et de langage avec des phénomènes linguistiques spécifiques.", "metrics": {"bleu_score": 52.712538551610564, "chrf_score": 81.16973617572883, "xcomet_score": 0.4601682126522064, "xcomet_qe_score": 0.5820883512496948, "metricx_score": 6.0340576171875, "metricx_qe_score": 5.422265529632568, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Pourquoi avons-nous rencontré des difficultés à établir ce benchmark ?", "metrics": {"bleu_score": 6.225616866546953, "chrf_score": 37.07647700447233, "xcomet_score": 0.22066684067249298, "xcomet_qe_score": 0.47648969292640686, "metricx_score": 15.297365188598633, "metricx_qe_score": 8.449380874633789, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Eh bien, au cours des dernières années, nous avons assisté à une explosion de modèles de vision et de langage basés sur des transformateurs, pré-entraînés sur de grandes quantités de paires d'images et de textes.", "metrics": {"bleu_score": 45.920941854034346, "chrf_score": 75.18456121213597, "xcomet_score": 0.9447667598724365, "xcomet_qe_score": 0.9879385232925415, "metricx_score": 2.7362353801727295, "metricx_qe_score": 2.433215618133545, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun de ces modèles repousse les limites de l'état de l'art dans les tâches de vision et de langage telles que la réponse à des questions visuelles, le raisonnement sur le sens commun visuel, la récupération d'images, l'ancrage de phrases.", "metrics": {"bleu_score": 30.638657254237277, "chrf_score": 68.54900002642619, "xcomet_score": 0.6605558395385742, "xcomet_qe_score": 0.685393750667572, "metricx_score": 4.236676216125488, "metricx_qe_score": 3.7649309635162354, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc bien compris le message. Les précisions sur ces points de référence spécifiques aux tâches augmentent régulièrement.", "metrics": {"bleu_score": 19.87207215766376, "chrf_score": 74.3285938060317, "xcomet_score": 0.8284640312194824, "xcomet_qe_score": 0.49467456340789795, "metricx_score": 4.88712739944458, "metricx_qe_score": 5.739770412445068, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "Mais savons-nous réellement ce que les modèles ont appris ?", "metrics": {"bleu_score": 51.69731539571708, "chrf_score": 87.01056627810956, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2264529466629028, "metricx_qe_score": 2.1026551723480225, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce qu'un transformateur de vision et de langage a compris lorsqu'il a attribué un score élevé pour que cette image et cette phrase correspondent ?", "metrics": {"bleu_score": 48.221575329820354, "chrf_score": 79.32837875334661, "xcomet_score": 0.7451979517936707, "xcomet_qe_score": 0.5714974403381348, "metricx_score": 2.6634278297424316, "metricx_qe_score": 2.7875521183013916, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "et le faible score pour celui-ci.", "metrics": {"bleu_score": 8.643019616048525, "chrf_score": 47.40371455455908, "xcomet_score": 0.8102941513061523, "xcomet_qe_score": 0.8544086217880249, "metricx_score": 5.3153510093688965, "metricx_qe_score": 5.168842315673828, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur la bonne chose ?", "metrics": {"bleu_score": 32.281751885843555, "chrf_score": 68.20305147191763, "xcomet_score": 0.7724132537841797, "xcomet_qe_score": 0.7463480830192566, "metricx_score": 1.717067003250122, "metricx_qe_score": 2.1995620727539062, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "Ou se concentrent-ils sur les biais tels que démontrés par les travaux antérieurs ?", "metrics": {"bleu_score": 36.362270465000705, "chrf_score": 65.67172680024657, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9018996953964233, "metricx_qe_score": 1.1912939548492432, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour éclairer davantage cet aspect, nous proposons une approche plus indépendante des tâches et introduisons des tests qui évaluent la sensibilité des modèles de vision et de langage à des phénomènes linguistiques spécifiques qui affectent à la fois les modalités linguistiques et visuelles.", "metrics": {"bleu_score": 62.256083968521104, "chrf_score": 83.94080047415878, "xcomet_score": 0.7756016254425049, "xcomet_qe_score": 0.8446800708770752, "metricx_score": 1.983102798461914, "metricx_qe_score": 3.1365673542022705, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la coréférence d'entité.", "metrics": {"bleu_score": 82.61095122056143, "chrf_score": 90.94875773716973, "xcomet_score": 0.8594756126403809, "xcomet_qe_score": 0.9149643778800964, "metricx_score": 1.7735008001327515, "metricx_qe_score": 2.1070194244384766, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "Mais comment tester si les modèles de vision et de langage ont capturé ces phénomènes ?", "metrics": {"bleu_score": 48.10977290978806, "chrf_score": 80.9244319176873, "xcomet_score": 0.9484028220176697, "xcomet_qe_score": 0.8684145212173462, "metricx_score": 1.5279712677001953, "metricx_qe_score": 1.7546184062957764, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant le foilage, une méthode précédemment appliquée uniquement pour les modèles de vision et de langage sur les phrases nominales par Ravi Shakar et ses collaborateurs, et sur le comptage par nous dans des travaux antérieurs.", "metrics": {"bleu_score": 26.920656092018476, "chrf_score": 71.12777710644482, "xcomet_score": 0.6017532348632812, "xcomet_qe_score": 0.5501443147659302, "metricx_score": 5.996160507202148, "metricx_qe_score": 5.689574718475342, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Le « foiling » signifie essentiellement que nous prenons la légende d'une image et produisons un « foil » en modifiant la légende de telle sorte qu'elle ne décrit plus l'image.", "metrics": {"bleu_score": 54.895488899892044, "chrf_score": 83.66011815312919, "xcomet_score": 0.9235228896141052, "xcomet_qe_score": 0.9660822749137878, "metricx_score": 2.232985258102417, "metricx_qe_score": 5.014932155609131, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous effectuons ces modifications de phrases en nous concentrant sur six éléments spécifiques, tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la coréférence d'entité, où chaque élément peut consister en un ou plusieurs instruments, au cas où nous trouverions plus d'une manière intéressante de créer des instances de contre-exemple.", "metrics": {"bleu_score": 74.55880255591713, "chrf_score": 86.23988393289866, "xcomet_score": 0.6316049098968506, "xcomet_qe_score": 0.5267356634140015, "metricx_score": 5.08890438079834, "metricx_qe_score": 4.368982315063477, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans le cas de la pièce d'action, nous avons deux instruments, l'un dans lequel le verbe d'action est remplacé par une action différente, et l'autre dans lequel les actants sont échangés.", "metrics": {"bleu_score": 54.432414045069585, "chrf_score": 76.41149406361484, "xcomet_score": 0.5800973773002625, "xcomet_qe_score": 0.5880336761474609, "metricx_score": 5.204880237579346, "metricx_qe_score": 5.28079891204834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la coréférence sont également des pièces qui nécessitent plus d'un instrument.", "metrics": {"bleu_score": 50.31747626530137, "chrf_score": 71.53026944150909, "xcomet_score": 0.7866995930671692, "xcomet_qe_score": 0.7524574398994446, "metricx_score": 4.640817165374756, "metricx_qe_score": 4.491874694824219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous créons ces faux par le fait de nous assurer qu'ils ne parviennent pas à décrire l'image, qu'ils sont des phrases grammaticales et autrement valides.", "metrics": {"bleu_score": 36.76308284763634, "chrf_score": 72.04351537589568, "xcomet_score": 0.6174365282058716, "xcomet_qe_score": 0.5003321170806885, "metricx_score": 8.3626708984375, "metricx_qe_score": 6.612709999084473, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "Ce n'est pas facile à faire parce qu'une légende annulée peut être moins probable qu'une légende originale.", "metrics": {"bleu_score": 38.488276585047046, "chrf_score": 72.15131779497494, "xcomet_score": 0.7316012382507324, "xcomet_qe_score": 0.717164158821106, "metricx_score": 6.904933929443359, "metricx_qe_score": 5.947262763977051, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien que ce ne soit pas impossible, il est statistiquement moins probable qu'une plante coupe un homme qu'un homme coupe des plantes, et les grands modèles de vision et de langage pourraient s'en rendre compte.", "metrics": {"bleu_score": 53.61806810457202, "chrf_score": 78.13104091601005, "xcomet_score": 0.785429060459137, "xcomet_qe_score": 0.7641260027885437, "metricx_score": 2.3604583740234375, "metricx_qe_score": 2.572516918182373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour obtenir des lames valides, nous devons agir.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 88.03360259381346, "xcomet_score": 0.8294509649276733, "xcomet_qe_score": 0.8252901434898376, "metricx_score": 3.554013967514038, "metricx_qe_score": 1.5871697664260864, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous utilisons des modèles linguistiques puissants pour proposer des contre-exemples.", "metrics": {"bleu_score": 50.698033524721, "chrf_score": 71.15033555075682, "xcomet_score": 0.9572921991348267, "xcomet_qe_score": 0.9540972709655762, "metricx_score": 3.42240834236145, "metricx_qe_score": 1.019761085510254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence en langage naturel ou NLI court pour filtrer les faux qui pourraient encore décrire l'image, car lors de la construction des faux, nous devons nous assurer qu'ils ne parviennent pas à décrire l'image.", "metrics": {"bleu_score": 54.78081726007865, "chrf_score": 79.23215123626828, "xcomet_score": 0.6049205660820007, "xcomet_qe_score": 0.5861525535583496, "metricx_score": 11.075035095214844, "metricx_qe_score": 8.612264633178711, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Pour tester cela automatiquement, nous appliquons l'inférence du langage naturel avec la logique suivante.", "metrics": {"bleu_score": 49.025517878204084, "chrf_score": 74.21178809689445, "xcomet_score": 0.9903548955917358, "xcomet_qe_score": 0.9898281097412109, "metricx_score": 1.1603026390075684, "metricx_qe_score": 1.0455312728881836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "Nous considérons qu'une image est la prémisse et sa légende l'hypothèse qui en découle.", "metrics": {"bleu_score": 64.1386525898168, "chrf_score": 79.02472122917035, "xcomet_score": 0.9898675680160522, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.01365065574646, "metricx_qe_score": 1.1841981410980225, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous considérons la légende comme la prémisse et le feuil comme son hypothèse.", "metrics": {"bleu_score": 50.09092657036855, "chrf_score": 74.40066460734937, "xcomet_score": 0.7723118662834167, "xcomet_qe_score": 0.5672578811645508, "metricx_score": 7.314517021179199, "metricx_qe_score": 8.265226364135742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit que le contre-exemple contredit ou est neutre par rapport à la légende, nous considérons cela comme un indicateur d'un contre-exemple valide.", "metrics": {"bleu_score": 59.817595536558535, "chrf_score": 73.10406731980788, "xcomet_score": 0.8254543542861938, "xcomet_qe_score": 0.8280724883079529, "metricx_score": 7.187023639678955, "metricx_qe_score": 4.200771808624268, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si une NLI prédit que le contre-exemple est impliqué par la légende, il ne peut pas être un bon contre-exemple puisqu'il donnera, par transitivité, une description vraie de l'image et nous filtrons ces contre-exemples.", "metrics": {"bleu_score": 39.317734814836555, "chrf_score": 61.47700692144495, "xcomet_score": 0.4747275710105896, "xcomet_qe_score": 0.5081540942192078, "metricx_score": 7.796477794647217, "metricx_qe_score": 6.545897483825684, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cette procédure n'est pas parfaite. C'est juste un indicateur pour une feuille valide.", "metrics": {"bleu_score": 32.785339777497235, "chrf_score": 61.875237030617, "xcomet_score": 0.8732159733772278, "xcomet_qe_score": 0.8231768012046814, "metricx_score": 5.029607772827148, "metricx_qe_score": 4.275565147399902, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, comme troisième mesure pour générer des contre-exemples valides, nous faisons appel à des annotateurs humains pour valider les données utilisées dans les valves.", "metrics": {"bleu_score": 54.60241725418134, "chrf_score": 75.88300052919332, "xcomet_score": 0.6341800689697266, "xcomet_qe_score": 0.6519006490707397, "metricx_score": 6.255385875701904, "metricx_qe_score": 6.080594539642334, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, après filtrage et évaluation humaine, nous avons autant d'exemples de test que ceux décrits dans ce tableau.", "metrics": {"bleu_score": 61.79396438001991, "chrf_score": 80.00454727922742, "xcomet_score": 0.9657013416290283, "xcomet_qe_score": 0.9653283357620239, "metricx_score": 1.9923498630523682, "metricx_qe_score": 2.553736686706543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que VALS ne fournit aucune donnée d'entraînement, mais uniquement des données de test.", "metrics": {"bleu_score": 28.304895944141947, "chrf_score": 59.02979244846107, "xcomet_score": 0.8620109558105469, "xcomet_qe_score": 0.9544814825057983, "metricx_score": 2.7719790935516357, "metricx_qe_score": 4.382838249206543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné qu'il s'agit uniquement d'un critère de référence pour les tests sans entraînement préalable, il est conçu pour exploiter les capacités existantes des modèles de vision et de langage après l'entraînement préalable.", "metrics": {"bleu_score": 27.588629375637943, "chrf_score": 58.213871051208244, "xcomet_score": 0.8257879018783569, "xcomet_qe_score": 0.8716930150985718, "metricx_score": 1.5197293758392334, "metricx_qe_score": 1.7259795665740967, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "Un réglage fin ne permettrait qu'aux modèles d'exploiter des artefacts ou des biais statistiques dans les données.", "metrics": {"bleu_score": 64.70107100770988, "chrf_score": 78.80458404508639, "xcomet_score": 0.951680064201355, "xcomet_qe_score": 0.9640669822692871, "metricx_score": 1.8282787799835205, "metricx_qe_score": 1.8219497203826904, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998902082443237, "xcomet_qe_score": 1.0, "metricx_score": 1.3476738929748535, "metricx_qe_score": 2.4462342262268066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme nous l’avons dit, nous sommes intéressés à évaluer les capacités des modèles de vision et de langage après l’entraînement préalable.", "metrics": {"bleu_score": 25.924945760983757, "chrf_score": 63.70402980579604, "xcomet_score": 0.9813010692596436, "xcomet_qe_score": 1.0, "metricx_score": 1.392293930053711, "metricx_qe_score": 1.5556659698486328, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec cinq modèles de vision et de langage sur les voyelles, à savoir CLIP, AlexMert, Wilbert, Wilbert Kelvin one et VisualBERT.", "metrics": {"bleu_score": 28.50959935683633, "chrf_score": 55.31801471393483, "xcomet_score": 0.2542332708835602, "xcomet_qe_score": 0.3189789056777954, "metricx_score": 8.151691436767578, "metricx_qe_score": 8.105782508850098, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos métriques d'évaluation les plus importantes sont la précision des modèles dans la classification des paires d'images et de phrases en légendes et en faux.", "metrics": {"bleu_score": 40.50710194872911, "chrf_score": 79.53457522310248, "xcomet_score": 0.5918936729431152, "xcomet_qe_score": 0.5641788840293884, "metricx_score": 6.6371917724609375, "metricx_qe_score": 5.66916036605835, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "Peut-être plus pertinent pour cette vidéo, nous allons présenter notre métrique plus permissive, la précision par paire, qui mesure si le score d'alignement de la phrase d'image est plus élevé pour la paire de texte d'image correcte que pour sa paire contrefaite.", "metrics": {"bleu_score": 54.00953186762318, "chrf_score": 71.47867918987662, "xcomet_score": 0.5515322089195251, "xcomet_qe_score": 0.5272539854049683, "metricx_score": 5.791715621948242, "metricx_qe_score": 4.884999752044678, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "Pour plus de mesures et de résultats à leur sujet, consultez notre article.", "metrics": {"bleu_score": 36.15855225145533, "chrf_score": 71.81765130966649, "xcomet_score": 0.9703108072280884, "xcomet_qe_score": 0.9889576435089111, "metricx_score": 2.0646443367004395, "metricx_qe_score": 1.7676552534103394, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats en termes de précision par paires sont présentés ici et ils sont cohérents avec les résultats obtenus avec les autres métriques. Il ressort que la meilleure performance en mode zéro-shot est réalisée par Wilbert Twelve in One, suivi de Wilbert, Alex Mert, Clip, et enfin VisualBird.", "metrics": {"bleu_score": 22.04315294788286, "chrf_score": 58.46032358952258, "xcomet_score": 0.4403151571750641, "xcomet_qe_score": 0.4441796541213989, "metricx_score": 7.704957962036133, "metricx_qe_score": 7.537064075469971, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est remarquable de constater que les instruments centrés sur des objets individuels comme l'existence et les phrases nominales sont presque résolus par Wilbert Twelve in One, soulignant que les modèles sont capables d'identifier les objets nommés et leur présence dans les images.", "metrics": {"bleu_score": 65.11725352361788, "chrf_score": 85.08799541800542, "xcomet_score": 0.5710713863372803, "xcomet_qe_score": 0.552716076374054, "metricx_score": 5.301266670227051, "metricx_qe_score": 4.994016170501709, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucune des pièces restantes ne peut être résolue de manière fiable dans nos paramètres d'opposition contradictoire.", "metrics": {"bleu_score": 34.14088641890569, "chrf_score": 65.70281354435463, "xcomet_score": 0.6875821352005005, "xcomet_qe_score": 0.686808705329895, "metricx_score": 6.405132293701172, "metricx_qe_score": 4.488535404205322, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "On constate, à travers la pluralité des instruments de comptage, que les modèles de vision et de langage ont du mal à distinguer les références à un seul objet par rapport à plusieurs objets ou à les compter dans une image.", "metrics": {"bleu_score": 48.38057051032844, "chrf_score": 72.27402047166548, "xcomet_score": 0.7916906476020813, "xcomet_qe_score": 0.848371148109436, "metricx_score": 4.781882286071777, "metricx_qe_score": 3.2599682807922363, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "La relation Ps montre qu'ils ont des difficultés à classer correctement une relation spatiale nommée entre des objets dans une image.", "metrics": {"bleu_score": 86.41944207171434, "chrf_score": 89.69458780142074, "xcomet_score": 0.7859853506088257, "xcomet_qe_score": 0.7297488451004028, "metricx_score": 5.345184803009033, "metricx_qe_score": 6.036438941955566, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "Ils ont également du mal à distinguer les actions et à identifier leurs participants, même si cela est soutenu par des biais de plausibilité comme nous le voyons dans la pièce d'action.", "metrics": {"bleu_score": 71.14277287369607, "chrf_score": 84.5252090510784, "xcomet_score": 0.6976503133773804, "xcomet_qe_score": 0.7325985431671143, "metricx_score": 4.011032581329346, "metricx_qe_score": 3.786548376083374, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "D'après le texte de référence, nous apprenons que le fait de suivre plusieurs références au même objet dans une image en utilisant des pronoms est également difficile pour les modèles de vision et de langage.", "metrics": {"bleu_score": 56.36036032217381, "chrf_score": 74.8992410325944, "xcomet_score": 0.7221888899803162, "xcomet_qe_score": 0.9048231840133667, "metricx_score": 3.0423953533172607, "metricx_qe_score": 3.26432204246521, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "À titre de vérification et parce que c'est une expérience intéressante, nous évaluons également deux modèles basés uniquement sur le texte, GPT-1 et GPT-2, pour déterminer si les valves peuvent être résolues par ces modèles unimodaux en calculant la perplexité de la légende correcte et de la légende contrefaite (pas d'image ici) et en prédisant l'entrée avec la perplexité la plus faible.", "metrics": {"bleu_score": 37.929855586465024, "chrf_score": 68.17518874879961, "xcomet_score": 0.5798920392990112, "xcomet_qe_score": 0.5693484544754028, "metricx_score": 8.0626802444458, "metricx_qe_score": 7.8380045890808105, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "Si la perplexité est plus élevée pour le texte masqué, nous considérons cela comme une indication que la légende masquée peut souffrir d'un biais de plausibilité ou d'autres biais linguistiques.", "metrics": {"bleu_score": 67.38463979895549, "chrf_score": 83.74827103512747, "xcomet_score": 0.692534863948822, "xcomet_qe_score": 0.6928061246871948, "metricx_score": 4.892007827758789, "metricx_qe_score": 4.442228317260742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est intéressant de constater que, dans certains cas, les modèles de texte uniquement GPT ont mieux capturé la plausibilité du monde que les modèles de vision et de langage.", "metrics": {"bleu_score": 46.06375119122777, "chrf_score": 73.21126466262103, "xcomet_score": 0.9477575421333313, "xcomet_qe_score": 0.9193128347396851, "metricx_score": 5.06500244140625, "metricx_qe_score": 5.264910697937012, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, VALSE est une référence qui utilise la lentille des constructions linguistiques pour aider la communauté à améliorer les modèles de vision et de langage en testant rigoureusement leurs capacités d'ancrage visuel.", "metrics": {"bleu_score": 40.49032858348942, "chrf_score": 71.8035056248005, "xcomet_score": 0.5500136613845825, "xcomet_qe_score": 0.6304489374160767, "metricx_score": 5.28281831741333, "metricx_qe_score": 4.843565940856934, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que les modèles de vision et de langage identifient bien les objets nommés et leur présence dans les images, comme le montre l'existence de la pièce, mais ont du mal à ancrer leur interdépendance et leurs relations dans des scènes visuelles lorsqu'ils sont contraints de respecter les indicateurs linguistiques.", "metrics": {"bleu_score": 61.62248193050929, "chrf_score": 85.16709755967733, "xcomet_score": 0.7198151350021362, "xcomet_qe_score": 0.728679895401001, "metricx_score": 5.248769283294678, "metricx_qe_score": 5.253415107727051, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions vraiment encourager la communauté à utiliser Vals pour mesurer les progrès réalisés dans le domaine de l'ancrage linguistique avec des modèles de vision et de langage.", "metrics": {"bleu_score": 44.348492631401015, "chrf_score": 73.75027099115601, "xcomet_score": 0.7001774311065674, "xcomet_qe_score": 0.7215561866760254, "metricx_score": 5.875976085662842, "metricx_qe_score": 6.417024612426758, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les valves pourraient être utilisées comme une évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou le réglage fin pour voir si un ensemble de données aide les modèles à s'améliorer sur l'un des aspects testés par les valves.", "metrics": {"bleu_score": 39.58442393362032, "chrf_score": 70.6583275019213, "xcomet_score": 0.6888823509216309, "xcomet_qe_score": 0.7214885950088501, "metricx_score": 9.174391746520996, "metricx_qe_score": 8.031097412109375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "Si cela vous intéresse, consultez les données de Valse sur GitHub et si vous avez des questions, n'hésitez pas à nous contacter.", "metrics": {"bleu_score": 63.07298528364232, "chrf_score": 79.58703649778293, "xcomet_score": 0.9624576568603516, "xcomet_qe_score": 0.951501190662384, "metricx_score": 1.1195738315582275, "metricx_qe_score": 1.0723271369934082, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kamisara, de l'Université de Tokyo.", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 84.03314218948648, "xcomet_score": 0.5569930672645569, "xcomet_qe_score": 0.4114086329936981, "metricx_score": 4.625857830047607, "metricx_qe_score": 4.551677703857422, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai une communication intitulée R et Sum, un ensemble de données à grande échelle pour l'évaluation automatique du risque et non de la durée par une sommation de journal de comité.", "metrics": {"bleu_score": 12.939351664346617, "chrf_score": 48.687514806945565, "xcomet_score": 0.15306970477104187, "xcomet_qe_score": 0.16316178441047668, "metricx_score": 14.475327491760254, "metricx_qe_score": 14.011741638183594, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais expliquer dans cet ordre.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 82.67586467120438, "xcomet_score": 0.9803920984268188, "xcomet_qe_score": 1.0, "metricx_score": 0.5986242294311523, "metricx_qe_score": 0.8819785118103027, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je vais présenter la neutralisation automatique des risques sur laquelle nous travaillons dans cette recherche.", "metrics": {"bleu_score": 61.73915358983323, "chrf_score": 78.9510161726651, "xcomet_score": 0.5647208094596863, "xcomet_qe_score": 0.5881162881851196, "metricx_score": 5.514909267425537, "metricx_qe_score": 6.244606971740723, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "La note de version est un document technique qui résume les modifications distribuées avec chaque version d'un produit logiciel.", "metrics": {"bleu_score": 80.3154665668484, "chrf_score": 93.61045789499667, "xcomet_score": 0.9964048862457275, "xcomet_qe_score": 0.976631760597229, "metricx_score": 0.28997549414634705, "metricx_qe_score": 0.35187777876853943, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'image montre une note de recherche pour Bajan deux point six.", "metrics": {"bleu_score": 25.01887350892531, "chrf_score": 43.347086632009486, "xcomet_score": 0.17073234915733337, "xcomet_qe_score": 0.24602629244327545, "metricx_score": 17.60593605041504, "metricx_qe_score": 16.856487274169922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Bibliothèque Userious. Ces nœuds jouent un rôle important dans le développement open source, mais ils prennent beaucoup de temps à préparer manuellement.", "metrics": {"bleu_score": 46.193725520648975, "chrf_score": 64.91373641345884, "xcomet_score": 0.15557925403118134, "xcomet_qe_score": 0.07482193410396576, "metricx_score": 11.23658561706543, "metricx_qe_score": 13.095399856567383, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Il serait donc très utile de pouvoir générer automatiquement des notes de version de haute qualité.", "metrics": {"bleu_score": 72.83860464220109, "chrf_score": 83.3655136180521, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6620479822158813, "metricx_qe_score": 0.7192174196243286, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "Je ferai référence à deux recherches antérieures sur la génération automatique de risques.", "metrics": {"bleu_score": 54.291218877831355, "chrf_score": 68.971415502931, "xcomet_score": 0.5673253536224365, "xcomet_qe_score": 0.6137893795967102, "metricx_score": 11.283202171325684, "metricx_qe_score": 8.956335067749023, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier est un système appelé Arena, sorti en 2014. Il est", "metrics": {"bleu_score": 21.97281387499715, "chrf_score": 45.84393192129094, "xcomet_score": 0.17174352705478668, "xcomet_qe_score": 0.22787576913833618, "metricx_score": 6.1742658615112305, "metricx_qe_score": 1.783738136291504, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il adopte une approche basée sur des règles, par exemple, en utilisant l'extracteur de modifications pour extraire les différences fondamentales, les modifications de bibliothèque et les modifications de documents à partir des différences entre les versions, puis en les combinant.", "metrics": {"bleu_score": 56.53553210890054, "chrf_score": 73.33638307999549, "xcomet_score": 0.8791584968566895, "xcomet_qe_score": 0.926351010799408, "metricx_score": 2.0714919567108154, "metricx_qe_score": 1.8037322759628296, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus remarquable de ce système est l'extracteur de problèmes dans le coin supérieur droit,", "metrics": {"bleu_score": 77.7811122305422, "chrf_score": 91.87716117035997, "xcomet_score": 0.848676323890686, "xcomet_qe_score": 0.8308253288269043, "metricx_score": 3.4437758922576904, "metricx_qe_score": 3.6951634883880615, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "Cela doit être lié à zéro, la question de l'écosystème et ne peut être appliqué qu'aux projets qui utilisent zéro.", "metrics": {"bleu_score": 33.96230123896639, "chrf_score": 57.8498277614904, "xcomet_score": 0.07612680643796921, "xcomet_qe_score": 0.0918852686882019, "metricx_score": 20.6524658203125, "metricx_qe_score": 20.93205451965332, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "ici. En d'autres termes, il ne peut pas être utilisé pour de nombreux projets sur GitHub.", "metrics": {"bleu_score": 75.08561371925762, "chrf_score": 90.3645644337058, "xcomet_score": 0.8512531518936157, "xcomet_qe_score": 0.8186489939689636, "metricx_score": 4.306835174560547, "metricx_qe_score": 5.232416152954102, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "Le deuxième est le deuil. Cette entrée a été annoncée en vingt-quatre.", "metrics": {"bleu_score": 6.754312828675707, "chrf_score": 32.47520496975913, "xcomet_score": 0.15171979367733002, "xcomet_qe_score": 0.1631772369146347, "metricx_score": 22.501468658447266, "metricx_qe_score": 20.87299156188965, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "vingt vingt. Il est disponible sur Internet et peut être installé via PIP.", "metrics": {"bleu_score": 17.678748653651848, "chrf_score": 71.29012705330358, "xcomet_score": 0.4646340608596802, "xcomet_qe_score": 0.7609593272209167, "metricx_score": 10.018999099731445, "metricx_qe_score": 11.16529655456543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système dispose d'un modèle de classification de texte basé sur l'exécution simple et propose une forme de cinq étiquettes, telles que des fonctionnalités ou des corrections de bogues, pour chaque message de commit d'entrée.", "metrics": {"bleu_score": 28.83666656222323, "chrf_score": 66.80794628457409, "xcomet_score": 0.5126230716705322, "xcomet_qe_score": 0.5643072128295898, "metricx_score": 6.86735725402832, "metricx_qe_score": 6.782802581787109, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un exemple d'utilisation qui renvoie une correction ou des corrections de bugs rebelles.", "metrics": {"bleu_score": 43.33207865423753, "chrf_score": 68.76480122778717, "xcomet_score": 0.5958290100097656, "xcomet_qe_score": 0.5958297252655029, "metricx_score": 7.1821441650390625, "metricx_qe_score": 6.924142360687256, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "La base de données d'entraînement de Graves est assez petite, d'environ cinq mille exemples, et sera présentée dans les expériences décrites ci-dessous.", "metrics": {"bleu_score": 25.381494737245898, "chrf_score": 63.59880897046708, "xcomet_score": 0.5673876404762268, "xcomet_qe_score": 0.5203335881233215, "metricx_score": 7.059393882751465, "metricx_qe_score": 7.8745951652526855, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle graphique de calendrier statistique n'est pas plus performant.", "metrics": {"bleu_score": 4.41902110634, "chrf_score": 32.456278636330815, "xcomet_score": 0.13806715607643127, "xcomet_qe_score": 0.15152664482593536, "metricx_score": 18.98935890197754, "metricx_qe_score": 20.42888641357422, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches connexes, mais il y a des problèmes d'applicabilité limitée et de ressources de données rares.", "metrics": {"bleu_score": 48.45766087853282, "chrf_score": 82.35147828234967, "xcomet_score": 0.9677211046218872, "xcomet_qe_score": 0.9111800193786621, "metricx_score": 1.0704854726791382, "metricx_qe_score": 1.2610890865325928, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des notes de version de haute qualité.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.998119592666626, "xcomet_qe_score": 0.9877771139144897, "metricx_score": 0.7568978071212769, "metricx_qe_score": 0.9668998718261719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le programme d'applicabilité limitée, nous proposons une méthode de résumé de classification de haute qualité utilisant uniquement le message du comité comme entrée.", "metrics": {"bleu_score": 34.01185071799047, "chrf_score": 63.73841517031246, "xcomet_score": 0.6001104116439819, "xcomet_qe_score": 0.583849310874939, "metricx_score": 9.506715774536133, "metricx_qe_score": 7.848118305206299, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée pour tous les dépôts anglais.", "metrics": {"bleu_score": 76.91605673134588, "chrf_score": 80.98835115515554, "xcomet_score": 0.7557715177536011, "xcomet_qe_score": 0.8315742015838623, "metricx_score": 2.4535419940948486, "metricx_qe_score": 0.9161605834960938, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème des ressources de données limitées, nous avons créé un ensemble de données RNSM composé d'environ quatre-vingt-deux mille données en collectant des données à partir de dépôts publics GitHub en utilisant l'API GitHub.", "metrics": {"bleu_score": 44.67357174225073, "chrf_score": 75.55310977973205, "xcomet_score": 0.8815456032752991, "xcomet_qe_score": 0.8956517577171326, "metricx_score": 4.557319641113281, "metricx_qe_score": 4.5506205558776855, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décris notre désert.", "metrics": {"bleu_score": 22.772101321113862, "chrf_score": 41.252730026822185, "xcomet_score": 0.3890964388847351, "xcomet_qe_score": 0.4221149682998657, "metricx_score": 12.627046585083008, "metricx_qe_score": 13.441385269165039, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre exemple de données.", "metrics": {"bleu_score": 53.7284965911771, "chrf_score": 76.85915067385532, "xcomet_score": 0.946622908115387, "xcomet_qe_score": 0.9420696496963501, "metricx_score": 0.9208157062530518, "metricx_qe_score": 1.0900479555130005, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche est un message de commit et le côté droit est une note de version.", "metrics": {"bleu_score": 53.816073893351884, "chrf_score": 62.84332482470565, "xcomet_score": 0.856730580329895, "xcomet_qe_score": 0.7727584838867188, "metricx_score": 3.6746692657470703, "metricx_qe_score": 3.766366481781006, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "La raison pour laquelle les notes sont appréciées comme améliorations, bureaux, etc.", "metrics": {"bleu_score": 13.380161378318954, "chrf_score": 48.08404837257819, "xcomet_score": 0.14182773232460022, "xcomet_qe_score": 0.14557476341724396, "metricx_score": 21.68819236755371, "metricx_qe_score": 21.02208137512207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons configuré une tâche qui prend les messages de commit comme entrée et dépasse les notes des pièces soudées à l'état brut.", "metrics": {"bleu_score": 29.608660106487147, "chrf_score": 49.51381345124338, "xcomet_score": 0.22825266420841217, "xcomet_qe_score": 0.3154139816761017, "metricx_score": 15.732767105102539, "metricx_qe_score": 14.08590030670166, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de résumé.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 80.28616903243483, "xcomet_score": 0.9564080238342285, "xcomet_qe_score": 0.9850058555603027, "metricx_score": 1.28573477268219, "metricx_qe_score": 0.8809378743171692, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons prédéfini quatre rubriques : fonctionnalités, améliorations, corrections de bugs, dépréciations, éléments à supprimer et changements incompatibles.", "metrics": {"bleu_score": 38.61450761584493, "chrf_score": 64.47701235931113, "xcomet_score": 0.5433773994445801, "xcomet_qe_score": 0.4724251627922058, "metricx_score": 5.129961013793945, "metricx_qe_score": 4.379508018493652, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces critères ont été établis sur la base de recherches antérieures et d'autres facteurs,", "metrics": {"bleu_score": 26.518122980477767, "chrf_score": 69.42818941190093, "xcomet_score": 0.9433406591415405, "xcomet_qe_score": 0.9769840240478516, "metricx_score": 1.944459319114685, "metricx_qe_score": 0.417855829000473, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de raison en bas à droite sont extraites des notes de raison affichées en bas à gauche.", "metrics": {"bleu_score": 31.56961170682444, "chrf_score": 53.18555570946547, "xcomet_score": 0.5509598255157471, "xcomet_qe_score": 0.5821443796157837, "metricx_score": 12.73198413848877, "metricx_qe_score": 11.017106056213379, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce stade, il est nécessaire de détecter les quatre déchets qui ont été préalablement disposés.", "metrics": {"bleu_score": 56.32809221870116, "chrf_score": 63.6759634124858, "xcomet_score": 0.6176738739013672, "xcomet_qe_score": 0.5731188058853149, "metricx_score": 8.838404655456543, "metricx_qe_score": 8.62292766571045, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "mais les rires ne sont pas toujours en accord avec chaque liberté,", "metrics": {"bleu_score": 23.90108882452814, "chrf_score": 49.38624969347515, "xcomet_score": 0.14801356196403503, "xcomet_qe_score": 0.13217338919639587, "metricx_score": 20.319766998291016, "metricx_qe_score": 18.636428833007812, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le pilote d'amélioration augmente les améliorations, les améliorations, les optimisations, etc.", "metrics": {"bleu_score": 22.250253290431033, "chrf_score": 61.50575775430956, "xcomet_score": 0.43523740768432617, "xcomet_qe_score": 0.5900490880012512, "metricx_score": 15.275463104248047, "metricx_qe_score": 16.72757339477539, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste de vocabulaire d'environ trente chiffres pour chacune de ces variations de rotation.", "metrics": {"bleu_score": 60.28817681965138, "chrf_score": 75.54697424097641, "xcomet_score": 0.6031332015991211, "xcomet_qe_score": 0.5357599258422852, "metricx_score": 11.241438865661621, "metricx_qe_score": 11.126524925231934, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez-le pour détecter le RIS et non les croûtes, et corrigez le reste du texte qui suit en remplaçant la phrase RIS par la croûte.", "metrics": {"bleu_score": 6.070833427954577, "chrf_score": 30.00740615171819, "xcomet_score": 0.12782354652881622, "xcomet_qe_score": 0.13464103639125824, "metricx_score": 14.954980850219727, "metricx_qe_score": 13.508770942687988, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, un message du comité.", "metrics": {"bleu_score": 12.794740298351046, "chrf_score": 45.02428673509368, "xcomet_score": 0.3330804109573364, "xcomet_qe_score": 0.7299835085868835, "metricx_score": 6.611763000488281, "metricx_qe_score": 6.925827980041504, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de commit ne sont pas liés à chaque vice.", "metrics": {"bleu_score": 54.52469119630866, "chrf_score": 63.40516896753172, "xcomet_score": 0.4445107877254486, "xcomet_qe_score": 0.4775262176990509, "metricx_score": 8.604681968688965, "metricx_qe_score": 10.764615058898926, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "Comme le montre l'image ci-dessous, si le risque actuel est de mille deux point cinq à dix-neuf, nous devons identifier", "metrics": {"bleu_score": 35.17261030016949, "chrf_score": 54.085866938551675, "xcomet_score": 0.1711007058620453, "xcomet_qe_score": 0.08629598468542099, "metricx_score": 22.875797271728516, "metricx_qe_score": 22.895545959472656, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "enregistrer la version de publication précédente 2.5.18 et obtenir sa diff. C'est un peu fastidieux et ce n'est pas suffisant de simplement obtenir une liste des publications et de regarder le résultat avant et après.", "metrics": {"bleu_score": 14.91304124931916, "chrf_score": 61.23086986107147, "xcomet_score": 0.550895094871521, "xcomet_qe_score": 0.3049321174621582, "metricx_score": 18.9498291015625, "metricx_qe_score": 15.906797409057617, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Il a créé une correspondance heuristique avec le bleu pour obtenir le concours précédent et le suivant.", "metrics": {"bleu_score": 7.994607499472017, "chrf_score": 54.956677272079524, "xcomet_score": 0.16859692335128784, "xcomet_qe_score": 0.1603323370218277, "metricx_score": 14.968969345092773, "metricx_qe_score": 14.327016830444336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "Voilà, les chevaux.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 7.5463722074195525, "xcomet_score": 0.11182447522878647, "xcomet_qe_score": 0.07862738519906998, "metricx_score": 20.612184524536133, "metricx_qe_score": 23.591785430908203, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "Au final, sept mille deux cents dépôts", "metrics": {"bleu_score": 15.181216783202624, "chrf_score": 29.66463753407857, "xcomet_score": 0.1627390831708908, "xcomet_qe_score": 0.14450986683368683, "metricx_score": 23.152732849121094, "metricx_qe_score": 20.16863250732422, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de jetons de nœuds libérés est de soixante-trois, ce qui est assez élevé pour une tâche de résumé.", "metrics": {"bleu_score": 59.86845801393644, "chrf_score": 66.40682591668933, "xcomet_score": 0.4780709445476532, "xcomet_qe_score": 0.47519007325172424, "metricx_score": 9.440235137939453, "metricx_qe_score": 7.509166717529297, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre de jetons uniques est assez élevé, atteignant huit millions huit cent trente mille. C'est l'un des", "metrics": {"bleu_score": 32.70029093408734, "chrf_score": 60.37018886605014, "xcomet_score": 0.31851017475128174, "xcomet_qe_score": 0.2841946482658386, "metricx_score": 14.711380958557129, "metricx_qe_score": 11.39554214477539, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "en raison du grand nombre de classes et de nerfs de méthode uniques présents dans le répertoire.", "metrics": {"bleu_score": 11.836068992777946, "chrf_score": 52.740471799751276, "xcomet_score": 0.4716393053531647, "xcomet_qe_score": 0.462842732667923, "metricx_score": 9.061813354492188, "metricx_qe_score": 8.862852096557617, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, j'expliquerai la méthode proposée.", "metrics": {"bleu_score": 36.74145494215666, "chrf_score": 75.59105076499984, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26971232891082764, "metricx_qe_score": 0.1778177171945572, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de résumé transversal extractif et abstratif se compose de deux modules plus récents", "metrics": {"bleu_score": 30.781789741768915, "chrf_score": 49.8687885832491, "xcomet_score": 0.18221063911914825, "xcomet_qe_score": 0.2796096205711365, "metricx_score": 10.935113906860352, "metricx_qe_score": 7.931600570678711, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "Un classificateur utilisant un bot ou un code bot et un générateur utilisant un bot.", "metrics": {"bleu_score": 23.578316044531807, "chrf_score": 68.44405377333584, "xcomet_score": 0.26621341705322266, "xcomet_qe_score": 0.23034343123435974, "metricx_score": 9.027627944946289, "metricx_qe_score": 11.75222396850586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, GEAS utilise une valeur croisée pour classer chaque message du comité en cinq catégories de disnœuds : fonctionnalités, améliorations, corrections de bogues, doublons, plus et autres.", "metrics": {"bleu_score": 16.89838056513914, "chrf_score": 49.77265675415391, "xcomet_score": 0.218308687210083, "xcomet_qe_score": 0.26071396470069885, "metricx_score": 13.223608016967773, "metricx_qe_score": 12.960542678833008, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages du comité classés comme Autres sont rejetés.", "metrics": {"bleu_score": 13.134549472120794, "chrf_score": 53.480767437541544, "xcomet_score": 0.7389079928398132, "xcomet_qe_score": 0.7504338622093201, "metricx_score": 5.531780242919922, "metricx_qe_score": 5.960855960845947, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, GES applique le générateur aux quatre documents de routeur indépendamment et génère des notes de risque pour chaque classe.", "metrics": {"bleu_score": 56.30127787148428, "chrf_score": 78.68464487950348, "xcomet_score": 0.23583027720451355, "xcomet_qe_score": 0.29982990026474, "metricx_score": 13.693424224853516, "metricx_qe_score": 11.683961868286133, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages de commit et les notes de lecture ne sont pas connues.", "metrics": {"bleu_score": 73.89984311706958, "chrf_score": 80.05176599916287, "xcomet_score": 0.7439485788345337, "xcomet_qe_score": 0.7411178350448608, "metricx_score": 6.553906440734863, "metricx_qe_score": 7.155002593994141, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour entraîner le classificateur, nous attribuons des pseudorubis à chaque message de commit d'entrée en utilisant les dix premiers caractères de chaque message de commit.", "metrics": {"bleu_score": 50.97049681318311, "chrf_score": 67.15853578764795, "xcomet_score": 0.5355132818222046, "xcomet_qe_score": 0.7257150411605835, "metricx_score": 8.294532775878906, "metricx_qe_score": 7.315367698669434, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons le résumé obstructif transversal, donc l'approche, par deux méthodes différentes.", "metrics": {"bleu_score": 18.92240568795936, "chrf_score": 52.23106977939217, "xcomet_score": 0.4235643148422241, "xcomet_qe_score": 0.3727972209453583, "metricx_score": 7.19521427154541, "metricx_qe_score": 6.576267719268799, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons GIS Single, se compose d'un réseau de section à section unique et génère un seul texte long isNote donné un niveau de concrétude des messages d'engagement d'entrée.", "metrics": {"bleu_score": 41.00627524244125, "chrf_score": 60.63624025632907, "xcomet_score": 0.07089337706565857, "xcomet_qe_score": 0.1303478181362152, "metricx_score": 18.581594467163086, "metricx_qe_score": 18.585044860839844, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte de sortie peut être divisé en segments transversaux basés sur des symboles de points de terminaison spécifiques à la croix.", "metrics": {"bleu_score": 9.760538573094808, "chrf_score": 52.23344976516414, "xcomet_score": 0.3579220771789551, "xcomet_qe_score": 0.42195817828178406, "metricx_score": 8.94564151763916, "metricx_qe_score": 8.507685661315918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons CSMarch, se compose de quatre réseaux différents de sec à sec, chacun correspondant à l'une des classes de nœuds de liste.", "metrics": {"bleu_score": 40.35118319685422, "chrf_score": 63.80629184599725, "xcomet_score": 0.10187581926584244, "xcomet_qe_score": 0.11307097971439362, "metricx_score": 18.38029670715332, "metricx_qe_score": 18.41899299621582, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, cela explique l'expérience de Fan.", "metrics": {"bleu_score": 5.795599612995366, "chrf_score": 40.42304474170508, "xcomet_score": 0.14172863960266113, "xcomet_qe_score": 0.13289029896259308, "metricx_score": 11.653861999511719, "metricx_qe_score": 8.734601020812988, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été comparées : CAS, CAS simple, CAS bouche, Prasseling et étude préalable succincte.", "metrics": {"bleu_score": 31.18953049955765, "chrf_score": 48.435879926793774, "xcomet_score": 0.3315185606479645, "xcomet_qe_score": 0.4502309262752533, "metricx_score": 14.338665962219238, "metricx_qe_score": 15.82750129699707, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'avortement, dans certains cas, ces notes sont produites en plusieurs phrases.", "metrics": {"bleu_score": 54.85113740772977, "chrf_score": 72.36593204319475, "xcomet_score": 0.19325733184814453, "xcomet_qe_score": 0.2621408998966217, "metricx_score": 14.362373352050781, "metricx_qe_score": 12.493062973022461, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Puisqu'il est difficile de calculer le nombre de phrases comme étant zéro, elles sont combinées avec des espaces et traitées comme une phrase longue.", "metrics": {"bleu_score": 71.51826245402509, "chrf_score": 81.30833632883143, "xcomet_score": 0.754680871963501, "xcomet_qe_score": 0.7246506214141846, "metricx_score": 10.502696990966797, "metricx_qe_score": 11.924047470092773, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "Le bureau est pénétré lorsque le système affiche une courte phrase", "metrics": {"bleu_score": 16.278331364721527, "chrf_score": 53.70916731765788, "xcomet_score": 0.4391763508319855, "xcomet_qe_score": 0.21816924214363098, "metricx_score": 12.835705757141113, "metricx_qe_score": 13.357534408569336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité entraîne un volume de brassage inférieur dans les résultats expérimentaux décrits ci-après", "metrics": {"bleu_score": 11.670054700674017, "chrf_score": 51.28847500713408, "xcomet_score": 0.7878668308258057, "xcomet_qe_score": 0.7280862331390381, "metricx_score": 6.764260292053223, "metricx_qe_score": 6.961703777313232, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous corruguons également une spécificité car rouge et brue ne peuvent pas être corrugés si les nœuds de libération sont vides.", "metrics": {"bleu_score": 22.133117633147442, "chrf_score": 59.11188799489126, "xcomet_score": 0.18370966613292694, "xcomet_qe_score": 0.22130407392978668, "metricx_score": 20.097713470458984, "metricx_qe_score": 19.010435104370117, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une spécificité élevée signifie que le modèle produit correctement un texte vide dans les cas où les notes de raisonnement supposent un texte vide.", "metrics": {"bleu_score": 66.90788963496665, "chrf_score": 78.67221595739723, "xcomet_score": 0.8752106428146362, "xcomet_qe_score": 0.8264263868331909, "metricx_score": 5.098026752471924, "metricx_qe_score": 4.45991325378418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats.", "metrics": {"bleu_score": 11.521590992286539, "chrf_score": 34.57828622839441, "xcomet_score": 0.7604808807373047, "xcomet_qe_score": 1.0, "metricx_score": 0.15108263492584229, "metricx_qe_score": 0.03296280279755592, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que l'ensemble de données contient des adresses e-mail, des valeurs de hachage, etc., nous éliminons également l'ensemble de données d'impression, qui les exclut.", "metrics": {"bleu_score": 28.9331164128846, "chrf_score": 58.61652776646946, "xcomet_score": 0.6481707692146301, "xcomet_qe_score": 0.662750244140625, "metricx_score": 9.554558753967285, "metricx_qe_score": 8.498857498168945, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "Elle a obtenu des scores aériens bien plus élevés, de plus de dix points supérieurs à la moyenne de base.", "metrics": {"bleu_score": 23.41812326184748, "chrf_score": 46.85686161376918, "xcomet_score": 0.1576591581106186, "xcomet_qe_score": 0.1761847734451294, "metricx_score": 12.913408279418945, "metricx_qe_score": 14.390714645385742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur l'ensemble de test vert, l'écart carré entre la méthode proposée et la base a bondi à plus de vingt points.", "metrics": {"bleu_score": 52.08202637221089, "chrf_score": 71.70148599092985, "xcomet_score": 0.3677904009819031, "xcomet_qe_score": 0.26033467054367065, "metricx_score": 9.932268142700195, "metricx_qe_score": 10.219074249267578, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent qu'elle est et qu'elle est significativement efficaces.", "metrics": {"bleu_score": 13.215955651112736, "chrf_score": 42.690852904528846, "xcomet_score": 0.13479627668857574, "xcomet_qe_score": 0.1489936113357544, "metricx_score": 20.594900131225586, "metricx_qe_score": 19.138687133789062, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "GAS a obtenu un meilleur score Rouge F que GAS, ce qui suggère que la combinaison d'un crossfire et d'un générateur est efficace pour entraîner le crossfire en utilisant des pseudobus.", "metrics": {"bleu_score": 45.073818171789, "chrf_score": 59.9392341406662, "xcomet_score": 0.04896622151136398, "xcomet_qe_score": 0.17017389833927155, "metricx_score": 21.46697425842285, "metricx_qe_score": 19.66103172302246, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "Une couverture élevée des GAS peut être atteinte probablement parce que le classificateur peut se concentrer sur la sélection des messages de commit pertinents pour chaque classe.", "metrics": {"bleu_score": 56.08477095443868, "chrf_score": 79.94920054745141, "xcomet_score": 0.6813015341758728, "xcomet_qe_score": 0.7556542158126831, "metricx_score": 6.8676228523254395, "metricx_qe_score": 6.240505695343018, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Elle a tendance à manger beaucoup plus cette année qu'elle ne le fait en solo.", "metrics": {"bleu_score": 3.4585921141027365, "chrf_score": 17.04570614426596, "xcomet_score": 0.12326200306415558, "xcomet_qe_score": 0.10924901813268661, "metricx_score": 25.0, "metricx_qe_score": 22.485097885131836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "ce qui suggère qu'il est également efficace de développer de manière indépendante différents modèles de résumé de perspective sur deux ans pour chaque note de vue d'herbe.", "metrics": {"bleu_score": 22.86867640176166, "chrf_score": 56.73727657274264, "xcomet_score": 0.11407443881034851, "xcomet_qe_score": 0.17274899780750275, "metricx_score": 16.308069229125977, "metricx_qe_score": 15.625776290893555, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "Héro et Éronase", "metrics": {"bleu_score": 0.0, "chrf_score": 7.718958355150626, "xcomet_score": 0.11593100428581238, "xcomet_qe_score": 0.09904850274324417, "metricx_score": 17.586549758911133, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes de Xia ont tendance à produire des phrases plus courtes que les phrases de référence humaines.", "metrics": {"bleu_score": 80.86627571031983, "chrf_score": 93.08927999051926, "xcomet_score": 0.5958991050720215, "xcomet_qe_score": 0.520405650138855, "metricx_score": 8.303533554077148, "metricx_qe_score": 9.904258728027344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure à droite, la phrase de référence a trois ou quatre phrases, alors qu'elle n'en a qu'une.", "metrics": {"bleu_score": 62.89505835420131, "chrf_score": 78.18264688872037, "xcomet_score": 0.40704643726348877, "xcomet_qe_score": 0.3139573037624359, "metricx_score": 10.16372013092041, "metricx_qe_score": 10.683074951171875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette réticence du modèle est que dans les données d'entraînement, seulement 33 % des phrases sont présentes dans les rubriques «  décombres  » et 40 % dans les rubriques «  améliorations  ».", "metrics": {"bleu_score": 28.23919656840293, "chrf_score": 53.7671058954346, "xcomet_score": 0.5570467114448547, "xcomet_qe_score": 0.6873487234115601, "metricx_score": 10.886669158935547, "metricx_qe_score": 9.115520477294922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes CES ne peuvent pas générer de notes de risque précises sans informations supplémentaires.", "metrics": {"bleu_score": 40.569661365913525, "chrf_score": 77.30612523130883, "xcomet_score": 0.5537747144699097, "xcomet_qe_score": 0.7659910917282104, "metricx_score": 8.138389587402344, "metricx_qe_score": 6.213953018188477, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple en haut à droite est un exemple de message de comité très confus et la phrase complète ne peut pas être générée sans référence à la demande ou au problème du Pérou correspondant.", "metrics": {"bleu_score": 64.42976193218, "chrf_score": 74.64399205885665, "xcomet_score": 0.36872443556785583, "xcomet_qe_score": 0.3534941077232361, "metricx_score": 16.261714935302734, "metricx_qe_score": 11.845805168151855, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous montre que les deux messages de commit dans l'entrée sont liés et devraient être combinés en une seule phrase, mais il ne parvient pas à le faire.", "metrics": {"bleu_score": 39.0944313761396, "chrf_score": 69.35618355922927, "xcomet_score": 0.8577835559844971, "xcomet_qe_score": 0.9136546850204468, "metricx_score": 5.396671772003174, "metricx_qe_score": 5.279102325439453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, une conclusion.", "metrics": {"bleu_score": 20.252884954471366, "chrf_score": 51.7870301786907, "xcomet_score": 0.9809033870697021, "xcomet_qe_score": 1.0, "metricx_score": 1.8073315620422363, "metricx_qe_score": 2.418452262878418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons créé un nouveau jeu de bureaux pour la génération automatique de profils personnels,", "metrics": {"bleu_score": 27.22589423069701, "chrf_score": 53.11661823112939, "xcomet_score": 0.1483362317085266, "xcomet_qe_score": 0.15412963926792145, "metricx_score": 12.976213455200195, "metricx_qe_score": 10.256331443786621, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également formé la tâche de saisir les messages du comité et de les résumer de manière à ce qu'ils soient applicables à tous les projets rédigés en anglais.", "metrics": {"bleu_score": 30.421649500894976, "chrf_score": 64.70756880996323, "xcomet_score": 0.6463732719421387, "xcomet_qe_score": 0.6239484548568726, "metricx_score": 6.047094821929932, "metricx_qe_score": 6.156630992889404, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que la méthode proposée a généré le meilleur résultat bruité non pas à une couverture supérieure à la montée de base.", "metrics": {"bleu_score": 29.515162380863735, "chrf_score": 55.690640728289644, "xcomet_score": 0.18753165006637573, "xcomet_qe_score": 0.14773260056972504, "metricx_score": 15.288768768310547, "metricx_qe_score": 14.358317375183105, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Consultez notre application d'audit du désert.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 23.625727223881324, "xcomet_score": 0.13114163279533386, "xcomet_qe_score": 0.1162799820303917, "metricx_score": 12.283699035644531, "metricx_qe_score": 15.895831108093262, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10382990539073944, "metricx_qe_score": 0.4022793173789978, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Safarari,", "metrics": {"bleu_score": 8.170609724417774, "chrf_score": 54.22886244637859, "xcomet_score": 0.20491938292980194, "xcomet_qe_score": 0.1446262001991272, "metricx_score": 6.209176063537598, "metricx_qe_score": 5.790604591369629, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "Et je vais présenter notre article, « Amélioration de quelques données tabulaires brèves en utilisant des architectures de transformateurs affinés ».", "metrics": {"bleu_score": 14.10002457876887, "chrf_score": 64.48758383071083, "xcomet_score": 0.6911844611167908, "xcomet_qe_score": 0.765955924987793, "metricx_score": 8.560914993286133, "metricx_qe_score": 6.410490036010742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "Les scientifiques des données analysent les données et se concentrent principalement sur la manipulation des caractéristiques existantes des données.", "metrics": {"bleu_score": 67.09293368821515, "chrf_score": 88.27468216654194, "xcomet_score": 0.9940310716629028, "xcomet_qe_score": 1.0, "metricx_score": 0.8471265435218811, "metricx_qe_score": 0.8129141330718994, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "Mais parfois ses fonctionnalités sont limitées.", "metrics": {"bleu_score": 26.647313141084275, "chrf_score": 76.94819920746691, "xcomet_score": 0.96598219871521, "xcomet_qe_score": 0.969377875328064, "metricx_score": 0.4936392307281494, "metricx_qe_score": 0.3298269808292389, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "La génération de caractéristiques à l'aide d'une autre source de données peut ajouter des informations substantielles.", "metrics": {"bleu_score": 63.019085559238604, "chrf_score": 78.13911569774599, "xcomet_score": 0.9807618856430054, "xcomet_qe_score": 1.0, "metricx_score": 1.872923493385315, "metricx_qe_score": 1.3984712362289429, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique des données tabulaires à l'aide de sources externes en texte libre.", "metrics": {"bleu_score": 43.200373340115924, "chrf_score": 80.324139365827, "xcomet_score": 0.9968491792678833, "xcomet_qe_score": 1.0, "metricx_score": 0.6752551794052124, "metricx_qe_score": 0.977837860584259, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Supposons que nous ayons un ensemble de données tabulaires et une base de connaissances.", "metrics": {"bleu_score": 64.75445426291287, "chrf_score": 89.73182752598848, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7479367256164551, "metricx_qe_score": 0.9663262367248535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique qui implique le couplage d'entités et l'analyse de texte pour extraire de nouvelles caractéristiques à partir du texte libre de la base de connaissances.", "metrics": {"bleu_score": 72.03362668653467, "chrf_score": 85.38744352759755, "xcomet_score": 0.9668317437171936, "xcomet_qe_score": 0.965725302696228, "metricx_score": 1.9439656734466553, "metricx_qe_score": 1.7883095741271973, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre est d'abord exactement ce processus automatique.", "metrics": {"bleu_score": 53.07712171072444, "chrf_score": 79.53167817792153, "xcomet_score": 0.6487555503845215, "xcomet_qe_score": 0.6181809902191162, "metricx_score": 7.233702659606934, "metricx_qe_score": 11.051931381225586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple. Dans un ensemble de données, il est introduit dans FAST.", "metrics": {"bleu_score": 6.437165254072419, "chrf_score": 49.9486445918102, "xcomet_score": 0.5067415237426758, "xcomet_qe_score": 0.6102390289306641, "metricx_score": 8.208649635314941, "metricx_qe_score": 10.058597564697266, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données est un ensemble de données universitaires.", "metrics": {"bleu_score": 26.58483576665878, "chrf_score": 71.2917353334564, "xcomet_score": 0.9974851608276367, "xcomet_qe_score": 0.9998142719268799, "metricx_score": 0.6133542060852051, "metricx_qe_score": 0.7305991649627686, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "lorsqu'il s'agit de classer les universités en universités de faible rang et en universités de haut rang.", "metrics": {"bleu_score": 67.73401400577126, "chrf_score": 76.18647639058622, "xcomet_score": 0.9777740240097046, "xcomet_qe_score": 0.972602367401123, "metricx_score": 1.2917836904525757, "metricx_qe_score": 1.7408027648925781, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons Wikipedia comme base de connaissances.", "metrics": {"bleu_score": 16.0529461904344, "chrf_score": 68.12699120128313, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.24026861786842346, "metricx_qe_score": 0.1657801866531372, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase de FEST est le couplage d'entités.", "metrics": {"bleu_score": 32.46679154750989, "chrf_score": 62.48092598773257, "xcomet_score": 0.6487202644348145, "xcomet_qe_score": 0.7916384935379028, "metricx_score": 5.374037265777588, "metricx_qe_score": 5.75582218170166, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque chaque entité dans cet exemple, le nom de l'université, est liée à une entité dans la base de connaissances.", "metrics": {"bleu_score": 67.3572805195092, "chrf_score": 86.38244935394447, "xcomet_score": 0.9294095039367676, "xcomet_qe_score": 0.8874855041503906, "metricx_score": 1.2952073812484741, "metricx_qe_score": 2.1607844829559326, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte des entités de la base de connaissances est extrait et ajouté au jeu de données.", "metrics": {"bleu_score": 67.36041912625802, "chrf_score": 89.91782906832555, "xcomet_score": 0.9177287220954895, "xcomet_qe_score": 0.9149763584136963, "metricx_score": 1.626519799232483, "metricx_qe_score": 1.662952184677124, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le texte est le résumé de la page Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5573669075965881, "metricx_qe_score": 0.8606062531471252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Nous devons maintenant générer ou extraire des caractéristiques du texte de récupération.", "metrics": {"bleu_score": 21.18854509032766, "chrf_score": 55.72008532123842, "xcomet_score": 0.9301801323890686, "xcomet_qe_score": 0.9603231549263, "metricx_score": 4.592691898345947, "metricx_qe_score": 3.7125062942504883, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc besoin d'une phase d'extraction des caractéristiques qui inclut l'analyse de texte.", "metrics": {"bleu_score": 38.70605144677149, "chrf_score": 67.7450657326771, "xcomet_score": 0.9889019727706909, "xcomet_qe_score": 0.9709123969078064, "metricx_score": 3.97355055809021, "metricx_qe_score": 3.969383716583252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est la principale nouveauté de cet article, et j'y plongerai plus avant dans les diapositives suivantes.", "metrics": {"bleu_score": 30.3761370013102, "chrf_score": 56.323741848519404, "xcomet_score": 0.7344129085540771, "xcomet_qe_score": 0.7619408369064331, "metricx_score": 4.122550010681152, "metricx_qe_score": 3.3167176246643066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction des caractéristiques, il y a une phase de génération des caractéristiques lorsque nous utilisons les caractéristiques extraites pour générer un petit nombre de nouvelles caractéristiques.", "metrics": {"bleu_score": 63.224657395432004, "chrf_score": 72.98475010364008, "xcomet_score": 0.9610253572463989, "xcomet_qe_score": 0.994035005569458, "metricx_score": 2.269667387008667, "metricx_qe_score": 1.3787375688552856, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, générez des caractéristiques en fonction du nombre de classes du jeu de données original.", "metrics": {"bleu_score": 9.880782578056978, "chrf_score": 56.06289422475845, "xcomet_score": 0.8874317407608032, "xcomet_qe_score": 0.6921939849853516, "metricx_score": 4.3469767570495605, "metricx_qe_score": 3.1474545001983643, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données original comporte deux classes", "metrics": {"bleu_score": 28.997844147152072, "chrf_score": 63.86111269607918, "xcomet_score": 0.9943541288375854, "xcomet_qe_score": 0.9959211349487305, "metricx_score": 1.0562043190002441, "metricx_qe_score": 0.8206802010536194, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, d'abord, générez deux nouvelles caractéristiques.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 37.27658636004621, "xcomet_score": 0.1754591166973114, "xcomet_qe_score": 0.2023487240076065, "metricx_score": 11.067998886108398, "metricx_qe_score": 8.594005584716797, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si l'ensemble de données comporte cinq classes, générez d'abord cinq nouvelles caractéristiques.", "metrics": {"bleu_score": 15.310245441182436, "chrf_score": 50.57598120536667, "xcomet_score": 0.4656464755535126, "xcomet_qe_score": 0.4734566807746887, "metricx_score": 7.779063701629639, "metricx_qe_score": 7.021667003631592, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque caractéristique représente la probabilité pour chaque classe.", "metrics": {"bleu_score": 75.06238537503395, "chrf_score": 78.89231057183392, "xcomet_score": 0.9665066003799438, "xcomet_qe_score": 1.0, "metricx_score": 1.271324634552002, "metricx_qe_score": 1.2625250816345215, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état actuel de l'art en matière d'analyse de texte, à savoir les modèles de langage basés sur les transformateurs tels que BERT, GPT, XLED, etc.", "metrics": {"bleu_score": 28.190041992923945, "chrf_score": 60.40692435881183, "xcomet_score": 0.7619550824165344, "xcomet_qe_score": 0.8525252342224121, "metricx_score": 5.779354572296143, "metricx_qe_score": 6.166758060455322, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "Mais il est peu probable que nous puissions entraîner un modèle linguistique en utilisant les ensembles de données d'entrée.", "metrics": {"bleu_score": 44.129945550173765, "chrf_score": 67.93411192596676, "xcomet_score": 0.9211719036102295, "xcomet_qe_score": 0.9688928127288818, "metricx_score": 2.4642231464385986, "metricx_qe_score": 2.0305304527282715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, une approche naïve consisterait à affiner la tâche cible.", "metrics": {"bleu_score": 48.86103195703452, "chrf_score": 67.95142514785971, "xcomet_score": 0.9104291796684265, "xcomet_qe_score": 0.8309173583984375, "metricx_score": 1.807779312133789, "metricx_qe_score": 2.9226772785186768, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans la phase d'extraction des caractéristiques, nous pouvons télécharger un modèle linguistique par train, ajuster finement le modèle linguistique sur l'ensemble de données cible.", "metrics": {"bleu_score": 19.257758240643728, "chrf_score": 57.60890285711984, "xcomet_score": 0.7261417508125305, "xcomet_qe_score": 0.7092847228050232, "metricx_score": 7.003330230712891, "metricx_qe_score": 7.076867580413818, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, pour affiner le modèle linguistique, classer le texte en catégories, abstraire en catégories, basses ou élevées.", "metrics": {"bleu_score": 33.09673047735293, "chrf_score": 60.58596380269577, "xcomet_score": 0.7024435997009277, "xcomet_qe_score": 0.7096185684204102, "metricx_score": 4.585487365722656, "metricx_qe_score": 6.455382347106934, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "Recevoir la sortie du modèle linguistique, qui est la probabilité pour chaque classe, et l'utiliser comme nouvelles caractéristiques.", "metrics": {"bleu_score": 24.118194478141294, "chrf_score": 63.86055080273998, "xcomet_score": 0.9192417860031128, "xcomet_qe_score": 0.9138619899749756, "metricx_score": 4.228279113769531, "metricx_qe_score": 4.0141448974609375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que les ensembles de données peuvent avoir peu de piles d'entités distinctes.", "metrics": {"bleu_score": 45.04136656702741, "chrf_score": 78.89534554766348, "xcomet_score": 0.7999585866928101, "xcomet_qe_score": 0.8175134658813477, "metricx_score": 6.397307395935059, "metricx_qe_score": 6.948291301727295, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, près de la moitié des ensembles de données contiennent moins de quatre cents échantillons, et le plus petit ensemble de données contenait trente-cinq échantillons dans son ensemble d'entraînement.", "metrics": {"bleu_score": 47.20162370319343, "chrf_score": 80.14864093508696, "xcomet_score": 0.9539071321487427, "xcomet_qe_score": 0.9548527002334595, "metricx_score": 1.5996663570404053, "metricx_qe_score": 1.2598321437835693, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, affiner un modèle linguistique sur ce jeu de données sera inefficace.", "metrics": {"bleu_score": 6.734395444347337, "chrf_score": 53.877796992225846, "xcomet_score": 0.9641237258911133, "xcomet_qe_score": 0.9743753671646118, "metricx_score": 1.4542535543441772, "metricx_qe_score": 1.3492319583892822, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons utiliser des connaissances antérieures sur des ensembles de données pré-analysés.", "metrics": {"bleu_score": 41.60751652217844, "chrf_score": 75.62618945472612, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9520556330680847, "metricx_qe_score": 1.021158218383789, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "Parce que nous appliquons rapidement sur plusieurs ensembles de données, nous pouvons utiliser les N-1 ensembles de données pour recueillir des informations sur les N-1 ensembles de données et utiliser ces informations lorsque nous analysons l'ensemble de données numéro n.", "metrics": {"bleu_score": 36.302575658104715, "chrf_score": 69.51833659626304, "xcomet_score": 0.44630396366119385, "xcomet_qe_score": 0.4789435863494873, "metricx_score": 7.555881500244141, "metricx_qe_score": 7.558235168457031, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "Ce que nous suggérons, c'est d'ajouter une autre phase d'affinage.", "metrics": {"bleu_score": 76.04321823471474, "chrf_score": 83.05632979523111, "xcomet_score": 0.9060847759246826, "xcomet_qe_score": 0.8419142961502075, "metricx_score": 1.8232682943344116, "metricx_qe_score": 1.9570674896240234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "une phase de réglage fin multitâche préliminaire.", "metrics": {"bleu_score": 25.848657697858535, "chrf_score": 70.65001504137368, "xcomet_score": 0.9047296643257141, "xcomet_qe_score": 0.8776587247848511, "metricx_score": 4.938012599945068, "metricx_qe_score": 6.571381568908691, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous trouvons lors du modèle linguistique plus de n moins un ensemble de données,", "metrics": {"bleu_score": 11.251329738544614, "chrf_score": 42.32974501620701, "xcomet_score": 0.20968519151210785, "xcomet_qe_score": 0.20560958981513977, "metricx_score": 18.472026824951172, "metricx_qe_score": 17.469636917114258, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "Puis nous exécutons une autre phase d'affinage, qui est un affinage de tâche cible lorsque nous affinons le modèle linguistique sur le n-ième ensemble de données cible.", "metrics": {"bleu_score": 22.7160528277135, "chrf_score": 63.11679059931124, "xcomet_score": 0.7883303165435791, "xcomet_qe_score": 0.7289074659347534, "metricx_score": 2.3267202377319336, "metricx_qe_score": 4.301273822784424, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "L'état de l'art en matière d'ajustement fin multitâche appelé MTDNN.", "metrics": {"bleu_score": 15.851165692617148, "chrf_score": 53.07429429229556, "xcomet_score": 0.928874135017395, "xcomet_qe_score": 0.9424594640731812, "metricx_score": 4.320301055908203, "metricx_qe_score": 5.478743076324463, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "Dans MTDNN, MTDNN conserve un nombre de tâches dans l'ensemble d'entraînement.", "metrics": {"bleu_score": 26.970156334232563, "chrf_score": 49.86098918337672, "xcomet_score": 0.43204042315483093, "xcomet_qe_score": 0.7162805795669556, "metricx_score": 12.535228729248047, "metricx_qe_score": 10.243557929992676, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans cet exemple, il y a quatre tâches dans l'ensemble d'entraînement. Donc, videz le RNT et maintenez quatre têtes, comme vous pouvez le voir sur l'image.", "metrics": {"bleu_score": 57.52221449999801, "chrf_score": 72.25073234608172, "xcomet_score": 0.2753934860229492, "xcomet_qe_score": 0.3351151943206787, "metricx_score": 10.17510986328125, "metricx_qe_score": 9.787235260009766, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "et il prélève un échantillon aléatoire de l'ensemble d'entraînement.", "metrics": {"bleu_score": 16.807407519804237, "chrf_score": 59.080133128743874, "xcomet_score": 0.7465322017669678, "xcomet_qe_score": 0.7612265348434448, "metricx_score": 2.302901029586792, "metricx_qe_score": 3.192049980163574, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "et si le lot aléatoire appartient par exemple aux tâches de classification de sing et seldon, il exécute un passage avant/arrière à travers la première tête", "metrics": {"bleu_score": 20.651050740495947, "chrf_score": 55.28458680073257, "xcomet_score": 0.297901451587677, "xcomet_qe_score": 0.2666008174419403, "metricx_score": 8.10122299194336, "metricx_qe_score": 7.021055698394775, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot aléatoire appartient à une tâche de classement par paires, il est ajouté au chemin avant et arrière via la dernière tête.", "metrics": {"bleu_score": 42.18427481900357, "chrf_score": 67.31419951416309, "xcomet_score": 0.6287747621536255, "xcomet_qe_score": 0.6600298881530762, "metricx_score": 9.3258056640625, "metricx_qe_score": 9.392969131469727, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, un tableau de jeux de données varie le nombre de classes.", "metrics": {"bleu_score": 39.375553105513404, "chrf_score": 65.1847575501719, "xcomet_score": 0.6984050869941711, "xcomet_qe_score": 0.601147472858429, "metricx_score": 9.949718475341797, "metricx_qe_score": 11.259522438049316, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a donc beaucoup de tâches.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7176141738891602, "metricx_qe_score": 0.8257766962051392, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "MTDN a conservé le nombre de chefs de classe dans les couches de sortie.", "metrics": {"bleu_score": 22.17387208793043, "chrf_score": 53.22494188995515, "xcomet_score": 0.3855263292789459, "xcomet_qe_score": 0.30883580446243286, "metricx_score": 9.901575088500977, "metricx_qe_score": 9.957093238830566, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, MTDN doit initialiser de nouvelles têtes pour un nouvel ensemble de données avec une nouvelle tâche.", "metrics": {"bleu_score": 49.030470692026626, "chrf_score": 74.97439182475838, "xcomet_score": 0.7897870540618896, "xcomet_qe_score": 0.7187458276748657, "metricx_score": 5.041070938110352, "metricx_qe_score": 6.0376811027526855, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche, appelée affinage par reformulation de tâche, consiste, au lieu de maintenir plusieurs têtes, à reformuler chaque ensemble de données en une phrase par problème de classification, ce qui correspond à des tâches à deux classes.", "metrics": {"bleu_score": 36.63950768236571, "chrf_score": 61.656171941039815, "xcomet_score": 0.5857596397399902, "xcomet_qe_score": 0.5779966115951538, "metricx_score": 3.659076690673828, "metricx_qe_score": 5.531994819641113, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple.", "metrics": {"bleu_score": 46.30777161991026, "chrf_score": 48.32474847235818, "xcomet_score": 0.9386066198348999, "xcomet_qe_score": 0.9773107767105103, "metricx_score": 0.2514381408691406, "metricx_qe_score": 0.34026220440864563, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre ensemble de données d'entrée, qui se compose d'entités, de caractéristiques, de texte et de classes.", "metrics": {"bleu_score": 38.75407750115177, "chrf_score": 64.16015151771236, "xcomet_score": 0.9720182418823242, "xcomet_qe_score": 0.9976086616516113, "metricx_score": 2.0105767250061035, "metricx_qe_score": 2.757319211959839, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous formulerons la tâche en classant le texte en bas et en haut pour classer le texte, l'abstrait et la classe en vrai ou faux.", "metrics": {"bleu_score": 46.6526707897875, "chrf_score": 61.107324666542986, "xcomet_score": 0.549079418182373, "xcomet_qe_score": 0.42285552620887756, "metricx_score": 5.79653263092041, "metricx_qe_score": 6.189865589141846, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous avons entraîné le modèle linguistique à classer l'abstrait et la classe comme abstrait et classe si l'abstrait appartenait ou non à la classe.", "metrics": {"bleu_score": 10.262212231189885, "chrf_score": 43.568502055393374, "xcomet_score": 0.5345107316970825, "xcomet_qe_score": 0.3398154079914093, "metricx_score": 6.13388204574585, "metricx_qe_score": 10.476956367492676, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le vecteur d'étiquette reste toujours le même, ce qui consiste toujours en deux classes.", "metrics": {"bleu_score": 41.180376356915765, "chrf_score": 72.77493133413215, "xcomet_score": 0.7852298617362976, "xcomet_qe_score": 0.7678843140602112, "metricx_score": 4.299830436706543, "metricx_qe_score": 5.226506233215332, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici l'algorithme de notre approche de réglage fin formulée.", "metrics": {"bleu_score": 7.805069386252457, "chrf_score": 46.388465139744824, "xcomet_score": 0.7349671721458435, "xcomet_qe_score": 0.7942308187484741, "metricx_score": 8.876639366149902, "metricx_qe_score": 9.455079078674316, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons donc le cadre complet.", "metrics": {"bleu_score": 53.7284965911771, "chrf_score": 81.9759249161167, "xcomet_score": 0.9789191484451294, "xcomet_qe_score": 0.9587022066116333, "metricx_score": 1.1847355365753174, "metricx_qe_score": 3.205934524536133, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "et le jeu de données s'estompe rapidement.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 25.14203128971706, "xcomet_score": 0.1126023530960083, "xcomet_qe_score": 0.0935119241476059, "metricx_score": 18.397357940673828, "metricx_qe_score": 16.630373001098633, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "Puis une phase rapide d'exécution du couplage d'entités.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 43.4590339025222, "xcomet_score": 0.5434883236885071, "xcomet_qe_score": 0.8340783715248108, "metricx_score": 10.419426918029785, "metricx_qe_score": 9.138790130615234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "Il extrait le texte de la base de connaissances, qui dans cet exemple est le résumé de la page Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9812904596328735, "xcomet_qe_score": 0.9507622718811035, "metricx_score": 1.6523830890655518, "metricx_qe_score": 2.673121929168701, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, il reformule la tâche en une phrase par tâche de classification.", "metrics": {"bleu_score": 27.756224165024996, "chrf_score": 67.56657489525301, "xcomet_score": 0.4927111268043518, "xcomet_qe_score": 0.5741708278656006, "metricx_score": 9.728302001953125, "metricx_qe_score": 8.853707313537598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "appliquez le modèle linguistique à la nouvelle tâche et à la probabilité de sortie pour chaque classe.", "metrics": {"bleu_score": 56.09383777282962, "chrf_score": 79.14586314901327, "xcomet_score": 0.6272528171539307, "xcomet_qe_score": 0.6064386367797852, "metricx_score": 5.203370571136475, "metricx_qe_score": 3.0030078887939453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "et notez que le modèle linguistique est déjà affiné sur un ensemble de données n-1 en utilisant un affinage préalable multitâche.", "metrics": {"bleu_score": 10.54135127219014, "chrf_score": 50.557051013075174, "xcomet_score": 0.6929858326911926, "xcomet_qe_score": 0.6926894783973694, "metricx_score": 3.0299460887908936, "metricx_qe_score": 3.8342370986938477, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous utilisons le vecteur de sortie du modèle linguistique comme une nouvelle caractéristique générée dans le nombre de classes.", "metrics": {"bleu_score": 67.40705509899853, "chrf_score": 77.82797724718824, "xcomet_score": 0.891135573387146, "xcomet_qe_score": 0.9339526891708374, "metricx_score": 3.8746848106384277, "metricx_qe_score": 5.268843650817871, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un ensemble de données de classification tabulaire de dix-sept exemples qui varient en taille, en caractéristiques, en équilibre, en domaine et en performance initiale.", "metrics": {"bleu_score": 36.79746482208511, "chrf_score": 80.1525056164803, "xcomet_score": 0.8434285521507263, "xcomet_qe_score": 0.6588465571403503, "metricx_score": 3.2941551208496094, "metricx_qe_score": 3.6583826541900635, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme base de connaissances, nous utilisons Wikipédia.", "metrics": {"bleu_score": 64.069143843707, "chrf_score": 82.77936370702274, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.31506168842315674, "metricx_qe_score": 0.3690527379512787, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concevons notre expérience comme une évaluation LiveOneOut lorsque nous entraînons rapidement plus de 16 ensembles de données et l'appliquons au 17e ensemble de données.", "metrics": {"bleu_score": 28.30789070123404, "chrf_score": 62.47050755609814, "xcomet_score": 0.24293719232082367, "xcomet_qe_score": 0.43201780319213867, "metricx_score": 10.199175834655762, "metricx_qe_score": 10.473761558532715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "Nous divisons également chaque ensemble de données en quatre défauts et appliquons une validation croisée à quatre défauts.", "metrics": {"bleu_score": 36.658827296012404, "chrf_score": 77.17710813558314, "xcomet_score": 0.5997856855392456, "xcomet_qe_score": 0.6011096239089966, "metricx_score": 10.156285285949707, "metricx_qe_score": 9.539617538452148, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous générons la nouvelle fonctionnalité et les évaluons à l'aide de cinq classificateurs d'évaluation.", "metrics": {"bleu_score": 35.23089031737454, "chrf_score": 74.96907095996136, "xcomet_score": 0.92185378074646, "xcomet_qe_score": 0.9126148819923401, "metricx_score": 2.8427164554595947, "metricx_qe_score": 4.1992387771606445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons dans notre expérience une architecture basée sur BERT.", "metrics": {"bleu_score": 8.68851996125416, "chrf_score": 36.028224074283024, "xcomet_score": 0.5403529405593872, "xcomet_qe_score": 0.8989875912666321, "metricx_score": 4.682814121246338, "metricx_qe_score": 1.7337007522583008, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre expérience.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 82.16212638893361, "xcomet_score": 0.9823514223098755, "xcomet_qe_score": 0.9937252998352051, "metricx_score": 0.3568568527698517, "metricx_qe_score": 0.5269936919212341, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "On peut voir que nous comparons notre cadre au réglage fin du jeu de données cible, au réglage fin de la tâche cible et au réglage fin préliminaire de MTDNN.", "metrics": {"bleu_score": 33.10670933889895, "chrf_score": 58.59802994501505, "xcomet_score": 0.6430913805961609, "xcomet_qe_score": 0.5884895324707031, "metricx_score": 5.366126537322998, "metricx_qe_score": 4.627584934234619, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "Et notre réglage fin reformulé a obtenu le meilleur résultat, la meilleure performance.", "metrics": {"bleu_score": 27.22589423069701, "chrf_score": 68.79523835097797, "xcomet_score": 0.849454402923584, "xcomet_qe_score": 0.8324892520904541, "metricx_score": 2.881743907928467, "metricx_qe_score": 3.918063163757324, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que MTDNN a obtenu une amélioration de 2 % par rapport à l'ajustement fin du jeu de données cible.", "metrics": {"bleu_score": 27.249745234058675, "chrf_score": 59.92053610258038, "xcomet_score": 0.7634662389755249, "xcomet_qe_score": 0.7737714052200317, "metricx_score": 4.546863079071045, "metricx_qe_score": 3.5425050258636475, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "Notre rendement a augmenté de six pour cent.", "metrics": {"bleu_score": 38.875142041440206, "chrf_score": 37.60566472012854, "xcomet_score": 0.8606078624725342, "xcomet_qe_score": 0.9336328506469727, "metricx_score": 4.87946891784668, "metricx_qe_score": 4.978270053863525, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous examinons le petit ensemble de données, nous pouvons voir que la performance de MTDNN diminue et que l'amélioration de la phase de réglage fin multitâche préliminaire diminue à 1,5 pour cent.", "metrics": {"bleu_score": 41.645706114025764, "chrf_score": 71.42042471790498, "xcomet_score": 0.9073532819747925, "xcomet_qe_score": 0.9089115858078003, "metricx_score": 4.108161926269531, "metricx_qe_score": 5.2786335945129395, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "Mais notre performance a augmenté à 11 % par rapport au réglage fin de la tâche cible seul.", "metrics": {"bleu_score": 39.67088290836578, "chrf_score": 59.5734129808527, "xcomet_score": 0.8378500938415527, "xcomet_qe_score": 0.8446800708770752, "metricx_score": 5.374772071838379, "metricx_qe_score": 7.307365417480469, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "Pour la sommation, FAST permet d'enrichir la vue de trente-cinq échantillons dans notre expérience.", "metrics": {"bleu_score": 15.094176936643688, "chrf_score": 50.2621515013473, "xcomet_score": 0.3281365633010864, "xcomet_qe_score": 0.3176317811012268, "metricx_score": 16.09038543701172, "metricx_qe_score": 14.05226993560791, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "Il utilise une seule architecture pour toutes les tâches et tous les ensembles de données.", "metrics": {"bleu_score": 41.69392927528885, "chrf_score": 83.89700221526849, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6135680675506592, "metricx_qe_score": 0.8140572905540466, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "Et il conserve la tête du modèle.", "metrics": {"bleu_score": 59.4603557501361, "chrf_score": 68.60498861472179, "xcomet_score": 0.9025007486343384, "xcomet_qe_score": 0.6470153331756592, "metricx_score": 3.7993338108062744, "metricx_qe_score": 6.2746782302856445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "Mais il ajoute trois phases de formulation.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 52.90795961727901, "xcomet_score": 0.48337867856025696, "xcomet_qe_score": 0.5773924589157104, "metricx_score": 6.802916049957275, "metricx_qe_score": 6.9669694900512695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'agit d'un ensemble de trains augmenté et il a besoin d'une valeur cible avec un sens sémantique afin que nous puissions l'introduire dans le modèle linguistique et l'utiliser dans le problème de classification des paires de phrases.", "metrics": {"bleu_score": 60.93516156211274, "chrf_score": 81.09077367235844, "xcomet_score": 0.6922029256820679, "xcomet_qe_score": 0.6880613565444946, "metricx_score": 6.520377159118652, "metricx_qe_score": 5.673673629760742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Merci.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10382990539073944, "metricx_qe_score": 0.4022793173789978, "linguapy_score": [1, "ITALIAN"]}}
