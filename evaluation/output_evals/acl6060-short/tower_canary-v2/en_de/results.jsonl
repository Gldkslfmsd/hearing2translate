{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen. Heute werde ich unsere Forschungsarbeit „Lernen, Probleme durch deduktive Netzwerklösung als komplexe Vernunftförderung zu lösen“ vorstellen.", "metrics": {"bleu_score": 28.55518364827566, "chrf_score": 50.48664678497813, "xcomet_score": 0.8422869443893433, "xcomet_qe_score": 0.8390427827835083, "metricx_score": 4.788208961486816, "metricx_qe_score": 6.421173572540283, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan vom Biden-KI-Labor und dies ist eine gemeinsame Arbeit mit Thierry von der Universität von Texas in Austin und Wayloo von SUDD.", "metrics": {"bleu_score": 31.823575336903108, "chrf_score": 64.87391930481039, "xcomet_score": 0.537166178226471, "xcomet_qe_score": 0.5431900024414062, "metricx_score": 9.812980651855469, "metricx_qe_score": 9.399792671203613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Schließen von Schlussfolgerungen sprechen.", "metrics": {"bleu_score": 61.153805769010226, "chrf_score": 76.7185803527244, "xcomet_score": 0.9879956245422363, "xcomet_qe_score": 0.990744411945343, "metricx_score": 3.5838305950164795, "metricx_qe_score": 3.219996452331543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Denken hilfreich ist.", "metrics": {"bleu_score": 16.21599014882373, "chrf_score": 55.986797401068664, "xcomet_score": 0.986242949962616, "xcomet_qe_score": 0.9959239959716797, "metricx_score": 0.2947690188884735, "metricx_qe_score": 0.27105236053466797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung stammt aus dem PALM-Papier, in dem sie Aufforderungen (prompts) verwenden, um das Mathwork-Problem in einem Fusion-Lern-Szenario zu lösen.", "metrics": {"bleu_score": 34.46568573681592, "chrf_score": 62.42995924681588, "xcomet_score": 0.7531041502952576, "xcomet_qe_score": 0.7898129224777222, "metricx_score": 6.681075572967529, "metricx_qe_score": 6.659747123718262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der linken Seite können wir sehen, dass wir möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten, wenn wir nur Beispiele mit Fragen und Antworten geben.", "metrics": {"bleu_score": 24.90784951946792, "chrf_score": 62.38395416705792, "xcomet_score": 0.9731227159500122, "xcomet_qe_score": 0.9771426320075989, "metricx_score": 0.668938159942627, "metricx_qe_score": 0.6014822125434875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir eine etwas ausführlichere Beschreibung des Schlussfolgerungsprozesses liefern, kann das Modell diese Beschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen.", "metrics": {"bleu_score": 8.880232502431426, "chrf_score": 48.02640976512747, "xcomet_score": 0.9980164766311646, "xcomet_qe_score": 0.9989877939224243, "metricx_score": 0.2724156677722931, "metricx_qe_score": 0.3460843563079834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es gut, interpretierbare mehrstufige Argumente als Ergebnis zu haben.", "metrics": {"bleu_score": 35.24025452531097, "chrf_score": 72.3983535668277, "xcomet_score": 0.9876559376716614, "xcomet_qe_score": 0.9739141464233398, "metricx_score": 0.5474210381507874, "metricx_qe_score": 0.7931287884712219, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir denken auch, dass Mathwork Problem eine einfache Anwendung ist, um solche Denkfähigkeiten zu bewerten.", "metrics": {"bleu_score": 28.160490429440994, "chrf_score": 62.04238555793305, "xcomet_score": 0.8679882287979126, "xcomet_qe_score": 0.8559107184410095, "metricx_score": 6.268372535705566, "metricx_qe_score": 5.850069046020508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Also hier in unserer Problemstellung, gegeben die Fragen, müssen wir diese Frage lösen und die numerischen Antworten erhalten.", "metrics": {"bleu_score": 42.155030936737305, "chrf_score": 69.07694404794913, "xcomet_score": 0.9656219482421875, "xcomet_qe_score": 0.9515513181686401, "metricx_score": 1.250336766242981, "metricx_qe_score": 1.3719356060028076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck mitgeliefert, der zu dieser bestimmten Antwort führt.", "metrics": {"bleu_score": 36.658827296012404, "chrf_score": 73.94919297563585, "xcomet_score": 0.9937454462051392, "xcomet_qe_score": 0.9931477308273315, "metricx_score": 1.5914438962936401, "metricx_qe_score": 2.6860313415527344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten.", "metrics": {"bleu_score": 55.70438815301074, "chrf_score": 77.83370476158633, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.9207534193992615, "metricx_qe_score": 1.0926321744918823, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass die Genauigkeit der Mengen bekannt ist.", "metrics": {"bleu_score": 67.09489882833027, "chrf_score": 75.51244970553542, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3594503402709961, "metricx_qe_score": 0.4582980275154114, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponentialfunktion.", "metrics": {"bleu_score": 88.43946454355333, "chrf_score": 92.45512886074718, "xcomet_score": 0.9999830722808838, "xcomet_qe_score": 1.0, "metricx_score": 0.4685169756412506, "metricx_qe_score": 0.6687296032905579, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese Basiseratoren zerlegt werden.", "metrics": {"bleu_score": 46.59538415189962, "chrf_score": 81.80422813319804, "xcomet_score": 0.9681638479232788, "xcomet_qe_score": 0.970799446105957, "metricx_score": 1.9439005851745605, "metricx_qe_score": 1.446823000907898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "So lassen sich frühere Arbeiten zur Methodenentwicklung zur Problemlösung tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baum-Modelle einteilen.", "metrics": {"bleu_score": 12.996186443727149, "chrf_score": 63.34238440659152, "xcomet_score": 0.9232358932495117, "xcomet_qe_score": 0.804806113243103, "metricx_score": 3.4942691326141357, "metricx_qe_score": 4.341549396514893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Ein traditionelles Sequenz-zu-Sequenz-Modell wandelt den Ausdruck in eine spezifische Sequenz für die Generierung um.", "metrics": {"bleu_score": 70.04517017457536, "chrf_score": 89.12752887935231, "xcomet_score": 0.9681763648986816, "xcomet_qe_score": 0.8920006155967712, "metricx_score": 0.40592655539512634, "metricx_qe_score": 0.5986844897270203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist ziemlich einfach zu implementieren und es kann auf viele verschiedene komplizierte Probleme verallgemeinert werden.", "metrics": {"bleu_score": 60.28817681965138, "chrf_score": 90.60331005062393, "xcomet_score": 0.9946746826171875, "xcomet_qe_score": 0.9855858087539673, "metricx_score": 0.2018919736146927, "metricx_qe_score": 0.2235337197780609, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Nachteile sind, dass die Leistung tatsächlich im Allgemeinen nicht besser ist als das Strukturmodell und dass die Interpretierbarkeit für Vorhersagen fehlt.", "metrics": {"bleu_score": 35.15233830455837, "chrf_score": 70.38220148990597, "xcomet_score": 0.9672523140907288, "xcomet_qe_score": 0.9740756154060364, "metricx_score": 0.6671372652053833, "metricx_qe_score": 0.9046380519866943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Richtung aufgrund des Transformer-Modells immer noch ziemlich beliebt.", "metrics": {"bleu_score": 36.362270465000705, "chrf_score": 71.46287182780632, "xcomet_score": 0.993114709854126, "xcomet_qe_score": 0.9854347705841064, "metricx_score": 0.8096921443939209, "metricx_qe_score": 1.5173392295837402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumgestützten Modellen strukturieren wir diese Ausdrücke tatsächlich in einer Baumform und folgen einer vorrangigen Durchmusterung bei der Baumgenerierung.", "metrics": {"bleu_score": 25.958657290343428, "chrf_score": 64.3665566020959, "xcomet_score": 0.9226542711257935, "xcomet_qe_score": 0.9254331588745117, "metricx_score": 2.897857904434204, "metricx_qe_score": 2.1560022830963135, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also weiterhin die Operatoren, bis wir die Blätter erreichen, die die Mengen darstellen.", "metrics": {"bleu_score": 58.068035053871284, "chrf_score": 77.01097019929338, "xcomet_score": 0.9865514039993286, "xcomet_qe_score": 0.9703897833824158, "metricx_score": 0.777895987033844, "metricx_qe_score": 1.2348867654800415, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute daran ist also, dass es uns diese binäre Baumstruktur liefert. Aber eigentlich ist es ziemlich kontraintuitiv, weil wir zuerst den Operator generieren und dann am Ende die Größen.", "metrics": {"bleu_score": 44.60616097899725, "chrf_score": 71.42842108897007, "xcomet_score": 0.9838472604751587, "xcomet_qe_score": 0.96638023853302, "metricx_score": 1.7777749300003052, "metricx_qe_score": 2.536311626434326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und die zweite Sache ist, dass es auch einige repetitive Berechnungen enthält.", "metrics": {"bleu_score": 7.141816289329644, "chrf_score": 47.727223318293795, "xcomet_score": 0.9655945301055908, "xcomet_qe_score": 0.9763085842132568, "metricx_score": 0.7164250612258911, "metricx_qe_score": 0.46059226989746094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck ansehen, wird acht mal drei plus drei tatsächlich zweimal generiert. Aber in Wirklichkeit sollten wir die Ergebnisse wiederverwenden.", "metrics": {"bleu_score": 48.632987321455005, "chrf_score": 76.17692075700876, "xcomet_score": 0.9989273548126221, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3871559202671051, "metricx_qe_score": 0.5225529670715332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Lösungsansatz möchten wir diese Probleme daher schrittweise und nachvollziehbar lösen.", "metrics": {"bleu_score": 13.98901826745798, "chrf_score": 47.61743114302095, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.34688055515289307, "metricx_qe_score": 0.11293022334575653, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "So können wir hier im zweiten Schritt beispielsweise diesen Divisor erhalten, der 27 ist.", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 56.983655608470166, "xcomet_score": 0.8876749873161316, "xcomet_qe_score": 0.9265271425247192, "metricx_score": 1.8557639122009277, "metricx_qe_score": 1.5365667343139648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um die relevanten Inhalte zu finden.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2288219928741455, "metricx_qe_score": 0.19367283582687378, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler.", "metrics": {"bleu_score": 72.59795291154772, "chrf_score": 95.55813636296386, "xcomet_score": 0.9975470304489136, "xcomet_qe_score": 0.9964474439620972, "metricx_score": 0.46138083934783936, "metricx_qe_score": 1.0272918939590454, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann, in diesem dritten Schritt, erhalten wir tatsächlich den Quotienten.", "metrics": {"bleu_score": 30.130404892785695, "chrf_score": 77.57371222673193, "xcomet_score": 0.998979926109314, "xcomet_qe_score": 0.9933691024780273, "metricx_score": 1.105760097503662, "metricx_qe_score": 1.6389633417129517, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Alles klar. Und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schrittes tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schrittes erhalten. Und schließlich können wir die Dividenden erhalten.", "metrics": {"bleu_score": 42.774464413593606, "chrf_score": 84.51674276127545, "xcomet_score": 0.988766074180603, "xcomet_qe_score": 0.9753909111022949, "metricx_score": 1.1573642492294312, "metricx_qe_score": 1.6349034309387207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Mengen zu erzeugen.", "metrics": {"bleu_score": 5.653041175801492, "chrf_score": 45.91049218852022, "xcomet_score": 0.9850688576698303, "xcomet_qe_score": 0.9840775728225708, "metricx_score": 0.6811023950576782, "metricx_qe_score": 1.1171298027038574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Das macht den Prozess genauer.", "metrics": {"bleu_score": 30.213753973567677, "chrf_score": 53.38238387625975, "xcomet_score": 0.9950906038284302, "xcomet_qe_score": 0.977350115776062, "metricx_score": 0.31846505403518677, "metricx_qe_score": 0.9903241395950317, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen präsentiert werden, und die auch einige Konstanten als unseren Ausgangszustand umfassen.", "metrics": {"bleu_score": 53.13915267239368, "chrf_score": 70.86349816837499, "xcomet_score": 0.9718585014343262, "xcomet_qe_score": 0.9730559587478638, "metricx_score": 1.7492811679840088, "metricx_qe_score": 2.1929426193237305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt.", "metrics": {"bleu_score": 36.06452879987793, "chrf_score": 80.28357106983552, "xcomet_score": 0.9844173192977905, "xcomet_qe_score": 0.9895853400230408, "metricx_score": 1.127659559249878, "metricx_qe_score": 2.294699192047119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "wo wir Operatoren von Qi bis Qj ausführen und ein solcher Ausdruck tatsächlich gerichtet ist.", "metrics": {"bleu_score": 2.8003037119445366, "chrf_score": 48.26444507444547, "xcomet_score": 0.8924214839935303, "xcomet_qe_score": 0.9302957057952881, "metricx_score": 2.272749423980713, "metricx_qe_score": 2.3510727882385254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben hier also auch Subtraktionswörter, um die entgegengesetzte Richtung darzustellen.", "metrics": {"bleu_score": 37.78066027750078, "chrf_score": 67.8391901332774, "xcomet_score": 0.9794484376907349, "xcomet_qe_score": 0.9207577109336853, "metricx_score": 0.8489255905151367, "metricx_qe_score": 0.9322788715362549, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie die Strahlenextraktion.", "metrics": {"bleu_score": 7.267884212102741, "chrf_score": 40.89767608334347, "xcomet_score": 0.8444095849990845, "xcomet_qe_score": 0.8458289504051208, "metricx_score": 6.101365089416504, "metricx_qe_score": 5.18652868270874, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formalen deduktiven System wenden wir zum Zeitpunkt t den Operator auf das Paar Qi und Qj an und erhalten dann diese neuen Ausdrücke.", "metrics": {"bleu_score": 30.601758484756367, "chrf_score": 65.57859787553369, "xcomet_score": 0.9605951905250549, "xcomet_qe_score": 0.9697924852371216, "metricx_score": 0.9773550033569336, "metricx_qe_score": 1.7684406042099, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen sie dem nächsten Zustand hinzu, um eine neue Größe zu werden.", "metrics": {"bleu_score": 54.451788461394045, "chrf_score": 68.28266996004608, "xcomet_score": 0.9115155935287476, "xcomet_qe_score": 0.9588823914527893, "metricx_score": 2.678921699523926, "metricx_qe_score": 2.5968291759490967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folie veranschaulicht also die Entwicklung des Zustands, bei dem wir dem aktuellen Zustand ständig Ausdrücke hinzufügen.", "metrics": {"bleu_score": 45.307778036928106, "chrf_score": 77.66445125558255, "xcomet_score": 0.9825006127357483, "xcomet_qe_score": 0.9246337413787842, "metricx_score": 0.8554598689079285, "metricx_qe_score": 1.551713466644287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modelimplementierungen verwenden wir zunächst ein vorgefertigtes Sprachmodell, das Vögel oder Roboter sein kann, kodieren dann einen Satz und erhalten diese Mengenrepräsentationen.", "metrics": {"bleu_score": 12.859070457371294, "chrf_score": 61.70654215757345, "xcomet_score": 0.8139516115188599, "xcomet_qe_score": 0.8046625256538391, "metricx_score": 5.812229633331299, "metricx_qe_score": 6.377471923828125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengenrepräsentationen erhalten haben, können wir mit der Inferenz beginnen.", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 80.11342334668107, "xcomet_score": 0.9894499778747559, "xcomet_qe_score": 0.9962592124938965, "metricx_score": 1.265170931816101, "metricx_qe_score": 5.284395694732666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q eins, um die Darstellung für Q eins zu erhalten. Sie werden durch Q zwei geteilt und dann mit Q vier multipliziert.", "metrics": {"bleu_score": 32.70534171825076, "chrf_score": 65.83052586462152, "xcomet_score": 0.7504158020019531, "xcomet_qe_score": 0.8093545436859131, "metricx_score": 8.358489036560059, "metricx_qe_score": 8.601024627685547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paarrepräsentation, die im Grunde genommen nur die Verkettung zwischen Q1 und Q2 ist. Und dann wenden wir ein Feedforward-Netzwerk an, das durch den Operator parametrisiert ist.", "metrics": {"bleu_score": 53.033171484560874, "chrf_score": 79.2434965550873, "xcomet_score": 0.9769686460494995, "xcomet_qe_score": 0.9100092053413391, "metricx_score": 1.782541275024414, "metricx_qe_score": 2.480076551437378, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksdarstellung Q1 geteilt durch Q2.", "metrics": {"bleu_score": 9.119700296511436, "chrf_score": 73.27706161929275, "xcomet_score": 0.9956886768341064, "xcomet_qe_score": 0.9830245971679688, "metricx_score": 0.49059343338012695, "metricx_qe_score": 0.8244310617446899, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis könnten wir in der Inferenzphase auch den falschen Ausdruck erhalten.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.999748945236206, "xcomet_qe_score": 0.9983681440353394, "metricx_score": 1.0329139232635498, "metricx_qe_score": 1.7124707698822021, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Somit ist hier der gesamte mögliche Ausdruck gleich drei Mal der Anzahl der Operatoren.", "metrics": {"bleu_score": 25.748661016289674, "chrf_score": 52.7444725734979, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3662348985671997, "metricx_qe_score": 1.5703243017196655, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir problemlos Einschränkungen hinzufügen können, um diesen Suchraum zu kontrollieren.", "metrics": {"bleu_score": 83.94327083733333, "chrf_score": 90.51905160562616, "xcomet_score": 0.9895412921905518, "xcomet_qe_score": 0.9804093837738037, "metricx_score": 0.7070599794387817, "metricx_qe_score": 0.9419331550598145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck zum Beispiel nicht erlaubt ist, können wir diesen Ausdruck einfach aus unserem Suchraum entfernen.", "metrics": {"bleu_score": 79.12619863720215, "chrf_score": 91.91935873447683, "xcomet_score": 0.9946538209915161, "xcomet_qe_score": 0.9921896457672119, "metricx_score": 0.6625986099243164, "metricx_qe_score": 0.9155831336975098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir dasselbe, aber der einzige Unterschied ist, dass wir eine weitere Menge haben.", "metrics": {"bleu_score": 57.315324705343166, "chrf_score": 78.13303465287163, "xcomet_score": 0.9531323909759521, "xcomet_qe_score": 0.9206116199493408, "metricx_score": 2.4306693077087402, "metricx_qe_score": 4.035942554473877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Menge stammt aus dem vorherigen berechneten Ausdruck.", "metrics": {"bleu_score": 66.90484408935988, "chrf_score": 90.6651605090456, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5240357518196106, "metricx_qe_score": 1.7341002225875854, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Und so können wir schließlich diesen endgültigen Ausdruck Q dreizehn erhalten.", "metrics": {"bleu_score": 33.62301724861857, "chrf_score": 79.1507493274328, "xcomet_score": 0.845206618309021, "xcomet_qe_score": 0.8495268225669861, "metricx_score": 7.89273738861084, "metricx_qe_score": 10.854336738586426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "dreimal Q vier. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke sich vom vorherigen Schritt unterscheidet.", "metrics": {"bleu_score": 45.12595975949003, "chrf_score": 78.31494372750588, "xcomet_score": 0.863202691078186, "xcomet_qe_score": 0.8077018857002258, "metricx_score": 10.313112258911133, "metricx_qe_score": 13.310973167419434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Daher erschweren solche Unterschiede die Anwendung der Beam Search, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgewogen ist.", "metrics": {"bleu_score": 62.33986310585777, "chrf_score": 86.85095675804986, "xcomet_score": 0.9234901070594788, "xcomet_qe_score": 0.9045683145523071, "metricx_score": 1.6121025085449219, "metricx_qe_score": 2.888383388519287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Das Training erfolgt also ähnlich wie bei einem Sequenz-zu-Sequenz-Modell, bei dem der Verlust in jedem Zeitschritt optimiert wird.", "metrics": {"bleu_score": 11.986062961075742, "chrf_score": 64.88745314222683, "xcomet_score": 0.9586124420166016, "xcomet_qe_score": 0.9207205176353455, "metricx_score": 0.47642016410827637, "metricx_qe_score": 0.7175843119621277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir dieses Tau auch, um darzustellen, wann wir diesen Generierungsprozess beenden sollten.", "metrics": {"bleu_score": 77.7811122305422, "chrf_score": 93.16890559489094, "xcomet_score": 0.9863818883895874, "xcomet_qe_score": 0.9747627973556519, "metricx_score": 0.6836692094802856, "metricx_qe_score": 1.0776443481445312, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz unterschiedlich, weil der Raum jedes Mal anders ist, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl der Vokabeln ist.", "metrics": {"bleu_score": 38.31514777195514, "chrf_score": 70.44377600681523, "xcomet_score": 0.9224405884742737, "xcomet_qe_score": 0.9127443432807922, "metricx_score": 1.9909183979034424, "metricx_qe_score": 4.1327033042907715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht uns auch, bestimmte Einschränkungen aufgrund von Vorwissen aufzuerlegen.", "metrics": {"bleu_score": 27.968424579665367, "chrf_score": 71.67160707664709, "xcomet_score": 0.9803454875946045, "xcomet_qe_score": 0.974533200263977, "metricx_score": 0.6423646807670593, "metricx_qe_score": 1.0084218978881836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Daher führen wir Experimente an den häufig verwendeten Methode-Problem-Datensätzen MAWPS, Math 23K, MathQA und SWAM durch.", "metrics": {"bleu_score": 22.495618488663066, "chrf_score": 67.18890565461277, "xcomet_score": 0.8420844674110413, "xcomet_qe_score": 0.8365577459335327, "metricx_score": 4.474799156188965, "metricx_qe_score": 4.887811183929443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den bisherigen besten Ansätzen.", "metrics": {"bleu_score": 85.07331335123531, "chrf_score": 97.6831168834807, "xcomet_score": 0.9915759563446045, "xcomet_qe_score": 0.9877573251724243, "metricx_score": 0.2909244894981384, "metricx_qe_score": 0.3001486659049988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere am besten performende Variante ist der Roberta Dedative Reasoner.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 49.61488482664932, "xcomet_score": 0.980056881904602, "xcomet_qe_score": 0.9797323942184448, "metricx_score": 1.4454708099365234, "metricx_qe_score": 2.154304265975952, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir im Gegensatz zu offensichtlichen Ansätzen, die Beam Search verwenden, keine Beam Search.", "metrics": {"bleu_score": 32.92888954242705, "chrf_score": 74.24528216790728, "xcomet_score": 0.8453670144081116, "xcomet_qe_score": 0.6983842849731445, "metricx_score": 5.030881881713867, "metricx_qe_score": 6.515745162963867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung. Die besten Ansätze sind daher oft ein baumbasiertes Modell.", "metrics": {"bleu_score": 8.130850857597444, "chrf_score": 60.17250321084001, "xcomet_score": 0.982223391532898, "xcomet_qe_score": 0.983550488948822, "metricx_score": 0.3999265730381012, "metricx_qe_score": 0.6382936835289001, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Schlussfolgerungsalgorithmus dieses baumgestützte Modell deutlich übertreffen.", "metrics": {"bleu_score": 6.061512325492642, "chrf_score": 43.57267316558383, "xcomet_score": 0.9497859477996826, "xcomet_qe_score": 0.9302561283111572, "metricx_score": 1.047020673751831, "metricx_qe_score": 0.9761191606521606, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen bei Math QA oder SWAM nicht wirklich hoch sind.", "metrics": {"bleu_score": 68.59238121837059, "chrf_score": 92.52397746158168, "xcomet_score": 0.9404298067092896, "xcomet_qe_score": 0.932187557220459, "metricx_score": 0.8497641086578369, "metricx_qe_score": 0.9492654800415039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Daher untersuchen wir die Ergebnisse vor Ort weiter.", "metrics": {"bleu_score": 35.49481056010054, "chrf_score": 64.64942423600574, "xcomet_score": 0.907302975654602, "xcomet_qe_score": 0.8809858560562134, "metricx_score": 2.6568868160247803, "metricx_qe_score": 4.605034351348877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Sumpf. Und dieser Datensatz ist herausfordernd, weil der Autor versucht hat, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie das Hinzufügen irrelevanter Informationen und zusätzlicher Mengen.", "metrics": {"bleu_score": 71.05425273104096, "chrf_score": 88.85521250410653, "xcomet_score": 0.8147966861724854, "xcomet_qe_score": 0.7909848093986511, "metricx_score": 6.366765975952148, "metricx_qe_score": 7.079122066497803, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Vorhersage stellen wir also fest, dass einige der Zwischenschritte tatsächlich negative Werte aufweisen.", "metrics": {"bleu_score": 62.36362995619313, "chrf_score": 79.24370378481665, "xcomet_score": 0.9368633031845093, "xcomet_qe_score": 0.931307315826416, "metricx_score": 1.5691273212432861, "metricx_qe_score": 1.214379072189331, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in dieser Frage, wie viele Äpfel Jake hat.", "metrics": {"bleu_score": 45.74563333993254, "chrf_score": 66.38851494416554, "xcomet_score": 0.9391733407974243, "xcomet_qe_score": 0.9326760768890381, "metricx_score": 0.8350750207901001, "metricx_qe_score": 0.7855211496353149, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Pitches, und Stephen hat acht Pitches, was völlig irrelevant ist.", "metrics": {"bleu_score": 46.997395980026965, "chrf_score": 73.40992066665967, "xcomet_score": 0.8293428421020508, "xcomet_qe_score": 0.8306050300598145, "metricx_score": 5.977339267730713, "metricx_qe_score": 5.068778038024902, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine Vorhersage wie diese, die negative Werte produziert.", "metrics": {"bleu_score": 85.5526185871245, "chrf_score": 89.61492330592665, "xcomet_score": 0.9857891798019409, "xcomet_qe_score": 0.9767706394195557, "metricx_score": 0.8259428143501282, "metricx_qe_score": 0.9031760096549988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke.", "metrics": {"bleu_score": 11.147892272337163, "chrf_score": 33.87680096462581, "xcomet_score": 0.7297190427780151, "xcomet_qe_score": 0.8604840636253357, "metricx_score": 6.011697769165039, "metricx_qe_score": 13.461858749389648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum also tatsächlich einschränken, indem wir solche Ergebnisse entfernen, die negativ sind, damit wir die Antwort richtig machen können.", "metrics": {"bleu_score": 16.327584367534385, "chrf_score": 69.96166327571213, "xcomet_score": 0.9405879974365234, "xcomet_qe_score": 0.8957418203353882, "metricx_score": 2.3067591190338135, "metricx_qe_score": 2.796703338623047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen außerdem fest, dass eine solche Einschränkung bei einigen Modellen tatsächlich zu einer erheblichen Verbesserung führt.", "metrics": {"bleu_score": 23.83041256525615, "chrf_score": 61.77685468856657, "xcomet_score": 0.9896655082702637, "xcomet_qe_score": 0.9792482852935791, "metricx_score": 0.581524670124054, "metricx_qe_score": 0.6082695126533508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei den Vögeln sieben Punkte verbessert. Und dann haben wir beim Roberta-Basismodell tatsächlich zwei Punkte verbessert.", "metrics": {"bleu_score": 19.98654694704214, "chrf_score": 68.26540621789071, "xcomet_score": 0.7921450138092041, "xcomet_qe_score": 0.8369373679161072, "metricx_score": 8.972548484802246, "metricx_qe_score": 8.6510009765625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat bessere Sprachverständnisfähigkeiten, sodass die Zahl hier für Roberta höher und für Bertha niedriger ist.", "metrics": {"bleu_score": 45.24163186821073, "chrf_score": 76.64271284213474, "xcomet_score": 0.9356439113616943, "xcomet_qe_score": 0.9345595836639404, "metricx_score": 1.6043663024902344, "metricx_qe_score": 2.611762762069702, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 66.69930586829759, "xcomet_score": 0.7862759828567505, "xcomet_qe_score": 0.7623720765113831, "metricx_score": 5.309876441955566, "metricx_qe_score": 7.541841983795166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information betrachtet werden kann.", "metrics": {"bleu_score": 62.947717160248736, "chrf_score": 84.17764605695129, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3106567859649658, "metricx_qe_score": 0.33078187704086304, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben und der Sumpf-Datensatz den größten Anteil hat.", "metrics": {"bleu_score": 53.49281915649842, "chrf_score": 77.66632150794375, "xcomet_score": 0.800133466720581, "xcomet_qe_score": 0.7716478109359741, "metricx_score": 4.431410789489746, "metricx_qe_score": 4.393261909484863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung.", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 95.153554655332, "xcomet_score": 0.9975186586380005, "xcomet_qe_score": 0.9953868389129639, "metricx_score": 0.17540127038955688, "metricx_qe_score": 0.28346192836761475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Bei den Proben ohne ungenutzte Mengen ist die Gesamtleistung tatsächlich höher als die tatsächliche Leistung.", "metrics": {"bleu_score": 57.87331539911485, "chrf_score": 83.31198459215295, "xcomet_score": 0.7844251394271851, "xcomet_qe_score": 0.6250734329223633, "metricx_score": 3.856468439102173, "metricx_qe_score": 4.782343864440918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben mit der ungenutzten Menge ist es tatsächlich viel schlimmer als, ähm, viel schlimmer als.", "metrics": {"bleu_score": 20.217803037339237, "chrf_score": 56.97725905933139, "xcomet_score": 0.8017451167106628, "xcomet_qe_score": 0.8235229849815369, "metricx_score": 8.845998764038086, "metricx_qe_score": 8.142240524291992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Schlechte Leistung. Bei MAWPS haben wir nicht wirklich zu viele Schreibtischfälle, daher ignoriere ich diesen Teil einfach.", "metrics": {"bleu_score": 49.030470692026626, "chrf_score": 75.05185618394286, "xcomet_score": 0.7107771039009094, "xcomet_qe_score": 0.6238955855369568, "metricx_score": 6.243983745574951, "metricx_qe_score": 7.019936561584473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Zum Schluss möchten wir die Interpretierbarkeit anhand eines Beispiels zur Fragebeteiligung veranschaulichen.", "metrics": {"bleu_score": 30.26643726685862, "chrf_score": 62.37239802054317, "xcomet_score": 0.8443458080291748, "xcomet_qe_score": 0.8299855589866638, "metricx_score": 3.880535125732422, "metricx_qe_score": 4.15089750289917, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Hier macht unser Modell also tatsächlich im ersten Schritt eine falsche Vorhersage.", "metrics": {"bleu_score": 59.18821883387651, "chrf_score": 91.4722764404711, "xcomet_score": 0.9996235370635986, "xcomet_qe_score": 0.9887526035308838, "metricx_score": 0.18725332617759705, "metricx_qe_score": 0.28759485483169556, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier in Verbindung bringen, richtig?", "metrics": {"bleu_score": 58.282339541526554, "chrf_score": 74.14869870292813, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.632936954498291, "metricx_qe_score": 0.534858226776123, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben daher, dass dieser Satz das Modell zu einer falschen Vorhersage verleiten könnte.", "metrics": {"bleu_score": 47.92365811426397, "chrf_score": 75.20665452469345, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.21269065141677856, "metricx_qe_score": 0.23636576533317566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man also hier weitere fünfunddreißig einpflanzt, führt das Modell zu der Annahme, dass es sich um eine Addition von Operatoren handelt.", "metrics": {"bleu_score": 8.383924775392588, "chrf_score": 41.558985733508926, "xcomet_score": 0.7908862233161926, "xcomet_qe_score": 0.7576378583908081, "metricx_score": 6.337822437286377, "metricx_qe_score": 5.285254001617432, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz so zu überarbeiten, dass er ungefähr so lautet: Die Anzahl der Birnbäume ist fünfundfünfzig weniger als die der Apfelbäume.", "metrics": {"bleu_score": 26.369556222377263, "chrf_score": 68.71680917573427, "xcomet_score": 0.9852981567382812, "xcomet_qe_score": 0.9761420488357544, "metricx_score": 1.1191613674163818, "metricx_qe_score": 1.107460856437683, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb sorgen wir dafür, dass die Semantik genauer vermittelt wird, sodass das Modell die Vorhersage korrekt treffen kann.", "metrics": {"bleu_score": 28.88593649410969, "chrf_score": 66.17320536764741, "xcomet_score": 0.9871047735214233, "xcomet_qe_score": 0.9768804311752319, "metricx_score": 0.7120528221130371, "metricx_qe_score": 1.02213454246521, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt also, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen.", "metrics": {"bleu_score": 72.13989879855205, "chrf_score": 92.34032208451053, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.49593037366867065, "metricx_qe_score": 0.6270440220832825, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, so ist zunächst unser Modell tatsächlich ziemlich effizient.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 89.61043306105663, "xcomet_score": 0.9739148020744324, "xcomet_qe_score": 0.9458500146865845, "metricx_score": 0.5305981040000916, "metricx_qe_score": 0.7917218804359436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "und wir sind in der Lage, ein interpretierbares Lösungsverfahren bereitzustellen.", "metrics": {"bleu_score": 63.15552371794033, "chrf_score": 82.26594593526863, "xcomet_score": 0.9907824993133545, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.35411617159843445, "metricx_qe_score": 0.37891367077827454, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können problemlos vorhandenes Wissen als Einschränkung einbeziehen, was die Leistung verbessern kann.", "metrics": {"bleu_score": 12.09431425432932, "chrf_score": 48.35575944125875, "xcomet_score": 0.9964690208435059, "xcomet_qe_score": 0.9884474873542786, "metricx_score": 1.1920850276947021, "metricx_qe_score": 0.9588064551353455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerklösaufgaben anwendbar ist, sondern auch auf andere Aufgaben, die mehrstufiges Denken erfordern.", "metrics": {"bleu_score": 22.894156860669913, "chrf_score": 62.45535171797562, "xcomet_score": 0.9760881662368774, "xcomet_qe_score": 0.9756455421447754, "metricx_score": 0.8217143416404724, "metricx_qe_score": 0.8356620073318481, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch gewisse Einschränkungen.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 27.78342294558877, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4435056149959564, "metricx_qe_score": 0.46961158514022827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und die zweite Sache ist, wie bereits erwähnt, dass es aufgrund der ungleichmäßigen Wahrscheinlichkeitsverteilung über verschiedene Zeitschritte hinweg ziemlich schwierig ist, Strahlsuchverfahren anzuwenden.", "metrics": {"bleu_score": 5.594147299480393, "chrf_score": 56.733769193837226, "xcomet_score": 0.9519944190979004, "xcomet_qe_score": 0.9586469531059265, "metricx_score": 1.1483701467514038, "metricx_qe_score": 0.8283216953277588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das war's dann auch schon mit dem Vortrag, und Fragen sind willkommen. Vielen Dank.", "metrics": {"bleu_score": 10.123734869668828, "chrf_score": 39.84217824615072, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.38633492588996887, "metricx_qe_score": 0.2567053735256195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Universität Maastricht.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 89.89040636842799, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07355811446905136, "metricx_qe_score": 0.018026236444711685, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine John-Arbeit mit Jerry präsentieren, die sich auf einen neuen Datensatz für die Gesetzesartikelabfrage bezieht.", "metrics": {"bleu_score": 17.401517708317762, "chrf_score": 55.891614575246976, "xcomet_score": 0.8751260042190552, "xcomet_qe_score": 0.824219822883606, "metricx_score": 6.324711799621582, "metricx_qe_score": 6.784874439239502, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtliche Fragen sind ein fester Bestandteil des Lebens vieler Menschen.", "metrics": {"bleu_score": 51.93071778680675, "chrf_score": 80.02423853964953, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.12561479210853577, "metricx_qe_score": 0.2410045564174652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Die Mehrheit der Bürger hat jedoch wenig bis kein Wissen über ihre Rechte und grundlegende rechtliche Verfahren.", "metrics": {"bleu_score": 53.989956849868726, "chrf_score": 76.13606575907788, "xcomet_score": 0.9977470636367798, "xcomet_qe_score": 0.998329758644104, "metricx_score": 0.37373673915863037, "metricx_qe_score": 0.4722508192062378, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Infolgedessen bleiben viele schutzbedürftige Bürger, die sich die kostspielige Hilfe eines Rechtsberaters nicht leisten können, ungeschützt oder werden sogar ausgebeutet.", "metrics": {"bleu_score": 43.550627085651314, "chrf_score": 66.10879283166386, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.33965596556663513, "metricx_qe_score": 0.3246442973613739, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Kluft zwischen den Menschen und dem Gesetz zu überbrücken, indem wir ein effektives Abrufsystem für Gesetzesartikel entwickeln.", "metrics": {"bleu_score": 73.52923728444678, "chrf_score": 86.27609983440121, "xcomet_score": 0.999346137046814, "xcomet_qe_score": 1.0, "metricx_score": 0.6910345554351807, "metricx_qe_score": 0.42843374609947205, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen professionellen Rechtshilfsdienst für ungelernte Menschen bereitstellen.", "metrics": {"bleu_score": 51.424016050282624, "chrf_score": 79.2533699098534, "xcomet_score": 0.9722024202346802, "xcomet_qe_score": 0.9760989546775818, "metricx_score": 0.24687537550926208, "metricx_qe_score": 0.14615485072135925, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem des gesetzlichen Artikelabrufs.", "metrics": {"bleu_score": 38.14127542721386, "chrf_score": 65.60114247324701, "xcomet_score": 0.969606876373291, "xcomet_qe_score": 0.9752712249755859, "metricx_score": 1.2604432106018066, "metricx_qe_score": 1.0085551738739014, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen, Sie stellen eine einfache Frage zu einem rechtlichen Thema, wie zum Beispiel: Was riskiert man, wenn man die berufliche Vertraulichkeit verletzt?", "metrics": {"bleu_score": 7.066026049079721, "chrf_score": 45.70067674059964, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5669432282447815, "metricx_qe_score": 0.36107027530670166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten Gesetzesartikel aus einem umfangreichen Gesetzeswerk abzurufen.", "metrics": {"bleu_score": 37.22520852859804, "chrf_score": 55.8714853649265, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.28178995847702026, "metricx_qe_score": 0.27836304903030396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsbeschaffungaufgabe bringt ihre eigenen Herausforderungen mit sich.", "metrics": {"bleu_score": 29.5580130165708, "chrf_score": 80.41547300241102, "xcomet_score": 0.9893065690994263, "xcomet_qe_score": 0.9853190779685974, "metricx_score": 0.060156676918268204, "metricx_qe_score": 0.17629507184028625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst befasst es sich mit zwei Arten von Sprache.", "metrics": {"bleu_score": 39.281465090051306, "chrf_score": 55.994172611278145, "xcomet_score": 0.9388857483863831, "xcomet_qe_score": 0.941964864730835, "metricx_score": 0.14668114483356476, "metricx_qe_score": 0.17115271091461182, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "allgemeine natürliche Sprache für die Fragen und komplexe illegale Sprache für die Statuten.", "metrics": {"bleu_score": 40.592153989989825, "chrf_score": 62.38440812937204, "xcomet_score": 0.8105102777481079, "xcomet_qe_score": 0.828879714012146, "metricx_score": 7.17300271987915, "metricx_qe_score": 6.753672122955322, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Unterschied in der Sprachverteilung erschwert es einem System, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die der Terminologie der Gesetze entspricht.", "metrics": {"bleu_score": 76.31937819302073, "chrf_score": 87.76418445222518, "xcomet_score": 0.9843072891235352, "xcomet_qe_score": 0.9167357683181763, "metricx_score": 0.48874443769454956, "metricx_qe_score": 0.6167373657226562, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das Gesetzbuch kein Stapel unabhängiger Artikel, die wie eine vollständige Informationsquelle für sich allein behandelt werden können, wie zum Beispiel Nachrichten oder Rezepte.", "metrics": {"bleu_score": 28.96326108724397, "chrf_score": 68.80474346285824, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9185369610786438, "metricx_qe_score": 0.6995346546173096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen handelt es sich um eine Strukturkollektion von Rechtsvorschriften, die erst im Gesamtzusammenhang eine vollständige Bedeutung erhalten, d. h. zusammen mit den ergänzenden Informationen aus den benachbarten Artikeln, den Bereichen und Teilbereichen, zu denen sie gehören, und ihrem Platz in der Struktur des Rechts.", "metrics": {"bleu_score": 46.34328175739396, "chrf_score": 70.75569401179676, "xcomet_score": 0.9867653250694275, "xcomet_qe_score": 0.9819221496582031, "metricx_score": 2.5891318321228027, "metricx_qe_score": 2.172319173812866, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich sind die gesetzlichen Artikel in kleinen Absätzen enthalten, die in den meisten Recherchewerken in der Regel die typische Abrufeinheit darstellen.", "metrics": {"bleu_score": 20.287366424876, "chrf_score": 52.5868914132859, "xcomet_score": 0.8664647340774536, "xcomet_qe_score": 0.8572639226913452, "metricx_score": 4.9825897216796875, "metricx_qe_score": 5.607648849487305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier gibt es lange Dokumente, die bis zu sechzig Jahre alt sein können.", "metrics": {"bleu_score": 59.687741756345, "chrf_score": 65.85685625898849, "xcomet_score": 0.7724261283874512, "xcomet_qe_score": 0.7885523438453674, "metricx_score": 9.503658294677734, "metricx_qe_score": 8.542369842529297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in der NLP haben großes Interesse an vielen rechtlichen Aufgaben geweckt, wie der Vorhersage von Gerichtsurteilen oder der automatisierten Vertragsüberprüfung.", "metrics": {"bleu_score": 27.876125942808734, "chrf_score": 68.87533477674228, "xcomet_score": 0.9824735522270203, "xcomet_qe_score": 0.9796125888824463, "metricx_score": 0.7610461115837097, "metricx_qe_score": 1.5529361963272095, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die statutarische Artikelabfrage aufgrund des Mangels an großen und hochwertigen, annotierten Datensätzen weitgehend unangetastet geblieben.", "metrics": {"bleu_score": 29.951021298936364, "chrf_score": 60.48350461963721, "xcomet_score": 0.9586632251739502, "xcomet_qe_score": 0.9696340560913086, "metricx_score": 1.3703378438949585, "metricx_qe_score": 1.2461371421813965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir einen neuen, auf französische Muttersprachler ausgerichteten Datensatz, um zu untersuchen, ob Retrieval-Modelle die Effizienz und Zuverlässigkeit eines juristischen Experten bei der Aufgabe des Abrufs von Gesetzesartikeln annähern können.", "metrics": {"bleu_score": 18.97722653436019, "chrf_score": 64.51387689726992, "xcomet_score": 0.9124314785003662, "xcomet_qe_score": 0.8867976665496826, "metricx_score": 2.417823314666748, "metricx_qe_score": 4.0178961753845215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Unsere belgischen gesetzlichen Artikel-Abrufsätze umfassen mehr als eintausend einhundert Liter.", "metrics": {"bleu_score": 2.2795097684495036, "chrf_score": 25.013372593589644, "xcomet_score": 0.6020877361297607, "xcomet_qe_score": 0.7005153894424438, "metricx_score": 18.670621871948242, "metricx_qe_score": 20.336994171142578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen decken ein breites Spektrum von Themen ab, von Familie, Wohnen, Geld bis hin zu Arbeit und Sozialversicherung.", "metrics": {"bleu_score": 76.06811142113595, "chrf_score": 83.4675625365499, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1865127980709076, "metricx_qe_score": 0.08286432921886444, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einem Korpus von mehr als 22.600 Artikeln versehen.", "metrics": {"bleu_score": 71.12545753924933, "chrf_score": 72.56705912941037, "xcomet_score": 0.8784903883934021, "xcomet_qe_score": 0.8804339170455933, "metricx_score": 2.864595890045166, "metricx_qe_score": 3.293088912963867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Gesetzbücher. Lassen Sie uns nun darüber sprechen, wie wir diese Datensätze gesammelt haben.", "metrics": {"bleu_score": 56.35190098079901, "chrf_score": 81.12083830659668, "xcomet_score": 0.6875137090682983, "xcomet_qe_score": 0.7104877829551697, "metricx_score": 6.143500804901123, "metricx_qe_score": 10.299114227294922, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst begannen wir damit, ein großes Korpus an rechtlichen Artikeln zusammenzustellen.", "metrics": {"bleu_score": 4.368583925857938, "chrf_score": 53.20801371074896, "xcomet_score": 0.9988807439804077, "xcomet_qe_score": 0.9839245676994324, "metricx_score": 0.06918288767337799, "metricx_qe_score": 0.17983639240264893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dreiundzwanzig öffentlich zugängliche belgische Kodizes untersucht und alle ihre Artikel sowie die entsprechenden Abschnittsüberschriften extrahiert.", "metrics": {"bleu_score": 46.24892603869296, "chrf_score": 76.63029186363799, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.1690499782562256, "metricx_qe_score": 3.5262906551361084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend haben wir rechtliche Fragen mit Verweisen auf relevante Gesetze zusammengetragen.", "metrics": {"bleu_score": 54.91004867761124, "chrf_score": 73.34652591000264, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1119459867477417, "metricx_qe_score": 0.14111986756324768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr rund viertausend E-Mails von belgischen Bürgern erhält, die um Rat bei einem persönlichen Rechtsproblem bitten.", "metrics": {"bleu_score": 60.083847465044315, "chrf_score": 75.02009904609712, "xcomet_score": 0.9980201721191406, "xcomet_qe_score": 1.0, "metricx_score": 0.08233527094125748, "metricx_qe_score": 0.13034330308437347, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team erfahrener Juristen die häufigsten rechtlichen Probleme in Belgien behandelt.", "metrics": {"bleu_score": 67.32378032068624, "chrf_score": 75.45597118707808, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5246574878692627, "metricx_qe_score": 0.6252104043960571, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen gesammelt, die mit Kategorien, Unterkategorien und rechtlichen Verweisen auf relevante Gesetze annotiert sind.", "metrics": {"bleu_score": 45.50680330812803, "chrf_score": 79.20109396728624, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3917781412601471, "metricx_qe_score": 0.5909736156463623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir die rechtlichen Verweise überprüft und die Fragen herausgefiltert, deren Verweise nicht auf Artikel in einem der von uns berücksichtigten Gesetzbücher verweisen.", "metrics": {"bleu_score": 77.95149903947966, "chrf_score": 89.43319301119351, "xcomet_score": 0.9820311069488525, "xcomet_qe_score": 0.9740122556686401, "metricx_score": 0.34323158860206604, "metricx_qe_score": 0.46972882747650146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Referenzen wurden mit den entsprechenden Artikel-IDs aus dem O-Korpus abgeglichen und in diese umgewandelt.", "metrics": {"bleu_score": 14.463984658071604, "chrf_score": 63.57182532201929, "xcomet_score": 0.9639681577682495, "xcomet_qe_score": 0.9561267495155334, "metricx_score": 2.696711778640747, "metricx_qe_score": 3.2615833282470703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen schließlich auf eintausend einundachtzig Fragen, die jeweils sorgfältig mit den IDs der relevanten Artikel aus dem Buch versehen waren.", "metrics": {"bleu_score": 27.93494750789679, "chrf_score": 44.11794963181227, "xcomet_score": 0.9009956121444702, "xcomet_qe_score": 0.8709392547607422, "metricx_score": 4.984715938568115, "metricx_qe_score": 9.569218635559082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zudem ist jede Frage mit einer Hauptkategorie und einer Verkettung von Unterkategorien versehen.", "metrics": {"bleu_score": 16.06455374563062, "chrf_score": 68.95843444781995, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4411522150039673, "metricx_qe_score": 1.2067121267318726, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel wird in der Struktur des Gesetzes mit einer Verkettung seiner nachfolgenden Überschrift versehen.", "metrics": {"bleu_score": 6.468490584192431, "chrf_score": 54.87434046577759, "xcomet_score": 0.9850741624832153, "xcomet_qe_score": 0.9630934000015259, "metricx_score": 2.109736919403076, "metricx_qe_score": 3.64687442779541, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten aber für zukünftige Forschungen zum rechtlichen Informationsbeschaffung oder zur rechtlichen Textklassifizierung von Interesse sein.", "metrics": {"bleu_score": 63.04186117582763, "chrf_score": 78.0611634912167, "xcomet_score": 0.9478473663330078, "xcomet_qe_score": 0.9638921618461609, "metricx_score": 0.8197318315505981, "metricx_qe_score": 1.007570505142212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns einige Merkmale unserer Datensätze betrachten.", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 58.694921872395845, "xcomet_score": 0.9891918897628784, "xcomet_qe_score": 0.9995100498199463, "metricx_score": 0.9365360140800476, "metricx_qe_score": 0.5409671068191528, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen sind zwischen fünf und vierundvierzig Wörter lang, mit einem Median von vierzig Wörtern.", "metrics": {"bleu_score": 54.11927503805856, "chrf_score": 69.60997504196638, "xcomet_score": 0.8604180812835693, "xcomet_qe_score": 0.9720292687416077, "metricx_score": 7.197946548461914, "metricx_qe_score": 6.347973346710205, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer mittleren Länge von einundsiebzig Wörtern, bei einhundertvierzig Gramm.", "metrics": {"bleu_score": 12.679003734465196, "chrf_score": 41.2274078229163, "xcomet_score": 0.6776851415634155, "xcomet_qe_score": 0.7312631607055664, "metricx_score": 12.593740463256836, "metricx_qe_score": 18.51824378967285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei davon überschreiten die Zahl von tausend.", "metrics": {"bleu_score": 5.11459870708889, "chrf_score": 13.970762708260139, "xcomet_score": 0.45063894987106323, "xcomet_qe_score": 0.2088565230369568, "metricx_score": 5.814474105834961, "metricx_qe_score": 9.830312728881836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine breite Palette von Themen, wobei etwa achtundachtzig Prozent von ihnen entweder über Familie, Wohnen, Geld oder Justiz handelten, oder", "metrics": {"bleu_score": 15.62421643421239, "chrf_score": 50.8744462129172, "xcomet_score": 0.9194834232330322, "xcomet_qe_score": 0.9291746616363525, "metricx_score": 5.071670055389404, "metricx_qe_score": 2.643954038619995, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "während die restlichen fünfzehn Prozent entweder soziale Sicherheit, Ausländer oder Arbeit betreffen.", "metrics": {"bleu_score": 48.41524713034602, "chrf_score": 82.8535800628498, "xcomet_score": 0.9910106658935547, "xcomet_qe_score": 0.9899691939353943, "metricx_score": 0.5257492661476135, "metricx_qe_score": 0.5365118980407715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind ebenfalls sehr vielfältig, da sie aus dreiunddreißig verschiedenen belgischen Kodizes stammen, die eine große Anzahl von Rechtsfragen abdecken.", "metrics": {"bleu_score": 44.36535621008064, "chrf_score": 68.40999337981489, "xcomet_score": 0.9833269119262695, "xcomet_qe_score": 0.9841316342353821, "metricx_score": 1.6168440580368042, "metricx_qe_score": 1.149609088897705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Codes gesammelt wurden.", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 74.7960335439847, "xcomet_score": 0.9758502244949341, "xcomet_qe_score": 0.94249027967453, "metricx_score": 3.0755269527435303, "metricx_qe_score": 2.747055768966675, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den zweiundzwanzigtausendsechsunddreißig Artikeln werden nur sechzehnhundertzwei als relevant für mindestens einen der genannten Punkte bezeichnet.", "metrics": {"bleu_score": 23.693055763743093, "chrf_score": 54.53260094448397, "xcomet_score": 0.9128451347351074, "xcomet_qe_score": 0.9302690029144287, "metricx_score": 3.631533622741699, "metricx_qe_score": 2.2893996238708496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "mindestens eine Frage in den Datensätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen entweder aus dem Bürgerlichen Gesetzbuch, dem Gerichtsverfassungsgesetz, dem Strafprozessgesetz oder dem Strafgesetzbuch.", "metrics": {"bleu_score": 34.93072415532013, "chrf_score": 65.24783149476664, "xcomet_score": 0.5473625659942627, "xcomet_qe_score": 0.6370112895965576, "metricx_score": 8.395983695983887, "metricx_qe_score": 10.648405075073242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit haben achtzehn von dreiunddreißig Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden.", "metrics": {"bleu_score": 32.920103612911184, "chrf_score": 60.27910627019698, "xcomet_score": 0.9475378394126892, "xcomet_qe_score": 0.9784769415855408, "metricx_score": 3.926422119140625, "metricx_qe_score": 3.299250602722168, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies lässt sich dadurch erklären, dass diese Codes weniger auf Einzelpersonen und deren Anliegen fokussiert sind.", "metrics": {"bleu_score": 42.94652316126124, "chrf_score": 58.825427863669454, "xcomet_score": 0.9909590482711792, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 3.776792049407959, "metricx_qe_score": 2.423426866531372, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt beträgt die durchschnittliche Anzahl der Zitate für diese zitierten Artikel zwei, und weniger als fünfundzwanzig Prozent von ihnen werden zitiert.", "metrics": {"bleu_score": 23.765837259435084, "chrf_score": 63.283059050535584, "xcomet_score": 0.8904857635498047, "xcomet_qe_score": 0.8781135678291321, "metricx_score": 7.631533622741699, "metricx_qe_score": 5.950040817260742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen vergleichen wir mehrere Abrufansätze, einschließlich lexikalischer und dichter Architektur.", "metrics": {"bleu_score": 26.305333213389257, "chrf_score": 51.86906528535297, "xcomet_score": 0.8923498392105103, "xcomet_qe_score": 0.8912854194641113, "metricx_score": 0.7241061925888062, "metricx_qe_score": 0.7118077874183655, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Anfrage in einem Artikel weist ein lexikales Modell dem Anfrage-Artikel-Paar eine Punktzahl zu, indem es die Summe über die Anfragetermini der Gewichte jedes dieser Termini in dem Artikel berechnet.", "metrics": {"bleu_score": 34.36189621162508, "chrf_score": 70.39905437045618, "xcomet_score": 0.8969709873199463, "xcomet_qe_score": 0.8446341156959534, "metricx_score": 5.077663421630859, "metricx_qe_score": 3.8071722984313965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM25-Rankingfunktionen.", "metrics": {"bleu_score": 32.46679154750989, "chrf_score": 78.0582574014455, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.879295825958252, "metricx_qe_score": 1.2028472423553467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die Schlüsselwörter enthalten, die in der Abfrage vorhanden sind.", "metrics": {"bleu_score": 72.67072830982373, "chrf_score": 86.87286610204312, "xcomet_score": 0.9916040897369385, "xcomet_qe_score": 0.9922547340393066, "metricx_score": 0.5713827610015869, "metricx_qe_score": 0.6251809000968933, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die die semantischen Beziehungen zwischen Suchanfragen und Artikeln erfassen kann.", "metrics": {"bleu_score": 60.67337731525327, "chrf_score": 88.50802870845924, "xcomet_score": 0.9970282316207886, "xcomet_qe_score": 0.9982069730758667, "metricx_score": 0.3790161907672882, "metricx_qe_score": 0.2229006588459015, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein BE-Encoder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen abbildet und einen relevanten Score zwischen einem Abfrage-Artikel-Paar durch die Ähnlichkeit ihrer Einbettungen berechnet.", "metrics": {"bleu_score": 43.441091034192404, "chrf_score": 78.1922784809455, "xcomet_score": 0.8754810690879822, "xcomet_qe_score": 0.8592586517333984, "metricx_score": 3.430755853652954, "metricx_qe_score": 5.078717231750488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen entstehen in der Regel durch eine Pooling-Operation am Ausgabewert eines Worteinbettungsmodells.", "metrics": {"bleu_score": 19.369604994860264, "chrf_score": 71.71405999023582, "xcomet_score": 0.9252197742462158, "xcomet_qe_score": 0.8571969270706177, "metricx_score": 0.9906667470932007, "metricx_qe_score": 1.7652883529663086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit von Siamese-Biancodern in einem Zero-Shot-Evaluierungssetup, was bedeutet, dass vorgefertigte Word-Embedding-Modelle ohne zusätzliche Feinabstimmung direkt angewendet werden.", "metrics": {"bleu_score": 19.16345623438237, "chrf_score": 65.2018359842637, "xcomet_score": 0.8377532958984375, "xcomet_qe_score": 0.8461626768112183, "metricx_score": 2.9478020668029785, "metricx_qe_score": 2.354060411453247, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Texterodierern, nämlich Word to Vec und FastText, und kontextbasierten Einbettungsmodellen, nämlich Roberta und insbesondere Camembert, einem französischen Roberta-Modell.", "metrics": {"bleu_score": 30.32929624979452, "chrf_score": 77.12472051547427, "xcomet_score": 0.9300470352172852, "xcomet_qe_score": 0.8948941230773926, "metricx_score": 5.319370269775391, "metricx_qe_score": 4.969597816467285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus trainieren wir unser eigenes Camembert-basiertes Modell. Über Quoter hinaus,", "metrics": {"bleu_score": 28.67033581673066, "chrf_score": 53.864538700553844, "xcomet_score": 0.7175880670547485, "xcomet_qe_score": 0.7280144691467285, "metricx_score": 9.64711856842041, "metricx_qe_score": 13.226873397827148, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Verwendet auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den beiden Varianten der Bianco-Architektur experimentieren.", "metrics": {"bleu_score": 42.18752038739221, "chrf_score": 78.6147265814712, "xcomet_score": 0.679316520690918, "xcomet_qe_score": 0.7563271522521973, "metricx_score": 7.528350353240967, "metricx_qe_score": 6.763354301452637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Wort-Embedding-Modell verwendet, das die Abfrage und den Artikel in einem gemeinsamen dichten Vektorraum zusammenführt, und Tutor, das zwei unabhängige Wort-Embedding-Modelle verwendet, die die Abfrage und den Artikel separat in unterschiedliche Embedding-Räume kodieren.", "metrics": {"bleu_score": 50.213791930812846, "chrf_score": 68.27233926751803, "xcomet_score": 0.5904546976089478, "xcomet_qe_score": 0.6233734488487244, "metricx_score": 6.946250915527344, "metricx_qe_score": 8.812674522399902, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentierten mit Mean-, Max- und CLS-Pooling sowie dem Punktprodukt und dem Kosinus zur Berechnung von Ähnlichkeiten.", "metrics": {"bleu_score": 20.973425791310696, "chrf_score": 65.54890185056391, "xcomet_score": 0.6741148233413696, "xcomet_qe_score": 0.6893693208694458, "metricx_score": 3.9374074935913086, "metricx_qe_score": 3.2387590408325195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Basislinie auf den Testsets.", "metrics": {"bleu_score": 46.713797772819994, "chrf_score": 78.27969313027582, "xcomet_score": 0.8633527755737305, "xcomet_qe_score": 0.8502287864685059, "metricx_score": 2.1518373489379883, "metricx_qe_score": 2.988901376724243, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den oben genannten lexikalischen Methoden wurden die Siamese-B-Encoder in einem Zero-Shot-Setup in der Mitte und die feinabgestimmten B-Encoder unten bewertet.", "metrics": {"bleu_score": 33.96230123896639, "chrf_score": 75.26614736095507, "xcomet_score": 0.883126974105835, "xcomet_qe_score": 0.8664548397064209, "metricx_score": 4.970944404602051, "metricx_qe_score": 4.659800052642822, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertrifft die fein abgestimmte Biancore alle anderen Basslinien deutlich.", "metrics": {"bleu_score": 14.991106946711685, "chrf_score": 71.79412778969827, "xcomet_score": 0.7831778526306152, "xcomet_qe_score": 0.7961218357086182, "metricx_score": 6.925686836242676, "metricx_qe_score": 7.408115863800049, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Zwei-Türme-Modell übertrifft seine siamesische Variante bei Recall bei einhundert, zeigt aber bei den anderen Metriken ähnliche Ergebnisse.", "metrics": {"bleu_score": 17.868702150275563, "chrf_score": 51.07135907089506, "xcomet_score": 0.899919867515564, "xcomet_qe_score": 0.8985438346862793, "metricx_score": 5.376144886016846, "metricx_qe_score": 5.1544389724731445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM twenty five deutlich schlechter abschnitt als der trainierte Biancoda, deutete seine Leistung darauf hin, dass es immer noch eine starke Basis für domänenspezifische Abfragen darstellt.", "metrics": {"bleu_score": 25.312245791949678, "chrf_score": 68.37419000779583, "xcomet_score": 0.7663042545318604, "xcomet_qe_score": 0.7718175649642944, "metricx_score": 8.71660041809082, "metricx_qe_score": 8.515249252319336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Zero-Shot-Evaluation von Siamese Biancoder stellen wir fest, dass die direkte Verwendung der Einbettungen eines vorgefertigten Kamembert-Modells ohne Optimierung für die Informationsbeschaffung zu schlechten Ergebnissen führt, was mit früheren Erkenntnissen übereinstimmt.", "metrics": {"bleu_score": 53.09130776616996, "chrf_score": 73.94131584726217, "xcomet_score": 0.6830160021781921, "xcomet_qe_score": 0.7197015285491943, "metricx_score": 6.428313732147217, "metricx_qe_score": 4.949330806732178, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir fest, dass das auf Wortvektoren basierende Biancoder-Modell die Modelle Vastex und bird deutlich übertrifft, was darauf hindeutet, dass vorgefertigte Wort-Embeddings für die Aufgabe möglicherweise geeigneter sind als Embeddings auf Zeichen- oder Subwort-Ebene, wenn sie direkt verwendet werden.", "metrics": {"bleu_score": 42.76106680395162, "chrf_score": 58.36029942008629, "xcomet_score": 0.6338766813278198, "xcomet_qe_score": 0.634489893913269, "metricx_score": 8.650222778320312, "metricx_qe_score": 8.147579193115234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl vielversprechend, deuten diese Ergebnisse auf reichlich Verbesserungspotenzial im Vergleich zu einem erfahrenen Rechtsexperten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Ergebnisse erzielen kann.", "metrics": {"bleu_score": 38.46814643805403, "chrf_score": 75.4083923453217, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.25267115235328674, "metricx_qe_score": 0.28529298305511475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns abschließend zwei Einschränkungen aller Datensätze diskutieren.", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 51.17416320578897, "xcomet_score": 0.9352281093597412, "xcomet_qe_score": 0.9325929880142212, "metricx_score": 3.5926592350006104, "metricx_qe_score": 2.4222865104675293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst wird der Korpus der Artikel auf diejenigen beschränkt, die aus den 32 betrachteten belgischen Kodizes gesammelt wurden, was nicht das gesamte belgische Recht abdeckt, da Artikel aus Dekreten, Richtlinien und Verordnungen fehlen.", "metrics": {"bleu_score": 52.97641930515562, "chrf_score": 71.39133899269325, "xcomet_score": 0.9494175910949707, "xcomet_qe_score": 0.9435999393463135, "metricx_score": 1.9016093015670776, "metricx_qe_score": 1.5807560682296753, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während des Datensatzesaufbaus werden alle Verweise auf diese nicht gesammelten Artikel ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der anfänglichen Anzahl relevanter Artikel erhalten.", "metrics": {"bleu_score": 37.098013257912044, "chrf_score": 67.89954233269525, "xcomet_score": 0.9645668268203735, "xcomet_qe_score": 0.9580910205841064, "metricx_score": 1.7166297435760498, "metricx_qe_score": 1.4263174533843994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsverlust bedeutet, dass die in den verbleibenden relevanten Artikeln enthaltene Antwort unvollständig sein könnte, obwohl sie dennoch völlig angemessen ist.", "metrics": {"bleu_score": 32.23833286593517, "chrf_score": 71.39148061335665, "xcomet_score": 0.9784382581710815, "xcomet_qe_score": 0.9664433002471924, "metricx_score": 1.5495657920837402, "metricx_qe_score": 1.495908498764038, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.111781045794487, "metricx_qe_score": 0.16189205646514893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Darf ich meine Mieter rauswerfen, wenn sie zu viel Lärm machen?", "metrics": {"bleu_score": 57.030171725674585, "chrf_score": 70.77358882366399, "xcomet_score": 0.9798026084899902, "xcomet_qe_score": 0.9785076975822449, "metricx_score": 0.337130069732666, "metricx_qe_score": 0.20861253142356873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt möglicherweise keine detaillierte Antwort im Gesetz, die eine spezifische Lärmschwelle quantifiziert, ab der eine Räumung zulässig ist.", "metrics": {"bleu_score": 47.10012314144843, "chrf_score": 72.40618912850917, "xcomet_score": 0.9626160860061646, "xcomet_qe_score": 0.9527648091316223, "metricx_score": 1.2290242910385132, "metricx_qe_score": 0.8942351937294006, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte sich der Vermieter wahrscheinlich stärker auf die Rechtsprechung verlassen und Präzedenzfälle finden, die seiner aktuellen Situation ähnlich sind.", "metrics": {"bleu_score": 68.48075777090853, "chrf_score": 84.80091616883692, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3991543650627136, "metricx_qe_score": 0.26826012134552, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Mieter zwei Partys pro Woche bis zwei Uhr.", "metrics": {"bleu_score": 57.991506770919095, "chrf_score": 65.74410514848171, "xcomet_score": 0.9598784446716309, "xcomet_qe_score": 0.9577928781509399, "metricx_score": 0.6385992765426636, "metricx_qe_score": 0.6603045463562012, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher eignen sich einige Fragen besser als andere für die gesetzliche Artikelabruftache, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen.", "metrics": {"bleu_score": 25.177251610618846, "chrf_score": 55.1325579958271, "xcomet_score": 0.959762454032898, "xcomet_qe_score": 0.907249391078949, "metricx_score": 4.238670825958252, "metricx_qe_score": 2.996033191680908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass alle Arbeiten das Interesse an der Entwicklung praktischer und zuverlässiger gesetzlicher Artikel-Abrufmuster wecken.", "metrics": {"bleu_score": 43.23177783155441, "chrf_score": 64.78283904470838, "xcomet_score": 0.9509927034378052, "xcomet_qe_score": 0.9579204320907593, "metricx_score": 3.6571426391601562, "metricx_qe_score": 2.4797282218933105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "die dazu beitragen können, den Zugang zur Justiz für alle zu verbessern.", "metrics": {"bleu_score": 72.72454093000138, "chrf_score": 87.14039222080227, "xcomet_score": 0.9684809446334839, "xcomet_qe_score": 0.9799574017524719, "metricx_score": 2.098275899887085, "metricx_qe_score": 1.3086503744125366, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sich unser Paper, den Set und den Code unter den folgenden Links ansehen. Vielen Dank.", "metrics": {"bleu_score": 32.26386416030252, "chrf_score": 64.29577223017608, "xcomet_score": 0.8268904685974121, "xcomet_qe_score": 0.8317936658859253, "metricx_score": 5.302870750427246, "metricx_qe_score": 3.4545891284942627, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an Vowls vorstellen zu können, einem aufgabenunabhängigen Benchmark, der für die Testung von Seh- und Sprachmodellen mit spezifischen sprachlichen Phänomenen gedacht ist.", "metrics": {"bleu_score": 44.53503875882245, "chrf_score": 72.0697462337995, "xcomet_score": 0.8562207818031311, "xcomet_qe_score": 0.8032194375991821, "metricx_score": 3.4223811626434326, "metricx_qe_score": 4.5139875411987305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark aufzustellen?", "metrics": {"bleu_score": 82.651681837938, "chrf_score": 80.38931868193252, "xcomet_score": 0.9983352422714233, "xcomet_qe_score": 1.0, "metricx_score": 0.18473100662231445, "metricx_qe_score": 0.25139009952545166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Nun, in den letzten Jahren haben wir eine Explosion von auf großen Mengen an Bild-Text-Paaren vortrainierten, auf Transformatoren basierenden Bild- und Sprachmodellen erlebt.", "metrics": {"bleu_score": 33.42769222679443, "chrf_score": 70.1311179165339, "xcomet_score": 0.9477119445800781, "xcomet_qe_score": 0.9812195897102356, "metricx_score": 2.3858439922332764, "metricx_qe_score": 1.6656640768051147, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle setzt neue Maßstäbe bei Aufgaben im Bereich Vision und Sprache, wie z. B. visuelle Fragebeantwortung, visuelle Alltagslogik, Bildabruf und Phrasenverankerung.", "metrics": {"bleu_score": 21.399100116541966, "chrf_score": 46.189929567017444, "xcomet_score": 0.9600635766983032, "xcomet_qe_score": 0.9837555289268494, "metricx_score": 1.751786470413208, "metricx_qe_score": 1.5763463973999023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Nachricht erhalten. Die Genauigkeiten bei diesen aufgabenbezogenen Benchmarks steigen stetig an.", "metrics": {"bleu_score": 15.960148938094363, "chrf_score": 67.69264159778564, "xcomet_score": 0.9904627799987793, "xcomet_qe_score": 0.9864076972007751, "metricx_score": 0.8046214580535889, "metricx_qe_score": 1.0637282133102417, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5102907419204712, "metricx_qe_score": 0.9778188467025757, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was versteht ein Vision-and-Language-Transformer, wenn er diesem Bild und diesem Satz eine hohe Übereinstimmungsscore zuordnet?", "metrics": {"bleu_score": 13.922162089907253, "chrf_score": 46.70589002827432, "xcomet_score": 0.8491271138191223, "xcomet_qe_score": 0.868714451789856, "metricx_score": 1.864455223083496, "metricx_qe_score": 2.3459982872009277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "und die niedrige Punktzahl für diesen.", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 62.23873690504617, "xcomet_score": 0.9402902126312256, "xcomet_qe_score": 0.940737247467041, "metricx_score": 1.08332097530365, "metricx_qe_score": 1.1384479999542236, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Seh- und Sprachmodelle auf das Richtige?", "metrics": {"bleu_score": 54.627576446464936, "chrf_score": 70.28470866703948, "xcomet_score": 0.9749812483787537, "xcomet_qe_score": 0.9868461489677429, "metricx_score": 0.48520544171333313, "metricx_qe_score": 0.4657630920410156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie sie in früheren Arbeiten gezeigt wurden?", "metrics": {"bleu_score": 37.0304683381906, "chrf_score": 74.7020182172442, "xcomet_score": 0.9824657440185547, "xcomet_qe_score": 1.0, "metricx_score": 0.3689274787902832, "metricx_qe_score": 0.30982154607772827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt genauer zu beleuchten, schlagen wir eine aufgabenunabhängige Richtung vor und führen Ventile ein, die die Empfindlichkeit von Seh- und Sprachmodellen gegenüber spezifischen sprachlichen Phänomenen testen, die sowohl die sprachliche als auch die visuelle Modalität betreffen.", "metrics": {"bleu_score": 39.46640283851441, "chrf_score": 75.08296260464992, "xcomet_score": 0.7876063585281372, "xcomet_qe_score": 0.8015797734260559, "metricx_score": 4.701697826385498, "metricx_qe_score": 4.094910621643066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir richten uns auf Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entität-Korreferenz aus.", "metrics": {"bleu_score": 48.59373818796306, "chrf_score": 78.40492428818209, "xcomet_score": 0.9060737490653992, "xcomet_qe_score": 0.9120620489120483, "metricx_score": 2.158731460571289, "metricx_qe_score": 2.3332507610321045, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Visions- und Sprachmodelle diese Phänomene erfasst haben?", "metrics": {"bleu_score": 18.010019776510696, "chrf_score": 58.33152183596542, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 1.8368278741836548, "metricx_qe_score": 0.8596996665000916, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, eine Methode, die zuvor von Ravi Shakar und seinen Mitarbeitern nur für Nomenphrasen in Sprach- und Sprachmodellen angewendet wurde und die wir in früheren Arbeiten beim Zählen verwendet haben.", "metrics": {"bleu_score": 11.963481421096448, "chrf_score": 60.6618125502641, "xcomet_score": 0.7390373945236206, "xcomet_qe_score": 0.7683547735214233, "metricx_score": 5.169499397277832, "metricx_qe_score": 4.144913196563721, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde genommen, dass wir die Bildunterschrift eines Bildes nehmen und eine Folie erstellen, indem wir die Bildunterschrift so verändern, dass sie das Bild nicht mehr beschreibt.", "metrics": {"bleu_score": 59.26761300137113, "chrf_score": 70.26484477031258, "xcomet_score": 0.8007689714431763, "xcomet_qe_score": 0.9510306119918823, "metricx_score": 3.62799072265625, "metricx_qe_score": 1.5641944408416748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Phrasenänderungen durch, indem wir uns auf sechs spezifische Elemente konzentrieren, wie Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entität-Koreferenz, wobei jedes Element aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als einen interessanten Weg finden, Folieninstanzen zu erstellen.", "metrics": {"bleu_score": 56.740205308643475, "chrf_score": 77.6767835816516, "xcomet_score": 0.7675464153289795, "xcomet_qe_score": 0.7818322777748108, "metricx_score": 4.3070478439331055, "metricx_qe_score": 3.517237901687622, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir im Fall des Aktionsstücks zwei Instrumente, bei einem wird das Aktionsverb durch eine andere Handlung ersetzt, und bei einem anderen werden die Handelnden ausgetauscht.", "metrics": {"bleu_score": 36.1058196368965, "chrf_score": 64.92533934923182, "xcomet_score": 0.9576996564865112, "xcomet_qe_score": 0.9492080211639404, "metricx_score": 1.842995524406433, "metricx_qe_score": 2.404083013534546, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Counting und Coreferenz sind ebenfalls Stücke, die mehr als ein Instrument haben.", "metrics": {"bleu_score": 54.3742768222752, "chrf_score": 68.94063227193999, "xcomet_score": 0.7107930779457092, "xcomet_qe_score": 0.7811764478683472, "metricx_score": 8.019936561584473, "metricx_qe_score": 6.570173263549805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir erstellen diese Folien, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatisch und anderweitig gültige Sätze sind.", "metrics": {"bleu_score": 54.51502908460081, "chrf_score": 68.43925729630817, "xcomet_score": 0.8916386365890503, "xcomet_qe_score": 0.9364609122276306, "metricx_score": 4.370861530303955, "metricx_qe_score": 2.4236598014831543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist nicht einfach zu bewerkstelligen, da eine vereitelte Bildunterschrift weniger wahrscheinlich sein kann als die ursprüngliche Bildunterschrift.", "metrics": {"bleu_score": 34.03336518440548, "chrf_score": 70.87811111361553, "xcomet_score": 0.9432674646377563, "xcomet_qe_score": 0.9378186464309692, "metricx_score": 1.4055936336517334, "metricx_qe_score": 0.9284965991973877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es, obwohl es nicht unmöglich ist, statistisch gesehen unwahrscheinlicher, dass Pflanzen einen Mann schneiden, als dass ein Mann Pflanzen schneidet, und große Seh- und Sprachmodelle könnten dies erkennen.", "metrics": {"bleu_score": 40.89926520845833, "chrf_score": 77.9998370692977, "xcomet_score": 0.9248617887496948, "xcomet_qe_score": 0.9364206790924072, "metricx_score": 1.4217321872711182, "metricx_qe_score": 1.507439136505127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Daher müssen wir Maßnahmen ergreifen, um gültige Folien zu erhalten.", "metrics": {"bleu_score": 15.580105704117443, "chrf_score": 43.8251646982806, "xcomet_score": 0.914238691329956, "xcomet_qe_score": 0.9424629211425781, "metricx_score": 2.5128772258758545, "metricx_qe_score": 1.7270570993423462, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir leistungsstarke Sprachmodelle, um Folien vorzuschlagen.", "metrics": {"bleu_score": 22.957488466614326, "chrf_score": 66.18621541782016, "xcomet_score": 0.8302624225616455, "xcomet_qe_score": 0.8594093322753906, "metricx_score": 3.486029863357544, "metricx_qe_score": 1.4817301034927368, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir natürliche Sprachinferenz oder kurz NLI, um Folien herauszufiltern, die das Bild immer noch beschreiben könnten, da wir beim Erstellen von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben.", "metrics": {"bleu_score": 42.96179024516559, "chrf_score": 68.20617336502349, "xcomet_score": 0.7913826107978821, "xcomet_qe_score": 0.9297796487808228, "metricx_score": 6.04335880279541, "metricx_qe_score": 3.4492151737213135, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir die natürliche Sprachinferenz mit der folgenden Begründung an.", "metrics": {"bleu_score": 53.32120696150479, "chrf_score": 74.82634951584023, "xcomet_score": 0.9898126125335693, "xcomet_qe_score": 0.9867130517959595, "metricx_score": 1.2718160152435303, "metricx_qe_score": 1.360027551651001, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als Prämisse und seine Bildunterschrift als die daraus abgeleitete Hypothese.", "metrics": {"bleu_score": 61.60362085721387, "chrf_score": 83.6645216391223, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14930161833763123, "metricx_qe_score": 0.24525202810764313, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus betrachten wir die Bildunterschrift als Prämisse und die Folie als ihre Hypothese.", "metrics": {"bleu_score": 57.73502691896262, "chrf_score": 74.11762538695275, "xcomet_score": 0.868510365486145, "xcomet_qe_score": 0.9282010197639465, "metricx_score": 1.1117359399795532, "metricx_qe_score": 0.5807561874389648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass die Folie dem Untertitel widerspricht oder neutral dazu ist, nehmen wir dies als Indikator für eine gültige Folie.", "metrics": {"bleu_score": 38.83375900135817, "chrf_score": 59.25767104266526, "xcomet_score": 0.7378366589546204, "xcomet_qe_score": 0.9781379103660583, "metricx_score": 2.7985432147979736, "metricx_qe_score": 0.83543860912323, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn eine NLI vorhersagt, dass die Folie durch die Bildunterschrift impliziert wird, kann sie keine gute Folie sein, da sie durch Transitivität eine wahrheitsgetreue Beschreibung des Bildes liefert und wir diese Folien herausfiltern.", "metrics": {"bleu_score": 35.50890979249747, "chrf_score": 61.77906582279373, "xcomet_score": 0.7279894351959229, "xcomet_qe_score": 0.8749145269393921, "metricx_score": 3.3893136978149414, "metricx_qe_score": 3.204108238220215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Verfahren ist nicht perfekt. Es ist nur ein Indikator für gültige Folie.", "metrics": {"bleu_score": 30.130404892785695, "chrf_score": 62.76396799000419, "xcomet_score": 0.8914466500282288, "xcomet_qe_score": 0.9170893430709839, "metricx_score": 2.8265020847320557, "metricx_qe_score": 1.658048152923584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher setzen wir als dritte Maßnahme zur Generierung gültiger Folien menschliche Annotatoren ein, um die in den Ventilen verwendeten Daten zu validieren.", "metrics": {"bleu_score": 71.86969683828065, "chrf_score": 84.23766586558158, "xcomet_score": 0.7554185390472412, "xcomet_qe_score": 0.8240822553634644, "metricx_score": 6.542293071746826, "metricx_qe_score": 5.767742156982422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nachdem wir also gefiltert und die menschlichen Bewertungen durchgeführt haben, haben wir so viele Testinstanzen wie in dieser Tabelle beschrieben.", "metrics": {"bleu_score": 32.77176740624639, "chrf_score": 69.04628423556275, "xcomet_score": 0.9968116283416748, "xcomet_qe_score": 0.9833482503890991, "metricx_score": 0.8913339972496033, "metricx_qe_score": 1.1801609992980957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten, sondern nur Testdaten liefert.", "metrics": {"bleu_score": 61.037911309497645, "chrf_score": 86.72873362317539, "xcomet_score": 0.9693964719772339, "xcomet_qe_score": 0.9949600696563721, "metricx_score": 0.46346515417099, "metricx_qe_score": 0.9033454060554504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich hierbei nur um einen Zero-Shot-Test-Benchmark handelt, ist er so konzipiert, dass er die vorhandenen Fähigkeiten von Bild- und Sprachmodellen nach der Vorab-Schulung nutzt.", "metrics": {"bleu_score": 45.5970651796198, "chrf_score": 74.72124251802431, "xcomet_score": 0.9530513286590576, "xcomet_qe_score": 0.9156138896942139, "metricx_score": 1.042995810508728, "metricx_qe_score": 1.8392834663391113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmungen würden den Modellen lediglich ermöglichen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen.", "metrics": {"bleu_score": 61.490732395580245, "chrf_score": 85.33623360695229, "xcomet_score": 0.9996768236160278, "xcomet_qe_score": 0.9978994131088257, "metricx_score": 0.20200496912002563, "metricx_qe_score": 0.2248767912387848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne schummeln und Abkürzungen nehmen.", "metrics": {"bleu_score": 61.62607099729587, "chrf_score": 91.83834013382479, "xcomet_score": 0.9979071617126465, "xcomet_qe_score": 0.999207615852356, "metricx_score": 0.635805606842041, "metricx_qe_score": 0.752661943435669, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie wir bereits erwähnt haben, sind wir daran interessiert zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach dem Vor-Training haben.", "metrics": {"bleu_score": 25.823077599534503, "chrf_score": 70.04995368587687, "xcomet_score": 0.9690914154052734, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.3541008234024048, "metricx_qe_score": 1.0721993446350098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen an Vokalen, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin one und VisualBERT.", "metrics": {"bleu_score": 31.26851492272872, "chrf_score": 59.71666744069844, "xcomet_score": 0.5522581338882446, "xcomet_qe_score": 0.5178526639938354, "metricx_score": 7.28475284576416, "metricx_qe_score": 6.763314247131348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satzen-Paaren in Bildunterschriften und Folien.", "metrics": {"bleu_score": 41.2295470431275, "chrf_score": 68.61811755417204, "xcomet_score": 0.8725413084030151, "xcomet_qe_score": 0.9093369245529175, "metricx_score": 3.871126890182495, "metricx_qe_score": 2.091221809387207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht noch relevanter für dieses Video ist unsere permissivere Metrik, die paarweise Genauigkeit, die misst, ob der Bildsatzzusammenführungswert für das korrekte Bild-Text-Paar höher ist als für das fehlgeschlagene Paar.", "metrics": {"bleu_score": 24.809337493666952, "chrf_score": 58.71405608307434, "xcomet_score": 0.9179370403289795, "xcomet_qe_score": 0.8930302858352661, "metricx_score": 3.418180227279663, "metricx_qe_score": 2.5858380794525146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Kennzahlen und Ergebnisse finden Sie in unserem Fachartikel.", "metrics": {"bleu_score": 30.37441422076457, "chrf_score": 63.45053959847419, "xcomet_score": 0.9983605146408081, "xcomet_qe_score": 0.9991034269332886, "metricx_score": 0.34570470452308655, "metricx_qe_score": 0.18274550139904022, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit der paarweisen Genauigkeit sind hier dargestellt und sie stimmen mit den Ergebnissen überein, die wir mit den anderen Metriken erhalten haben. Die beste Zero-Shot-Leistung wird von Wilbert Twelve in One erzielt, gefolgt von Wilbert, Alex Mert, Clip und schließlich VisualBird.", "metrics": {"bleu_score": 29.888359845795886, "chrf_score": 63.97748236135674, "xcomet_score": 0.5346282720565796, "xcomet_qe_score": 0.5396735072135925, "metricx_score": 6.301475524902344, "metricx_qe_score": 6.0747761726379395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert Twelve in One nahezu gelöst werden, was zeigt, dass Modelle in der Lage sind, benannte Objekte und deren Präsenz in Bildern zu identifizieren.", "metrics": {"bleu_score": 51.60257227984051, "chrf_score": 70.0632511555097, "xcomet_score": 0.8460685610771179, "xcomet_qe_score": 0.7497305870056152, "metricx_score": 3.646960735321045, "metricx_qe_score": 3.2723920345306396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Keines der verbleibenden Rätsel kann jedoch in unseren adversarial foiling-Einstellungen zuverlässig gelöst werden.", "metrics": {"bleu_score": 43.748114312246464, "chrf_score": 69.41164107555447, "xcomet_score": 0.8437739014625549, "xcomet_qe_score": 0.8794375658035278, "metricx_score": 3.0933268070220947, "metricx_qe_score": 2.866753101348877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus der Mehrdeutigkeit bei Zählinstrumenten geht hervor, dass Seh- und Sprachmodelle Schwierigkeiten haben, zwischen Verweisen auf einzelne oder mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen.", "metrics": {"bleu_score": 54.51690941226528, "chrf_score": 73.42759170691093, "xcomet_score": 0.9660592079162598, "xcomet_qe_score": 0.9319701194763184, "metricx_score": 2.2248687744140625, "metricx_qe_score": 1.6771266460418701, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Der Wert Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren.", "metrics": {"bleu_score": 61.69034543248988, "chrf_score": 73.93290752426758, "xcomet_score": 0.8938490152359009, "xcomet_qe_score": 0.8915335536003113, "metricx_score": 2.448861598968506, "metricx_qe_score": 2.5998265743255615, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Teilnehmer zu identifizieren, selbst wenn sie durch Plausibilitätsvorurteile unterstützt werden, wie wir im Handlungsabschnitt sehen.", "metrics": {"bleu_score": 74.82073974516572, "chrf_score": 87.72469022367775, "xcomet_score": 0.9618733525276184, "xcomet_qe_score": 0.9036961197853088, "metricx_score": 1.2282260656356812, "metricx_qe_score": 2.294051170349121, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Co-Referenzstück erfahren wir, dass es auch für Seh- und Sprachmodelle schwierig ist, mehrere Verweise auf dasselbe Objekt in einem Bild mithilfe von Pronomen zu verfolgen.", "metrics": {"bleu_score": 36.64158786944278, "chrf_score": 62.77092754025344, "xcomet_score": 0.9347281455993652, "xcomet_qe_score": 0.9183974266052246, "metricx_score": 2.2710437774658203, "metricx_qe_score": 2.313331127166748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Zur Überprüfung und weil es ein interessantes Experiment ist, vergleichen wir auch zwei textbasierte Modelle, GPT-1 und GPT-2, um zu beurteilen, ob Valves durch diese unimodalen Modelle lösbar ist, indem wir die Perplexität der korrekten und der vereitelten Bildunterschrift (hier kein Bild) berechnen und den Eintrag mit der niedrigsten Perplexität vorhersagen.", "metrics": {"bleu_score": 43.824999278283066, "chrf_score": 71.44320337631767, "xcomet_score": 0.7484869956970215, "xcomet_qe_score": 0.8091262578964233, "metricx_score": 4.028810024261475, "metricx_qe_score": 3.659334421157837, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die Folie höher ist, nehmen wir dies als Hinweis darauf, dass die beschriftete Folie unter Plausibilitätsverzerrung oder anderen sprachlichen Verzerrungen leiden könnte.", "metrics": {"bleu_score": 17.3118788776567, "chrf_score": 57.37510393037722, "xcomet_score": 0.7806734442710876, "xcomet_qe_score": 0.7729219198226929, "metricx_score": 5.170084476470947, "metricx_qe_score": 3.1797666549682617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Es ist interessant zu beobachten, dass in einigen Fällen die Text-only-GPT-Modelle die Plausibilität der Welt besser erfasst haben als die Vision- und Sprachmodelle.", "metrics": {"bleu_score": 57.978239744332505, "chrf_score": 80.00302860218257, "xcomet_score": 0.9651898145675659, "xcomet_qe_score": 0.9631242752075195, "metricx_score": 2.728938579559326, "metricx_qe_score": 1.9459929466247559, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend ist VALSE ein Benchmark, der die Linse sprachlicher Konstrukte nutzt, um der Gemeinschaft zu helfen, Seh- und Sprachmodelle zu verbessern, indem er deren visuelle Begründungsmöglichkeiten gründlich testet.", "metrics": {"bleu_score": 9.079416511678337, "chrf_score": 50.60057455997497, "xcomet_score": 0.9443161487579346, "xcomet_qe_score": 0.8666661977767944, "metricx_score": 2.187821388244629, "metricx_qe_score": 2.7734177112579346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und deren Präsenz in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre Wechselbeziehungen und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren.", "metrics": {"bleu_score": 51.203696730285166, "chrf_score": 70.29992804330689, "xcomet_score": 0.8787615299224854, "xcomet_qe_score": 0.8094558715820312, "metricx_score": 2.762620687484741, "metricx_qe_score": 3.0744781494140625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich dazu ermutigen, Vals zur Messung des Fortschritts bei der sprachlichen Verankerung mit Vision- und Sprachmodellen zu verwenden.", "metrics": {"bleu_score": 40.76128826387552, "chrf_score": 70.22836235497067, "xcomet_score": 0.8061509728431702, "xcomet_qe_score": 0.8300650715827942, "metricx_score": 3.6033968925476074, "metricx_qe_score": 4.896855354309082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und mehr noch, Ventile könnten als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz den Modellen bei der Verbesserung der von Ventilen getesteten Aspekte hilft.", "metrics": {"bleu_score": 45.08250975606119, "chrf_score": 70.16207336202507, "xcomet_score": 0.723054051399231, "xcomet_qe_score": 0.7488691806793213, "metricx_score": 10.643782615661621, "metricx_qe_score": 10.490955352783203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, überprüfen Sie die Valse-Daten auf GitHub und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren.", "metrics": {"bleu_score": 42.76870065071357, "chrf_score": 63.852447176173435, "xcomet_score": 0.956834077835083, "xcomet_qe_score": 0.9551780223846436, "metricx_score": 0.9542456865310669, "metricx_qe_score": 1.1496713161468506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamisara von der Universität Tokio.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 85.90010292854612, "xcomet_score": 0.8411325216293335, "xcomet_qe_score": 0.8582547307014465, "metricx_score": 3.293498992919922, "metricx_qe_score": 2.8148841857910156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Vortrag mit dem Titel „R und Sum – ein umfangreicher Datensatz für die automatische Risikobewertung statt Dauer durch eine Komiteelog-Zusammenfassung“ halten.", "metrics": {"bleu_score": 3.333744983027298, "chrf_score": 24.11562281642189, "xcomet_score": 0.6458002328872681, "xcomet_qe_score": 0.6732739210128784, "metricx_score": 7.971848964691162, "metricx_qe_score": 9.274961471557617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 88.05371765891114, "xcomet_score": 0.9900722503662109, "xcomet_qe_score": 0.983869731426239, "metricx_score": 0.4221750497817993, "metricx_qe_score": 0.7891620397567749, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikoneutralisierung vorstellen, an der wir in dieser Forschung arbeiten.", "metrics": {"bleu_score": 71.9548353625319, "chrf_score": 76.16346674535282, "xcomet_score": 0.7578198313713074, "xcomet_qe_score": 0.7835947871208191, "metricx_score": 5.934166431427002, "metricx_qe_score": 4.448812484741211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Ein Release-Hinweis ist ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Version eines Softwareprodukts verteilt werden.", "metrics": {"bleu_score": 78.78025709745913, "chrf_score": 85.58338921584, "xcomet_score": 0.9723960161209106, "xcomet_qe_score": 0.9743133187294006, "metricx_score": 0.42971330881118774, "metricx_qe_score": 0.3461042046546936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt eine Forschungsnotiz für Bajan 2.6.", "metrics": {"bleu_score": 16.14682615668325, "chrf_score": 32.31306942494337, "xcomet_score": 0.3202108144760132, "xcomet_qe_score": 0.2678188681602478, "metricx_score": 7.652360439300537, "metricx_qe_score": 9.451106071472168, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Userious-Bibliothek. Diese Knoten spielen eine wichtige Rolle in der Open-Source-Entwicklung, aber sie sind zeitaufwendig, wenn sie manuell vorbereitet werden.", "metrics": {"bleu_score": 9.849349468888725, "chrf_score": 56.25239911048882, "xcomet_score": 0.7796899080276489, "xcomet_qe_score": 0.7870379686355591, "metricx_score": 9.05561637878418, "metricx_qe_score": 11.16164779663086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, automatisch hochwertige Versionshinweise zu erstellen.", "metrics": {"bleu_score": 31.46660996956415, "chrf_score": 63.1928417989476, "xcomet_score": 0.9991512298583984, "xcomet_qe_score": 0.9856826066970825, "metricx_score": 0.40793439745903015, "metricx_qe_score": 0.49929553270339966, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mich auf zwei frühere Forschungen zur automatischen Risikobewertung beziehen.", "metrics": {"bleu_score": 12.192091596713041, "chrf_score": 48.262939575732915, "xcomet_score": 0.7720921039581299, "xcomet_qe_score": 0.8598228693008423, "metricx_score": 5.814689636230469, "metricx_qe_score": 1.8554106950759888, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens Arena, das im Jahr 2014 veröffentlicht wurde. Es ist", "metrics": {"bleu_score": 45.27471870952891, "chrf_score": 62.919275527374595, "xcomet_score": 0.9222451448440552, "xcomet_qe_score": 0.8562582731246948, "metricx_score": 4.655970096588135, "metricx_qe_score": 1.039899468421936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es wird ein regelbasierter Ansatz verwendet, bei dem beispielsweise der Änderungs-Extractor verwendet wird, um die wesentlichen Unterschiede, Bibliotheksänderungen und Dokumentänderungen aus den Unterschieden zwischen den Versionen zu extrahieren und sie schließlich zu kombinieren.", "metrics": {"bleu_score": 40.85492989646262, "chrf_score": 74.6718525385536, "xcomet_score": 0.9450137615203857, "xcomet_qe_score": 0.9546427130699158, "metricx_score": 0.9465689659118652, "metricx_qe_score": 1.0619127750396729, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das auffälligste Merkmal dieses Systems ist der Issue-Extractor in der oberen rechten Ecke.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 69.51410378159578, "xcomet_score": 0.8349988460540771, "xcomet_qe_score": 0.8857951164245605, "metricx_score": 4.131425380706787, "metricx_qe_score": 3.8075649738311768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dies muss mit dem Thema „Zero“ im Zusammenhang mit dem Ökosystem verknüpft sein und kann nur auf Projekte angewendet werden, die „Zero“ verwenden.", "metrics": {"bleu_score": 37.30515851532068, "chrf_score": 56.35597253219603, "xcomet_score": 0.628160834312439, "xcomet_qe_score": 0.5542745590209961, "metricx_score": 8.518970489501953, "metricx_qe_score": 9.042425155639648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "hier. Mit anderen Worten, es kann für viele Projekte auf GitHub nicht verwendet werden.", "metrics": {"bleu_score": 36.73341329152364, "chrf_score": 80.47209799208214, "xcomet_score": 0.8793346881866455, "xcomet_qe_score": 0.8474425673484802, "metricx_score": 1.9433190822601318, "metricx_qe_score": 2.9848616123199463, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite ist Trauer. Dieser Eintrag wurde in vierundzwanzig angekündigt.", "metrics": {"bleu_score": 8.91376552139813, "chrf_score": 36.97148081390423, "xcomet_score": 0.5696654319763184, "xcomet_qe_score": 0.6176115870475769, "metricx_score": 17.84369468688965, "metricx_qe_score": 13.502236366271973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "twenty twenty. Es ist im Internet verfügbar und kann über PIP installiert werden.", "metrics": {"bleu_score": 57.02822264405544, "chrf_score": 85.45587272171169, "xcomet_score": 0.8767707347869873, "xcomet_qe_score": 0.8766701221466064, "metricx_score": 3.7079882621765137, "metricx_qe_score": 4.545970439910889, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, auf Laufzeit basierendes Textklassifizierungsmodell und ordnet jeder Eingabeaufgabenmeldung eine von fünf Etiketten zu, wie z. B. Funktionen oder Fehlerbehebungen.", "metrics": {"bleu_score": 28.72825463059374, "chrf_score": 61.936747013336344, "xcomet_score": 0.8405783176422119, "xcomet_qe_score": 0.8337393999099731, "metricx_score": 2.376645565032959, "metricx_qe_score": 1.432440161705017, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Beispiel für eine Verwendung, die eine korrigierende oder fehlerbehebende Rückmeldung liefert.", "metrics": {"bleu_score": 7.692375026049747, "chrf_score": 37.278055618482526, "xcomet_score": 0.945517897605896, "xcomet_qe_score": 0.9662061929702759, "metricx_score": 1.5092865228652954, "metricx_qe_score": 1.2709238529205322, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsdaten für Graves sind ziemlich klein, etwa fünftausend, und werden in den unten beschriebenen Experimenten gezeigt.", "metrics": {"bleu_score": 67.09293368821515, "chrf_score": 81.7390317369144, "xcomet_score": 0.7940101027488708, "xcomet_qe_score": 0.8045228719711304, "metricx_score": 5.788893699645996, "metricx_qe_score": 6.999545097351074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des statistischen Grafikplanungsmodells ist nicht höher.", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 57.52306638658291, "xcomet_score": 0.7455767393112183, "xcomet_qe_score": 0.8119046688079834, "metricx_score": 6.4392266273498535, "metricx_qe_score": 9.374103546142578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich stelle zwei verwandte Forschungen vor, aber es gibt Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen.", "metrics": {"bleu_score": 19.90581597344524, "chrf_score": 68.69849392827619, "xcomet_score": 0.985526442527771, "xcomet_qe_score": 0.9883807897567749, "metricx_score": 1.1597368717193604, "metricx_qe_score": 0.34474772214889526, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit löst diese beiden Probleme und erstellt automatisch hochwertige Versionshinweise.", "metrics": {"bleu_score": 17.62522535975287, "chrf_score": 64.89951497950884, "xcomet_score": 0.9785851240158081, "xcomet_qe_score": 0.942573070526123, "metricx_score": 0.8507263660430908, "metricx_qe_score": 0.7995465397834778, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das Programm zur begrenzten Anwendbarkeit schlagen wir eine hochwertige Klassifizierungs- und Zusammenfassungsmethode vor, die nur Ausschussnachrichten als Eingabe verwendet.", "metrics": {"bleu_score": 42.07643463510615, "chrf_score": 69.02720349309665, "xcomet_score": 0.7606741189956665, "xcomet_qe_score": 0.7718231678009033, "metricx_score": 6.767330646514893, "metricx_qe_score": 6.229933261871338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Repositorien verwendet werden.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 95.11418954579285, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1226445809006691, "metricx_qe_score": 0.19834718108177185, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der knappen Datenressourcen haben wir einen RNSM-Datensatz mit etwa achtundachtzigtausend Datensätzen erstellt, indem wir Daten aus öffentlichen GitHub-Repositories mithilfe der GitHub-API gesammelt haben.", "metrics": {"bleu_score": 41.41137575702457, "chrf_score": 71.2732480887238, "xcomet_score": 0.9813233613967896, "xcomet_qe_score": 0.9715926647186279, "metricx_score": 2.5483715534210205, "metricx_qe_score": 1.9460238218307495, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich unsere Wüste.", "metrics": {"bleu_score": 13.540372457315735, "chrf_score": 56.65371525150881, "xcomet_score": 0.7790601253509521, "xcomet_qe_score": 0.7862811088562012, "metricx_score": 7.6902995109558105, "metricx_qe_score": 8.631659507751465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten.", "metrics": {"bleu_score": 19.721218241637786, "chrf_score": 60.614263059545905, "xcomet_score": 0.9531964063644409, "xcomet_qe_score": 0.9582484364509583, "metricx_score": 0.32169288396835327, "metricx_qe_score": 0.6557445526123047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist eine Commit-Nachricht und die rechte Seite ist ein Release-Hinweis.", "metrics": {"bleu_score": 25.919218840980953, "chrf_score": 55.38374446830764, "xcomet_score": 0.8914765119552612, "xcomet_qe_score": 0.8570623397827148, "metricx_score": 1.137716293334961, "metricx_qe_score": 1.0633834600448608, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund, warum Notizen als Verbesserungen, Büroarbeiten usw. geliebt werden", "metrics": {"bleu_score": 14.458924666162856, "chrf_score": 39.900013179910474, "xcomet_score": 0.2024839222431183, "xcomet_qe_score": 0.1464024782180786, "metricx_score": 11.554696083068848, "metricx_qe_score": 15.62514591217041, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Commit-Nachrichten als Eingabe verwendet und die Rohschweißnotizen übertrifft.", "metrics": {"bleu_score": 41.73395339580241, "chrf_score": 61.11306528273266, "xcomet_score": 0.7587565183639526, "xcomet_qe_score": 0.6711056232452393, "metricx_score": 7.979122638702393, "metricx_qe_score": 7.558347225189209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassung betrachtet werden.", "metrics": {"bleu_score": 35.640264633541825, "chrf_score": 70.59235623874235, "xcomet_score": 0.9989168643951416, "xcomet_qe_score": 0.9841593503952026, "metricx_score": 0.2331073135137558, "metricx_qe_score": 0.43441444635391235, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Rubriken für Features, Verbesserungen, Fehlerbehebungen, Deprecationen, Entfernungen und Breaking Changes vordefiniert.", "metrics": {"bleu_score": 27.447938256311044, "chrf_score": 52.63446853538418, "xcomet_score": 0.6774689555168152, "xcomet_qe_score": 0.7892779111862183, "metricx_score": 5.271586894989014, "metricx_qe_score": 3.479109525680542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden auf der Grundlage früherer Forschungen und anderer Faktoren festgelegt.", "metrics": {"bleu_score": 42.86982293646294, "chrf_score": 83.72819307446454, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09534885734319687, "metricx_qe_score": 0.20928341150283813, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund, warum die Hinweise unten rechts aus den Hinweisen unten links extrahiert werden.", "metrics": {"bleu_score": 13.834368456410951, "chrf_score": 62.6619520673275, "xcomet_score": 0.4777930974960327, "xcomet_qe_score": 0.22031298279762268, "metricx_score": 4.093996047973633, "metricx_qe_score": 5.567152500152588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zeitpunkt ist es notwendig, die vier im Voraus eingerichteten Müllbehälter zu erkennen.", "metrics": {"bleu_score": 14.152447972070973, "chrf_score": 45.408402319923916, "xcomet_score": 0.8183265924453735, "xcomet_qe_score": 0.81708163022995, "metricx_score": 4.228969573974609, "metricx_qe_score": 3.6117606163024902, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "aber die Lacher stimmen nicht immer mit jeder Freiheit überein,", "metrics": {"bleu_score": 13.950796967929138, "chrf_score": 32.6716719713993, "xcomet_score": 0.2827628254890442, "xcomet_qe_score": 0.13466216623783112, "metricx_score": 15.57054328918457, "metricx_qe_score": 14.430702209472656, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel erhöht der Verbesserungs-Treiber Verbesserungen, Erweiterungen, Optimierungen und so weiter.", "metrics": {"bleu_score": 59.5640359271809, "chrf_score": 68.24404287655362, "xcomet_score": 0.8545859456062317, "xcomet_qe_score": 0.8327852487564087, "metricx_score": 8.941533088684082, "metricx_qe_score": 8.73165512084961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben für jede dieser Rotationsvarianten eine Vokabelliste mit etwa dreißig Zahlen erstellt.", "metrics": {"bleu_score": 17.96071710171446, "chrf_score": 64.70624894298622, "xcomet_score": 0.8059388399124146, "xcomet_qe_score": 0.8376946449279785, "metricx_score": 7.232810020446777, "metricx_qe_score": 7.356566905975342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um den RIS-Fehler zu erkennen und den Rest des Textes als RIS-Fehler-Satz für die Kruste zu korrigieren.", "metrics": {"bleu_score": 5.121721695550078, "chrf_score": 25.3676849242814, "xcomet_score": 0.14471758902072906, "xcomet_qe_score": 0.1330237239599228, "metricx_score": 12.075697898864746, "metricx_qe_score": 8.797711372375488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes folgt eine Mitteilung des Komitees.", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 54.06282077751562, "xcomet_score": 0.8431663513183594, "xcomet_qe_score": 0.8846864104270935, "metricx_score": 4.321789741516113, "metricx_qe_score": 4.900452136993408, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Commit-Nachrichten sind nicht an jeden Fehler gebunden.", "metrics": {"bleu_score": 36.28241434631104, "chrf_score": 63.34809714075459, "xcomet_score": 0.8548795580863953, "xcomet_qe_score": 0.8237502574920654, "metricx_score": 6.279853343963623, "metricx_qe_score": 6.0449347496032715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der Abbildung unten gezeigt, wenn das aktuelle Risiko zwischen eintausend zwei Punkt fünf und neunzehn liegt, müssen wir feststellen", "metrics": {"bleu_score": 8.170731914355969, "chrf_score": 34.07613601665495, "xcomet_score": 0.2732641398906708, "xcomet_qe_score": 0.4018833339214325, "metricx_score": 22.50648307800293, "metricx_qe_score": 20.70918083190918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Archivieren Sie die vorherige Versionsausgabe 2.5.18 und erhalten Sie deren Differenz. Das ist etwas langweilig und es reicht nicht aus, einfach eine Liste der Ausgaben zu erhalten und sich das Vorher und Nachher anzusehen.", "metrics": {"bleu_score": 16.503993118366616, "chrf_score": 47.38381539389964, "xcomet_score": 0.5799669027328491, "xcomet_qe_score": 0.4450766444206238, "metricx_score": 11.951250076293945, "metricx_qe_score": 11.61830997467041, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er erstellte eine heuristische Zuordnung für Blau, um die vorherige und die nächste Veranstaltung zu erhalten.", "metrics": {"bleu_score": 38.05371078682543, "chrf_score": 57.50965240436764, "xcomet_score": 0.737636387348175, "xcomet_qe_score": 0.7450333833694458, "metricx_score": 13.714120864868164, "metricx_qe_score": 12.509283065795898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind sie, die Pferde.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 10.50727259570157, "xcomet_score": 0.12412470579147339, "xcomet_qe_score": 0.09917774796485901, "metricx_score": 5.151971340179443, "metricx_qe_score": 9.658624649047852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende, siebentausendzweihundert Repositories", "metrics": {"bleu_score": 8.697972365316721, "chrf_score": 36.525647379832435, "xcomet_score": 0.7562354803085327, "xcomet_qe_score": 0.675834059715271, "metricx_score": 17.601245880126953, "metricx_qe_score": 16.724950790405273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der freigegebenen Knoten-Token dreiundsechzig, was für eine Zusammenfassung recht hoch ist.", "metrics": {"bleu_score": 41.15109772030928, "chrf_score": 66.11866585016188, "xcomet_score": 0.882499635219574, "xcomet_qe_score": 0.8621060252189636, "metricx_score": 6.8648457527160645, "metricx_qe_score": 5.357515811920166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Anzahl der eindeutigen Token ist mit achtundachtzigtausenddreihunderttausend recht groß. Dies ist einer der", "metrics": {"bleu_score": 28.295596283263514, "chrf_score": 61.17550512617258, "xcomet_score": 0.750051736831665, "xcomet_qe_score": 0.7201061248779297, "metricx_score": 6.649034023284912, "metricx_qe_score": 4.66241455078125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl einzigartiger Klassen und Methodennerven, die im Repertoire zu finden sind.", "metrics": {"bleu_score": 3.4585921141027365, "chrf_score": 36.35612688496085, "xcomet_score": 0.8564918637275696, "xcomet_qe_score": 0.8477431535720825, "metricx_score": 2.6987438201904297, "metricx_qe_score": 1.7534147500991821, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes werde ich die vorgeschlagene Methode erläutern.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das quer-extraktive und abstrahierende Summierungsmodell besteht aus zwei neueren Modulen", "metrics": {"bleu_score": 14.301399262246576, "chrf_score": 59.35883516434867, "xcomet_score": 0.7747782468795776, "xcomet_qe_score": 0.8060005903244019, "metricx_score": 5.857452869415283, "metricx_qe_score": 5.449555397033691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifikator, der Bot oder Code-Bot verwendet, und ein Generator, der Bot verwendet.", "metrics": {"bleu_score": 12.39899236095509, "chrf_score": 65.25232341325808, "xcomet_score": 0.7267606258392334, "xcomet_qe_score": 0.6768394708633423, "metricx_score": 8.4385986328125, "metricx_qe_score": 9.88459300994873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Kreuzwert, um jede Kommitee-Nachricht in fünf Disnodeklassen zu klassifizieren: Features, Verbesserungen, Fehlerbehebungen, Duplikate und andere.", "metrics": {"bleu_score": 15.542549544776186, "chrf_score": 53.4618648828285, "xcomet_score": 0.6434114575386047, "xcomet_qe_score": 0.5958520174026489, "metricx_score": 8.440598487854004, "metricx_qe_score": 7.5966901779174805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als Sonstiges eingestuften Komiteemitteilungen werden verworfen.", "metrics": {"bleu_score": 27.054113452696992, "chrf_score": 60.979060654802595, "xcomet_score": 0.9693200588226318, "xcomet_qe_score": 0.9111208915710449, "metricx_score": 2.854755401611328, "metricx_qe_score": 2.491774559020996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wendet GES den Generator unabhängig auf die vier Router-Dokumente an und generiert Risikobemerkungen für jede Klasse.", "metrics": {"bleu_score": 22.095434806633396, "chrf_score": 50.08350484583068, "xcomet_score": 0.6917266845703125, "xcomet_qe_score": 0.7052468657493591, "metricx_score": 7.710411071777344, "metricx_qe_score": 7.376220226287842, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Zusammenhänge zwischen Commit-Nachrichten und Lesebestätigungen nicht bekannt.", "metrics": {"bleu_score": 53.33505353503043, "chrf_score": 68.28829699047371, "xcomet_score": 0.8622483015060425, "xcomet_qe_score": 0.8512316942214966, "metricx_score": 1.9708213806152344, "metricx_qe_score": 1.9146403074264526, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifikator zu trainieren, weisen wir daher jedem Eingabekommittennachricht Pseudorubine zu, indem wir die ersten zehn Zeichen jeder Kommittennachricht verwenden.", "metrics": {"bleu_score": 35.711505008239, "chrf_score": 62.14007032535832, "xcomet_score": 0.7980047464370728, "xcomet_qe_score": 0.8597161173820496, "metricx_score": 10.837059020996094, "metricx_qe_score": 9.67134952545166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die quer-obstruktive Zusammenfassung, also den Ansatz, mit zwei verschiedenen Methoden.", "metrics": {"bleu_score": 3.9297193407553004, "chrf_score": 51.28236243932961, "xcomet_score": 0.7896707057952881, "xcomet_qe_score": 0.7788470983505249, "metricx_score": 8.935827255249023, "metricx_qe_score": 7.820403575897217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzelnen Sekt-zu-Sekt-Netzwerk und generiert einen einzigen langen isNote-Text, wenn eine Konkretheit der Eingabe-Commit-Nachrichten gegeben ist.", "metrics": {"bleu_score": 34.603412045868055, "chrf_score": 65.70377146204106, "xcomet_score": 0.44514182209968567, "xcomet_qe_score": 0.48626992106437683, "metricx_score": 15.925010681152344, "metricx_qe_score": 17.369857788085938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgabetext kann in Quersegmente unterteilt werden, basierend auf speziellen querspezifischen Endpunktsymbolen.", "metrics": {"bleu_score": 6.191082705295718, "chrf_score": 49.83808836610758, "xcomet_score": 0.9102205038070679, "xcomet_qe_score": 0.9187856912612915, "metricx_score": 4.404232501983643, "metricx_qe_score": 3.338106870651245, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir CSMarch nennen, besteht aus vier verschiedenen sec-to-sec-Netzwerken, von denen jedes einer der Listenknotenklassen entspricht.", "metrics": {"bleu_score": 60.80105469061645, "chrf_score": 74.54928047098625, "xcomet_score": 0.6314088702201843, "xcomet_qe_score": 0.6288274526596069, "metricx_score": 8.881420135498047, "metricx_qe_score": 8.916733741760254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das erklärt Fans Experiment.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 36.82617140297801, "xcomet_score": 0.8116499185562134, "xcomet_qe_score": 0.876292884349823, "metricx_score": 6.906456470489502, "metricx_qe_score": 5.262182712554932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen: CAS, CAS single, CAS mouth, Prasseling und vorherige Kurzstudie.", "metrics": {"bleu_score": 22.617373614366574, "chrf_score": 53.04186093478581, "xcomet_score": 0.6168363690376282, "xcomet_qe_score": 0.6198907494544983, "metricx_score": 12.402546882629395, "metricx_qe_score": 13.569756507873535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Abtreibung werden diese Hinweise in manchen Fällen in mehreren Sätzen ausgegeben.", "metrics": {"bleu_score": 24.132419941840606, "chrf_score": 52.19235059445752, "xcomet_score": 0.8014376163482666, "xcomet_qe_score": 0.8162506818771362, "metricx_score": 12.931951522827148, "metricx_qe_score": 6.625919342041016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt.", "metrics": {"bleu_score": 77.09002428237393, "chrf_score": 90.47656401175612, "xcomet_score": 0.876798689365387, "xcomet_qe_score": 0.8787704706192017, "metricx_score": 5.31808614730835, "metricx_qe_score": 6.5746684074401855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro wird durchdrungen, wenn das System einen kurzen Satz ausgibt", "metrics": {"bleu_score": 58.10588684968076, "chrf_score": 63.45432806447119, "xcomet_score": 0.7679616212844849, "xcomet_qe_score": 0.7670672535896301, "metricx_score": 10.14769172668457, "metricx_qe_score": 10.7294340133667, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Braugebinnis in den nachfolgend beschriebenen Versuchsergebnissen.", "metrics": {"bleu_score": 48.44273237963865, "chrf_score": 71.73987635870145, "xcomet_score": 0.8042153120040894, "xcomet_qe_score": 0.8228168487548828, "metricx_score": 7.328380584716797, "metricx_qe_score": 8.633286476135254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich korrigieren wir auch eine Besonderheit, da Rouge und Brue nicht korrigiert werden können, wenn die Freisetzungsknoten leer sind.", "metrics": {"bleu_score": 27.19326877457978, "chrf_score": 48.20812461949599, "xcomet_score": 0.5803816318511963, "xcomet_qe_score": 0.6367624402046204, "metricx_score": 8.966833114624023, "metricx_qe_score": 8.070575714111328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell in Fällen, in denen die Begründungshinweise leer sind, korrekt leere Texte ausgibt.", "metrics": {"bleu_score": 56.80635025297613, "chrf_score": 73.48160489255243, "xcomet_score": 0.9642781019210815, "xcomet_qe_score": 0.9577279686927795, "metricx_score": 4.233248233795166, "metricx_qe_score": 4.261234760284424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse.", "metrics": {"bleu_score": 42.72870063962342, "chrf_score": 48.96283815298874, "xcomet_score": 0.9982582330703735, "xcomet_qe_score": 0.9951757192611694, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, löschen wir auch den Druckdatensatz, der diese ausschließt.", "metrics": {"bleu_score": 64.03113144057492, "chrf_score": 74.06328546580792, "xcomet_score": 0.811581015586853, "xcomet_qe_score": 0.8407421708106995, "metricx_score": 8.071828842163086, "metricx_qe_score": 7.18763542175293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat große Luftpunkte erreicht, die mehr als zehn Punkte über dem Basiswert liegen.", "metrics": {"bleu_score": 38.50322886878711, "chrf_score": 49.30657311405526, "xcomet_score": 0.6126563549041748, "xcomet_qe_score": 0.6677190065383911, "metricx_score": 10.674118995666504, "metricx_qe_score": 12.202075004577637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere beim grünen Testset sprang die quadratische Lücke zwischen der vorgeschlagenen Methode und dem Basiswert auf mehr als zwanzig Punkte.", "metrics": {"bleu_score": 37.39214909689668, "chrf_score": 63.40735666189023, "xcomet_score": 0.7626857757568359, "xcomet_qe_score": 0.7623178958892822, "metricx_score": 7.762388229370117, "metricx_qe_score": 7.543434143066406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse deuten darauf hin, dass sie und sie signifikant wirksam sind.", "metrics": {"bleu_score": 10.571070857151541, "chrf_score": 49.244730956925146, "xcomet_score": 0.3358173370361328, "xcomet_qe_score": 0.2099924385547638, "metricx_score": 10.677261352539062, "metricx_qe_score": 12.240510940551758, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS erzielte einen besseren Rouge-F-Score als GAS, was darauf hindeutet, dass die Kombination eines Crossfire und eines Generators effektiv für das Training des Crossfire mit Pseudobus ist.", "metrics": {"bleu_score": 36.3791759842712, "chrf_score": 59.251943387140784, "xcomet_score": 0.32972845435142517, "xcomet_qe_score": 0.35115447640419006, "metricx_score": 16.892255783081055, "metricx_qe_score": 16.745220184326172, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, weil der Klassifikator sich darauf konzentrieren kann, relevante Commit-Nachrichten für jede Klasse auszuwählen.", "metrics": {"bleu_score": 43.02123694194219, "chrf_score": 81.29529616235075, "xcomet_score": 0.8478903770446777, "xcomet_qe_score": 0.871589183807373, "metricx_score": 4.708438873291016, "metricx_qe_score": 5.794610500335693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie isst dieses Jahr viel mehr als sonst,", "metrics": {"bleu_score": 5.669791110976001, "chrf_score": 13.11611489899493, "xcomet_score": 0.12226612120866776, "xcomet_qe_score": 0.11440174281597137, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es ebenfalls effektiv ist, für jede Ansicht des Notizfelds für Gras eigenständige Modelle zur Zusammenfassung der zweijährigen Perspektive zu entwickeln.", "metrics": {"bleu_score": 13.75686194233942, "chrf_score": 39.920484728984796, "xcomet_score": 0.3542948067188263, "xcomet_qe_score": 0.4838419258594513, "metricx_score": 13.46605396270752, "metricx_qe_score": 12.419468879699707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Held und Eronasus", "metrics": {"bleu_score": 0.0, "chrf_score": 7.279375851520527, "xcomet_score": 0.20181190967559814, "xcomet_qe_score": 0.07988241314888, "metricx_score": 12.229496002197266, "metricx_qe_score": 21.2924861907959, "linguapy_score": [1, "ESTONIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xias Methoden neigen dazu, kürzere Sätze als menschliche Referenzsätze zu erzeugen.", "metrics": {"bleu_score": 15.133218633429316, "chrf_score": 63.321009056137314, "xcomet_score": 0.8414553999900818, "xcomet_qe_score": 0.7811298370361328, "metricx_score": 3.7409327030181885, "metricx_qe_score": 6.066111087799072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung rechts hat der Referenzsatz drei oder vier Sätze, während sie nur einen hat.", "metrics": {"bleu_score": 22.095434806633396, "chrf_score": 65.30347734727992, "xcomet_score": 0.8954623937606812, "xcomet_qe_score": 0.8761724829673767, "metricx_score": 4.278946876525879, "metricx_qe_score": 4.440934181213379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzurückhaltung ist, dass in den Trainingsdaten nur 33 % der Sätze in den Merkmalsrubriken enthalten sind und 40 % in den Verbesserungsrubriken.", "metrics": {"bleu_score": 30.873604434250225, "chrf_score": 53.25234030803758, "xcomet_score": 0.8673402070999146, "xcomet_qe_score": 0.9527055025100708, "metricx_score": 2.6453702449798584, "metricx_qe_score": 2.6144256591796875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES-Methoden ohne zusätzliche Informationen keine genauen Risikobewertungen erstellen.", "metrics": {"bleu_score": 46.59538415189962, "chrf_score": 79.06398621238986, "xcomet_score": 0.8027787208557129, "xcomet_qe_score": 0.939699113368988, "metricx_score": 5.119899272918701, "metricx_qe_score": 3.5508005619049072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das oberste Beispiel rechts ist ein Beispiel für eine sehr chaotische Komiteemitteilung, und der vollständige Satz kann nicht ohne Bezugnahme auf die entsprechende Peru-Anfrage oder das entsprechende Problem generiert werden.", "metrics": {"bleu_score": 35.258590512600755, "chrf_score": 61.64313448117935, "xcomet_score": 0.8022403717041016, "xcomet_qe_score": 0.8143411874771118, "metricx_score": 7.7577595710754395, "metricx_qe_score": 6.874503135681152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden Commit-Nachrichten in der Eingabe miteinander verknüpft sind und in einen Satz kombiniert werden sollten, was jedoch nicht geschieht.", "metrics": {"bleu_score": 58.217473175544946, "chrf_score": 69.93370725971467, "xcomet_score": 0.9830095767974854, "xcomet_qe_score": 0.989694356918335, "metricx_score": 0.6336588859558105, "metricx_qe_score": 1.0152636766433716, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend eine Schlussfolgerung.", "metrics": {"bleu_score": 9.688464563433238, "chrf_score": 8.61068339763784, "xcomet_score": 0.9979920387268066, "xcomet_qe_score": 1.0, "metricx_score": 0.516656219959259, "metricx_qe_score": 0.07823039591312408, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Schreibtisch-Set für die automatische Personen-Generierung gebaut,", "metrics": {"bleu_score": 28.291332071489855, "chrf_score": 53.86608619052308, "xcomet_score": 0.599378228187561, "xcomet_qe_score": 0.6063952445983887, "metricx_score": 19.087419509887695, "metricx_qe_score": 14.771162033081055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben uns auch die Aufgabe gestellt, Ausschussmitteilungen einzugeben und zu zusammenzufassen, damit sie für alle in Englisch verfassten Projekte anwendbar sind.", "metrics": {"bleu_score": 9.415476131384017, "chrf_score": 43.373078052581725, "xcomet_score": 0.8379451036453247, "xcomet_qe_score": 0.8468767404556274, "metricx_score": 5.203919410705566, "metricx_qe_score": 5.523608207702637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode die besten Ergebnisse bei höherer Abdeckung als der Basisanstieg nicht aufgrund von Rauschen liefert.", "metrics": {"bleu_score": 32.2888846243622, "chrf_score": 57.39821935349335, "xcomet_score": 0.757644534111023, "xcomet_qe_score": 0.7717962265014648, "metricx_score": 7.197088718414307, "metricx_qe_score": 8.24512767791748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte testen Sie unsere Wüsten-Audit-App.", "metrics": {"bleu_score": 5.484411595600381, "chrf_score": 26.896020668387465, "xcomet_score": 0.16804513335227966, "xcomet_qe_score": 0.15502965450286865, "metricx_score": 5.489988803863525, "metricx_qe_score": 7.973504543304443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 87.72426647426647, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist a safarari,", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 51.94454625654264, "xcomet_score": 0.7884452939033508, "xcomet_qe_score": 0.7862277030944824, "metricx_score": 6.696664333343506, "metricx_qe_score": 6.667305946350098, "linguapy_score": [1, "ROMANIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unseren Artikel vorstellen: „Anreicherung weniger kurzer tabellarischer Daten mit Hilfe von Fine-Tuning-Transformer-Architekturen“.", "metrics": {"bleu_score": 5.439330544349821, "chrf_score": 45.83783656098604, "xcomet_score": 0.9021272659301758, "xcomet_qe_score": 0.9341305494308472, "metricx_score": 4.670626640319824, "metricx_qe_score": 5.309453010559082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Wissenschaftler im Bereich Datenanalyse untersuchen Daten und konzentrieren sich hauptsächlich darauf, die vorhandenen Merkmale der Daten zu manipulieren.", "metrics": {"bleu_score": 20.76047003130265, "chrf_score": 60.13310551806901, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.44928857684135437, "metricx_qe_score": 0.5914640426635742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal sind seine Funktionen jedoch begrenzt.", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 64.00608971343024, "xcomet_score": 0.9848285913467407, "xcomet_qe_score": 0.9813604950904846, "metricx_score": 0.2338239848613739, "metricx_qe_score": 0.19498953223228455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Generierung von Merkmalen unter Verwendung einer anderen Datenquelle kann erhebliche Informationen hinzufügen.", "metrics": {"bleu_score": 53.33505353503043, "chrf_score": 82.18509248514383, "xcomet_score": 0.934609591960907, "xcomet_qe_score": 0.9908032417297363, "metricx_score": 0.7497941255569458, "metricx_qe_score": 0.4627454876899719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Tabellen-Daten-Anreicherung mit freiem Text aus externen Quellen.", "metrics": {"bleu_score": 65.26220818377338, "chrf_score": 81.21621517856362, "xcomet_score": 0.9909963607788086, "xcomet_qe_score": 0.9810761213302612, "metricx_score": 0.518690288066864, "metricx_qe_score": 0.5698849558830261, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben einen tabellarischen Datensatz und eine Wissensdatenbank.", "metrics": {"bleu_score": 57.60844201603898, "chrf_score": 79.00937431964408, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.27129918336868286, "metricx_qe_score": 0.1727202832698822, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intit und Textanalyse umfasst, um neue Merkmale aus dem freien Text der Wissensdatenbank zu extrahieren.", "metrics": {"bleu_score": 44.689472642345265, "chrf_score": 68.15705577083702, "xcomet_score": 0.9120373725891113, "xcomet_qe_score": 0.9134067296981812, "metricx_score": 4.864489555358887, "metricx_qe_score": 5.735929489135742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist genau dieser automatische Prozess.", "metrics": {"bleu_score": 62.401954419369176, "chrf_score": 84.75044971165464, "xcomet_score": 0.8918439149856567, "xcomet_qe_score": 0.888335645198822, "metricx_score": 3.8839259147644043, "metricx_qe_score": 4.871129512786865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns ein Beispiel an. In einem Datensatz wird es in FAST eingespeist.", "metrics": {"bleu_score": 14.382644562327254, "chrf_score": 62.5100118737378, "xcomet_score": 0.8643445372581482, "xcomet_qe_score": 0.8613684177398682, "metricx_score": 5.2984771728515625, "metricx_qe_score": 5.405134677886963, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Datensatz ein Universitätsdatensatz.", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 89.90466953471022, "xcomet_score": 0.9997750520706177, "xcomet_qe_score": 0.9985378980636597, "metricx_score": 0.0, "metricx_qe_score": 0.172540083527565, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "wenn es darum geht, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten einzuteilen.", "metrics": {"bleu_score": 6.608973813188645, "chrf_score": 48.25273496269871, "xcomet_score": 0.9675695896148682, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.764939546585083, "metricx_qe_score": 0.4773743450641632, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase von FEST ist die Entitätsverknüpfung.", "metrics": {"bleu_score": 33.03164318013809, "chrf_score": 54.011727145293676, "xcomet_score": 0.926429271697998, "xcomet_qe_score": 0.9227926731109619, "metricx_score": 3.7848188877105713, "metricx_qe_score": 4.282503128051758, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist jede Entität, der Universitätsname, mit einer Entität in der Wissensdatenbank verknüpft.", "metrics": {"bleu_score": 13.221444357315312, "chrf_score": 66.43125314853019, "xcomet_score": 0.9992901086807251, "xcomet_qe_score": 1.0, "metricx_score": 0.34358224272727966, "metricx_qe_score": 0.4089629650115967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Der Text der Entitäten der Wissensdatenbank wird extrahiert und dem Datensatz hinzugefügt.", "metrics": {"bleu_score": 63.436083375358535, "chrf_score": 83.52314659305554, "xcomet_score": 0.9969322681427002, "xcomet_qe_score": 0.9849759936332703, "metricx_score": 0.4604550302028656, "metricx_qe_score": 0.7611286640167236, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text das Abstract der Wikipedia-Seite.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3184393048286438, "metricx_qe_score": 0.23803302645683289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Nun müssen wir Merkmale aus dem Retriever-Text generieren oder extrahieren.", "metrics": {"bleu_score": 34.53155548318878, "chrf_score": 63.98391559603801, "xcomet_score": 0.9082878232002258, "xcomet_qe_score": 0.9564100503921509, "metricx_score": 2.6036884784698486, "metricx_qe_score": 2.44445538520813, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen daher eine Phasen der Merkmalsextraktion, die eine Textanalyse umfasst.", "metrics": {"bleu_score": 4.308098852550457, "chrf_score": 45.05692673178714, "xcomet_score": 0.9753824472427368, "xcomet_qe_score": 0.9704187512397766, "metricx_score": 4.410046577453613, "metricx_qe_score": 3.9062564373016357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers, und ich werde in den nächsten Folien tief darauf eingehen.", "metrics": {"bleu_score": 11.540436442918624, "chrf_score": 49.811817373530985, "xcomet_score": 0.9366270899772644, "xcomet_qe_score": 0.9441334009170532, "metricx_score": 1.521579384803772, "metricx_qe_score": 2.003983736038208, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Merkmalsextraktionsphase folgt eine Merkmalgenerierungsphase, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren.", "metrics": {"bleu_score": 42.07088992176657, "chrf_score": 58.15047768082773, "xcomet_score": 0.9549112319946289, "xcomet_qe_score": 0.9854632616043091, "metricx_score": 0.38462281227111816, "metricx_qe_score": 0.31377241015434265, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Generieren Sie zunächst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes.", "metrics": {"bleu_score": 57.60844201603898, "chrf_score": 71.56285882802177, "xcomet_score": 0.8871498107910156, "xcomet_qe_score": 0.9078870415687561, "metricx_score": 2.062178134918213, "metricx_qe_score": 2.3905651569366455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen", "metrics": {"bleu_score": 89.483931681437, "chrf_score": 98.49752398086483, "xcomet_score": 0.998803973197937, "xcomet_qe_score": 0.9922256469726562, "metricx_score": 0.17233462631702423, "metricx_qe_score": 0.3795880675315857, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Generieren Sie zunächst zwei neue Merkmale.", "metrics": {"bleu_score": 14.535768424205482, "chrf_score": 35.60764150851362, "xcomet_score": 0.8146731853485107, "xcomet_qe_score": 0.9277145266532898, "metricx_score": 3.8589236736297607, "metricx_qe_score": 2.662846565246582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, generieren Sie zunächst fünf neue Merkmale.", "metrics": {"bleu_score": 53.2800971987552, "chrf_score": 72.8157902247783, "xcomet_score": 0.9390479326248169, "xcomet_qe_score": 0.945482611656189, "metricx_score": 3.5458719730377197, "metricx_qe_score": 3.8177876472473145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jedes Merkmal repräsentiert die Wahrscheinlichkeit für jede Klasse.", "metrics": {"bleu_score": 41.80134288483487, "chrf_score": 66.03373064615856, "xcomet_score": 0.9946569204330444, "xcomet_qe_score": 0.9989062547683716, "metricx_score": 0.4736848473548889, "metricx_qe_score": 0.4538906514644623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Textanalyse, der auf Transformer-basierten Sprachmodellen wie BERT, GPT, XLEDs usw. basiert.", "metrics": {"bleu_score": 51.36268735913038, "chrf_score": 77.38954222618986, "xcomet_score": 0.892256498336792, "xcomet_qe_score": 0.8583552241325378, "metricx_score": 4.038422584533691, "metricx_qe_score": 5.199862957000732, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist unwahrscheinlich, dass wir Sprachmodelle mit den Eingabe-Datensätzen trainieren können.", "metrics": {"bleu_score": 50.698033524721, "chrf_score": 79.88893253122812, "xcomet_score": 0.9910430908203125, "xcomet_qe_score": 0.9834277629852295, "metricx_score": 0.8321244120597839, "metricx_qe_score": 1.4405949115753174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wäre daher eine gezielte Feinabstimmung der Aufgabe.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 54.691902102120046, "xcomet_score": 0.9543554782867432, "xcomet_qe_score": 1.0, "metricx_score": 1.4736865758895874, "metricx_qe_score": 1.4933459758758545, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Merkmalsextraktions-Phase können wir also pro Trainings-Sprachmodell das Sprachmodell über den Zieldatensatz feinabstimmen.", "metrics": {"bleu_score": 40.62196374197349, "chrf_score": 65.27867402019837, "xcomet_score": 0.9648785591125488, "xcomet_qe_score": 0.9211142659187317, "metricx_score": 1.5187385082244873, "metricx_qe_score": 2.3363797664642334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel soll das Sprachmodell verfeinert werden, um Texte in Klassen zu klassifizieren, abstrahieren in Klassen, niedrig oder hoch.", "metrics": {"bleu_score": 16.076749185995254, "chrf_score": 54.74115744962019, "xcomet_score": 0.8717489838600159, "xcomet_qe_score": 0.8358533382415771, "metricx_score": 5.243805885314941, "metricx_qe_score": 5.118057727813721, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen Sie die Ausgabe des Sprachmodells entgegen, die die Wahrscheinlichkeit für jede Klasse darstellt, und verwenden Sie diese als neue Merkmale.", "metrics": {"bleu_score": 55.925988689124864, "chrf_score": 76.76108817104807, "xcomet_score": 0.9111985564231873, "xcomet_qe_score": 0.9504566192626953, "metricx_score": 1.7607396841049194, "metricx_qe_score": 0.8687825202941895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datensätze nur wenige verschiedene Entitätsstapel haben können.", "metrics": {"bleu_score": 50.096893227219766, "chrf_score": 61.1671875427133, "xcomet_score": 0.9279068112373352, "xcomet_qe_score": 0.9184132814407349, "metricx_score": 1.7368135452270508, "metricx_qe_score": 1.8175157308578491, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als vierhundert Proben, und der kleinste Datensatz enthielt fünfunddreißig Proben in seinem Trainingsdatensatz.", "metrics": {"bleu_score": 39.022736644855655, "chrf_score": 71.63389001325353, "xcomet_score": 0.9719887971878052, "xcomet_qe_score": 0.9692212343215942, "metricx_score": 0.8394748568534851, "metricx_qe_score": 0.9142633676528931, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wird das Feinabstimmen eines Sprachmodells mit diesem Datensatz unwirksam sein.", "metrics": {"bleu_score": 8.516593018819643, "chrf_score": 60.45310312729215, "xcomet_score": 0.9917244911193848, "xcomet_qe_score": 0.9892953634262085, "metricx_score": 0.456582248210907, "metricx_qe_score": 0.4526948928833008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorhandenes Wissen über bereits analysierte Datensätze nutzen.", "metrics": {"bleu_score": 47.987820666906615, "chrf_score": 67.6370007790967, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.06788907945156097, "metricx_qe_score": 0.07013900578022003, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir schnell auf mehrere Datensätze anwenden, können wir die N-1-Datensätze nutzen, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen bei der Analyse des n-ten Datensatzes verwenden.", "metrics": {"bleu_score": 34.19880745403971, "chrf_score": 68.41688964376581, "xcomet_score": 0.6710475087165833, "xcomet_qe_score": 0.6248816251754761, "metricx_score": 5.392074108123779, "metricx_qe_score": 5.336583137512207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist eine weitere Feinabstimmungsphase hinzuzufügen.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 85.87863575855958, "xcomet_score": 0.9772741794586182, "xcomet_qe_score": 0.9562488794326782, "metricx_score": 0.8425611257553101, "metricx_qe_score": 0.9712173938751221, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Feinabstimmungsphase für mehrere Aufgaben.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 59.037216242561875, "xcomet_score": 0.9776685237884521, "xcomet_qe_score": 0.9845494031906128, "metricx_score": 1.2031822204589844, "metricx_qe_score": 0.8987575769424438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir während des Sprachmodells über n minus eins Datensätze finden,", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 46.05704235667363, "xcomet_score": 0.7887448072433472, "xcomet_qe_score": 0.775530219078064, "metricx_score": 12.05125617980957, "metricx_qe_score": 12.615208625793457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Feinabstimmungsphase durch, bei der es sich um eine Zielaufgabfeinabstimmung handelt, wenn wir das Sprachmodell anhand des n-ten Zieldatensatzes verfeinern.", "metrics": {"bleu_score": 35.89746259568356, "chrf_score": 69.81536742366067, "xcomet_score": 0.9155382513999939, "xcomet_qe_score": 0.9033188819885254, "metricx_score": 1.4673267602920532, "metricx_qe_score": 1.3790117502212524, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der aktuelle Stand der Technik bei der Multitask-Feinanpassung, genannt MTDNN.", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 43.80012040599225, "xcomet_score": 0.9948821067810059, "xcomet_qe_score": 0.9931203126907349, "metricx_score": 1.2057831287384033, "metricx_qe_score": 1.6179959774017334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN behält MTDNN die Anzahl der Aufgaben im Trainingsdatensatz bei.", "metrics": {"bleu_score": 12.689698066272173, "chrf_score": 43.119633214710575, "xcomet_score": 0.9338164329528809, "xcomet_qe_score": 0.9478851556777954, "metricx_score": 6.026437759399414, "metricx_qe_score": 3.570699691772461, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainingsdatensatz. Leeren Sie also das DNN und behalten Sie vier Köpfe bei, wie Sie auf dem Bild sehen können.", "metrics": {"bleu_score": 52.28804392271881, "chrf_score": 69.9799263640035, "xcomet_score": 0.778306782245636, "xcomet_qe_score": 0.7640283703804016, "metricx_score": 8.181472778320312, "metricx_qe_score": 7.799801349639893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "und es wird eine zufällige Stichprobe aus dem Trainingsdatensatz entnommen.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 48.614980456277415, "xcomet_score": 0.9629402160644531, "xcomet_qe_score": 0.9505178332328796, "metricx_score": 1.8028451204299927, "metricx_qe_score": 2.2252261638641357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "und wenn die zufällige Charge beispielsweise zu den Klassifizierungsaufgaben von Sing und Seldon gehört, führt sie einen Vorwärts-Rückwärts-Pass durch den ersten Kopf aus", "metrics": {"bleu_score": 12.062940248564933, "chrf_score": 44.333646937546696, "xcomet_score": 0.668788492679596, "xcomet_qe_score": 0.6958037614822388, "metricx_score": 6.76422119140625, "metricx_qe_score": 7.370708465576172, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zur paarweisen Sortieaufgabe gehört, wird sie über den letzten Kopf dem Vorwärts- und Rückwärtsweg hinzugefügt.", "metrics": {"bleu_score": 6.962249700749937, "chrf_score": 48.39097876672589, "xcomet_score": 0.7867851257324219, "xcomet_qe_score": 0.7917596697807312, "metricx_score": 5.729798316955566, "metricx_qe_score": 4.121194362640381, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario variiert eine Tabelle von Datensätzen die Anzahl der Klassen.", "metrics": {"bleu_score": 27.968424579665367, "chrf_score": 70.45771935845295, "xcomet_score": 0.9231967926025391, "xcomet_qe_score": 0.8989845514297485, "metricx_score": 3.026820659637451, "metricx_qe_score": 3.0675973892211914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.05911726504564285, "metricx_qe_score": 0.12243705987930298, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN behielt die Anzahl der Klassenköpfe der Ausgabeschichten bei.", "metrics": {"bleu_score": 4.085507150363302, "chrf_score": 28.037350669410333, "xcomet_score": 0.8103566765785217, "xcomet_qe_score": 0.8960884809494019, "metricx_score": 6.22267484664917, "metricx_qe_score": 6.576685428619385, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus muss MTDN neue Köpfe für einen neuen Datensatz mit einer neuen Aufgabe initialisieren.", "metrics": {"bleu_score": 61.000344570143675, "chrf_score": 70.56314249699945, "xcomet_score": 0.8802145719528198, "xcomet_qe_score": 0.9043592214584351, "metricx_score": 5.5652594566345215, "metricx_qe_score": 5.705242156982422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als Task-Reformulierung-Feinabstimmung bezeichnet wird, besteht darin, dass wir – anstatt mehrere Heads beizubehalten – jeden Datensatz in einen Satz pro Klassifikationsproblem umformulieren, bei dem es sich um Aufgaben mit zwei Klassen handelt.", "metrics": {"bleu_score": 29.509281772645696, "chrf_score": 70.06423653459282, "xcomet_score": 0.7938896417617798, "xcomet_qe_score": 0.8183654546737671, "metricx_score": 7.769693851470947, "metricx_qe_score": 6.790990829467773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns ein Beispiel an.", "metrics": {"bleu_score": 80.91067115702207, "chrf_score": 82.06979784224109, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.035305172204971313, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Datensatz, der aus Entitäten, Merkmalen, Text und Klassen besteht.", "metrics": {"bleu_score": 64.52121005104219, "chrf_score": 73.91125005285495, "xcomet_score": 0.9887470006942749, "xcomet_qe_score": 0.9876417517662048, "metricx_score": 0.8849254846572876, "metricx_qe_score": 0.6319785714149475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden die Aufgabe so formulieren, dass wir den Text in niedrig und hoch einteilen, um den Text, das Abstrakt und die Klasse als wahr oder falsch zu klassifizieren.", "metrics": {"bleu_score": 7.205335066302805, "chrf_score": 47.857176652531024, "xcomet_score": 0.8925528526306152, "xcomet_qe_score": 0.8761974573135376, "metricx_score": 2.368173837661743, "metricx_qe_score": 1.8134195804595947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten: Wir trainierten das Sprachmodell, um Abstrakte und Klassen zu klassifizieren, und zwar als abstrakt und zur Klasse gehörig, wenn der Abstrakte zur Klasse gehörte, oder nicht.", "metrics": {"bleu_score": 18.164305788156724, "chrf_score": 59.75711235954054, "xcomet_score": 0.6925162672996521, "xcomet_qe_score": 0.6140041351318359, "metricx_score": 3.7663159370422363, "metricx_qe_score": 5.490483283996582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Label-Vektor bleibt in diesem Fall also immer gleich, der immer aus zwei Klassen besteht.", "metrics": {"bleu_score": 37.709297891717654, "chrf_score": 58.07414856881879, "xcomet_score": 0.9513887166976929, "xcomet_qe_score": 0.8809167146682739, "metricx_score": 1.63785982131958, "metricx_qe_score": 2.001210927963257, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren formulierten Feinabstimmungsansatz.", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 85.90649345126857, "xcomet_score": 0.9060694575309753, "xcomet_qe_score": 0.8523393273353577, "metricx_score": 2.560305595397949, "metricx_qe_score": 3.0909786224365234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns also den vollständigen Rahmen an.", "metrics": {"bleu_score": 43.167001068522545, "chrf_score": 62.61096584754464, "xcomet_score": 0.9491994976997375, "xcomet_qe_score": 0.9430612921714783, "metricx_score": 0.7002825140953064, "metricx_qe_score": 0.9148326516151428, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und Datensätze verblassen schnell.", "metrics": {"bleu_score": 7.16047614494885, "chrf_score": 18.608227952586994, "xcomet_score": 0.1412542164325714, "xcomet_qe_score": 0.14303089678287506, "metricx_score": 9.275513648986816, "metricx_qe_score": 10.880698204040527, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Phase der Entitätsverknüpfung.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 21.78325800714219, "xcomet_score": 0.9262211322784424, "xcomet_qe_score": 0.9149888157844543, "metricx_score": 5.311716556549072, "metricx_qe_score": 6.706035614013672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensdatenbank, in diesem Beispiel den Abstract der Wikipedia-Seite.", "metrics": {"bleu_score": 42.1262979301172, "chrf_score": 79.27585002650149, "xcomet_score": 0.9855296611785889, "xcomet_qe_score": 0.9553920030593872, "metricx_score": 0.9722869396209717, "metricx_qe_score": 1.2876640558242798, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend formuliert es die Aufgabe für jede Klassifizierungsaufgabe in einen Satz um.", "metrics": {"bleu_score": 15.133218633429316, "chrf_score": 54.465187439779925, "xcomet_score": 0.8762243390083313, "xcomet_qe_score": 0.8616666793823242, "metricx_score": 1.9284802675247192, "metricx_qe_score": 2.812605619430542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe und die Ausgabewahrscheinlichkeit für jede Klasse an.", "metrics": {"bleu_score": 61.000344570143675, "chrf_score": 84.11076086933832, "xcomet_score": 0.9473416805267334, "xcomet_qe_score": 0.9243819713592529, "metricx_score": 0.5544359087944031, "metricx_qe_score": 0.48198819160461426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "und beachten Sie, dass das Sprachmodell bereits über einem n-1-Datensatz mit einer vorläufigen Multitask-Feinabstimmung verfeinert wurde.", "metrics": {"bleu_score": 17.92334464048543, "chrf_score": 67.24056981130715, "xcomet_score": 0.8272424936294556, "xcomet_qe_score": 0.8564095497131348, "metricx_score": 1.8933213949203491, "metricx_qe_score": 3.1069419384002686, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verwenden wir den Ausgabevektor des Sprachmodells als neu generiertes Merkmal in der Anzahl der Klassen.", "metrics": {"bleu_score": 41.31624154858751, "chrf_score": 74.35970905163671, "xcomet_score": 0.9304149746894836, "xcomet_qe_score": 0.9150216579437256, "metricx_score": 0.8662654757499695, "metricx_qe_score": 1.6151846647262573, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Framework zu bewerten, verwenden wir einen siebzehn tabellarischen Klassifikationsdatensatz, der in Größe, Merkmalen, Ausgewogenheit, Domäne und anfänglicher Leistung variiert.", "metrics": {"bleu_score": 29.108736587772473, "chrf_score": 62.11784240556201, "xcomet_score": 0.9128075838088989, "xcomet_qe_score": 0.9167575836181641, "metricx_score": 5.0557451248168945, "metricx_qe_score": 3.9815902709960938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensbasis verwenden wir Wikipedia.", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 95.4310132341269, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.02063114196062088, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir gestalten unser Experiment als LiveOneOut-Evaluation, wenn wir schnell auf mehr als 16 Datensätzen trainieren und es auf den 17. Datensatz anwenden.", "metrics": {"bleu_score": 39.61867597457339, "chrf_score": 67.30411553602737, "xcomet_score": 0.7080134153366089, "xcomet_qe_score": 0.695778489112854, "metricx_score": 8.384116172790527, "metricx_qe_score": 7.8601460456848145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen jeden Datensatz auch in vier Fehler auf und wenden die Kreuzvalidierung mit vier Fehlern an.", "metrics": {"bleu_score": 13.910732727119134, "chrf_score": 57.04676846058956, "xcomet_score": 0.8096367120742798, "xcomet_qe_score": 0.7606910467147827, "metricx_score": 8.976105690002441, "metricx_qe_score": 7.75667142868042, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend generieren wir das neue Merkmal und bewerten es mit fünf Bewertungs-Klassifikatoren.", "metrics": {"bleu_score": 11.121234698968381, "chrf_score": 52.18414366695713, "xcomet_score": 0.9879056215286255, "xcomet_qe_score": 0.994999885559082, "metricx_score": 1.93365478515625, "metricx_qe_score": 0.9579792022705078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine auf BERT basierende Architektur.", "metrics": {"bleu_score": 15.851165692617148, "chrf_score": 68.10168504579508, "xcomet_score": 0.9978176355361938, "xcomet_qe_score": 1.0, "metricx_score": 0.4331548810005188, "metricx_qe_score": 1.183579683303833, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 85.51131524815735, "xcomet_score": 0.9987486600875854, "xcomet_qe_score": 0.9999598264694214, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unseren Rahmen mit der Feinabstimmung auf den Zieldatensatz, der Feinabstimmung auf die Zielaufgabe und der vorläufigen Feinabstimmung von MTDNN vergleichen.", "metrics": {"bleu_score": 44.179182268315785, "chrf_score": 80.52487053023373, "xcomet_score": 0.9731992483139038, "xcomet_qe_score": 0.9174416065216064, "metricx_score": 1.2957327365875244, "metricx_qe_score": 2.5502846240997314, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere reformulierte Feinabstimmung erzielte das beste Ergebnis, die beste Leistung.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 75.46901629778341, "xcomet_score": 0.9719527959823608, "xcomet_qe_score": 0.959789514541626, "metricx_score": 0.7571651935577393, "metricx_qe_score": 0.7233876585960388, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "während MTDNN eine 2%ige Verbesserung gegenüber dem Zieldatensatz-Feintuning erzielte.", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 52.17846755798898, "xcomet_score": 0.9483853578567505, "xcomet_qe_score": 0.9662890434265137, "metricx_score": 1.809868574142456, "metricx_qe_score": 2.335754632949829, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Einweichverfahren erzielte eine Verbesserung von sechs Prozent.", "metrics": {"bleu_score": 33.471898740037666, "chrf_score": 57.719613465152634, "xcomet_score": 0.9145995378494263, "xcomet_qe_score": 0.9336198568344116, "metricx_score": 3.289803981781006, "metricx_qe_score": 3.162689208984375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns den kleinen Datensatz ansehen, können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Multitask-Feinabstimmungsphase auf 1,5 Prozent sinkt.", "metrics": {"bleu_score": 78.2616411968807, "chrf_score": 91.92761952682125, "xcomet_score": 0.9839307069778442, "xcomet_qe_score": 0.9702614545822144, "metricx_score": 1.2398329973220825, "metricx_qe_score": 1.6658599376678467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Leistung stieg jedoch auf 11 % im Vergleich zur alleinigen Feinabstimmung der Zielaufgabe.", "metrics": {"bleu_score": 13.834368456410946, "chrf_score": 57.61233475865504, "xcomet_score": 0.9766436815261841, "xcomet_qe_score": 0.9521549940109253, "metricx_score": 0.97670978307724, "metricx_qe_score": 1.1384952068328857, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Summierung ermöglicht FAST die Anreicherung von Ansichten aus 35 Proben in unserem Experiment.", "metrics": {"bleu_score": 23.578316044531807, "chrf_score": 67.15354517625126, "xcomet_score": 0.7806775569915771, "xcomet_qe_score": 0.780860185623169, "metricx_score": 8.691695213317871, "metricx_qe_score": 8.6317777633667, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben und Datensätze.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9911325573921204, "xcomet_qe_score": 0.990761399269104, "metricx_score": 0.262288898229599, "metricx_qe_score": 0.4292936623096466, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells bei.", "metrics": {"bleu_score": 14.923729480049115, "chrf_score": 53.19779455934452, "xcomet_score": 0.8010821342468262, "xcomet_qe_score": 0.8085924386978149, "metricx_score": 3.4997620582580566, "metricx_qe_score": 4.307626724243164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Es werden jedoch drei Formulierungsphasen hinzugefügt.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 52.66942327342372, "xcomet_score": 0.9005876183509827, "xcomet_qe_score": 0.8906817436218262, "metricx_score": 4.478050231933594, "metricx_qe_score": 4.450523376464844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es handelt sich um einen erweiterten Zug und er benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfüttern und ihn bei der Klassifizierung von Satzauskünften verwenden können.", "metrics": {"bleu_score": 42.45990361593234, "chrf_score": 65.53256131976032, "xcomet_score": 0.7643315196037292, "xcomet_qe_score": 0.7726520299911499, "metricx_score": 4.3230671882629395, "metricx_qe_score": 4.141287803649902, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 87.72426647426647, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
