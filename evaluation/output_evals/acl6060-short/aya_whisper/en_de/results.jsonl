{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, heute möchte ich unsere Forschungsarbeit vorstellen: \"Learning to Reason Deductively, Metabolic Problem Solving as Complex Region Extraction\" (Lernen, um deduktiv zu argumentieren: Stoffwechsel-Problemlösung als Extraktion komplexer Regionen).", "metrics": {"bleu_score": 16.685328082754545, "chrf_score": 68.05725007044956, "xcomet_score": 0.6873672008514404, "xcomet_qe_score": 0.7481787204742432, "metricx_score": 5.106345176696777, "metricx_qe_score": 5.198299884796143, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan vom ByteDance AI Lab und dies ist eine gemeinsame Arbeit mit Jerry von der University of Texas in Austin und Weilu von der SUTD.", "metrics": {"bleu_score": 54.13485181669889, "chrf_score": 81.97064090476553, "xcomet_score": 0.7859454154968262, "xcomet_qe_score": 0.7879218459129333, "metricx_score": 4.005974292755127, "metricx_qe_score": 3.6575591564178467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Schlussfolgern sprechen.", "metrics": {"bleu_score": 74.19446627365011, "chrf_score": 77.74542357158826, "xcomet_score": 0.9978975057601929, "xcomet_qe_score": 0.9892458319664001, "metricx_score": 1.5679526329040527, "metricx_qe_score": 0.7867498993873596, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel, in dem mehrstufiges Denken hilfreich ist.", "metrics": {"bleu_score": 22.516517620830943, "chrf_score": 61.90532359614802, "xcomet_score": 0.9717187881469727, "xcomet_qe_score": 0.9835052490234375, "metricx_score": 0.34128183126449585, "metricx_qe_score": 0.34876734018325806, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung stammt aus dem Pound-Aufsatz, in dem sie eine Prompting-Methode anwenden, um ein mathematisches Problem in einem Few-Shot-Lernszenario zu lösen.", "metrics": {"bleu_score": 46.51052535355049, "chrf_score": 68.3666296747015, "xcomet_score": 0.6095032691955566, "xcomet_qe_score": 0.6456556916236877, "metricx_score": 5.313223838806152, "metricx_qe_score": 5.124233722686768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der linken Seite können wir sehen, dass wir bei der Bereitstellung von Beispielen mit lediglich Fragen und Antworten möglicherweise nicht die korrekten Antworten erhalten.", "metrics": {"bleu_score": 25.78732931085238, "chrf_score": 57.31360571041038, "xcomet_score": 0.9909197092056274, "xcomet_qe_score": 0.9914305210113525, "metricx_score": 0.39029380679130554, "metricx_qe_score": 0.48481863737106323, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch eine weitere Begriffsbeschreibung hinzufügen, ist das Modell in der Lage, die Begriffsbeschreibung vorherzusagen und hier auch eine korrekte Vorhersage zu treffen.", "metrics": {"bleu_score": 79.37559205024688, "chrf_score": 83.24605125008225, "xcomet_score": 0.8683081865310669, "xcomet_qe_score": 0.990456223487854, "metricx_score": 1.635516881942749, "metricx_qe_score": 1.1194257736206055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist daher wünschenswert, interpretierbare, mehrstufige Schlussfolgerungen als Ausgabe zu erhalten.", "metrics": {"bleu_score": 8.032276872815308, "chrf_score": 43.350400749423464, "xcomet_score": 0.9976707696914673, "xcomet_qe_score": 0.9977114200592041, "metricx_score": 0.7489388585090637, "metricx_qe_score": 0.6083562970161438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind der Meinung, dass das Methodenproblem eine direkte Anwendung zur Bewertung solcher Denkfähigkeiten darstellt.", "metrics": {"bleu_score": 5.653041175801492, "chrf_score": 38.097931878359994, "xcomet_score": 0.8676879405975342, "xcomet_qe_score": 0.8726348876953125, "metricx_score": 4.774408340454102, "metricx_qe_score": 3.7260026931762695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Problemsetup hier, angesichts der gestellten Fragen, müssen wir diese Fragen lösen und die numerischen Antworten erhalten.", "metrics": {"bleu_score": 37.02730401700487, "chrf_score": 77.94588994828317, "xcomet_score": 0.996117115020752, "xcomet_qe_score": 0.9885294437408447, "metricx_score": 1.659064769744873, "metricx_qe_score": 1.8974195718765259, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns auch der mathematische Ausdruck gegeben, der zu dieser bestimmten Antwort führt.", "metrics": {"bleu_score": 38.8905561152711, "chrf_score": 75.36768720778252, "xcomet_score": 0.9743032455444336, "xcomet_qe_score": 0.980651319026947, "metricx_score": 1.851338267326355, "metricx_qe_score": 3.033282995223999, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Auch bestimmte Annahmen gelten hier, wie in früheren Arbeiten.", "metrics": {"bleu_score": 39.23542209424606, "chrf_score": 72.01657945268651, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.092039942741394, "metricx_qe_score": 1.2434914112091064, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "wir gehen von der Genauigkeit der Mengen aus, die bekannt sind", "metrics": {"bleu_score": 16.40212036255558, "chrf_score": 62.07993569054777, "xcomet_score": 0.9566555023193359, "xcomet_qe_score": 0.9645310640335083, "metricx_score": 1.3168541193008423, "metricx_qe_score": 2.261852502822876, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir berücksichtigen nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponentiation.", "metrics": {"bleu_score": 72.97627709554281, "chrf_score": 84.72758294162406, "xcomet_score": 0.9584972858428955, "xcomet_qe_score": 0.970852255821228, "metricx_score": 1.11212956905365, "metricx_qe_score": 0.7522974610328674, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Zudem können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren zerlegt werden.", "metrics": {"bleu_score": 24.08856270485351, "chrf_score": 69.75857175380699, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.34393835067749023, "metricx_qe_score": 0.41923123598098755, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten zur Problemlösungsmethode lassen sich tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baum-Modelle einteilen.", "metrics": {"bleu_score": 12.846109021376952, "chrf_score": 63.50864127838645, "xcomet_score": 0.9264233708381653, "xcomet_qe_score": 0.8424152731895447, "metricx_score": 3.482170343399048, "metricx_qe_score": 4.193432807922363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenz-zu-Sequenz-Modelle wandeln den Ausdruck in eine spezifische Sequenz für die Generierung um.", "metrics": {"bleu_score": 65.68676846078536, "chrf_score": 87.5508392717858, "xcomet_score": 0.9704602956771851, "xcomet_qe_score": 0.9272842407226562, "metricx_score": 0.35999101400375366, "metricx_qe_score": 0.5602827072143555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist recht einfach umzusetzen, und es kann auf viele verschiedene komplexe Probleme verallgemeinert werden.", "metrics": {"bleu_score": 18.16725573641283, "chrf_score": 60.441270748386, "xcomet_score": 0.9951019287109375, "xcomet_qe_score": 0.9902627468109131, "metricx_score": 0.08399583399295807, "metricx_qe_score": 0.12594476342201233, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachteile der Leistung sind jedoch im Allgemeinen nicht besser als beim strukturierten Modell. Es fehlt an Interpretierbarkeit für Vorhersagen.", "metrics": {"bleu_score": 22.017363105897306, "chrf_score": 69.18261108228091, "xcomet_score": 0.9409219026565552, "xcomet_qe_score": 0.9430574178695679, "metricx_score": 5.314568996429443, "metricx_qe_score": 5.487011432647705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Doch diese Richtung ist tatsächlich immer noch recht populär aufgrund des Transformer-Modells.", "metrics": {"bleu_score": 16.26170171519489, "chrf_score": 56.36030565722292, "xcomet_score": 0.9915884733200073, "xcomet_qe_score": 0.9732703566551208, "metricx_score": 1.175027847290039, "metricx_qe_score": 1.5181503295898438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Form eines Baums und folgen bei der Baumerzeugung einer vorgeordneten Durchlaufreihenfolge (Pre-Order-Traversal).", "metrics": {"bleu_score": 27.876286341624862, "chrf_score": 66.28777768955231, "xcomet_score": 0.8790626525878906, "xcomet_qe_score": 0.8627972602844238, "metricx_score": 3.83919095993042, "metricx_qe_score": 3.304126262664795, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also die Operatoren weiter, bis wir die Blätter erreichen, welche die Mengen darstellen.", "metrics": {"bleu_score": 43.31852022730596, "chrf_score": 69.99300790156744, "xcomet_score": 0.9581563472747803, "xcomet_qe_score": 0.9326426982879639, "metricx_score": 0.9440788626670837, "metricx_qe_score": 1.3498461246490479, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist das Gute, dass es uns tatsächlich diese binäre Baumstruktur liefert. Aber eigentlich ist es recht kontraintuitiv, da wir den Operator zuerst generieren und am Ende die Mengen.", "metrics": {"bleu_score": 15.397423418798372, "chrf_score": 58.8092804482046, "xcomet_score": 0.9417592883110046, "xcomet_qe_score": 0.9315651655197144, "metricx_score": 2.435364007949829, "metricx_qe_score": 3.465210199356079, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, dass es auch einige repetitive Berechnungen enthält.", "metrics": {"bleu_score": 7.768562846380176, "chrf_score": 47.706038381448195, "xcomet_score": 0.9632657170295715, "xcomet_qe_score": 0.9886444807052612, "metricx_score": 0.5970625281333923, "metricx_qe_score": 0.3579446077346802, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass der Ausdruck 8 mal 3 plus 3 tatsächlich zweimal berechnet wird. Tatsächlich sollten wir die Ergebnisse jedoch wiederverwenden.", "metrics": {"bleu_score": 13.315494041203438, "chrf_score": 52.35614575290663, "xcomet_score": 0.9974188804626465, "xcomet_qe_score": 1.0, "metricx_score": 0.47669723629951477, "metricx_qe_score": 0.9540175199508667, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme schrittweise und auf interpretierbare Weise lösen.", "metrics": {"bleu_score": 57.630617615163025, "chrf_score": 86.02995903306915, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13535255193710327, "metricx_qe_score": 0.15873467922210693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "So können wir beispielsweise hier im zweiten Schritt diesen Divisor erhalten, der 27 beträgt.", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 56.57293071192958, "xcomet_score": 0.9219411611557007, "xcomet_qe_score": 0.9224913716316223, "metricx_score": 1.5377671718597412, "metricx_qe_score": 1.207029104232788, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um die relevanten Inhalte zu finden.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2288219928741455, "metricx_qe_score": 0.19367283582687378, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler.", "metrics": {"bleu_score": 72.59795291154772, "chrf_score": 95.55813636296386, "xcomet_score": 0.9975470304489136, "xcomet_qe_score": 0.9964474439620972, "metricx_score": 0.46138083934783936, "metricx_qe_score": 1.0272918939590454, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir bei diesem dritten Schritt tatsächlich den Quotienten.", "metrics": {"bleu_score": 25.470553981698203, "chrf_score": 74.44156883194914, "xcomet_score": 0.9878969192504883, "xcomet_qe_score": 0.979393482208252, "metricx_score": 1.0448079109191895, "metricx_qe_score": 1.5607749223709106, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, und nach diesen drei Schritten können wir tatsächlich die Ergebnisse aus dem zweiten Schritt nutzen und dann die Ergebnisse des vierten Schritts erhalten. Und schließlich können wir die Dividenden erzielen.", "metrics": {"bleu_score": 33.918247054808944, "chrf_score": 76.13152459379101, "xcomet_score": 0.9776896834373474, "xcomet_qe_score": 0.9672836065292358, "metricx_score": 1.4823403358459473, "metricx_qe_score": 1.8130043745040894, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu erzeugen.", "metrics": {"bleu_score": 5.675727444525874, "chrf_score": 46.703457460055716, "xcomet_score": 0.9845016002655029, "xcomet_qe_score": 0.9866928458213806, "metricx_score": 1.0455368757247925, "metricx_qe_score": 0.9161331653594971, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "So wird der Prozess genauer.", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 76.36666892444792, "xcomet_score": 0.9795993566513062, "xcomet_qe_score": 0.959902286529541, "metricx_score": 0.4132263660430908, "metricx_qe_score": 0.7096289992332458, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir zunächst mit einer Reihe von Größen, die in den Fragen präsentiert werden, und schließen auch einige Konstanten als unseren Anfangszustand ein.", "metrics": {"bleu_score": 51.90404971567761, "chrf_score": 74.42756390976267, "xcomet_score": 0.9766792058944702, "xcomet_qe_score": 0.9721423983573914, "metricx_score": 1.4518060684204102, "metricx_qe_score": 2.2081165313720703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Die Ausdruck wird also durch EIJOP dargestellt.", "metrics": {"bleu_score": 24.936514388871338, "chrf_score": 73.69549007385977, "xcomet_score": 0.9437373876571655, "xcomet_qe_score": 0.9364434480667114, "metricx_score": 2.7321832180023193, "metricx_qe_score": 4.401228427886963, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "wo wir den Operator von QI nach QJ ausführen, und dieser Ausdruck ist tatsächlich zielgerichtet.", "metrics": {"bleu_score": 29.80310476492179, "chrf_score": 65.92703812285791, "xcomet_score": 0.9234845638275146, "xcomet_qe_score": 0.938278317451477, "metricx_score": 3.2300221920013428, "metricx_qe_score": 3.4918806552886963, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Auch hier haben wir die Subtraktion umgekehrt, um die entgegengesetzte Richtung darzustellen.", "metrics": {"bleu_score": 17.055805176321822, "chrf_score": 59.63064659994011, "xcomet_score": 0.9254834651947021, "xcomet_qe_score": 0.9208272695541382, "metricx_score": 1.9723429679870605, "metricx_qe_score": 1.8383269309997559, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist recht ähnlich wie bei der Extraktion von Beziehungen.", "metrics": {"bleu_score": 11.731175160263996, "chrf_score": 65.98237691585497, "xcomet_score": 0.9959346055984497, "xcomet_qe_score": 0.9803628921508789, "metricx_score": 2.5423927307128906, "metricx_qe_score": 2.8191909790039062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System wenden wir also im Zeit Schritt t den Operator zwischen der qi- und qj-Paarung an und erhalten dann diese neuen Ausdrücke.", "metrics": {"bleu_score": 28.145489791822474, "chrf_score": 75.69633142765882, "xcomet_score": 0.918135941028595, "xcomet_qe_score": 0.9117752909660339, "metricx_score": 1.2050514221191406, "metricx_qe_score": 1.4169811010360718, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es dem nächsten Zustand hinzu, um eine neue Größe zu bilden.", "metrics": {"bleu_score": 54.451788461394045, "chrf_score": 68.2372151492082, "xcomet_score": 0.9828433990478516, "xcomet_qe_score": 0.9423977136611938, "metricx_score": 2.212794303894043, "metricx_qe_score": 2.500767469406128, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Folie visualisiert die Evolution des Zustands, bei dem wir kontinuierlich Ausdrucksformen zum aktuellen Zustand hinzufügen.", "metrics": {"bleu_score": 12.151974811408735, "chrf_score": 46.71633200107056, "xcomet_score": 0.8950797319412231, "xcomet_qe_score": 0.8763614296913147, "metricx_score": 3.740598201751709, "metricx_qe_score": 4.291769504547119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vortrainiertes Sprachmodell, das entweder ein Brit- oder ein Roberta-Modell sein kann, kodieren dann einen Satz und erhalten anschließend diese Mengenrepräsentationen.", "metrics": {"bleu_score": 28.148513679189655, "chrf_score": 66.51359329813921, "xcomet_score": 0.9340462684631348, "xcomet_qe_score": 0.9304593801498413, "metricx_score": 2.633840799331665, "metricx_qe_score": 5.12449836730957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir die Mengenrepräsentationen erhalten, können wir mit der Inferenz beginnen.", "metrics": {"bleu_score": 57.991506770919095, "chrf_score": 67.68353657933929, "xcomet_score": 0.9953783750534058, "xcomet_qe_score": 0.9986000061035156, "metricx_score": 1.052518606185913, "metricx_qe_score": 4.974758148193359, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 geteilt durch Q2 und dann multipliziert mit Q4 zu erhalten.", "metrics": {"bleu_score": 32.69674158925178, "chrf_score": 73.96064058514744, "xcomet_score": 0.8871511220932007, "xcomet_qe_score": 0.8865020275115967, "metricx_score": 8.315768241882324, "metricx_qe_score": 7.378793239593506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erhalten wir die Paardarstellung, die im Wesentlichen nur die Verkettung zwischen Q1 und Q2 ist. Anschließend wenden wir ein Feedforward-Netzwerk an, das durch den Operator parametrisiert wird.", "metrics": {"bleu_score": 53.28146481396489, "chrf_score": 81.29357079886724, "xcomet_score": 0.9781473875045776, "xcomet_qe_score": 0.8531640768051147, "metricx_score": 1.5968005657196045, "metricx_qe_score": 2.5126700401306152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksdarstellung Q1 geteilt durch Q2.", "metrics": {"bleu_score": 9.119700296511436, "chrf_score": 73.27706161929275, "xcomet_score": 0.9956886768341064, "xcomet_qe_score": 0.9830245971679688, "metricx_score": 0.49059343338012695, "metricx_qe_score": 0.8244310617446899, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Tatsächlich können wir aber in der Praxis, in der Inferenzphase, auch auf die falsche Ausdrucksweise stoßen.", "metrics": {"bleu_score": 14.025775160081468, "chrf_score": 59.17038352038203, "xcomet_score": 0.9960805177688599, "xcomet_qe_score": 0.9919737577438354, "metricx_score": 1.8554266691207886, "metricx_qe_score": 1.8538806438446045, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die gesamte mögliche Ausdrucksmenge gleich dem Dreifachen der Anzahl der Operatoren.", "metrics": {"bleu_score": 52.960749334062214, "chrf_score": 70.6836959421056, "xcomet_score": 0.9484992027282715, "xcomet_qe_score": 0.9443392157554626, "metricx_score": 0.9606267213821411, "metricx_qe_score": 1.9824979305267334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir hier einfach Einschränkungen hinzufügen können, um diesen Suchraum zu kontrollieren.", "metrics": {"bleu_score": 79.12619863720215, "chrf_score": 90.84813342161019, "xcomet_score": 0.9902621507644653, "xcomet_qe_score": 0.9831626415252686, "metricx_score": 0.732684314250946, "metricx_qe_score": 0.935750424861908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn dieser Ausdruck nicht erlaubt ist, können wir ihn einfach aus unserem Suchraum entfernen.", "metrics": {"bleu_score": 70.42311846346826, "chrf_score": 91.89778880066595, "xcomet_score": 0.995607852935791, "xcomet_qe_score": 0.9966379404067993, "metricx_score": 0.4199473261833191, "metricx_qe_score": 1.2032403945922852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt tun wir also dasselbe, aber der einzige Unterschied besteht darin, dass wir eine weitere Menge hinzufügen.", "metrics": {"bleu_score": 28.75338096125627, "chrf_score": 59.570033037686834, "xcomet_score": 0.9729422330856323, "xcomet_qe_score": 0.9528729915618896, "metricx_score": 2.7868010997772217, "metricx_qe_score": 4.910496711730957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe ergibt sich aus der zuvor berechneten Ausdruck.", "metrics": {"bleu_score": 17.747405280050266, "chrf_score": 47.15833338912985, "xcomet_score": 0.978090763092041, "xcomet_qe_score": 0.967440128326416, "metricx_score": 2.5130889415740967, "metricx_qe_score": 4.488777160644531, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Endlich können wir diesen letzten Ausdruck Q erhalten.", "metrics": {"bleu_score": 6.856346714060815, "chrf_score": 44.83849965145716, "xcomet_score": 0.8773088455200195, "xcomet_qe_score": 0.8636043071746826, "metricx_score": 7.296420097351074, "metricx_qe_score": 10.018956184387207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Im vierten Quartal (Q4) können wir auch sehen, dass die Anzahl aller möglichen Ausdrücke sich von dem vorherigen Schritt unterscheidet.", "metrics": {"bleu_score": 37.25748409395151, "chrf_score": 73.07926626476545, "xcomet_score": 0.859628438949585, "xcomet_qe_score": 0.8225393295288086, "metricx_score": 9.041574478149414, "metricx_qe_score": 9.507589340209961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Solche Unterschiede machen es schwierig, Beam Search anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgewogen ist.", "metrics": {"bleu_score": 51.88910185721436, "chrf_score": 75.2373315966562, "xcomet_score": 0.9223674535751343, "xcomet_qe_score": 0.9238342642784119, "metricx_score": 1.8666919469833374, "metricx_qe_score": 2.9563307762145996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Das Trainingsverfahren ähnelt dem Training eines Sequenz-zu-Sequenz-Modells, bei dem wir den Verlust an jedem Zeitschritt optimieren.", "metrics": {"bleu_score": 61.73766800528, "chrf_score": 85.10012937859605, "xcomet_score": 0.939070463180542, "xcomet_qe_score": 0.9086557030677795, "metricx_score": 0.35711076855659485, "metricx_qe_score": 0.5152873396873474, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir ebenfalls dieses Tau, um anzugeben, wann wir den Generierungsprozess beenden sollten.", "metrics": {"bleu_score": 38.89055611527108, "chrf_score": 74.17229977465702, "xcomet_score": 0.997305154800415, "xcomet_qe_score": 0.9867621660232544, "metricx_score": 0.8023474216461182, "metricx_qe_score": 1.263301968574524, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz unterschiedlich, da der Raum sich in jedem Zeitschritt ändert, während in einem traditionellen Sequenz-zu-Sequenz-Modell die Anzahl des Vokabulars bestimmt.", "metrics": {"bleu_score": 30.265234810120514, "chrf_score": 74.37460004400631, "xcomet_score": 0.9151864051818848, "xcomet_qe_score": 0.7925528883934021, "metricx_score": 2.5515918731689453, "metricx_qe_score": 3.7061028480529785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht uns auch, bestimmte Einschränkungen aus vorherigem Wissen zu übernehmen.", "metrics": {"bleu_score": 19.67497981115564, "chrf_score": 53.01324571825046, "xcomet_score": 0.9700798988342285, "xcomet_qe_score": 0.9166089296340942, "metricx_score": 1.027911901473999, "metricx_qe_score": 1.2258548736572266, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Daher führen wir Experimente mit den gängigen Methodik-Problem-Datensätzen MAWPS, MAT23K, MATQA und SWAMP durch.", "metrics": {"bleu_score": 26.133508249249093, "chrf_score": 49.635034166996846, "xcomet_score": 0.9224706888198853, "xcomet_qe_score": 0.9342186450958252, "metricx_score": 5.225041389465332, "metricx_qe_score": 4.988859176635742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen Batch-Verfahren.", "metrics": {"bleu_score": 61.153805769010226, "chrf_score": 69.84307488167299, "xcomet_score": 0.8547655344009399, "xcomet_qe_score": 0.8648167252540588, "metricx_score": 3.1498212814331055, "metricx_qe_score": 4.066086769104004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere bestperformende Variante ist daher der Robeta Dictative Reasoner.", "metrics": {"bleu_score": 9.980099403873663, "chrf_score": 46.14482883448026, "xcomet_score": 0.8911975622177124, "xcomet_qe_score": 0.8957813382148743, "metricx_score": 3.999082565307617, "metricx_qe_score": 4.979234218597412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Tatsächlich verwenden wir im Gegensatz zu offensichtlichen Ansätzen, die Beam Search nutzen, keine Beam Search.", "metrics": {"bleu_score": 35.98215729185766, "chrf_score": 68.36959295911865, "xcomet_score": 0.868167519569397, "xcomet_qe_score": 0.7787662148475647, "metricx_score": 4.54081392288208, "metricx_qe_score": 5.6547064781188965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, die besten Ansätze sind oft baumbasierte Modelle.", "metrics": {"bleu_score": 35.08439695638686, "chrf_score": 71.0099549495657, "xcomet_score": 0.9703253507614136, "xcomet_qe_score": 0.9774734377861023, "metricx_score": 0.5110778212547302, "metricx_qe_score": 0.5005422830581665, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Schlussfolgerer diese baumbasierte Modell deutlich übertreffen.", "metrics": {"bleu_score": 7.208393585152543, "chrf_score": 48.81105851181854, "xcomet_score": 0.9019976854324341, "xcomet_qe_score": 0.8411878943443298, "metricx_score": 4.217687129974365, "metricx_qe_score": 4.490784168243408, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings können wir erkennen, dass die absoluten Zahlen auf Mathqa oder SWAM nicht wirklich hoch sind.", "metrics": {"bleu_score": 42.93663233009673, "chrf_score": 65.46254551152202, "xcomet_score": 0.9509896039962769, "xcomet_qe_score": 0.9342222213745117, "metricx_score": 1.1884067058563232, "metricx_qe_score": 0.9786567687988281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "So untersuchen wir die Ergebnisse weiter auf", "metrics": {"bleu_score": 32.66828640925501, "chrf_score": 63.714951264538065, "xcomet_score": 0.7715263366699219, "xcomet_qe_score": 0.7876843214035034, "metricx_score": 4.322882175445557, "metricx_qe_score": 1.6406431198120117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Datensammlung ist herausfordernd, da der Autor versucht hat, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. irrelevante Informationen und zusätzliche Mengen.", "metrics": {"bleu_score": 60.44646711158496, "chrf_score": 75.22049478047481, "xcomet_score": 0.9713879823684692, "xcomet_qe_score": 0.9558899402618408, "metricx_score": 1.6516250371932983, "metricx_qe_score": 1.3345062732696533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Vorhersage stellen wir fest, dass einige der Zwischenwerte tatsächlich negativ sind.", "metrics": {"bleu_score": 61.60362085721387, "chrf_score": 83.12284166487707, "xcomet_score": 0.9996477365493774, "xcomet_qe_score": 0.9977097511291504, "metricx_score": 0.32287538051605225, "metricx_qe_score": 0.4282243847846985, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel hat Drake?", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 61.677860405893604, "xcomet_score": 0.8487570285797119, "xcomet_qe_score": 0.8232401609420776, "metricx_score": 3.9376285076141357, "metricx_qe_score": 3.8272454738616943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie zum Beispiel 17 weniger Vorschläge. Und Steven hat 8 Vorschläge, was völlig irrelevant ist.", "metrics": {"bleu_score": 42.06308920964751, "chrf_score": 71.97955141428567, "xcomet_score": 0.8426337242126465, "xcomet_qe_score": 0.8315716981887817, "metricx_score": 5.814126491546631, "metricx_qe_score": 5.165560722351074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also Vorhersagen wie diese, die negative Werte erzeugen.", "metrics": {"bleu_score": 54.844980922047604, "chrf_score": 79.30386297209215, "xcomet_score": 0.9908307790756226, "xcomet_qe_score": 0.9766910076141357, "metricx_score": 0.4803025424480438, "metricx_qe_score": 0.5867586731910706, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "und wir beobachten diese beiden Ausdrücke", "metrics": {"bleu_score": 9.408660393931463, "chrf_score": 33.72231721253372, "xcomet_score": 0.7100077867507935, "xcomet_qe_score": 0.8392543196678162, "metricx_score": 10.409055709838867, "metricx_qe_score": 12.031658172607422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können den Suchraum tatsächlich einschränken, indem wir die negativen Ergebnisse entfernen, um die korrekte Antwort zu finden.", "metrics": {"bleu_score": 39.10803275292361, "chrf_score": 63.99704144099343, "xcomet_score": 0.9507015943527222, "xcomet_qe_score": 0.8582492470741272, "metricx_score": 1.3586176633834839, "metricx_qe_score": 1.9217572212219238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass diese Einschränkung die Leistung einiger Modelle tatsächlich erheblich verbessert.", "metrics": {"bleu_score": 12.171248402468247, "chrf_score": 52.81314850286765, "xcomet_score": 0.987906813621521, "xcomet_qe_score": 0.9771198034286499, "metricx_score": 0.7440986633300781, "metricx_qe_score": 0.5416887402534485, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert. Und dann haben wir beim auf Robeta basierenden Modell tatsächlich zwei Punkte verbessert.", "metrics": {"bleu_score": 18.088201962129947, "chrf_score": 56.95412136394823, "xcomet_score": 0.7893918752670288, "xcomet_qe_score": 0.789770245552063, "metricx_score": 9.880406379699707, "metricx_qe_score": 8.707884788513184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell verfügt über eine bessere Sprachverständnis-Fähigkeit, sodass die Zahl hier für Robita höher und für Bird niedriger ist.", "metrics": {"bleu_score": 25.85071874780497, "chrf_score": 66.35873634297074, "xcomet_score": 0.8465044498443604, "xcomet_qe_score": 0.8510833978652954, "metricx_score": 4.638401985168457, "metricx_qe_score": 5.5416975021362305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch, die Schwierigkeit dahinter zu analysieren.", "metrics": {"bleu_score": 28.291332071489855, "chrf_score": 64.95413272249276, "xcomet_score": 0.8864922523498535, "xcomet_qe_score": 0.8106286525726318, "metricx_score": 1.0357882976531982, "metricx_qe_score": 3.20353102684021, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der nicht genutzten Mengen hier als irrelevante Information betrachtet werden kann.", "metrics": {"bleu_score": 65.14613449066714, "chrf_score": 91.71419711300132, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.549547016620636, "metricx_qe_score": 0.5778229832649231, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben, und das SWAMP-Datenset weist den größten Anteil auf.", "metrics": {"bleu_score": 57.78883676487948, "chrf_score": 75.53997134421031, "xcomet_score": 0.9631901979446411, "xcomet_qe_score": 0.9400043487548828, "metricx_score": 2.200000762939453, "metricx_qe_score": 2.480548143386841, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung.", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 95.153554655332, "xcomet_score": 0.9975186586380005, "xcomet_qe_score": 0.9953868389129639, "metricx_score": 0.17540127038955688, "metricx_qe_score": 0.28346192836761475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "für die Proben ohne ungenutzte Mengen. Somit ist die Gesamtleistung tatsächlich höher als die Gesamtleistung.", "metrics": {"bleu_score": 38.989389329183524, "chrf_score": 71.91932908492863, "xcomet_score": 0.729349672794342, "xcomet_qe_score": 0.5820772647857666, "metricx_score": 4.560854434967041, "metricx_qe_score": 6.334840774536133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei jenen Proben, bei denen die nicht verwendete Menge tatsächlich viel schlimmer ist als die viel schlimmere Art und Weise, ...", "metrics": {"bleu_score": 4.8589719316429765, "chrf_score": 40.370450145899525, "xcomet_score": 0.7680602073669434, "xcomet_qe_score": 0.7624642848968506, "metricx_score": 10.951576232910156, "metricx_qe_score": 15.169139862060547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Leistung. Für MAWPS haben wir nicht allzu viele Datenträger-Hüllen, daher ignoriere ich diesen Teil einfach.", "metrics": {"bleu_score": 42.08598069524091, "chrf_score": 62.028845025763744, "xcomet_score": 0.721696138381958, "xcomet_qe_score": 0.643686056137085, "metricx_score": 7.05405330657959, "metricx_qe_score": 5.6545491218566895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretierbarkeit durch ein Absturz- und Störbeispiel veranschaulichen.", "metrics": {"bleu_score": 14.323145079400492, "chrf_score": 55.11329457926857, "xcomet_score": 0.8646447658538818, "xcomet_qe_score": 0.8868826627731323, "metricx_score": 2.7280192375183105, "metricx_qe_score": 3.6313648223876953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "So macht unser Modell hier tatsächlich bereits in dem ersten Schritt eine falsche Vorhersage.", "metrics": {"bleu_score": 19.765441873349218, "chrf_score": 75.45435801163384, "xcomet_score": 0.9711668491363525, "xcomet_qe_score": 0.9670575857162476, "metricx_score": 0.3705650269985199, "metricx_qe_score": 0.4555167257785797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "So können wir diesen Ausdruck tatsächlich mit dem Satz hier korrelieren.", "metrics": {"bleu_score": 49.5958668188253, "chrf_score": 76.87254739882869, "xcomet_score": 0.9572954177856445, "xcomet_qe_score": 0.9460722804069519, "metricx_score": 1.0830196142196655, "metricx_qe_score": 1.2796534299850464, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir vermuten, dass dieser Satz das Modell zu einer falschen Vorhersage führt.", "metrics": {"bleu_score": 44.01624063197169, "chrf_score": 61.50515664731094, "xcomet_score": 0.9862431287765503, "xcomet_qe_score": 0.9831336140632629, "metricx_score": 0.7913036346435547, "metricx_qe_score": 0.712576150894165, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Hier also bewirkt das Drucken weiterer 35, dass das Modell glaubt, es sollte ein Additionsoperator sein.", "metrics": {"bleu_score": 21.397345553739402, "chrf_score": 57.99861423974956, "xcomet_score": 0.8313615322113037, "xcomet_qe_score": 0.7502386569976807, "metricx_score": 3.0557806491851807, "metricx_qe_score": 4.253304481506348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz zu überarbeiten, sodass er etwa wie folgt lautet: \"Die Anzahl der Birnbäume ist 55 geringer als die der Apfelbäume.\"", "metrics": {"bleu_score": 16.436148154531303, "chrf_score": 63.886901225235626, "xcomet_score": 0.9775955677032471, "xcomet_qe_score": 0.9844517707824707, "metricx_score": 1.9365681409835815, "metricx_qe_score": 1.626961350440979, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "So stellen wir sicher, dass präzisere Semantiken vermittelt werden, damit das Modell in der Lage ist, korrekte Vorhersagen zu treffen.", "metrics": {"bleu_score": 30.360503983597873, "chrf_score": 58.30737896541074, "xcomet_score": 0.9798104763031006, "xcomet_qe_score": 0.9809880256652832, "metricx_score": 0.7464599609375, "metricx_qe_score": 1.0740253925323486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt also, wie interpretierbare Vorhersagen uns dabei helfen, das Modellverhalten zu verstehen.", "metrics": {"bleu_score": 65.31441986620497, "chrf_score": 87.78591383994161, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.36359453201293945, "metricx_qe_score": 0.5395598411560059, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist zunächst festzuhalten, dass unser Modell tatsächlich recht effizient ist.", "metrics": {"bleu_score": 22.637359354764463, "chrf_score": 72.35574448644218, "xcomet_score": 0.999850869178772, "xcomet_qe_score": 0.9990302324295044, "metricx_score": 0.3146381378173828, "metricx_qe_score": 0.3834235668182373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind in der Lage, ein interpretierbares Lösungsprozedere bereitzustellen.", "metrics": {"bleu_score": 53.3167536340577, "chrf_score": 69.52464438786939, "xcomet_score": 0.9886326789855957, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.46534186601638794, "metricx_qe_score": 0.4487377107143402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige Vorkenntnisse als Einschränkung einbeziehen, was zur Verbesserung der Leistung beitragen kann.", "metrics": {"bleu_score": 53.569769608593234, "chrf_score": 72.03146058680989, "xcomet_score": 0.9979966878890991, "xcomet_qe_score": 0.987479031085968, "metricx_score": 1.0859284400939941, "metricx_qe_score": 0.8178043365478516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Aufgaben zur Problemlösung mit Kartenmaterial, sondern auch auf andere Aufgaben mit mehrstufigem Denken angewendet werden kann.", "metrics": {"bleu_score": 9.441218922485383, "chrf_score": 52.749149962231655, "xcomet_score": 0.9509656429290771, "xcomet_qe_score": 0.9231250286102295, "metricx_score": 5.619482517242432, "metricx_qe_score": 4.981855869293213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch gewisse Einschränkungen.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 27.78342294558877, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer großen Anzahl von Operatoren oder Konstanten könnte der Speicherverbrauch recht hoch sein.", "metrics": {"bleu_score": 33.14559338934352, "chrf_score": 71.09204232523905, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3799840211868286, "metricx_qe_score": 0.40686294436454773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und zweitens ist es, wie erwähnt, aufgrund der unausgewogenen Wahrscheinlichkeitsverteilung zu verschiedenen Zeitpunkten recht anspruchsvoll, die Beam-Suche anzuwenden.", "metrics": {"bleu_score": 16.171249275965106, "chrf_score": 57.173220756365815, "xcomet_score": 0.9092899560928345, "xcomet_qe_score": 0.9022048711776733, "metricx_score": 1.8694348335266113, "metricx_qe_score": 2.1308934688568115, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "So, das ist das Ende des Vortrags, und Fragen sind willkommen. Vielen Dank.", "metrics": {"bleu_score": 15.844501337268932, "chrf_score": 48.22982550652609, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.4172332286834717, "metricx_qe_score": 0.31250476837158203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Universität Maastricht.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 89.89040636842799, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07355811446905136, "metricx_qe_score": 0.018026236444711685, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine erstellten Arbeiten mit Jerry präsentieren, die sich mit einem neuen Datensatz für die Abfrage von Gesetzestexten befassen.", "metrics": {"bleu_score": 12.712870441499998, "chrf_score": 50.16211681452851, "xcomet_score": 0.9702828526496887, "xcomet_qe_score": 0.9700704216957092, "metricx_score": 1.1853803396224976, "metricx_qe_score": 1.026363730430603, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein integraler Bestandteil des Lebens vieler Menschen.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 82.26501053168111, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26483702659606934, "metricx_qe_score": 0.08028143644332886, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "aber die Mehrheit der Bürgerinnen und Bürger hat nur wenig oder gar kein Wissen über ihre Rechte und grundlegenden rechtlichen Verfahren.", "metrics": {"bleu_score": 25.376192011638008, "chrf_score": 74.84737060730862, "xcomet_score": 0.9905406832695007, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5625749826431274, "metricx_qe_score": 0.6140262484550476, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Folge bleiben viele schutzbedürftige Bürger, die sich die kostspielige Hilfe eines Rechtsanwalts nicht leisten können, ungeschützt oder werden, schlimmstenfalls, ausgenutzt.", "metrics": {"bleu_score": 45.08190458674736, "chrf_score": 70.75324023170188, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10737162828445435, "metricx_qe_score": 0.06724495440721512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Kluft zwischen Menschen und dem Recht zu überbrücken, indem wir effektive Abrufsysteme für gesetzliche Artikel entwickeln.", "metrics": {"bleu_score": 46.30535875362438, "chrf_score": 68.77290375411674, "xcomet_score": 0.9815667867660522, "xcomet_qe_score": 0.9809976816177368, "metricx_score": 0.7349588871002197, "metricx_qe_score": 0.5225694179534912, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen professionellen Rechtsbeistand für ungelerntes Personal bereitstellen.", "metrics": {"bleu_score": 50.08718428920986, "chrf_score": 65.54791265269337, "xcomet_score": 0.9750005006790161, "xcomet_qe_score": 0.9880375862121582, "metricx_score": 1.0625481605529785, "metricx_qe_score": 0.6445099115371704, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns der Hauptleistung dieser Arbeit zuwenden, beschreiben wir zunächst das Problem der gesetzlichen Artikelrecherche.", "metrics": {"bleu_score": 20.838925800486027, "chrf_score": 57.15839037832071, "xcomet_score": 0.9040508270263672, "xcomet_qe_score": 0.9122943878173828, "metricx_score": 1.0794123411178589, "metricx_qe_score": 0.9948389530181885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer einfachen Frage zu einem geringfügigen Thema, wie beispielsweise: Welche Risiken gehe ich ein, wenn ich die berufliche Verschwiegenheit verletze?", "metrics": {"bleu_score": 9.00911347430732, "chrf_score": 45.450798052230965, "xcomet_score": 0.8737049102783203, "xcomet_qe_score": 0.8844693899154663, "metricx_score": 2.0542562007904053, "metricx_qe_score": 2.1061363220214844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetzeskorpus zu extrahieren.", "metrics": {"bleu_score": 20.789290034925113, "chrf_score": 51.03597110927775, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5836690664291382, "metricx_qe_score": 0.4435122609138489, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe der Informationsbeschaffung bringt ihre eigenen Herausforderungen mit sich.", "metrics": {"bleu_score": 25.965358893403383, "chrf_score": 71.86167546281403, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08975847065448761, "metricx_qe_score": 0.40193426609039307, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal befasst es sich mit zwei Arten von Sprache.", "metrics": {"bleu_score": 35.08439695638686, "chrf_score": 54.15657463222438, "xcomet_score": 0.9414843916893005, "xcomet_qe_score": 0.9420942664146423, "metricx_score": 0.22256316244602203, "metricx_qe_score": 0.2385120987892151, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Alltägliche natürliche Sprache für die Fragen und komplexe juristische Sprache für die Gesetze.", "metrics": {"bleu_score": 67.83686168526629, "chrf_score": 80.80767472078846, "xcomet_score": 0.9909193515777588, "xcomet_qe_score": 0.9908598065376282, "metricx_score": 0.5987762808799744, "metricx_qe_score": 0.5864245295524597, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Unterschied in der Sprachverteilung macht es einem System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die der Terminologie von Gesetzen entspricht.", "metrics": {"bleu_score": 74.18884216837819, "chrf_score": 89.5364051141271, "xcomet_score": 0.9860074520111084, "xcomet_qe_score": 0.9205923080444336, "metricx_score": 0.5203334093093872, "metricx_qe_score": 0.605320930480957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Zum einen ist das Gesetzesrecht keine Ansammlung unabhängiger Artikel, die als vollständige Informationsquelle für sich stehen können, im Gegensatz beispielsweise zu Nachrichten oder Rezepten.", "metrics": {"bleu_score": 29.37225538639114, "chrf_score": 71.44339774039781, "xcomet_score": 0.9883893728256226, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.5644276738166809, "metricx_qe_score": 0.6555445194244385, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen handelt es sich um eine strukturierte Sammlung rechtlicher Bestimmungen, die nur in ihrem gesamten Kontext eine vollständige Bedeutung erlangen, also zusammen mit den ergänzenden Informationen aus den benachbarten Artikeln, den Bereichen und Unterbereichen, zu denen sie gehören, sowie ihrer Position in der Struktur des Gesetzes.", "metrics": {"bleu_score": 34.047955911039296, "chrf_score": 66.97230473807204, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13686877489089966, "metricx_qe_score": 0.22256779670715332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Zuletzt sind gesetzliche Artikel keine kurzen Absätze, die üblicherweise die typische Abruf-Einheit in den meisten Abrufwerken darstellen.", "metrics": {"bleu_score": 13.608687680894436, "chrf_score": 43.221250361752226, "xcomet_score": 0.934638261795044, "xcomet_qe_score": 0.9486221075057983, "metricx_score": 2.254838705062866, "metricx_qe_score": 1.2363216876983643, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier gibt es lange Dokumente, die bis zu sechs Seiten umfassen können.", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 76.84514517071142, "xcomet_score": 0.9986963272094727, "xcomet_qe_score": 1.0, "metricx_score": 0.6939531564712524, "metricx_qe_score": 0.4866970181465149, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich der NLP (Natural Language Processing) haben ein enormes Interesse an vielen juristischen Aufgaben geweckt, wie z. B. der Vorhersage von Gerichtsentscheidungen oder der automatisierten Vertragsprüfung.", "metrics": {"bleu_score": 38.41906830251733, "chrf_score": 70.55906617715962, "xcomet_score": 0.9948431253433228, "xcomet_qe_score": 0.9921290874481201, "metricx_score": 0.31612688302993774, "metricx_qe_score": 0.3474913239479065, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelabfrage ist jedoch aufgrund des Mangels an großen und hochwertigen Label-Datensätzen weitgehend unberührt geblieben.", "metrics": {"bleu_score": 36.75667565747676, "chrf_score": 62.53715616412148, "xcomet_score": 0.9581472873687744, "xcomet_qe_score": 0.9915581941604614, "metricx_score": 1.7193385362625122, "metricx_qe_score": 1.6870920658111572, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit stellen wir ein neues, französisches, bürgerzentriertes Datenset vor, um zu untersuchen, ob ein Abrufmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten bei der Aufgabe der Abrufung von Gesetzestexten annähernd erreichen kann.", "metrics": {"bleu_score": 28.4321629599378, "chrf_score": 58.11659886129345, "xcomet_score": 0.919638454914093, "xcomet_qe_score": 0.9456533193588257, "metricx_score": 1.5464504957199097, "metricx_qe_score": 1.1022677421569824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Unser belgischer gesetzlicher Artikel-Abruf-Datensatz, PSART, besteht aus mehr als 1.100 rechtlichen Dokumenten.", "metrics": {"bleu_score": 18.49330493475226, "chrf_score": 40.95806412931195, "xcomet_score": 0.7421720027923584, "xcomet_qe_score": 0.8265602588653564, "metricx_score": 7.086108207702637, "metricx_qe_score": 6.808681964874268, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnen und Finanzen bis hin zu Arbeit und Sozialversicherung.", "metrics": {"bleu_score": 33.07940864397776, "chrf_score": 57.14623035657523, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05382709950208664, "metricx_qe_score": 0.034449782222509384, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einem Korpus von mehr als 22.600 etikettiert.", "metrics": {"bleu_score": 70.84542882975748, "chrf_score": 71.76776740171006, "xcomet_score": 0.7972091436386108, "xcomet_qe_score": 0.8102025985717773, "metricx_score": 3.974726915359497, "metricx_qe_score": 4.710604667663574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Gesetzbücher. Sprechen wir nun darüber, wie wir diese Datensätze gesammelt haben.", "metrics": {"bleu_score": 18.69300079996002, "chrf_score": 58.000528994296964, "xcomet_score": 0.7540857791900635, "xcomet_qe_score": 0.7674424648284912, "metricx_score": 7.4866042137146, "metricx_qe_score": 9.78213882446289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst begannen wir damit, einen großen Korpus aus Rechtsartikeln zusammenzustellen.", "metrics": {"bleu_score": 15.580105704117443, "chrf_score": 68.56739629174807, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2510942816734314, "metricx_qe_score": 0.41841262578964233, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich zugängliche belgische Gesetzbücher berücksichtigt und alle ihre Artikel sowie die entsprechenden Abschnittüberschriften extrahiert.", "metrics": {"bleu_score": 68.99302125555486, "chrf_score": 95.66887741769793, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.543300986289978, "metricx_qe_score": 0.6798845529556274, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend sammelten wir rechtliche Fragen mit Verweisen auf die einschlägigen Gesetze.", "metrics": {"bleu_score": 44.833867003844595, "chrf_score": 68.36792960577105, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20172259211540222, "metricx_qe_score": 0.3513491451740265, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr rund 4.000 E-Mails von belgischen Bürgern erhält, die Rat zu einer persönlichen Rechtsangelegenheit suchen.", "metrics": {"bleu_score": 59.547934876380445, "chrf_score": 81.7527861758795, "xcomet_score": 0.9982326030731201, "xcomet_qe_score": 1.0, "metricx_score": 0.277900367975235, "metricx_qe_score": 0.2546919584274292, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team erfahrener Juristen die häufigsten rechtlichen Probleme in Belgien behandelt.", "metrics": {"bleu_score": 67.32378032068624, "chrf_score": 75.45597118707808, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5246574878692627, "metricx_qe_score": 0.6252104043960571, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen gesammelt, die mit Kategorien, Unterkategorien und rechtlichen Verweisen auf relevante Gesetze annotiert sind.", "metrics": {"bleu_score": 45.50680330812803, "chrf_score": 79.20109396728624, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3917781412601471, "metricx_qe_score": 0.5909736156463623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend analysierten wir die Rechtsquellen und filterten die Fragen heraus, deren Referenzen keine Artikel in einem der von uns betrachteten Gesetzbücher waren.", "metrics": {"bleu_score": 22.110178939494233, "chrf_score": 49.2488133370697, "xcomet_score": 0.9780102968215942, "xcomet_qe_score": 0.9711463451385498, "metricx_score": 0.49956172704696655, "metricx_qe_score": 0.7376396656036377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Referenzen wurden abgeglichen und in die entsprechenden Artikel-IDs aus Ocorpus umgewandelt.", "metrics": {"bleu_score": 41.232116527739876, "chrf_score": 67.90051089081886, "xcomet_score": 0.9683449268341064, "xcomet_qe_score": 0.9733867049217224, "metricx_score": 3.2974467277526855, "metricx_qe_score": 2.6117191314697266, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Letztendlich landeten wir bei 1108 Fragen, die jeweils sorgfältig mit den IDs der relevanten Artikel gekennzeichnet waren.", "metrics": {"bleu_score": 23.34772241783051, "chrf_score": 45.133128497170524, "xcomet_score": 0.9529184699058533, "xcomet_qe_score": 0.9196922779083252, "metricx_score": 1.8887842893600464, "metricx_qe_score": 6.237764835357666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich erhält jede Frage eine Hauptkategorie und eine Verkettung von Unterkategorien.", "metrics": {"bleu_score": 74.25271143743538, "chrf_score": 83.16261380596148, "xcomet_score": 0.9880697727203369, "xcomet_qe_score": 0.9875448346138, "metricx_score": 1.4650192260742188, "metricx_qe_score": 1.3019050359725952, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel enthält eine Verkettung ihrer nachfolgenden Überschrift in der Struktur des Gesetzes.", "metrics": {"bleu_score": 13.834368456410946, "chrf_score": 60.31964010721841, "xcomet_score": 0.9810454845428467, "xcomet_qe_score": 0.9637426137924194, "metricx_score": 2.8446524143218994, "metricx_qe_score": 3.8826515674591064, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten jedoch für zukünftige Forschungen im Bereich der rechtlichen Informationsbeschaffung oder der rechtlichen Steuerklassifizierung von Interesse sein.", "metrics": {"bleu_score": 48.64547353242454, "chrf_score": 69.6550521915149, "xcomet_score": 0.8916373252868652, "xcomet_qe_score": 0.8971074223518372, "metricx_score": 5.428324222564697, "metricx_qe_score": 4.877872943878174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Werfen wir einen Blick auf einige Merkmale unserer Datensätze.", "metrics": {"bleu_score": 9.980099403873663, "chrf_score": 54.42591518181904, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.18846166133880615, "metricx_qe_score": 0.16931921243667603, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen haben eine Länge zwischen 5 und 44 Wörtern, mit einem Median von 14 Wörtern.", "metrics": {"bleu_score": 22.786788980326644, "chrf_score": 53.78912426005093, "xcomet_score": 0.9597468376159668, "xcomet_qe_score": 0.9797479510307312, "metricx_score": 1.4528350830078125, "metricx_qe_score": 0.7749128341674805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind deutlich länger, mit einer medianen Länge von 77 Wörtern, bei 142", "metrics": {"bleu_score": 16.715995163653716, "chrf_score": 44.18135017586112, "xcomet_score": 0.8117091655731201, "xcomet_qe_score": 0.7464232444763184, "metricx_score": 11.237098693847656, "metricx_qe_score": 7.018628120422363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "über 1000", "metrics": {"bleu_score": 0.0, "chrf_score": 2.6211950394588497, "xcomet_score": 0.16366828978061676, "xcomet_qe_score": 0.1467054933309555, "metricx_score": 17.719276428222656, "metricx_qe_score": 14.737393379211426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfassen die Fragen ein breites Themenspektrum, wobei etwa 85 % von ihnen sich entweder mit Familie, Wohnen, Finanzen oder Recht beschäftigen.", "metrics": {"bleu_score": 21.37557596199515, "chrf_score": 52.55015997139848, "xcomet_score": 0.9880337715148926, "xcomet_qe_score": 0.9885863661766052, "metricx_score": 0.4236809313297272, "metricx_qe_score": 0.16486939787864685, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "während sich die verbleibenden 15 % auf die soziale Sicherheit, Ausländer oder Arbeit beziehen.", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 56.85974688123431, "xcomet_score": 0.9907159805297852, "xcomet_qe_score": 0.9792540073394775, "metricx_score": 0.6115039587020874, "metricx_qe_score": 0.7188026905059814, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind ebenfalls sehr vielfältig, da sie aus 32 verschiedenen belgischen Gesetzbüchern stammen, die eine große Anzahl rechtlicher Themen abdecken.", "metrics": {"bleu_score": 68.7941939352187, "chrf_score": 82.53132570014687, "xcomet_score": 0.9973621368408203, "xcomet_qe_score": 0.9967601299285889, "metricx_score": 0.12938451766967773, "metricx_qe_score": 0.2019561380147934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Gesetze gesammelt wurden.", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 81.17173780576216, "xcomet_score": 0.9626122713088989, "xcomet_qe_score": 0.9320229291915894, "metricx_score": 0.9739340543746948, "metricx_qe_score": 3.5438766479492188, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den 22.633 Artikeln werden nur 1.612 als für mindestens einen", "metrics": {"bleu_score": 43.001501058239725, "chrf_score": 63.74410610746645, "xcomet_score": 0.6746301054954529, "xcomet_qe_score": 0.3504645824432373, "metricx_score": 8.487068176269531, "metricx_qe_score": 9.67127513885498, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "eine Frage in den Datensätzen. Und etwa 80 % dieser zitierten Artikel stammen entweder aus dem Bürgerlichen Gesetzbuch, dem Gerichtsverfassungsgesetz, dem Strafprozessordnung oder dem Strafgesetzbuch.", "metrics": {"bleu_score": 32.73438058221482, "chrf_score": 62.609445295473975, "xcomet_score": 0.7386733889579773, "xcomet_qe_score": 0.7124360203742981, "metricx_score": 7.869987487792969, "metricx_qe_score": 10.65577507019043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen haben 18 von 32 Codes weniger als 5 Artikel, die als für mindestens eine Frage relevant erwähnt werden.", "metrics": {"bleu_score": 20.46592065585361, "chrf_score": 56.15406183220074, "xcomet_score": 0.9524415731430054, "xcomet_qe_score": 0.96983802318573, "metricx_score": 2.3215794563293457, "metricx_qe_score": 2.2391579151153564, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Was dadurch erklärt werden kann, dass diese Codes weniger auf Individuen und ihre Anliegen fokussieren.", "metrics": {"bleu_score": 11.022825290043492, "chrf_score": 42.838658321263814, "xcomet_score": 0.9799657464027405, "xcomet_qe_score": 0.9882124066352844, "metricx_score": 4.8596625328063965, "metricx_qe_score": 3.4576783180236816, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt beträgt die mittlere Anzahl der Zitationen für diese zitierten Artikel 2, und weniger als 25 % von ihnen sind", "metrics": {"bleu_score": 18.494134750252883, "chrf_score": 46.477733179596086, "xcomet_score": 0.827593207359314, "xcomet_qe_score": 0.8508083820343018, "metricx_score": 11.077449798583984, "metricx_qe_score": 9.53565788269043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen vergleichen wir mehrere Abrufmethoden, einschließlich lexikalischer und dichter Architekturen.", "metrics": {"bleu_score": 20.23302501778005, "chrf_score": 49.26143550794992, "xcomet_score": 0.9659762382507324, "xcomet_qe_score": 0.9777017831802368, "metricx_score": 0.8675940036773682, "metricx_qe_score": 0.7447395324707031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrage-Artikel-Paarung einen Wert zu, indem es die Summe der Gewichte jedes dieser Begriffe in diesem Artikel berechnet.", "metrics": {"bleu_score": 40.769946443977375, "chrf_score": 70.33318990624706, "xcomet_score": 0.9443095922470093, "xcomet_qe_score": 0.9337329864501953, "metricx_score": 2.5664138793945312, "metricx_qe_score": 2.6146392822265625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TF-IDF- und BM25-Ranking-Funktionen.", "metrics": {"bleu_score": 32.46679154750989, "chrf_score": 87.20967805283807, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6824494004249573, "metricx_qe_score": 1.3517117500305176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem dieser Ansätze besteht darin, dass sie nur Artikel zurückrufen können, die Schlüsselwörter enthalten, die in der Abfrage vorhanden sind.", "metrics": {"bleu_score": 49.124158433111575, "chrf_score": 74.01961929783236, "xcomet_score": 0.9879562854766846, "xcomet_qe_score": 0.9883304834365845, "metricx_score": 2.226461887359619, "metricx_qe_score": 1.5153238773345947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer auf Neuronen basierenden Architektur, die semantische Beziehungen zwischen Anfragen und Artikeln erfassen kann.", "metrics": {"bleu_score": 68.80430849756435, "chrf_score": 89.24114264028027, "xcomet_score": 0.9927635192871094, "xcomet_qe_score": 0.9986488819122314, "metricx_score": 0.41268911957740784, "metricx_qe_score": 0.3206271827220917, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Encoder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen abbildet und einen Relevanz-Score zwischen einer Abfrage-Artikel-Paarung anhand der Ähnlichkeit ihrer Einbettungen berechnet.", "metrics": {"bleu_score": 50.37208022655438, "chrf_score": 83.13214117398601, "xcomet_score": 0.8694502115249634, "xcomet_qe_score": 0.8517340421676636, "metricx_score": 2.114194393157959, "metricx_qe_score": 2.8863131999969482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen entstehen typischerweise durch eine Pooling-Operation auf der Ausgabe eines Wort-Einbettungsmodells.", "metrics": {"bleu_score": 29.48553103743023, "chrf_score": 70.05155790559239, "xcomet_score": 0.9056642055511475, "xcomet_qe_score": 0.8769818544387817, "metricx_score": 1.184972882270813, "metricx_qe_score": 2.3925483226776123, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Effektivität von Siamese b-Encodern in einem Zero-Shot-Evaluierungsszenario, was bedeutet, dass vorab trainierte Holz-Einbettungsmodelle direkt aus der Box ohne zusätzliche Feinabstimmung angewendet werden.", "metrics": {"bleu_score": 26.66090188234886, "chrf_score": 75.01039237981078, "xcomet_score": 0.75489342212677, "xcomet_qe_score": 0.731878399848938, "metricx_score": 6.27388334274292, "metricx_qe_score": 5.769403457641602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, sowie kontextabhängigen Einbettungsmodellen, nämlich Robota und spezifischer Camembert, welches ein französisches Robota-Modell ist.", "metrics": {"bleu_score": 14.668528946556558, "chrf_score": 65.49036535913856, "xcomet_score": 0.9109074473381042, "xcomet_qe_score": 0.8660686612129211, "metricx_score": 4.999417781829834, "metricx_qe_score": 4.098969459533691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes, auf Camembert basierendes Modell über die Codierer hinaus.", "metrics": {"bleu_score": 31.523777567675985, "chrf_score": 59.35018266985431, "xcomet_score": 0.8182375431060791, "xcomet_qe_score": 0.8178970813751221, "metricx_score": 6.507439613342285, "metricx_qe_score": 6.4506964683532715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Datensätzen. Beachten Sie, dass wir für das Training die beiden Varianten der Bianco-Architektur experimentell untersuchen.", "metrics": {"bleu_score": 25.34743707366162, "chrf_score": 66.25156286493541, "xcomet_score": 0.7038954496383667, "xcomet_qe_score": 0.6068614721298218, "metricx_score": 9.350529670715332, "metricx_qe_score": 9.530984878540039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Wort-Einbettungsmodell verwendet, das die Abfrage und den Artikel in einen gemeinsamen dichten Vektorraum abbildet. Und Tutowa, das zwei unabhängige Wort-Einbettungsmodelle verwendet, die die Abfrage und den Artikel separat in unterschiedliche Einbettungsräume kodieren.", "metrics": {"bleu_score": 49.66088881851595, "chrf_score": 78.4637294633211, "xcomet_score": 0.7706674337387085, "xcomet_qe_score": 0.7119166851043701, "metricx_score": 5.175889492034912, "metricx_qe_score": 6.194055080413818, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Mittelwert-, Maximal- und CLS-Pooling sowie Punktprodukt und Kosinus zur Berechnung von Ähnlichkeiten.", "metrics": {"bleu_score": 25.97064970745608, "chrf_score": 79.42745418961536, "xcomet_score": 0.8681161403656006, "xcomet_qe_score": 0.8503940105438232, "metricx_score": 1.2092218399047852, "metricx_qe_score": 1.713172435760498, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Basismessung auf dem Testdatensatz.", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 66.08205403901798, "xcomet_score": 0.9095273017883301, "xcomet_qe_score": 0.9383864402770996, "metricx_score": 1.3905811309814453, "metricx_qe_score": 1.236983060836792, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den oben genannten lexikalischen Methoden, den siamesischen b-Encodern, die in einem Zero-Shot-Setup in der Mitte bewertet wurden, und den feinabgestimmten b-Encodern darunter.", "metrics": {"bleu_score": 22.56490809237466, "chrf_score": 68.67237415452449, "xcomet_score": 0.8995507955551147, "xcomet_qe_score": 0.8640793561935425, "metricx_score": 5.186811447143555, "metricx_qe_score": 4.481362342834473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertrifft der feinabgestimmte B-Encoder alle anderen Basslinien erheblich.", "metrics": {"bleu_score": 18.60045401920258, "chrf_score": 80.53898167228635, "xcomet_score": 0.866960346698761, "xcomet_qe_score": 0.8700107336044312, "metricx_score": 4.935486793518066, "metricx_qe_score": 4.804893493652344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Zweiturm-Modell schneidet bei der Rückrufgenauigkeit bei 100 im Vergleich zu seiner siamesischen Variante besser ab, zeigt jedoch bei den anderen Metriken eine ähnliche Leistung.", "metrics": {"bleu_score": 10.924856017658641, "chrf_score": 50.734854114420514, "xcomet_score": 0.9336509704589844, "xcomet_qe_score": 0.935614824295044, "metricx_score": 2.195568561553955, "metricx_qe_score": 2.113658905029297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM25 im Vergleich zum trainierten Biancoda deutlich schlechter abschnitt, zeigt seine Leistung, dass es immer noch eine starke Basislinie für die domänenspezifische Informationsrückgewinnung darstellt.", "metrics": {"bleu_score": 17.678748653651848, "chrf_score": 63.77169780657903, "xcomet_score": 0.7721846699714661, "xcomet_qe_score": 0.8046671748161316, "metricx_score": 6.804813385009766, "metricx_qe_score": 6.789921760559082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Zero-Shot-Bewertung des Siamese-Biancoders stellen wir fest, dass die direkte Verwendung der Einbettungen eines vorab trainierten Camembert-Modells ohne Optimierung für die Informationsrückgewinnungsaufgabe zu schlechten Ergebnissen führt, was mit früheren Erkenntnissen übereinstimmt.", "metrics": {"bleu_score": 53.635905252552426, "chrf_score": 78.10440448754846, "xcomet_score": 0.8003969788551331, "xcomet_qe_score": 0.7735011577606201, "metricx_score": 2.3943228721618652, "metricx_qe_score": 2.061542272567749, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellten wir fest, dass das auf Word2Vec basierende Biance-Modell die FastText- und Bird-basierten Modelle deutlich übertreffen konnte. Dies deutet darauf hin, dass möglicherweise vorab trainierte wortbasierte Einbettungen für die Aufgabe besser geeignet sind als zeichnen- oder subwortbasierte Einbettungen, wenn sie direkt verwendet werden.", "metrics": {"bleu_score": 23.962966980870544, "chrf_score": 62.882633149084036, "xcomet_score": 0.5921409130096436, "xcomet_qe_score": 0.5852084755897522, "metricx_score": 6.908051490783691, "metricx_qe_score": 6.687495708465576, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl vielversprechend, deuten diese Ergebnisse auf erhebliche Verbesserungsmöglichkeiten hin im Vergleich zu einem geschickten Rechtsexperten, der letztlich zu jeder Frage alle relevanten Artikel finden und somit perfekte Ergebnisse erzielen kann.", "metrics": {"bleu_score": 21.14641321105091, "chrf_score": 63.958340347640515, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.49284687638282776, "metricx_qe_score": 0.3598121404647827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend wollen wir zwei Einschränkungen aller Datensätze diskutieren.", "metrics": {"bleu_score": 10.147104008451905, "chrf_score": 50.21516055547076, "xcomet_score": 0.9352709054946899, "xcomet_qe_score": 0.9311783909797668, "metricx_score": 2.7148525714874268, "metricx_qe_score": 1.4220895767211914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf diejenigen beschränkt, die aus den 32 berücksichtigten belgischen Gesetzbüchern gesammelt wurden, was nicht das gesamte belgische Recht abdeckt, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen.", "metrics": {"bleu_score": 52.59274262418306, "chrf_score": 76.48913488023481, "xcomet_score": 0.9444582462310791, "xcomet_qe_score": 0.9429373145103455, "metricx_score": 1.8520530462265015, "metricx_qe_score": 1.8243623971939087, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während des Aufbaus des Datensatzes werden alle Verweise auf diese nicht gesammelten Artikel ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der anfänglichen Anzahl relevanter Artikel enthalten.", "metrics": {"bleu_score": 43.02459853568892, "chrf_score": 68.74547648897355, "xcomet_score": 0.9827593564987183, "xcomet_qe_score": 0.9744861125946045, "metricx_score": 1.1968237161636353, "metricx_qe_score": 1.058178186416626, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsverlust impliziert, dass die Antwort, die in den verbleibenden relevanten Artikeln enthalten ist, unvollständig sein könnte, obwohl sie immer noch völlig angemessen ist.", "metrics": {"bleu_score": 77.70868553166369, "chrf_score": 86.6893097164127, "xcomet_score": 0.9783514738082886, "xcomet_qe_score": 0.958383321762085, "metricx_score": 1.77516508102417, "metricx_qe_score": 1.901847243309021, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle Rechtsfragen allein mit Gesetzen beantwortet werden können.", "metrics": {"bleu_score": 76.59552353576204, "chrf_score": 87.41325221070413, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.01791616901755333, "metricx_qe_score": 0.15809199213981628, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage, ob ich meine Mieter beeinflussen kann, wenn sie zu viel Lärm machen,", "metrics": {"bleu_score": 44.89771072202119, "chrf_score": 68.55755209323995, "xcomet_score": 0.8432713747024536, "xcomet_qe_score": 0.8202929496765137, "metricx_score": 4.644018173217773, "metricx_qe_score": 4.934665679931641, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Es kann sein, dass das gesetzliche Recht keine detaillierte Antwort bietet, die einen spezifischen Geräuschschwellenwert quantifiziert, ab dem eine Räumung zulässig ist.", "metrics": {"bleu_score": 21.50934554032252, "chrf_score": 56.43180465637839, "xcomet_score": 0.9817785024642944, "xcomet_qe_score": 0.9872211813926697, "metricx_score": 0.9250701069831848, "metricx_qe_score": 0.7557576298713684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich stärker auf die Rechtsprechung zurückgreifen und Präzedenzfälle finden, die ihrer aktuellen Situation ähnlich sind.", "metrics": {"bleu_score": 41.0362943260989, "chrf_score": 76.1320203749647, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.452372670173645, "metricx_qe_score": 0.32244908809661865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel veranstaltet der Mieter wöchentlich zwei Partys bis 2 Uhr morgens.", "metrics": {"bleu_score": 16.664087508224515, "chrf_score": 64.00026435515352, "xcomet_score": 0.9894815683364868, "xcomet_qe_score": 0.9800301790237427, "metricx_score": 0.23137451708316803, "metricx_qe_score": 0.1648014485836029, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher eignen sich einige Fragen besser als andere für die gesetzliche Artikelabrufdatenaufgabe, und der Bereich der weniger geeigneten Fragen bleibt zu bestimmen.", "metrics": {"bleu_score": 24.680222803952912, "chrf_score": 56.18583458573971, "xcomet_score": 0.9471027255058289, "xcomet_qe_score": 0.9356512427330017, "metricx_score": 2.015779972076416, "metricx_qe_score": 1.4931879043579102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur gesetzlichen Artikel-Rückgewinnung weckt.", "metrics": {"bleu_score": 55.65223707435515, "chrf_score": 71.87489239326523, "xcomet_score": 0.9535152912139893, "xcomet_qe_score": 0.9692267179489136, "metricx_score": 1.9180357456207275, "metricx_qe_score": 0.8003433346748352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zu Gerechtigkeit für alle zu verbessern.", "metrics": {"bleu_score": 61.62607099729587, "chrf_score": 78.09070176388342, "xcomet_score": 0.9838943481445312, "xcomet_qe_score": 1.0, "metricx_score": 0.6685551404953003, "metricx_qe_score": 0.4498259425163269, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unsere Arbeit, DATSET&CODE, unter den folgenden Links einsehen:\n\nVielen Dank.", "metrics": {"bleu_score": 25.63380983782248, "chrf_score": 55.47468365197656, "xcomet_score": 0.920276939868927, "xcomet_qe_score": 0.9609239101409912, "metricx_score": 7.985556602478027, "metricx_qe_score": 6.8752546310424805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Wir freuen uns, unsere Arbeit an VAUS vorzustellen, einem aufgabenunabhängigen Benchmark, der dazu dient, visuelle und sprachliche Modelle mit spezifischen linguistischen Phänomenen zu testen.", "metrics": {"bleu_score": 9.03671460499742, "chrf_score": 53.294104893172076, "xcomet_score": 0.8090928792953491, "xcomet_qe_score": 0.8341317176818848, "metricx_score": 4.627701282501221, "metricx_qe_score": 4.661034107208252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark zu etablieren?", "metrics": {"bleu_score": 75.39221180326287, "chrf_score": 80.66693411150588, "xcomet_score": 0.9970982074737549, "xcomet_qe_score": 0.9944957494735718, "metricx_score": 0.2042403370141983, "metricx_qe_score": 0.28973454236984253, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von transformatorbasierten Vision- und Sprachmodellen erlebt, die auf großen Mengen von Bild-Text-Paaren vorabtrainiert wurden.", "metrics": {"bleu_score": 43.07079424240215, "chrf_score": 72.81014360628897, "xcomet_score": 0.9334266185760498, "xcomet_qe_score": 0.9469716548919678, "metricx_score": 2.173920154571533, "metricx_qe_score": 1.9925508499145508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle schiebt den Stand der Technik in den Bereichen Sehen und Sprache voran, wie z. B. visuelle Fragebeantwortung, visuelle gesunder Menschenverstand-Schlussfolgerung, Bildabruf, Phrasenverankerung und weitere.", "metrics": {"bleu_score": 23.270804908165125, "chrf_score": 53.18100555420029, "xcomet_score": 0.9299469590187073, "xcomet_qe_score": 0.9336035251617432, "metricx_score": 3.0371344089508057, "metricx_qe_score": 2.807490110397339, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Also erhielten wir eine Nachricht. Die Genauigkeiten bei diesen aufgabenbezogenen Benchmarks nehmen stetig zu.", "metrics": {"bleu_score": 9.327679971502556, "chrf_score": 52.72224653980211, "xcomet_score": 0.9813904762268066, "xcomet_qe_score": 0.9758379459381104, "metricx_score": 0.8856423497200012, "metricx_qe_score": 1.3969690799713135, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir tatsächlich, was die Modelle wirklich gelernt haben?", "metrics": {"bleu_score": 40.12671145009052, "chrf_score": 86.22836570213883, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.48919209837913513, "metricx_qe_score": 0.8848564028739929, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Sprach-Transformer verstanden, als er dieser Bild- und Satzpaarung eine hohe Übereinstimmungspunktzahl zuwies?", "metrics": {"bleu_score": 19.75829551377349, "chrf_score": 60.75711429949215, "xcomet_score": 0.8971221446990967, "xcomet_qe_score": 0.8998109102249146, "metricx_score": 1.4219844341278076, "metricx_qe_score": 2.399477958679199, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "und eine niedrige Punktzahl für diese Aufgabe.", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 68.11285362198022, "xcomet_score": 0.9823320508003235, "xcomet_qe_score": 0.9747308492660522, "metricx_score": 1.0096596479415894, "metricx_qe_score": 1.1718268394470215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich visuelle und sprachliche Modelle auf das Richtige?", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 49.57409187641929, "xcomet_score": 0.9732088446617126, "xcomet_qe_score": 0.9870170950889587, "metricx_score": 0.6196063756942749, "metricx_qe_score": 0.383514404296875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Voreingenommenheiten, wie sie in früheren Arbeiten gezeigt wurden?", "metrics": {"bleu_score": 37.0304683381906, "chrf_score": 74.94495401375616, "xcomet_score": 0.9937005043029785, "xcomet_qe_score": 1.0, "metricx_score": 0.2957363724708557, "metricx_qe_score": 0.2559237480163574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt weiter zu beleuchten, schlagen wir eine eher aufgabenunabhängige Richtung vor und führen Ventile ein, die die Sensitivität von Seh- und Sprachmodellen gegenüber spezifischen sprachlichen Phänomenen testen, die sowohl die sprachliche als auch die visuelle Modalität beeinflussen.", "metrics": {"bleu_score": 36.296771737863, "chrf_score": 69.66048036174271, "xcomet_score": 0.7929261922836304, "xcomet_qe_score": 0.8008260726928711, "metricx_score": 4.349906921386719, "metricx_qe_score": 3.9654417037963867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir fokussieren Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitäts-Coreferenz.", "metrics": {"bleu_score": 45.06908224507598, "chrf_score": 74.72805273273671, "xcomet_score": 0.9311553239822388, "xcomet_qe_score": 0.9330446720123291, "metricx_score": 1.6312443017959595, "metricx_qe_score": 1.5091272592544556, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle diese Phänomene erfasst haben?", "metrics": {"bleu_score": 18.010019776510696, "chrf_score": 58.27132232830024, "xcomet_score": 0.9880971312522888, "xcomet_qe_score": 0.9893398284912109, "metricx_score": 1.2659409046173096, "metricx_qe_score": 0.7758669853210449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch die FOIL-Methode, eine zuvor für Seh- und Sprachmodelle angewendete Technik, jedoch nur für Nominalphrasen von Ravi Shekhar und Mitarbeitern, sowie auf Zählen in unserer früheren Arbeit, lässt sich dies erreichen.", "metrics": {"bleu_score": 13.740950768136107, "chrf_score": 56.688017465138266, "xcomet_score": 0.7978392839431763, "xcomet_qe_score": 0.8748267292976379, "metricx_score": 4.563262462615967, "metricx_qe_score": 4.363589286804199, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Wesentlichen, dass wir die Bildunterschrift eines Bildes nehmen und eine Folie erstellen, indem wir die Bildunterschrift so verändern, dass sie das Bild nicht mehr beschreibt.", "metrics": {"bleu_score": 59.035838588615405, "chrf_score": 67.65504378701095, "xcomet_score": 0.7880864143371582, "xcomet_qe_score": 0.9443144798278809, "metricx_score": 3.576050281524658, "metricx_qe_score": 1.5036132335662842, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Phrasenänderungen durch, indem wir uns auf sechs spezifische Bereiche konzentrieren, wie Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitäts-Coreferenz, wobei jeder Bereich aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Methode zur Erstellung von FOIL-Instanzen finden.", "metrics": {"bleu_score": 47.237623417806816, "chrf_score": 73.60481095659833, "xcomet_score": 0.8518749475479126, "xcomet_qe_score": 0.9073477387428284, "metricx_score": 2.6372833251953125, "metricx_qe_score": 2.600600004196167, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir beim Aktionssegment zwei Instrumente: eines, bei dem das Aktionsverb durch eine andere Aktion geändert wird, und eines, bei dem die Akteure ausgetauscht werden.", "metrics": {"bleu_score": 45.94947999814308, "chrf_score": 65.44567548982012, "xcomet_score": 0.9559000730514526, "xcomet_qe_score": 0.940194845199585, "metricx_score": 2.257558822631836, "metricx_qe_score": 2.5113749504089355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Referenzierung sind ebenfalls Teile, die mehr als ein Instrument haben.", "metrics": {"bleu_score": 62.628449627654696, "chrf_score": 68.36218874265673, "xcomet_score": 0.9010167121887207, "xcomet_qe_score": 0.9117263555526733, "metricx_score": 2.577836751937866, "metricx_qe_score": 3.601621150970459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir erstellen diese Folien, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalisch korrekte und ansonsten gültige Sätze sind.", "metrics": {"bleu_score": 59.12723140736851, "chrf_score": 74.91699514971785, "xcomet_score": 0.902816116809845, "xcomet_qe_score": 0.9389380812644958, "metricx_score": 3.403322696685791, "metricx_qe_score": 2.061774730682373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist nicht einfach zu tun, da eine untertitelte Bildunterschrift weniger wahrscheinlich sein kann als die ursprüngliche Bildunterschrift.", "metrics": {"bleu_score": 20.76047003130265, "chrf_score": 58.743647213856285, "xcomet_score": 0.8140162229537964, "xcomet_qe_score": 0.8252915143966675, "metricx_score": 3.3743796348571777, "metricx_qe_score": 2.928915023803711, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es statistisch gesehen weniger wahrscheinlich, dass Pflanzen einen Menschen verletzen als dass Menschen Pflanzen beschädigen, auch wenn es nicht unmöglich ist. Große Vision- und Sprachmodelle könnten diese Nuance erfassen.", "metrics": {"bleu_score": 19.451888725956593, "chrf_score": 66.74542452202249, "xcomet_score": 0.9514889717102051, "xcomet_qe_score": 0.9609445929527283, "metricx_score": 2.5023550987243652, "metricx_qe_score": 1.3435291051864624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Daher müssen wir handeln, um gültige Folien zu erhalten.", "metrics": {"bleu_score": 36.029870008455966, "chrf_score": 52.70563014012848, "xcomet_score": 0.9064809083938599, "xcomet_qe_score": 0.9300216436386108, "metricx_score": 2.968672275543213, "metricx_qe_score": 1.6910076141357422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir leistungsstarke Sprachmodelle, um Foils vorzuschlagen.", "metrics": {"bleu_score": 22.957488466614326, "chrf_score": 63.506797477802756, "xcomet_score": 0.8387070894241333, "xcomet_qe_score": 0.8701152801513672, "metricx_score": 4.8929853439331055, "metricx_qe_score": 4.105778694152832, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir natürliche Sprachinferenz, kurz NLI, um Foils auszufiltern, die immer noch das Bild beschreiben könnten, da wir beim Konstruieren von Foils sicherstellen müssen, dass sie das Bild nicht beschreiben.", "metrics": {"bleu_score": 32.164471346566856, "chrf_score": 63.75460368776411, "xcomet_score": 0.7806448340415955, "xcomet_qe_score": 0.8434062004089355, "metricx_score": 7.563268661499023, "metricx_qe_score": 6.328136920928955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir natürliche Sprachinferenz mit der folgenden Begründung an.", "metrics": {"bleu_score": 47.0979469721022, "chrf_score": 72.66430637999359, "xcomet_score": 0.9916956424713135, "xcomet_qe_score": 0.9926766157150269, "metricx_score": 1.312764286994934, "metricx_qe_score": 1.2690821886062622, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als Prämisse und seine Bildunterschrift als daraus folgende Hypothese.", "metrics": {"bleu_score": 35.45185134900477, "chrf_score": 65.78664728061253, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.227126806974411, "metricx_qe_score": 0.33467331528663635, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich betrachten wir die Bildunterschrift als Prämisse und die FOIL-Methode als deren Hypothese.", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 53.89264110837988, "xcomet_score": 0.8898801803588867, "xcomet_qe_score": 0.9248313903808594, "metricx_score": 2.956234931945801, "metricx_qe_score": 1.7000081539154053, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass das FOIL der Bildunterschrift widerspricht oder neutral dazu steht, interpretieren wir dies als Hinweis auf ein gültiges FOIL.", "metrics": {"bleu_score": 25.29974973126262, "chrf_score": 52.94119929918064, "xcomet_score": 0.8406130075454712, "xcomet_qe_score": 0.9829944968223572, "metricx_score": 4.4932122230529785, "metricx_qe_score": 2.054824113845825, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die FOIL durch die Bildunterschrift impliziert wird, kann es sich nicht um eine gute FOIL handeln, da sie durch Transitivität eine wahre Beschreibung des Bildes liefern würde und wir solche FOILs herausfiltern.", "metrics": {"bleu_score": 31.9762958429705, "chrf_score": 57.14424154945351, "xcomet_score": 0.7311129570007324, "xcomet_qe_score": 0.7533693909645081, "metricx_score": 5.822728157043457, "metricx_qe_score": 5.461478233337402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Verfahren ist jedoch nicht perfekt, es dient lediglich als Indikator für gültige Folien.", "metrics": {"bleu_score": 21.305413619585096, "chrf_score": 58.03517009682751, "xcomet_score": 0.9076249599456787, "xcomet_qe_score": 0.9882248044013977, "metricx_score": 1.5676958560943604, "metricx_qe_score": 0.47599631547927856, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher setzen wir als dritte Maßnahme zur Generierung gültiger FOIs menschliche Annotatoren ein, um die in VALS verwendeten Daten zu validieren.", "metrics": {"bleu_score": 75.22135016840222, "chrf_score": 86.32273354363598, "xcomet_score": 0.915652871131897, "xcomet_qe_score": 0.9862256050109863, "metricx_score": 3.247945547103882, "metricx_qe_score": 2.3987531661987305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung verfügen wir über so viele Testfälle, wie in dieser Tabelle beschrieben.", "metrics": {"bleu_score": 56.79161104357995, "chrf_score": 68.92332344111058, "xcomet_score": 0.9999455213546753, "xcomet_qe_score": 0.9996459484100342, "metricx_score": 0.8075124025344849, "metricx_qe_score": 0.740578293800354, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten liefert, sondern nur Testdaten.", "metrics": {"bleu_score": 28.025542898280413, "chrf_score": 81.78857772591213, "xcomet_score": 0.9688535928726196, "xcomet_qe_score": 0.9927035570144653, "metricx_score": 0.4330703616142273, "metricx_qe_score": 0.8924462795257568, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "da es sich lediglich um einen Zero-Shot-Test-Benchmark handelt. Es ist darauf ausgelegt, die bestehenden Fähigkeiten von Bild- und Sprachmodellen nach dem Prätraining zu nutzen.", "metrics": {"bleu_score": 9.797066524017463, "chrf_score": 65.96955115663998, "xcomet_score": 0.8797338604927063, "xcomet_qe_score": 0.7800008654594421, "metricx_score": 3.0721707344055176, "metricx_qe_score": 3.257711887359619, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmung würde Modellen nur ermöglichen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen.", "metrics": {"bleu_score": 73.64816905995104, "chrf_score": 91.48698544935452, "xcomet_score": 0.9989519119262695, "xcomet_qe_score": 0.9931868314743042, "metricx_score": 0.2552180290222168, "metricx_qe_score": 0.29619288444519043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir wissen alle, dass diese Modelle gerne schummeln und Abkürzungen nehmen.", "metrics": {"bleu_score": 46.825687910244035, "chrf_score": 81.6311608348254, "xcomet_score": 0.9984153509140015, "xcomet_qe_score": 0.9992567300796509, "metricx_score": 0.5725303888320923, "metricx_qe_score": 0.7877547740936279, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie bereits erwähnt, sind wir daran interessiert, die Fähigkeiten der Vision- und Sprachmodelle nach dem Prätraining zu bewerten.", "metrics": {"bleu_score": 18.258155983864146, "chrf_score": 58.67049008001168, "xcomet_score": 0.9865331649780273, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.230276346206665, "metricx_qe_score": 0.7256960868835449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen an Vokalen, nämlich mit CLIP, LXMIRT, VILBERT, VILBERT12IN1 und VISUALBERT.", "metrics": {"bleu_score": 27.764493708491923, "chrf_score": 60.87381845204448, "xcomet_score": 0.7401057481765747, "xcomet_qe_score": 0.7257860898971558, "metricx_score": 5.997348785400391, "metricx_qe_score": 5.326331615447998, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satz-Paaren in Bildunterschriften und Scheingegenstände.", "metrics": {"bleu_score": 46.09603493497927, "chrf_score": 70.31221592776463, "xcomet_score": 0.8887609243392944, "xcomet_qe_score": 0.8054176568984985, "metricx_score": 2.2370998859405518, "metricx_qe_score": 2.8259694576263428, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht relevanter für dieses Video werden wir unsere weniger restriktive Metrik, die paarweise Genauigkeit, vorstellen, die misst, ob die Bild-Satz-Ausrichtungspunktzahl für das korrekte Bild-Text-Paar höher ist als für sein manipuliertes Paar.", "metrics": {"bleu_score": 30.725699993030275, "chrf_score": 70.27351048482156, "xcomet_score": 0.9042367935180664, "xcomet_qe_score": 0.8406141996383667, "metricx_score": 2.631087303161621, "metricx_qe_score": 2.3788001537323, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Metriken und Ergebnisse dazu, verweisen wir auf unsere Publikation.", "metrics": {"bleu_score": 20.448007360218387, "chrf_score": 61.76353615463049, "xcomet_score": 0.9997813701629639, "xcomet_qe_score": 1.0, "metricx_score": 0.7023999691009521, "metricx_qe_score": 0.5938980579376221, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit paarweiser Genauigkeit sind hier dargestellt und stimmen mit den Ergebnissen überein, die wir aus den anderen Metriken erhalten haben. Es ist so, dass die beste Zero-Shot-Leistung von Wilbert 12 in 1 erreicht wird, gefolgt von Wilbert, Alexmert, Klip und schließlich Visualbert.", "metrics": {"bleu_score": 44.69785291399124, "chrf_score": 71.29226446272308, "xcomet_score": 0.5560270547866821, "xcomet_qe_score": 0.5693792104721069, "metricx_score": 7.6195292472839355, "metricx_qe_score": 7.045363426208496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf individuelle Objekte wie Existenz und Nomenphrasen konzentrieren, in Wilbert 12 in 1 fast vollständig gelöst werden, was darauf hinweist, dass Modelle in der Lage sind, benannte Objekte und ihre Präsenz in Bildern zu identifizieren.", "metrics": {"bleu_score": 53.295492957635986, "chrf_score": 69.24722310689441, "xcomet_score": 0.8630722165107727, "xcomet_qe_score": 0.8850442171096802, "metricx_score": 4.220351219177246, "metricx_qe_score": 4.046988487243652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann keines der verbleibenden Teile in unseren feindseligen Enttarnungs-Einstellungen zuverlässig gelöst werden.", "metrics": {"bleu_score": 29.420957081163703, "chrf_score": 66.42632415279192, "xcomet_score": 0.9574068784713745, "xcomet_qe_score": 0.9265667796134949, "metricx_score": 2.2362022399902344, "metricx_qe_score": 3.357290267944336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus der Vielfalt und den Zählinstrumenten erkennen wir, dass visuelle und sprachliche Modelle Schwierigkeiten haben, Verweise auf einzelne versus mehrere Objekte zu unterscheiden oder diese in einem Bild zu zählen.", "metrics": {"bleu_score": 40.679751030160055, "chrf_score": 68.45396043074538, "xcomet_score": 0.9379719495773315, "xcomet_qe_score": 0.9084105491638184, "metricx_score": 2.371213912963867, "metricx_qe_score": 2.479069948196411, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Relationsaufgabe zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren.", "metrics": {"bleu_score": 63.83964846132483, "chrf_score": 77.27570780458458, "xcomet_score": 0.943102240562439, "xcomet_qe_score": 0.9140920639038086, "metricx_score": 0.6098007559776306, "metricx_qe_score": 1.0671653747558594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Akteure zu identifizieren, selbst wenn sie durch Plausibilitätsverzerrungen unterstützt werden, wie wir es beim Handlungsstück beobachten.", "metrics": {"bleu_score": 63.19211739683715, "chrf_score": 79.62809689047586, "xcomet_score": 0.9452019929885864, "xcomet_qe_score": 0.8867355585098267, "metricx_score": 1.2338836193084717, "metricx_qe_score": 1.4723408222198486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Coreferenzstück erfahren wir, dass das Nachverfolgen mehrerer Referenzen auf dasselbe Objekt in einem Bild mithilfe von Pronomen auch für visuelle und sprachliche Modelle schwierig ist.", "metrics": {"bleu_score": 30.958265761546162, "chrf_score": 55.84539898394419, "xcomet_score": 0.9486154317855835, "xcomet_qe_score": 0.8837816715240479, "metricx_score": 2.9452919960021973, "metricx_qe_score": 3.3499059677124023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Plausibilitätsprüfung und aufgrund des interessanten Experiments vergleichen wir auch zwei textbasierte Modelle, GPT-1 und GPT-2, um zu bewerten, ob VALS durch diese unimodalen Modelle lösbar ist, indem wir die Perplexität der korrekten und der manipulierten Bildunterschrift berechnen und den Eintrag mit der niedrigsten Perplexität vorhersagen.", "metrics": {"bleu_score": 28.74415752686828, "chrf_score": 63.41797990003688, "xcomet_score": 0.8452858924865723, "xcomet_qe_score": 0.8702936172485352, "metricx_score": 1.7019275426864624, "metricx_qe_score": 1.5182313919067383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Perplexität für die FOIL-Methode höher ist, interpretieren wir dies als Hinweis darauf, dass die FOIL-generierte Bildunterschrift unter Umständen an Plausibilitätsverzerrung oder anderen sprachlichen Verzerrungen leidet.", "metrics": {"bleu_score": 28.197516484364975, "chrf_score": 60.861591081726274, "xcomet_score": 0.9043083786964417, "xcomet_qe_score": 0.9497181177139282, "metricx_score": 3.095344305038452, "metricx_qe_score": 3.1757054328918457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die reinen Text-GPT-Modelle die Plausibilität der Welt besser erfasst haben als die Modelle für Sehen und Sprache.", "metrics": {"bleu_score": 59.11564351236676, "chrf_score": 81.21176091378614, "xcomet_score": 0.9802778959274292, "xcomet_qe_score": 0.9740350246429443, "metricx_score": 0.9265124201774597, "metricx_qe_score": 0.9611108303070068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend ist VALS ein Benchmark, der mithilfe linguistischer Konstrukte die Gemeinschaft dabei unterstützt, Vision- und Sprachmodelle zu verbessern, indem er deren visuelle Verankerungsfähigkeiten streng testet.", "metrics": {"bleu_score": 6.430003320610373, "chrf_score": 54.2308652165675, "xcomet_score": 0.8184168338775635, "xcomet_qe_score": 0.9226884245872498, "metricx_score": 2.6378936767578125, "metricx_qe_score": 0.96742844581604, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Vision- und Sprachmodelle benannte Objekte und ihre Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren.", "metrics": {"bleu_score": 54.78005111893967, "chrf_score": 76.18982076545791, "xcomet_score": 0.8613950610160828, "xcomet_qe_score": 0.8663557767868042, "metricx_score": 3.9652295112609863, "metricx_qe_score": 3.4821534156799316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Gemeinschaft wirklich ermutigen, VALS für die Messung des Fortschritts hin zur sprachlichen Verankerung mit Vision- und Sprachmodellen zu nutzen.", "metrics": {"bleu_score": 37.85337839658648, "chrf_score": 67.81013365084327, "xcomet_score": 0.9284570813179016, "xcomet_qe_score": 0.9647626876831055, "metricx_score": 2.7365365028381348, "metricx_qe_score": 3.1987171173095703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "VALS könnte sogar noch weitergehend als indirekte Bewertung von Datensätzen genutzt werden, da Modelle vor und nach dem Training oder Feintuning evaluiert werden könnten, um zu prüfen, ob ein Datensatz den Modellen hilft, sich in Bezug auf eines der durch VALS getesteten Aspekte zu verbessern.", "metrics": {"bleu_score": 34.02736009778198, "chrf_score": 62.198029461037166, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2293620109558105, "metricx_qe_score": 0.557235836982727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Falls Sie interessiert sind, werfen Sie doch einen Blick auf die VALS-Daten auf GitHub und zögern Sie nicht, uns bei Fragen zu kontaktieren.", "metrics": {"bleu_score": 20.368049655566388, "chrf_score": 51.58753279186455, "xcomet_score": 0.9981502294540405, "xcomet_qe_score": 1.0, "metricx_score": 1.4080432653427124, "metricx_qe_score": 0.8765740394592285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kami Zerua von der Universität Tokio.", "metrics": {"bleu_score": 63.40466277046863, "chrf_score": 85.52444193023891, "xcomet_score": 0.8398730754852295, "xcomet_qe_score": 0.8375144600868225, "metricx_score": 3.063661813735962, "metricx_qe_score": 2.9113340377807617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Vortrag über eine Arbeit mit dem Titel RNSUM halten, ein umfangreiches Datenset für die automatische Erstellung von Listen durch Zusammenfassung von Commit-Protokollen.", "metrics": {"bleu_score": 3.0717490052419585, "chrf_score": 29.129494514720566, "xcomet_score": 0.8971912860870361, "xcomet_qe_score": 0.8916191458702087, "metricx_score": 2.9202938079833984, "metricx_qe_score": 2.99604868888855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 88.05371765891114, "xcomet_score": 0.9900722503662109, "xcomet_qe_score": 0.983869731426239, "metricx_score": 0.4221750497817993, "metricx_qe_score": 0.7891620397567749, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikobenachrichtigung vorstellen, an der wir in dieser Forschung arbeiten.", "metrics": {"bleu_score": 71.9548353625319, "chrf_score": 73.2517737860325, "xcomet_score": 0.8050347566604614, "xcomet_qe_score": 0.8105419874191284, "metricx_score": 4.0274553298950195, "metricx_qe_score": 1.0507744550704956, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNode ist ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Version eines Softwareprodukts verteilt werden.", "metrics": {"bleu_score": 77.94261798719093, "chrf_score": 81.5010883021114, "xcomet_score": 0.8466965556144714, "xcomet_qe_score": 0.8213678002357483, "metricx_score": 6.979217052459717, "metricx_qe_score": 6.539538383483887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Versionshinweise für Version 2.6.1.", "metrics": {"bleu_score": 18.70274255449444, "chrf_score": 56.500452076012934, "xcomet_score": 0.4467293620109558, "xcomet_qe_score": 0.6208859086036682, "metricx_score": 4.992263317108154, "metricx_qe_score": 2.4205451011657715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Dies spielt zwar keine wichtige Rolle in der Open-Source-Entwicklung, aber die manuelle Vorbereitung ist zeitaufwändig.", "metrics": {"bleu_score": 9.42119686197517, "chrf_score": 61.736207568466575, "xcomet_score": 0.8068727254867554, "xcomet_qe_score": 0.8036825656890869, "metricx_score": 6.060606956481934, "metricx_qe_score": 6.217278003692627, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, automatisch hochwertige Release-Notizen generieren zu können.", "metrics": {"bleu_score": 37.07609241841855, "chrf_score": 55.87087189402479, "xcomet_score": 0.99309241771698, "xcomet_qe_score": 1.0, "metricx_score": 0.35153454542160034, "metricx_qe_score": 0.16297785937786102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zum automatischen Zuhörer-Generieren verweisen.", "metrics": {"bleu_score": 10.71174444166974, "chrf_score": 51.78359314355006, "xcomet_score": 0.7150737047195435, "xcomet_qe_score": 0.7523289918899536, "metricx_score": 10.606156349182129, "metricx_qe_score": 8.754657745361328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens Arena, das 2014 veröffentlicht wurde.", "metrics": {"bleu_score": 19.209413468550956, "chrf_score": 52.08972312408571, "xcomet_score": 0.9819424152374268, "xcomet_qe_score": 0.9836039543151855, "metricx_score": 0.3357934057712555, "metricx_qe_score": 0.4636992812156677, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es verfolgt einen regelbasierten Ansatz, beispielsweise durch die Verwendung des Änderungsextraktors, um aus den Unterschieden zwischen den Veröffentlichungen heraus wesentliche Unterschiede, Bibliotheksänderungen und Dokumentänderungen zu extrahieren und diese schließlich zu kombinieren.", "metrics": {"bleu_score": 36.408018851286805, "chrf_score": 71.34971235614555, "xcomet_score": 0.9811257123947144, "xcomet_qe_score": 0.8960469961166382, "metricx_score": 2.0571675300598145, "metricx_qe_score": 2.1357522010803223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das auffälligste Merkmal dieses Systems ist der Problem-Extraktor in der oberen rechten Ecke.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 72.7722338077958, "xcomet_score": 0.9073622226715088, "xcomet_qe_score": 0.9073933959007263, "metricx_score": 2.5669567584991455, "metricx_qe_score": 1.884312629699707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "die mit Jira, dem Issue-Tracking-System, verknüpft sein müssen und nur auf Projekte angewendet werden können, die Jira verwenden.", "metrics": {"bleu_score": 39.328368415488114, "chrf_score": 57.286235764333895, "xcomet_score": 0.8703522682189941, "xcomet_qe_score": 0.8752357959747314, "metricx_score": 2.901127576828003, "metricx_qe_score": 2.136956214904785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden.", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 93.16258475153698, "xcomet_score": 0.9909387230873108, "xcomet_qe_score": 0.9895014762878418, "metricx_score": 0.2981245517730713, "metricx_qe_score": 0.4196746051311493, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist GRIF. Erstmals im Jahr 2020 angekündigt,", "metrics": {"bleu_score": 10.71174444166974, "chrf_score": 45.621636370890926, "xcomet_score": 0.7824095487594604, "xcomet_qe_score": 0.6829854249954224, "metricx_score": 6.687697887420654, "metricx_qe_score": 4.218353748321533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Es ist im Internet verfügbar und kann über PIP gespeichert werden.", "metrics": {"bleu_score": 67.0422683816333, "chrf_score": 75.53137210277426, "xcomet_score": 0.9232152104377747, "xcomet_qe_score": 0.9601089954376221, "metricx_score": 3.5335781574249268, "metricx_qe_score": 2.9840102195739746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, auf maschinellem Lernen basierendes Modul zur Textklassifizierung und gibt für jede Eingabemeldung zu einem Commit eine von fünf Variablen aus, wie z. B. Funktionen oder Fehlerbehebungen.", "metrics": {"bleu_score": 25.516994599541135, "chrf_score": 63.476059485667655, "xcomet_score": 0.9342094659805298, "xcomet_qe_score": 0.9820678234100342, "metricx_score": 0.794952929019928, "metricx_qe_score": 0.9277644753456116, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild stellt ein Beispiel für die Verwendung dar, die eine korrigierende oder fehlerbehebende Beschriftung zurückgibt.", "metrics": {"bleu_score": 5.875148471810145, "chrf_score": 41.43346399166784, "xcomet_score": 0.9292219281196594, "xcomet_qe_score": 0.9397892355918884, "metricx_score": 2.080082416534424, "metricx_qe_score": 1.9255032539367676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsdaten von Goyafet sind relativ klein, etwa 5000, und werden in den unten beschriebenen Experimenten dargestellt.", "metrics": {"bleu_score": 49.60402400672393, "chrf_score": 73.60493178312403, "xcomet_score": 0.8012650609016418, "xcomet_qe_score": 0.7811667919158936, "metricx_score": 7.015674114227295, "metricx_qe_score": 7.6323699951171875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des Textklassifizierungsmodells ist nicht hoch.", "metrics": {"bleu_score": 50.000000000000014, "chrf_score": 83.33360912349363, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20595994591712952, "metricx_qe_score": 0.44808152318000793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungsarbeiten, doch es gab Probleme hinsichtlich der begrenzten Anwendbarkeit und spärlicher Datenressourcen.", "metrics": {"bleu_score": 11.308686807183287, "chrf_score": 63.52191410297854, "xcomet_score": 0.9828608632087708, "xcomet_qe_score": 0.9852498173713684, "metricx_score": 0.2622067928314209, "metricx_qe_score": 0.221702441573143, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit löst diese beiden Probleme und erzeugt automatisch hochwertige Freigabeknoten.", "metrics": {"bleu_score": 24.925832743644712, "chrf_score": 54.86163648340953, "xcomet_score": 0.8432998657226562, "xcomet_qe_score": 0.8167769908905029, "metricx_score": 4.702234745025635, "metricx_qe_score": 4.065844535827637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das Programm mit begrenzter Anwendbarkeit schlagen wir eine hochwertige Klassifizierungs-Zusammenfassungsmethode vor, die ausschließlich die Commit-Nachrichten als Eingabe verwendet.", "metrics": {"bleu_score": 31.636203710595492, "chrf_score": 68.56018224410735, "xcomet_score": 0.949032187461853, "xcomet_qe_score": 0.9447530508041382, "metricx_score": 1.7727259397506714, "metricx_qe_score": 2.5566325187683105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Dieser vorgeschlagene Ansatz kann für alle englischen Bibliotheken verwendet werden.", "metrics": {"bleu_score": 35.08439695638686, "chrf_score": 65.93401805653396, "xcomet_score": 0.9877747297286987, "xcomet_qe_score": 1.0, "metricx_score": 1.142592191696167, "metricx_qe_score": 1.5228886604309082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem knapp verfügbarer Datenressourcen haben wir einen RNSUM-Datensatz erstellt, der aus etwa 82.000 Datensätzen besteht. Dazu haben wir Daten aus öffentlichen GitHub-Repositorys mithilfe der GitHub-API gesammelt.", "metrics": {"bleu_score": 38.142851105726145, "chrf_score": 76.363119980957, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5624396204948425, "metricx_qe_score": 0.7714002132415771, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich, wie sie sitzen.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 45.81888337431841, "xcomet_score": 0.8469996452331543, "xcomet_qe_score": 0.8392122983932495, "metricx_score": 3.1890149116516113, "metricx_qe_score": 3.5065932273864746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel für Daten.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 81.3052385800557, "xcomet_score": 0.9865502119064331, "xcomet_qe_score": 0.9950288534164429, "metricx_score": 0.11113797873258591, "metricx_qe_score": 0.3509396016597748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Commit-Nachricht, und die rechte Seite ist die Release-Notiz.", "metrics": {"bleu_score": 6.725321874176006, "chrf_score": 43.71988037736576, "xcomet_score": 0.8974237442016602, "xcomet_qe_score": 0.8533340692520142, "metricx_score": 1.00760817527771, "metricx_qe_score": 0.9980171918869019, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Veröffentlichungsnotizen sind als Verbesserungen, Arbeitsplätze usw. gekennzeichnet.", "metrics": {"bleu_score": 28.997844147152072, "chrf_score": 41.97944213183612, "xcomet_score": 0.8378271460533142, "xcomet_qe_score": 0.8495986461639404, "metricx_score": 4.22865629196167, "metricx_qe_score": 4.512636661529541, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die übertragenen Nachrichten als Eingabe entgegennimmt und die rohen, verkabelten Stückknoten als Ausgabe liefert.", "metrics": {"bleu_score": 36.51934656347456, "chrf_score": 57.58137859372503, "xcomet_score": 0.7406172156333923, "xcomet_qe_score": 0.6051676273345947, "metricx_score": 6.426543235778809, "metricx_qe_score": 6.907036304473877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassung Aufgabe betrachtet werden.", "metrics": {"bleu_score": 34.57207846419412, "chrf_score": 80.34091178236358, "xcomet_score": 0.9727598428726196, "xcomet_qe_score": 0.9682350754737854, "metricx_score": 1.0417708158493042, "metricx_qe_score": 1.1935328245162964, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Ebenen vorgegeben: Funktionen, Verbesserungen, Fehlerbehebungen, Veraltungen, Entfernungen und breakinge Änderungen.", "metrics": {"bleu_score": 41.682189465797684, "chrf_score": 60.77711532019627, "xcomet_score": 0.6491080522537231, "xcomet_qe_score": 0.6613378524780273, "metricx_score": 7.829631805419922, "metricx_qe_score": 7.456554889678955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aussagen basieren auf früheren Forschungen und anderen Faktoren.", "metrics": {"bleu_score": 32.72874319918699, "chrf_score": 58.04868768924416, "xcomet_score": 0.998989462852478, "xcomet_qe_score": 0.993698239326477, "metricx_score": 0.6643075346946716, "metricx_qe_score": 1.2448961734771729, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Kranznotizen unten rechts sind aus den Kranznotizen unten links extrahiert.", "metrics": {"bleu_score": 29.50234363196403, "chrf_score": 48.26846164855672, "xcomet_score": 0.9050498008728027, "xcomet_qe_score": 0.987035870552063, "metricx_score": 5.093401908874512, "metricx_qe_score": 4.875247478485107, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zeitpunkt ist es notwendig, die vier im Voraus festgelegten Ebenen zu erkennen.", "metrics": {"bleu_score": 14.152447972070973, "chrf_score": 43.19746145691411, "xcomet_score": 0.9208931922912598, "xcomet_qe_score": 0.9119939208030701, "metricx_score": 1.408889651298523, "metricx_qe_score": 0.9937087297439575, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "aber die Stufen sind nicht immer mit jeder Bibliothek konsistent.", "metrics": {"bleu_score": 18.36028134946796, "chrf_score": 48.581623950900926, "xcomet_score": 0.808223307132721, "xcomet_qe_score": 0.7948556542396545, "metricx_score": 4.798022270202637, "metricx_qe_score": 4.07870626449585, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel umfasst das Verbesserungsniveau Verbesserungen, Verbesserungen, Optimierungen und so weiter.", "metrics": {"bleu_score": 40.52587697205425, "chrf_score": 63.844342608576156, "xcomet_score": 0.7904601097106934, "xcomet_qe_score": 0.8380531072616577, "metricx_score": 5.358537673950195, "metricx_qe_score": 5.134858131408691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben für jede dieser Notationsvarianten eine Vokabelliste mit Teilstudienebenen erstellt.", "metrics": {"bleu_score": 25.639731692567885, "chrf_score": 64.73879601140533, "xcomet_score": 0.8412261009216309, "xcomet_qe_score": 0.8345999121665955, "metricx_score": 5.3788604736328125, "metricx_qe_score": 5.465226173400879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Klasse der Veröffentlichungsnotiz zu erkennen und den Text der folgenden Liste als Satz der Veröffentlichungsnotiz für die Klasse zu korrigieren.", "metrics": {"bleu_score": 9.547615491387061, "chrf_score": 37.26417979639367, "xcomet_score": 0.7553755640983582, "xcomet_qe_score": 0.6790580749511719, "metricx_score": 8.119309425354004, "metricx_qe_score": 8.23544979095459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes folgt eine Commit-Nachricht.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9995623826980591, "xcomet_qe_score": 0.9971550703048706, "metricx_score": 0.8402528166770935, "metricx_qe_score": 1.1925365924835205, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Verbindungsnachrichten sind nicht an jede Liste gebunden.", "metrics": {"bleu_score": 22.811360354329615, "chrf_score": 51.23122796584323, "xcomet_score": 0.7041829824447632, "xcomet_qe_score": 0.710027813911438, "metricx_score": 8.779387474060059, "metricx_qe_score": 6.817710876464844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie im nachstehenden Bild gezeigt, müssen wir bei der aktuellen Liste der Versionen 2.5 bis 19 identifizieren,", "metrics": {"bleu_score": 8.739936402468247, "chrf_score": 45.4541233900999, "xcomet_score": 0.7382427453994751, "xcomet_qe_score": 0.7386281490325928, "metricx_score": 9.307586669921875, "metricx_qe_score": 9.058127403259277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "die vorherige Release-Version, 2.5.18, und gehen Sie dabei tief in die Details. Dies ist etwas mühsam, und es reicht nicht aus, lediglich eine Liste der Releases zu betrachten und die Änderungen vor und nach dem Update zu vergleichen.", "metrics": {"bleu_score": 19.54251878985873, "chrf_score": 54.120752089918035, "xcomet_score": 0.7342775464057922, "xcomet_qe_score": 0.6969246864318848, "metricx_score": 11.067813873291016, "metricx_qe_score": 11.890591621398926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine heuristische Abgleichsregel erstellt, um die vorherige und die nächste Version zu erhalten.", "metrics": {"bleu_score": 88.43946454355333, "chrf_score": 91.21659349101108, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3962783217430115, "metricx_qe_score": 0.4697111248970032, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Das ist Tanarsis.", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 10.96854093253664, "xcomet_score": 0.1330590397119522, "xcomet_qe_score": 0.09115450829267502, "metricx_score": 2.919602870941162, "metricx_qe_score": 4.26296329498291, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende 7200 Repositories.", "metrics": {"bleu_score": 9.346579571601447, "chrf_score": 39.23284304120118, "xcomet_score": 0.5573707818984985, "xcomet_qe_score": 0.20920604467391968, "metricx_score": 14.78959846496582, "metricx_qe_score": 18.42436408996582, "linguapy_score": [1, "CATALAN"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der Release-Knoten-Token 63, was für eine Zusammenfassungsaufgabe recht hoch ist.", "metrics": {"bleu_score": 66.81082569496672, "chrf_score": 76.60409886071251, "xcomet_score": 0.8749797344207764, "xcomet_qe_score": 0.8572068810462952, "metricx_score": 4.520707130432129, "metricx_qe_score": 3.7038609981536865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist die Anzahl der eindeutigen Token mit 8.830.000 recht hoch.", "metrics": {"bleu_score": 16.108992769687397, "chrf_score": 60.40088981259644, "xcomet_score": 0.9790205955505371, "xcomet_qe_score": 0.973145067691803, "metricx_score": 1.3230139017105103, "metricx_qe_score": 1.4270962476730347, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl eindeutiger Klassennamen und Methodenbezeichnungen, die im Repository vorkommen.", "metrics": {"bleu_score": 6.649479326478728, "chrf_score": 49.199281571468056, "xcomet_score": 0.9879574775695801, "xcomet_qe_score": 0.9613237380981445, "metricx_score": 0.888516902923584, "metricx_qe_score": 0.6119290590286255, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes werde ich die vorgeschlagene Methode erläutern.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das klassenbasierte extraktive-dann-abstrakte Zusammenfassungsmodell besteht aus zwei neuronalen Modulen,", "metrics": {"bleu_score": 39.80304924457956, "chrf_score": 76.04437499793193, "xcomet_score": 0.9496070146560669, "xcomet_qe_score": 0.9501568675041199, "metricx_score": 1.8913055658340454, "metricx_qe_score": 3.4779953956604004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "ein Klassifikator, der BERT oder CodeBert verwendet, und ein Generator, der BERT verwendet.", "metrics": {"bleu_score": 12.39899236095509, "chrf_score": 72.31089275967017, "xcomet_score": 0.9667581915855408, "xcomet_qe_score": 0.9581570625305176, "metricx_score": 4.315376281738281, "metricx_qe_score": 3.2586095333099365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet CAS einen Klassifikator, um jede Commit-Nachricht in fünf Klassen für Versionsnotizen einzuordnen. Wir wählen Implementierungen, Fehlerbehebungen, Deprecations, Verbesserungen und Sonstiges.", "metrics": {"bleu_score": 34.63803402108582, "chrf_score": 62.78153854629146, "xcomet_score": 0.719721257686615, "xcomet_qe_score": 0.7314897179603577, "metricx_score": 5.829617500305176, "metricx_qe_score": 5.451316833496094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die Commit-Nachrichten, die als sonstige klassifiziert sind, werden verworfen.", "metrics": {"bleu_score": 14.991106946711685, "chrf_score": 61.01989879955973, "xcomet_score": 0.9861851930618286, "xcomet_qe_score": 0.9316509962081909, "metricx_score": 0.6552645564079285, "metricx_qe_score": 1.1676812171936035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet CES den Generator unabhängig voneinander auf die vier Etikettendokumente an und erzeugt für jede Klasse Freigabeknoten.", "metrics": {"bleu_score": 17.979969665124507, "chrf_score": 62.281840220927634, "xcomet_score": 0.8005645871162415, "xcomet_qe_score": 0.8121263384819031, "metricx_score": 6.0837907791137695, "metricx_qe_score": 6.180351734161377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Korrespondenzen zwischen Commit-Nachrichten und gelesenen Knoten nicht bekannt.", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 84.34441266111084, "xcomet_score": 0.879207968711853, "xcomet_qe_score": 0.8139369487762451, "metricx_score": 3.404689311981201, "metricx_qe_score": 4.382169246673584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Daher weisen wir, um den Klassifikator zu trainieren, jedem Eingabecomit-Nachricht mithilfe der ersten 10 Zeichen jeder Commit-Nachricht sudo-Labels zu.", "metrics": {"bleu_score": 20.432904857495735, "chrf_score": 54.772746010141404, "xcomet_score": 0.7660004496574402, "xcomet_qe_score": 0.7704538106918335, "metricx_score": 8.31325626373291, "metricx_qe_score": 7.525601387023926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die klassenbasierte abstrakte Zusammenfassung durch unseren Ansatz mit zwei verschiedenen Methoden.", "metrics": {"bleu_score": 4.246549372656572, "chrf_score": 61.996211030053296, "xcomet_score": 0.904335618019104, "xcomet_qe_score": 0.8913887739181519, "metricx_score": 1.8888661861419678, "metricx_qe_score": 2.571319580078125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir cssingle nennen, besteht aus einem einzelnen Geschlechts-zu-Geschlechts-Netzwerk und erzeugt einen einzelnen langen Textknoten, der aus einer Verkettung der Eingabekommit-Nachrichten generiert wird.", "metrics": {"bleu_score": 29.266575603174896, "chrf_score": 59.58674065568652, "xcomet_score": 0.6300815939903259, "xcomet_qe_score": 0.6187748908996582, "metricx_score": 11.141140937805176, "metricx_qe_score": 11.168096542358398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgabe-Text kann basierend auf speziellen, klassen-spezifischen Endpunkt-Symbolen in segmente aufgeteilt werden, die die gesamte Klasse umfassen.", "metrics": {"bleu_score": 2.7076576267554477, "chrf_score": 47.44676008408567, "xcomet_score": 0.9695874452590942, "xcomet_qe_score": 0.9733507633209229, "metricx_score": 1.0467263460159302, "metricx_qe_score": 0.8842340111732483, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir CAS-Merge nennen, besteht aus vier verschiedenen Sek-zu-Sek-Netzwerken, von denen jeweils eines einer der am wenigsten bekannten Klassen entspricht.", "metrics": {"bleu_score": 42.97310736875145, "chrf_score": 72.07508249992446, "xcomet_score": 0.6060740351676941, "xcomet_qe_score": 0.6274466514587402, "metricx_score": 6.858926773071289, "metricx_qe_score": 6.578195095062256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, lassen Sie mich das Experiment erklären.", "metrics": {"bleu_score": 8.392229812593097, "chrf_score": 52.50382629168674, "xcomet_score": 0.9908618927001953, "xcomet_qe_score": 1.0, "metricx_score": 0.29363977909088135, "metricx_qe_score": 0.3043555021286011, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen: CAS, CS einzeln, CS zusammenführen, Clustering und die vorherige Studie Trauer.", "metrics": {"bleu_score": 26.52951833482444, "chrf_score": 54.74030836744069, "xcomet_score": 0.7133058905601501, "xcomet_qe_score": 0.7120726108551025, "metricx_score": 12.831605911254883, "metricx_qe_score": 12.954398155212402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Bewertung werden diese Knoten in einigen Fällen in mehreren Sätzen ausgegeben.", "metrics": {"bleu_score": 29.5560575580374, "chrf_score": 53.712085909339145, "xcomet_score": 0.8015331029891968, "xcomet_qe_score": 0.8310895562171936, "metricx_score": 6.160503387451172, "metricx_qe_score": 5.552343368530273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze zu berechnen, werden diese mit Leerzeichen verbunden und als ein langer Satz behandelt.", "metrics": {"bleu_score": 60.67337731525327, "chrf_score": 77.16387229078686, "xcomet_score": 0.9981695413589478, "xcomet_qe_score": 1.0, "metricx_score": 0.40911802649497986, "metricx_qe_score": 0.6727392077445984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Blau wird panelisiert, wenn das System einen kurzen Satz ausgibt.", "metrics": {"bleu_score": 66.52049901111006, "chrf_score": 67.17467581245906, "xcomet_score": 0.7979680299758911, "xcomet_qe_score": 0.8034722805023193, "metricx_score": 8.339495658874512, "metricx_qe_score": 7.383359432220459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem niedrigeren Blauwert in den nachfolgend beschriebenen experimentellen Ergebnissen.", "metrics": {"bleu_score": 36.6192636299943, "chrf_score": 69.49331129585248, "xcomet_score": 0.8925919532775879, "xcomet_qe_score": 0.9689237475395203, "metricx_score": 2.9451346397399902, "metricx_qe_score": 2.37973690032959, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich berechnen wir auch die Spezifität, da Rot und Blau nicht berechnet werden können, wenn die Freigabeknoten leer sind.", "metrics": {"bleu_score": 64.7084148066781, "chrf_score": 74.57335178839057, "xcomet_score": 0.8643578290939331, "xcomet_qe_score": 0.8879368305206299, "metricx_score": 4.422264575958252, "metricx_qe_score": 2.6248130798339844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell in Fällen, in denen die Freigabeknoten leere Texte annehmen, korrekt einen leeren Text ausgibt.", "metrics": {"bleu_score": 54.96963644696961, "chrf_score": 69.4434710259903, "xcomet_score": 0.9289055466651917, "xcomet_qe_score": 0.9223475456237793, "metricx_score": 2.1664795875549316, "metricx_qe_score": 1.7970470190048218, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse.", "metrics": {"bleu_score": 42.72870063962342, "chrf_score": 48.96283815298874, "xcomet_score": 0.9982582330703735, "xcomet_qe_score": 0.9951757192611694, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, haben wir auch den bereinigten Datensatz bewertet, der diese ausschließt.", "metrics": {"bleu_score": 87.25129388059685, "chrf_score": 94.88657999513984, "xcomet_score": 0.99851393699646, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.47783321142196655, "metricx_qe_score": 0.43253716826438904, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "CEAS und CAS erreichten lockere L-Werte, die mehr als 10 Punkte über den Basiswerten lagen.", "metrics": {"bleu_score": 37.8311388907207, "chrf_score": 69.19513956097798, "xcomet_score": 0.8455451726913452, "xcomet_qe_score": 0.8592199087142944, "metricx_score": 5.799825668334961, "metricx_qe_score": 6.2729010581970215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere beim sauberen Testset sprang die Punktedifferenz zwischen den vorgeschlagenen Methoden und der Basis um mehr als 20 Punkte an.", "metrics": {"bleu_score": 6.61476354612817, "chrf_score": 53.466216770983635, "xcomet_score": 0.8706197738647461, "xcomet_qe_score": 0.8736132383346558, "metricx_score": 4.870973587036133, "metricx_qe_score": 4.028304100036621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass CES und GS signifikant wirksam sind.", "metrics": {"bleu_score": 38.827267775222325, "chrf_score": 67.87816849944247, "xcomet_score": 0.6878489851951599, "xcomet_qe_score": 0.7388418912887573, "metricx_score": 7.799397945404053, "metricx_qe_score": 8.499894142150879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "CAS erzielte eine bessere Root-Fail-Bewertung als CAS, was darauf hindeutet, dass die Kombination eines Klassifikators und eines Generators effektiv ist, um den Klassifikator mithilfe von Pseudo-Doubles zu trainieren.", "metrics": {"bleu_score": 48.25626803124849, "chrf_score": 71.3617799496207, "xcomet_score": 0.5466781854629517, "xcomet_qe_score": 0.567400336265564, "metricx_score": 10.226633071899414, "metricx_qe_score": 10.936136245727539, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von CAS kann wahrscheinlich erreicht werden, da der Klassifikator sich darauf konzentrieren kann, für jede Klasse relevante Commit-Nachrichten auszuwählen.", "metrics": {"bleu_score": 27.74870273560583, "chrf_score": 76.39472259526853, "xcomet_score": 0.8915858864784241, "xcomet_qe_score": 0.8968987464904785, "metricx_score": 4.018651962280273, "metricx_qe_score": 5.573118209838867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "CAS-Match liefert in der Regel höhere Ergebnisse als CAS-Single.", "metrics": {"bleu_score": 15.619699684601283, "chrf_score": 38.652285561275576, "xcomet_score": 0.8175395727157593, "xcomet_qe_score": 0.8468744158744812, "metricx_score": 7.458024501800537, "metricx_qe_score": 8.960854530334473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Vorschlagend, dass es ebenfalls effektiv ist, unabhängig voneinander unterschiedliche absorbierende Zusammenfassungsmodelle für jede Freigabeknoten-Klasse zu entwickeln.", "metrics": {"bleu_score": 13.060233299346658, "chrf_score": 64.74564247503704, "xcomet_score": 0.7519089579582214, "xcomet_qe_score": 0.732943594455719, "metricx_score": 6.437493324279785, "metricx_qe_score": 6.321610927581787, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Helden- und Fehleranalyse", "metrics": {"bleu_score": 0.0, "chrf_score": 49.905038499517325, "xcomet_score": 0.4836306571960449, "xcomet_qe_score": 0.5852845907211304, "metricx_score": 4.304367542266846, "metricx_qe_score": 5.341307640075684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "CS-Methoden neigen dazu, kürzere Sätze als menschliche Referenzsätze zu erzeugen.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 66.41760489232195, "xcomet_score": 0.9560073018074036, "xcomet_qe_score": 0.9210281372070312, "metricx_score": 2.2149550914764404, "metricx_qe_score": 2.232160806655884, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung rechts hat der Referenzsatz 3 oder 4 Sätze, während CAS nur einen einzigen Satz enthält.", "metrics": {"bleu_score": 20.76047003130265, "chrf_score": 57.26508246255983, "xcomet_score": 0.9987814426422119, "xcomet_qe_score": 0.9974651336669922, "metricx_score": 0.2829304337501526, "metricx_qe_score": 0.6161594986915588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Zurückhaltung des Modells ist, dass in den Trainingsdaten nur 33 % der Sätze im Merkmals-Label und 40 % im Verbesserungs-Label vorhanden sind.", "metrics": {"bleu_score": 32.52392115769682, "chrf_score": 53.29254329199752, "xcomet_score": 0.8467683792114258, "xcomet_qe_score": 0.9850772619247437, "metricx_score": 1.9780361652374268, "metricx_qe_score": 1.8349695205688477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich können CES-Methoden keine genauen VsNode ohne zusätzliche Informationen generieren.", "metrics": {"bleu_score": 17.423472443716534, "chrf_score": 58.05723607368017, "xcomet_score": 0.7667388916015625, "xcomet_qe_score": 0.7533752918243408, "metricx_score": 8.783391952514648, "metricx_qe_score": 9.538128852844238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel rechts ist ein Beispiel für eine sehr unordentliche Kommentarmeldung, und der vollständige Satz kann nicht generiert werden, ohne auf den entsprechenden Pull-Request oder das entsprechende Issue Bezug zu nehmen.", "metrics": {"bleu_score": 27.373915552099295, "chrf_score": 58.29641409155069, "xcomet_score": 0.8162703514099121, "xcomet_qe_score": 0.8194794654846191, "metricx_score": 4.768872261047363, "metricx_qe_score": 3.9896445274353027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden Commit-Nachrichten in der Eingabe miteinander verwandt sind und zu einem Satz kombiniert werden sollten, was jedoch nicht geschieht.", "metrics": {"bleu_score": 65.58090491210355, "chrf_score": 74.74098684431168, "xcomet_score": 0.9721454381942749, "xcomet_qe_score": 0.9917607307434082, "metricx_score": 0.8369044065475464, "metricx_qe_score": 1.2413870096206665, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ein Schluss.", "metrics": {"bleu_score": 9.688464563433238, "chrf_score": 4.716981132075471, "xcomet_score": 0.9363614320755005, "xcomet_qe_score": 0.9707931280136108, "metricx_score": 4.732882499694824, "metricx_qe_score": 2.645772695541382, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine neue, automatisierte Anlage für die Beglaubigung von Rechtsfällen entwickelt.", "metrics": {"bleu_score": 8.889175589171739, "chrf_score": 39.77649089201045, "xcomet_score": 0.5405961871147156, "xcomet_qe_score": 0.7412843704223633, "metricx_score": 8.841971397399902, "metricx_qe_score": 6.107378005981445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben uns auch die Aufgabe gestellt, Commit-Nachrichten einzugeben und zusammenzufassen, sodass dies für alle in Englisch geschriebenen Projekte anwendbar ist.", "metrics": {"bleu_score": 15.240135805212745, "chrf_score": 59.82002897619287, "xcomet_score": 0.9989528656005859, "xcomet_qe_score": 1.0, "metricx_score": 1.00471031665802, "metricx_qe_score": 1.4312278032302856, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment zeigt, dass die vorgeschlagene Methode bei höherer Abdeckung weniger rauschbehaftete Leads erzeugte als die Vergleichsverfahren.", "metrics": {"bleu_score": 23.210911117419965, "chrf_score": 56.685434874247456, "xcomet_score": 0.8861434459686279, "xcomet_qe_score": 0.8689829111099243, "metricx_score": 5.90769624710083, "metricx_qe_score": 6.1260271072387695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte überprüfen Sie den Code für das Audit-Register \"Wüste\".", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 19.311659441157893, "xcomet_score": 0.1460656225681305, "xcomet_qe_score": 0.13582159578800201, "metricx_score": 7.315014839172363, "metricx_qe_score": 6.320306777954102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 20.4664420548395, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.02491046115756035, "metricx_qe_score": 0.1274172067642212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Asaf Harari.", "metrics": {"bleu_score": 54.10822690539397, "chrf_score": 81.82110562545346, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [1, "NYNORSK"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unseren Artikel \"Few-Shot Tabular Data Enrichment Using Fine-Tuning Transformers Architectures\" vorstellen.", "metrics": {"bleu_score": 26.92050880955931, "chrf_score": 81.09644729156814, "xcomet_score": 0.9313990473747253, "xcomet_qe_score": 0.9022775292396545, "metricx_score": 3.5835371017456055, "metricx_qe_score": 3.2351250648498535, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "So analysieren Wissenschaftler Daten und konzentrieren sich hauptsächlich auf die Manipulation der vorhandenen Datenmerkmale.", "metrics": {"bleu_score": 54.21806974540424, "chrf_score": 72.92990013820855, "xcomet_score": 0.9851350784301758, "xcomet_qe_score": 0.9907837510108948, "metricx_score": 1.9170544147491455, "metricx_qe_score": 1.5115506649017334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "manchmal sind diese Funktionen jedoch eingeschränkt.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 66.54419657310568, "xcomet_score": 0.9881318211555481, "xcomet_qe_score": 0.9861507415771484, "metricx_score": 0.12968039512634277, "metricx_qe_score": 0.06342301517724991, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Merkmalsgenerierung unter Verwendung einer anderen Datenquelle kann erhebliche Informationen hinzufügen.", "metrics": {"bleu_score": 44.74378372649925, "chrf_score": 74.63484940831616, "xcomet_score": 0.9258098006248474, "xcomet_qe_score": 0.9860126972198486, "metricx_score": 0.5729458332061768, "metricx_qe_score": 0.4881567358970642, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung tabellarischer Daten unter Verwendung von externen Quellen in Freitextform.", "metrics": {"bleu_score": 49.582717346593746, "chrf_score": 80.82995657716275, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.24988606572151184, "metricx_qe_score": 0.30780157446861267, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir verfügen über einen tabellarischen Datensatz und eine Wissensdatenbank.", "metrics": {"bleu_score": 31.61487584488944, "chrf_score": 68.49347568277352, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19600623846054077, "metricx_qe_score": 0.12556982040405273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatisierten Prozess, der Entitätsverknüpfung und Textanalyse umfasst, um neue Merkmale aus dem freien Text der Wissensdatenbank zu extrahieren.", "metrics": {"bleu_score": 37.838571834477285, "chrf_score": 68.0148744078661, "xcomet_score": 0.9934208393096924, "xcomet_qe_score": 0.9943423271179199, "metricx_score": 0.44632238149642944, "metricx_qe_score": 0.3294266164302826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework ist genau dieser automatische Prozess.", "metrics": {"bleu_score": 62.401954419369176, "chrf_score": 73.70546045174258, "xcomet_score": 0.8916159272193909, "xcomet_qe_score": 0.9362524747848511, "metricx_score": 3.4029643535614014, "metricx_qe_score": 4.633840560913086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns ein Beispiel in den Datensätzen an, die in FAST eingespeist werden.", "metrics": {"bleu_score": 17.696061128311285, "chrf_score": 55.50313735801817, "xcomet_score": 0.900783360004425, "xcomet_qe_score": 0.9042341709136963, "metricx_score": 5.009964942932129, "metricx_qe_score": 5.050056457519531, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel handelt es sich um einen Datensatz einer Universität.", "metrics": {"bleu_score": 14.323145079400492, "chrf_score": 59.32373356252133, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07512873411178589, "metricx_qe_score": 0.124759241938591, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "wenn sein Ziel darin besteht, Universitäten in schlecht platzierte Universitäten und hochplatzierte Universitäten einzuteilen.", "metrics": {"bleu_score": 6.917184228205474, "chrf_score": 45.46994461606139, "xcomet_score": 0.9447687864303589, "xcomet_qe_score": 0.9894389510154724, "metricx_score": 1.867842674255371, "metricx_qe_score": 1.7102022171020508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensdatenbank nutzen wir Wikipedia.", "metrics": {"bleu_score": 32.46679154750991, "chrf_score": 60.45156098499045, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05020706355571747, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase von FAST ist die Entitätsverknüpfung.", "metrics": {"bleu_score": 33.03164318013809, "chrf_score": 53.590844520541935, "xcomet_score": 0.8783867955207825, "xcomet_qe_score": 0.891694188117981, "metricx_score": 4.506548881530762, "metricx_qe_score": 4.237422943115234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "wenn jede Entität, in diesem Beispiel der Universitätsname, mit einer Entität innerhalb der Wissensdatenbank verknüpft ist.", "metrics": {"bleu_score": 45.03955556330877, "chrf_score": 78.80364900354773, "xcomet_score": 0.9806042909622192, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6269818544387817, "metricx_qe_score": 0.39745351672172546, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Wissensdatenbank wird extrahiert und dem Datensatz hinzugefügt.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 81.767360179553, "xcomet_score": 0.9777982831001282, "xcomet_qe_score": 0.9698386788368225, "metricx_score": 0.8740183115005493, "metricx_qe_score": 1.0021990537643433, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text die Zusammenfassung der Wikipedia-Seite.", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 76.01689202226493, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2522701621055603, "metricx_qe_score": 0.2034890055656433, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Merkmale aus dem abgerufenen Text generieren oder extrahieren.", "metrics": {"bleu_score": 67.0422683816333, "chrf_score": 77.33494683082183, "xcomet_score": 0.9531110525131226, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.8071900010108948, "metricx_qe_score": 0.34741824865341187, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen eine Phase der Merkmalsextraktion, die eine Textanalyse umfasst.", "metrics": {"bleu_score": 12.545696183524145, "chrf_score": 47.60896528798703, "xcomet_score": 0.9933080673217773, "xcomet_qe_score": 0.9910120964050293, "metricx_score": 3.7967703342437744, "metricx_qe_score": 3.2716939449310303, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuigkeit dieses Artikels, und ich werde in den nächsten Folien tiefer darauf eingehen.", "metrics": {"bleu_score": 11.540436442918624, "chrf_score": 45.55421919235281, "xcomet_score": 0.9718782901763916, "xcomet_qe_score": 0.9940099716186523, "metricx_score": 1.571252465248108, "metricx_qe_score": 1.3566840887069702, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Phase der Merkmalsextraktion folgt eine Phase der Merkmalsgenerierung, in der wir die extrahierten Merkmale nutzen, um eine kleine Anzahl neuer Merkmale zu generieren.", "metrics": {"bleu_score": 51.20881027815125, "chrf_score": 65.3476522728924, "xcomet_score": 0.9552345275878906, "xcomet_qe_score": 0.9898672103881836, "metricx_score": 0.36895984411239624, "metricx_qe_score": 0.27461957931518555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "zuerst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes generieren.", "metrics": {"bleu_score": 58.10588684968076, "chrf_score": 71.91189039329024, "xcomet_score": 0.9225383996963501, "xcomet_qe_score": 0.9232572317123413, "metricx_score": 2.2077577114105225, "metricx_qe_score": 2.293743371963501, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen,", "metrics": {"bleu_score": 88.01117367933934, "chrf_score": 98.12893305910325, "xcomet_score": 0.9895354509353638, "xcomet_qe_score": 0.9922080039978027, "metricx_score": 0.2057073414325714, "metricx_qe_score": 0.2756565511226654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "So ERZEUGE schnell zwei neue Merkmale.", "metrics": {"bleu_score": 14.535768424205482, "chrf_score": 23.510459509658862, "xcomet_score": 0.8564455509185791, "xcomet_qe_score": 0.925859272480011, "metricx_score": 14.469527244567871, "metricx_qe_score": 15.204263687133789, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Datenset jedoch fünf Klassen hat, generieren Sie zunächst fünf neue Merkmale.", "metrics": {"bleu_score": 30.130404892785695, "chrf_score": 59.66877931772596, "xcomet_score": 0.9432962536811829, "xcomet_qe_score": 0.9491128921508789, "metricx_score": 3.7472848892211914, "metricx_qe_score": 3.8543243408203125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Merkmalsausprägung stellt die Wahrscheinlichkeit für jede Klasse dar.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 78.83055913300888, "xcomet_score": 0.9930373430252075, "xcomet_qe_score": 0.9949196577072144, "metricx_score": 0.46418488025665283, "metricx_qe_score": 0.30904218554496765, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Zur Analyse des Textes nutzen wir den aktuellen Stand der Technik im Bereich der Textanalyse, nämlich transformerbasierte Sprachmodelle wie BERT, GPT, XNL und weitere.", "metrics": {"bleu_score": 16.09791748450962, "chrf_score": 50.73285248806746, "xcomet_score": 0.9623785018920898, "xcomet_qe_score": 0.963208794593811, "metricx_score": 0.6568076014518738, "metricx_qe_score": 0.6624621748924255, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "es ist jedoch unwahrscheinlich, dass wir Sprachmodelle mit den Eingabedatensätzen trainieren können.", "metrics": {"bleu_score": 50.698033524721, "chrf_score": 77.66435161445926, "xcomet_score": 0.9763429164886475, "xcomet_qe_score": 0.9627835750579834, "metricx_score": 0.98589026927948, "metricx_qe_score": 1.3706510066986084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz besteht also darin, eine Zielaufgabe feinabzustimmen.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 45.84763871330344, "xcomet_score": 0.9548841714859009, "xcomet_qe_score": 0.9330913424491882, "metricx_score": 1.4743200540542603, "metricx_qe_score": 1.9211320877075195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der zukünftigen Extraktionsphase können wir das Peritrain-Sprachmodell herunterladen und das Sprachmodell anhand des Ziel-Datensatzes feinabstimmen.", "metrics": {"bleu_score": 19.032892442937786, "chrf_score": 60.96981902627386, "xcomet_score": 0.8902639150619507, "xcomet_qe_score": 0.8560424447059631, "metricx_score": 2.84993314743042, "metricx_qe_score": 3.544445276260376, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell feinabgestimmt, um Text in Klassen einzuteilen, abstrakte Konzepte in Klassen zu kategorisieren, ob niedrig oder hoch,", "metrics": {"bleu_score": 11.973536848747031, "chrf_score": 50.319174057181726, "xcomet_score": 0.9002034664154053, "xcomet_qe_score": 0.8643686771392822, "metricx_score": 2.191638469696045, "metricx_qe_score": 3.3616995811462402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Sprachmodell-Ausgabe, welche die Wahrscheinlichkeit für jede Klasse darstellt, und verwenden Sie diese als neue Merkmale.", "metrics": {"bleu_score": 41.77393822296787, "chrf_score": 68.63413158834024, "xcomet_score": 0.9030680656433105, "xcomet_qe_score": 0.9585674405097961, "metricx_score": 1.7151973247528076, "metricx_qe_score": 0.9079760313034058, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass der Datensatz möglicherweise nur wenige eindeutige Entitätsschlagwörter enthält.", "metrics": {"bleu_score": 47.82215756494833, "chrf_score": 63.21847314644763, "xcomet_score": 0.90822833776474, "xcomet_qe_score": 0.892754077911377, "metricx_score": 1.6633366346359253, "metricx_qe_score": 1.2689709663391113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthalten fast die Hälfte der Datensätze weniger als 400 Beispiele, und der kleinste Datensatz umfasst 35 Beispiele in seinem Trainingsdatensatz.", "metrics": {"bleu_score": 44.27274357129557, "chrf_score": 69.0798837800888, "xcomet_score": 0.9129650592803955, "xcomet_qe_score": 0.9725848436355591, "metricx_score": 0.7182132005691528, "metricx_qe_score": 0.6365783214569092, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wird es ineffektiv sein, ein Sprachmodell mit diesem Datensatz feinabzustimmen.", "metrics": {"bleu_score": 3.673526562988939, "chrf_score": 42.03318675829515, "xcomet_score": 0.9773702621459961, "xcomet_qe_score": 0.9635931253433228, "metricx_score": 0.6857329607009888, "metricx_qe_score": 1.0050580501556396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "aber wir können auf vorhandenes Wissen über vorab analysierte Datensätze zurückgreifen,", "metrics": {"bleu_score": 10.127993013562818, "chrf_score": 52.201287206766956, "xcomet_score": 0.9824000597000122, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.2665172815322876, "metricx_qe_score": 0.24323630332946777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "da wir FAST auf mehrere Datensätze anwenden, können wir die N-1 Datensätze nutzen, um Informationen über diese N-1 Datensätze zu sammeln, und diese Informationen heranziehen, wenn wir den N-ten Datensatz analysieren.", "metrics": {"bleu_score": 45.84640947308265, "chrf_score": 74.83334820996322, "xcomet_score": 0.7139862775802612, "xcomet_qe_score": 0.7197896242141724, "metricx_score": 2.2773776054382324, "metricx_qe_score": 2.5414745807647705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist, eine weitere Feinabstimmungsphase hinzuzufügen,", "metrics": {"bleu_score": 35.08439695638686, "chrf_score": 85.30651584686842, "xcomet_score": 0.9765812158584595, "xcomet_qe_score": 0.9629456996917725, "metricx_score": 0.8937133550643921, "metricx_qe_score": 0.9736015200614929, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "eine vorläufige Multitasking-Feinabstimmungsphase.", "metrics": {"bleu_score": 21.444097124017667, "chrf_score": 83.35896305795195, "xcomet_score": 0.9838378429412842, "xcomet_qe_score": 0.961916446685791, "metricx_score": 0.6891024708747864, "metricx_qe_score": 0.9286389350891113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "wenn Sie das Sprachmodell mit N-1 Datensätzen feinabstimmen,", "metrics": {"bleu_score": 0.0, "chrf_score": 46.223532352764295, "xcomet_score": 0.9039968252182007, "xcomet_qe_score": 0.8799124956130981, "metricx_score": 1.5785260200500488, "metricx_qe_score": 1.5124293565750122, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Feinabstimmungsphase durch, die eine zielgerichtete Feinabstimmung ist, wenn wir das Sprachmodell über den n-ten Ziel-Datensatz feinabstimmen.", "metrics": {"bleu_score": 66.66823117022298, "chrf_score": 84.42090928143875, "xcomet_score": 0.9497817754745483, "xcomet_qe_score": 0.9011423587799072, "metricx_score": 2.109623432159424, "metricx_qe_score": 2.2991065979003906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "der Stand der Technik in der mehrtaskigen Feinabstimmung, genannt leeres DNN.", "metrics": {"bleu_score": 3.673526562988939, "chrf_score": 40.69653920661474, "xcomet_score": 0.7496925592422485, "xcomet_qe_score": 0.7662792205810547, "metricx_score": 8.673154830932617, "metricx_qe_score": 7.747328281402588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN hält MTDNN Köpfe in der Anzahl der Aufgaben im Trainingsdatensatz.", "metrics": {"bleu_score": 14.563331524569785, "chrf_score": 43.37523116506538, "xcomet_score": 0.7801797389984131, "xcomet_qe_score": 0.8104354739189148, "metricx_score": 12.99277114868164, "metricx_qe_score": 9.864819526672363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainingsdatensatz. Daher ein leeres DNN, mit vier Köpfen, wie Sie im Bild sehen können.", "metrics": {"bleu_score": 44.40750605884705, "chrf_score": 67.11442890723391, "xcomet_score": 0.8097013235092163, "xcomet_qe_score": 0.819961667060852, "metricx_score": 8.25782585144043, "metricx_qe_score": 7.116453647613525, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "und es wählt zufällig einen Batch aus dem Trainingsdatensatz aus.", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 36.67201474528408, "xcomet_score": 0.8699500560760498, "xcomet_qe_score": 0.9188172817230225, "metricx_score": 3.4909157752990723, "metricx_qe_score": 3.3146300315856934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der zufällige Batch beispielsweise Aufgaben der Einzelsatz-Klassifizierung entspricht, führt man einen Vorwärts- und Rückwärtsdurchlauf durch den ersten Kopf aus.", "metrics": {"bleu_score": 5.928330061638001, "chrf_score": 43.88974300765279, "xcomet_score": 0.7990215420722961, "xcomet_qe_score": 0.8864830732345581, "metricx_score": 5.745102882385254, "metricx_qe_score": 4.866846561431885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der zufällige Batch zur paarweisen Rangaufgabe gehört, durchläuft seine Haltung die letzte Kopfeinheit in Vor- und Rückwärtsrichtung.", "metrics": {"bleu_score": 7.339934569877101, "chrf_score": 45.4015726813551, "xcomet_score": 0.6837822794914246, "xcomet_qe_score": 0.6654336452484131, "metricx_score": 9.059138298034668, "metricx_qe_score": 8.91821575164795, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario wird ein tabellarischer Datensatz die Anzahl der Klassen bestimmen.", "metrics": {"bleu_score": 20.098339913206324, "chrf_score": 67.49249491905631, "xcomet_score": 0.9284146428108215, "xcomet_qe_score": 0.9093546271324158, "metricx_score": 3.0434556007385254, "metricx_qe_score": 2.8661510944366455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.05911726504564285, "metricx_qe_score": 0.12243705987930298, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "mtDNN verwaltet die Köpfe bzw. Ausgabeschichten mehrerer Klassen,", "metrics": {"bleu_score": 7.603985612048923, "chrf_score": 23.33562323760878, "xcomet_score": 0.8380042910575867, "xcomet_qe_score": 0.8838328123092651, "metricx_score": 5.401691436767578, "metricx_qe_score": 4.309734344482422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich muss emptyDNA neue Köpfe für einen neuen Datensatz mit einer neuen Aufgabe initialisieren.", "metrics": {"bleu_score": 61.32167468990615, "chrf_score": 73.70682784932609, "xcomet_score": 0.7401145696640015, "xcomet_qe_score": 0.8241610527038574, "metricx_score": 7.544076442718506, "metricx_qe_score": 8.448963165283203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, den wir Aufgaben-Uformulierung-Feinabstimmung nennen, besteht darin, anstelle mehrerer Köpfe jede Datensammlung in einen Satz pro Klassifizierungsproblem umzuformulieren, was Aufgaben mit zwei Klassen entspricht.", "metrics": {"bleu_score": 21.80848443203709, "chrf_score": 61.183682758503146, "xcomet_score": 0.8066655397415161, "xcomet_qe_score": 0.8150709867477417, "metricx_score": 5.162560939788818, "metricx_qe_score": 3.226050615310669, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Nun schauen wir uns ein Beispiel an.", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 93.59669096423634, "xcomet_score": 0.9841150045394897, "xcomet_qe_score": 0.9875154495239258, "metricx_score": 0.02345561981201172, "metricx_qe_score": 0.09022459387779236, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Eingabedatensatz, der aus Entitäten, Merkmalen, Text und Klassen besteht.", "metrics": {"bleu_score": 57.56799653136483, "chrf_score": 71.28296402896673, "xcomet_score": 0.9936966896057129, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5844475030899048, "metricx_qe_score": 0.36022478342056274, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe um: Statt die Texte in niedrig und hoch einzuordnen, klassifizieren wir nun den Text, die Zusammenfassung und die Klasse als wahr oder falsch.", "metrics": {"bleu_score": 9.4900123763462, "chrf_score": 47.26705359823359, "xcomet_score": 0.9713290929794312, "xcomet_qe_score": 0.9396892786026001, "metricx_score": 0.5023834705352783, "metricx_qe_score": 0.7348831295967102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, wir trainieren das Sprachmodell, um abstrakte Konzepte und Klassen zu klassifizieren, um zu bestimmen, ob ein abstraktes Konzept zu einer bestimmten Klasse gehört oder nicht.", "metrics": {"bleu_score": 16.30729246361482, "chrf_score": 51.11073084929728, "xcomet_score": 0.6754119396209717, "xcomet_qe_score": 0.5510561466217041, "metricx_score": 2.8969573974609375, "metricx_qe_score": 4.9316630363464355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Das Label-Vektor in diesem Fall bleibt immer bestehen und besteht stets aus zwei Klassen.", "metrics": {"bleu_score": 17.909119337460318, "chrf_score": 56.053630325177416, "xcomet_score": 0.9546092748641968, "xcomet_qe_score": 0.9376883506774902, "metricx_score": 1.7100530862808228, "metricx_qe_score": 2.9686717987060547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ist der Algorithmus für unser umformulierter Feinabstimmungsansatz.", "metrics": {"bleu_score": 27.77619034011791, "chrf_score": 78.56066209817389, "xcomet_score": 0.9635847806930542, "xcomet_qe_score": 0.9502177834510803, "metricx_score": 1.1691830158233643, "metricx_qe_score": 2.4931564331054688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Also werfen wir einen Blick auf das gesamte Rahmenwerk.", "metrics": {"bleu_score": 4.990049701936832, "chrf_score": 35.93203700743251, "xcomet_score": 0.9842977523803711, "xcomet_qe_score": 0.981928288936615, "metricx_score": 0.9705333709716797, "metricx_qe_score": 0.574085533618927, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "Das hat die Fed in Gang gesetzt.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 16.786617944163336, "xcomet_score": 0.10962574928998947, "xcomet_qe_score": 0.09033159911632538, "metricx_score": 7.605058670043945, "metricx_qe_score": 10.117586135864258, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "und dann eine schnelle Ausführungsphase der Entitätsverknüpfung", "metrics": {"bleu_score": 0.0, "chrf_score": 21.160543800469636, "xcomet_score": 0.9163416028022766, "xcomet_qe_score": 0.8757220506668091, "metricx_score": 6.028104782104492, "metricx_qe_score": 6.835475444793701, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensdatenbank, die in diesem Beispiel die Zusammenfassung der Wikipedia-Seite ist.", "metrics": {"bleu_score": 60.3161203621801, "chrf_score": 77.34452190616351, "xcomet_score": 0.9809863567352295, "xcomet_qe_score": 0.9441378712654114, "metricx_score": 1.2681747674942017, "metricx_qe_score": 1.5275083780288696, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann formulieren Sie die Aufgabe in einem Satz pro Klassifizierungaufgabe um.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 57.500581849602426, "xcomet_score": 0.7617970705032349, "xcomet_qe_score": 0.6174660921096802, "metricx_score": 6.834904193878174, "metricx_qe_score": 5.754851341247559, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "wendete das Sprachmodell auf die neue Aufgabe an und berechnete die Ausgabewahrscheinlichkeit für jede Klasse,", "metrics": {"bleu_score": 40.325042950627804, "chrf_score": 76.30805455401527, "xcomet_score": 0.9638084173202515, "xcomet_qe_score": 0.9542391300201416, "metricx_score": 0.5683203339576721, "metricx_qe_score": 1.1491934061050415, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits mithilfe einer vorläufigen multitask-Feinabstimmung mit dem N-1-Datensatz feinabgestimmt wurde.", "metrics": {"bleu_score": 13.618796864073044, "chrf_score": 72.34477193120354, "xcomet_score": 0.8745630979537964, "xcomet_qe_score": 0.8058249950408936, "metricx_score": 3.58176851272583, "metricx_qe_score": 4.012759208679199, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu generierte Merkmalsgröße in der Anzahl der Klassen.", "metrics": {"bleu_score": 50.28248236576277, "chrf_score": 78.46615186581874, "xcomet_score": 0.9872312545776367, "xcomet_qe_score": 0.9247689247131348, "metricx_score": 0.6288744807243347, "metricx_qe_score": 0.954902708530426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zur Bewertung unseres Frameworks verwenden wir einen Datensatz für tabellarische Klassifizierung mit 17 Datensätzen, der Größe, Merkmale, Ausgewogenheit, Domäne und anfängliche Leistung überprüft.", "metrics": {"bleu_score": 18.5031995613929, "chrf_score": 58.25349261638916, "xcomet_score": 0.9616608619689941, "xcomet_qe_score": 0.9606235027313232, "metricx_score": 3.3135762214660645, "metricx_qe_score": 3.945711612701416, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis nutzen wir Wikipedia.", "metrics": {"bleu_score": 37.99178428257963, "chrf_score": 73.88259230639666, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir konzipieren unser Experiment als eine Live-Bewertung, wenn wir schnell über 16 Datensätze trainieren und es auf den 17. Datensatz anwenden.", "metrics": {"bleu_score": 43.313716303061824, "chrf_score": 64.26126352247, "xcomet_score": 0.6888213157653809, "xcomet_qe_score": 0.7240843772888184, "metricx_score": 6.84930419921875, "metricx_qe_score": 6.724470615386963, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen jeden Datensatz ebenfalls in vier Faltungen auf und wenden eine vierfache Kreuzvalidierung an.", "metrics": {"bleu_score": 53.24221584015077, "chrf_score": 71.53871273193134, "xcomet_score": 0.896668553352356, "xcomet_qe_score": 0.9187518954277039, "metricx_score": 2.7311246395111084, "metricx_qe_score": 2.7399375438690186, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann erzeugen wir die neue Merkmalsgröße und bewerten sie mithilfe von fünf Bewertungsklassifikatoren.", "metrics": {"bleu_score": 14.949751774990691, "chrf_score": 56.10597202224512, "xcomet_score": 0.926753044128418, "xcomet_qe_score": 0.9365215301513672, "metricx_score": 0.925437867641449, "metricx_qe_score": 0.7637434005737305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment verwenden wir eine auf BERT basierende Architektur.", "metrics": {"bleu_score": 4.9323515694897075, "chrf_score": 56.01568592697345, "xcomet_score": 0.9993091821670532, "xcomet_qe_score": 1.0, "metricx_score": 0.5000662803649902, "metricx_qe_score": 1.1500259637832642, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 85.51131524815735, "xcomet_score": 0.9987486600875854, "xcomet_qe_score": 0.9999598264694214, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unseren Rahmen mit der Feinabstimmung auf den Ziel-Datensatz, der Feinabstimmung auf die Zielaufgabe und der vorläufigen Feinabstimmung von MTDNN vergleichen.", "metrics": {"bleu_score": 44.179182268315785, "chrf_score": 78.49656362786897, "xcomet_score": 0.9668482542037964, "xcomet_qe_score": 0.9145578145980835, "metricx_score": 1.7420036792755127, "metricx_qe_score": 3.075629949569702, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "und unsere neu formulierte Feinabstimmung das beste Ergebnis, die beste Leistung erzielen.", "metrics": {"bleu_score": 25.336549464486474, "chrf_score": 79.73623309177148, "xcomet_score": 0.9367902278900146, "xcomet_qe_score": 0.92647784948349, "metricx_score": 5.14434814453125, "metricx_qe_score": 5.477811336517334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "während es leer war, erreichte es eine Verbesserung von zwei Prozent gegenüber dem Ziel-Datensatz bei der Feinabstimmung.", "metrics": {"bleu_score": 6.809398432036521, "chrf_score": 66.48734777268707, "xcomet_score": 0.5477510690689087, "xcomet_qe_score": 0.6397396326065063, "metricx_score": 6.101409435272217, "metricx_qe_score": 5.836007118225098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "unser Ansatz führte zu einer Verbesserung von 6 %.", "metrics": {"bleu_score": 8.171014300726602, "chrf_score": 37.53181810048732, "xcomet_score": 0.9772920608520508, "xcomet_qe_score": 0.9762461185455322, "metricx_score": 0.21260786056518555, "metricx_qe_score": 0.31338274478912354, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Bei Betrachtung des kleinen Datensatzes können wir erkennen, dass die Leistung von mtDNN abnimmt und die Verbesserung der vorläufigen Multitask-Feinabstimmungsphase auf 1,5 Prozent sinkt.", "metrics": {"bleu_score": 53.75574039788564, "chrf_score": 79.71128215452002, "xcomet_score": 0.9626637697219849, "xcomet_qe_score": 0.9321931600570679, "metricx_score": 1.7941949367523193, "metricx_qe_score": 2.1020078659057617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "aber unsere Leistung stieg auf 11 % im Vergleich zur Zielaufgabe Feinabstimmung allein.", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 62.325369720686375, "xcomet_score": 0.9250864386558533, "xcomet_qe_score": 0.9379920363426208, "metricx_score": 1.7029036283493042, "metricx_qe_score": 1.763443112373352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Summierung ermöglicht FAST eine Few-Shot-Anreicherung aus 35 Proben in unserem Experiment.", "metrics": {"bleu_score": 46.825687910244035, "chrf_score": 83.28503557722394, "xcomet_score": 0.8037571907043457, "xcomet_qe_score": 0.6978038549423218, "metricx_score": 4.4690752029418945, "metricx_qe_score": 6.0732550621032715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze.", "metrics": {"bleu_score": 55.0695314903184, "chrf_score": 90.0929663869274, "xcomet_score": 0.9807785749435425, "xcomet_qe_score": 0.9429309368133545, "metricx_score": 1.1379332542419434, "metricx_qe_score": 1.739567518234253, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und es erhält den Kopf des Modells.", "metrics": {"bleu_score": 27.054113452696992, "chrf_score": 51.044931205249476, "xcomet_score": 0.8508344888687134, "xcomet_qe_score": 0.80791175365448, "metricx_score": 4.170662879943848, "metricx_qe_score": 5.384573936462402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "aber es fügt eine Umformulierungsphase hinzu", "metrics": {"bleu_score": 27.482545710800192, "chrf_score": 82.86400114422669, "xcomet_score": 0.9328208565711975, "xcomet_qe_score": 0.9140899181365967, "metricx_score": 0.46403002738952637, "metricx_qe_score": 3.0240063667297363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "das erweiterte Zugset und seine Anforderungen, einen Zielwert mit semantischer Bedeutung, den wir in das Sprachmodell einspeisen und im Satz für das Klassifizierungsproblem verwenden können.", "metrics": {"bleu_score": 36.90964953921975, "chrf_score": 66.86553408868141, "xcomet_score": 0.7769936919212341, "xcomet_qe_score": 0.7835835814476013, "metricx_score": 6.0696868896484375, "metricx_qe_score": 6.567503929138184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 20.4664420548395, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.02491046115756035, "metricx_qe_score": 0.1274172067642212, "linguapy_score": [0, "GERMAN"]}}
