{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous, aujourd'hui je vais présenter notre travail de recherche intitulé « Apprendre à Raisonner Déductivement : Résolution de Problèmes Métaboliques comme Extraction de Régions Complexes ».", "metrics": {"bleu_score": 16.748366556857587, "chrf_score": 58.89533115637654, "xcomet_score": 0.6834510564804077, "xcomet_qe_score": 0.7117681503295898, "metricx_score": 10.648433685302734, "metricx_qe_score": 8.950722694396973, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "Je suis Alan du laboratoire d'intelligence artificielle de ByteDance, et ceci est un travail en collaboration avec Jerry de l'Université du Texas à Austin et Weilu du SUTD.", "metrics": {"bleu_score": 53.26184432055905, "chrf_score": 78.85587447338919, "xcomet_score": 0.6912493705749512, "xcomet_qe_score": 0.6747922897338867, "metricx_score": 3.9828436374664307, "metricx_qe_score": 3.625220537185669, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, j'aimerais aborder notre motivation pour le raisonnement.", "metrics": {"bleu_score": 64.07117598241614, "chrf_score": 85.47864077852374, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.6316269636154175, "metricx_qe_score": 1.7437201738357544, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous présentons un exemple où un raisonnement en plusieurs étapes est utile.", "metrics": {"bleu_score": 49.615778556328834, "chrf_score": 76.9026440533571, "xcomet_score": 0.9998564720153809, "xcomet_qe_score": 1.0, "metricx_score": 0.4455254077911377, "metricx_qe_score": 0.6300855278968811, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Cette figure est extraite du document de Pound où ils utilisent des invites pour résoudre le problème mathématique dans un scénario d'apprentissage par quelques exemples.", "metrics": {"bleu_score": 8.702340416048491, "chrf_score": 48.48658399968201, "xcomet_score": 0.21225827932357788, "xcomet_qe_score": 0.18094952404499054, "metricx_score": 12.971901893615723, "metricx_qe_score": 11.160594940185547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Sur le côté gauche, nous pouvons voir que si nous fournissons des échantillons avec uniquement des questions et des réponses, nous risquons de ne pas obtenir les réponses correctes.", "metrics": {"bleu_score": 46.848729727358375, "chrf_score": 65.04861485908097, "xcomet_score": 0.9005885124206543, "xcomet_qe_score": 0.9488869905471802, "metricx_score": 2.510009288787842, "metricx_qe_score": 1.5225400924682617, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si nous fournissons une description plus détaillée du raisonnement, le modèle est capable de prédire la description du raisonnement et également de faire une prédiction correcte dans ce cas.", "metrics": {"bleu_score": 39.026381629283975, "chrf_score": 70.91083985203205, "xcomet_score": 0.9656002521514893, "xcomet_qe_score": 0.9916070699691772, "metricx_score": 1.01596200466156, "metricx_qe_score": 1.4925843477249146, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Il est donc bénéfique d'avoir une raisonnement multi-étapes interprétable en tant que sortie.", "metrics": {"bleu_score": 7.474875887495341, "chrf_score": 50.52727510569057, "xcomet_score": 0.9338055849075317, "xcomet_qe_score": 0.9435029029846191, "metricx_score": 4.160048007965088, "metricx_qe_score": 4.632001876831055, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pensons également que le problème de méthode est une application directe pour évaluer de telles capacités de raisonnement.", "metrics": {"bleu_score": 63.67075680957933, "chrf_score": 79.67952366575398, "xcomet_score": 0.7422282099723816, "xcomet_qe_score": 0.6918374300003052, "metricx_score": 8.228606224060059, "metricx_qe_score": 6.7190046310424805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Voici donc, dans notre énoncé de problème, compte tenu des questions posées, nous devons résoudre cette question et obtenir les réponses numériques.", "metrics": {"bleu_score": 70.16116562610198, "chrf_score": 82.64931628264172, "xcomet_score": 0.9511736631393433, "xcomet_qe_score": 0.9489008784294128, "metricx_score": 3.127535820007324, "metricx_qe_score": 3.2540645599365234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos ensembles de données, on nous fournit également l'expression mathématique qui conduit à cette réponse particulière.", "metrics": {"bleu_score": 49.24584878270649, "chrf_score": 80.4898386286658, "xcomet_score": 0.9812469482421875, "xcomet_qe_score": 0.9807901382446289, "metricx_score": 2.5261175632476807, "metricx_qe_score": 3.0201244354248047, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, certaines hypothèses s'appliquent également comme dans les travaux précédents.", "metrics": {"bleu_score": 72.92571723872932, "chrf_score": 81.74616035973521, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.85512375831604, "metricx_qe_score": 2.617657423019409, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "nous supposons que la précision des quantités est connue", "metrics": {"bleu_score": 77.25505949016376, "chrf_score": 96.10701894445121, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.9910596013069153, "metricx_qe_score": 1.4724169969558716, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous ne considérons que les opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentiation.", "metrics": {"bleu_score": 92.10589320522861, "chrf_score": 95.68299687983432, "xcomet_score": 0.969541072845459, "xcomet_qe_score": 0.9754696488380432, "metricx_score": 1.1877816915512085, "metricx_qe_score": 0.6469014883041382, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les opérateurs complexes peuvent en réalité être décomposés en ces opérateurs de base.", "metrics": {"bleu_score": 50.7196093945688, "chrf_score": 69.8708284380725, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5208061337471008, "metricx_qe_score": 0.4972343444824219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, les travaux précédents sur la résolution de problèmes de méthodes peuvent en réalité être catégorisés en modèles séquence-à-séquence et séquence-à-arbre.", "metrics": {"bleu_score": 15.292705335458642, "chrf_score": 55.036984646542294, "xcomet_score": 0.6500421762466431, "xcomet_qe_score": 0.660407304763794, "metricx_score": 6.996065139770508, "metricx_qe_score": 7.980782508850098, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de séquence à séquence traditionnels convertissent l'expression en une séquence spécifique pour la génération.", "metrics": {"bleu_score": 56.35190098079901, "chrf_score": 86.9620549120146, "xcomet_score": 0.8227502107620239, "xcomet_qe_score": 0.7702916860580444, "metricx_score": 2.2815446853637695, "metricx_qe_score": 3.030402660369873, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Et sa mise en œuvre est plutôt aisée, tout en permettant de généraliser à de nombreux problèmes complexes et variés.", "metrics": {"bleu_score": 14.230715327204656, "chrf_score": 51.3201585849419, "xcomet_score": 0.9775742292404175, "xcomet_qe_score": 1.0, "metricx_score": 1.532957673072815, "metricx_qe_score": 1.2765885591506958, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, les inconvénients de la performance ne sont en général pas meilleurs que ceux du modèle structuré. De plus, il manque d'interprétabilité pour les prédictions.", "metrics": {"bleu_score": 5.300658717390603, "chrf_score": 60.38448991499729, "xcomet_score": 0.6803964972496033, "xcomet_qe_score": 0.7595106363296509, "metricx_score": 8.294145584106445, "metricx_qe_score": 6.853999614715576, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en réalité, cette approche reste assez populaire en raison du modèle de transformateur.", "metrics": {"bleu_score": 50.95172447616117, "chrf_score": 60.31920210701023, "xcomet_score": 0.7781165838241577, "xcomet_qe_score": 0.8076372742652893, "metricx_score": 3.3465423583984375, "metricx_qe_score": 1.8341376781463623, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Dans les modèles basés sur des arbres, nous structurons en fait ces expressions sous forme d'arbre et suivons une traversée en ordre préalable lors de la génération des arbres.", "metrics": {"bleu_score": 35.57547439720247, "chrf_score": 67.8657671217531, "xcomet_score": 0.8977138996124268, "xcomet_qe_score": 0.9099192023277283, "metricx_score": 4.98754358291626, "metricx_qe_score": 5.320915222167969, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous continuons à générer les opérateurs jusqu'à atteindre les feuilles, qui sont les quantités.", "metrics": {"bleu_score": 48.29737357282969, "chrf_score": 68.59380166669116, "xcomet_score": 0.8445690870285034, "xcomet_qe_score": 0.8047857284545898, "metricx_score": 3.0916500091552734, "metricx_qe_score": 4.486753463745117, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le point positif ici est qu'il nous offre réellement cette structure d'arbre binaire. Cependant, cela est en fait assez contre-intuitif car nous générons d'abord l'opérateur, puis à la fin nous générons les quantités.", "metrics": {"bleu_score": 28.23152381695714, "chrf_score": 63.432217600631645, "xcomet_score": 0.9636838436126709, "xcomet_qe_score": 0.966812014579773, "metricx_score": 3.1984524726867676, "metricx_qe_score": 4.048101425170898, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est qu'elle contient également certains calculs répétitifs.", "metrics": {"bleu_score": 42.86982293646294, "chrf_score": 81.65232219346137, "xcomet_score": 0.922925591468811, "xcomet_qe_score": 0.9670112133026123, "metricx_score": 1.6212388277053833, "metricx_qe_score": 1.2855981588363647, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, si nous examinons cette expression, 8 fois 3 plus 3 est en réalité calculé deux fois. Cependant, en réalité, nous devrions réutiliser les résultats.", "metrics": {"bleu_score": 38.52355651798958, "chrf_score": 61.59325890368385, "xcomet_score": 0.9798725843429565, "xcomet_qe_score": 0.982213020324707, "metricx_score": 0.7474446296691895, "metricx_qe_score": 0.9371537566184998, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre approche proposée, nous souhaitons résoudre ces problèmes de manière progressive et interprétable.", "metrics": {"bleu_score": 28.93253943064403, "chrf_score": 69.909502008471, "xcomet_score": 0.9994187355041504, "xcomet_qe_score": 1.0, "metricx_score": 0.8990775346755981, "metricx_qe_score": 0.9327937364578247, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, par exemple, ici à la deuxième étape, nous pouvons obtenir ce diviseur, qui est 27.", "metrics": {"bleu_score": 35.587851490678766, "chrf_score": 66.80063906132145, "xcomet_score": 0.9471346139907837, "xcomet_qe_score": 0.9496146440505981, "metricx_score": 2.305850028991699, "metricx_qe_score": 3.522915840148926, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "nous pouvons également nous référer aux questions originales pour trouver les contenus pertinents.", "metrics": {"bleu_score": 64.53174978135057, "chrf_score": 90.19067619641787, "xcomet_score": 0.9884665012359619, "xcomet_qe_score": 0.9876962900161743, "metricx_score": 0.7069063782691956, "metricx_qe_score": 0.7623097896575928, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous obtenons les diviseurs.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9926035404205322, "xcomet_qe_score": 0.9813810586929321, "metricx_score": 2.1472244262695312, "metricx_qe_score": 2.927687406539917, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Et ensuite, à cette troisième étape, nous obtenons effectivement le quotient.", "metrics": {"bleu_score": 61.62607099729587, "chrf_score": 74.99507475504917, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.649139881134033, "metricx_qe_score": 3.1404383182525635, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, et après ces trois étapes, nous pouvons en fait utiliser les résultats de la deuxième étape et ensuite obtenir les résultats de la quatrième étape. Et enfin, nous pouvons obtenir les dividendes.", "metrics": {"bleu_score": 62.26290213382865, "chrf_score": 83.12445531626953, "xcomet_score": 0.981859564781189, "xcomet_qe_score": 0.975584864616394, "metricx_score": 2.2143478393554688, "metricx_qe_score": 3.0627200603485107, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, nous générons en fait l'expression entière directement plutôt que de générer des opérateurs ou des quantités individuelles.", "metrics": {"bleu_score": 39.080227521872686, "chrf_score": 64.37617971500515, "xcomet_score": 0.9843628406524658, "xcomet_qe_score": 0.9744850993156433, "metricx_score": 1.2532000541687012, "metricx_qe_score": 1.3570153713226318, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "Cela rend le processus plus précis.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6321161985397339, "metricx_qe_score": 1.023879885673523, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre système déductif, nous commençons d'abord par un ensemble de quantités présentées dans les questions, incluant également certaines constantes comme état initial.", "metrics": {"bleu_score": 48.9174669738847, "chrf_score": 80.15515431548751, "xcomet_score": 0.9725418090820312, "xcomet_qe_score": 0.9542827606201172, "metricx_score": 2.979970693588257, "metricx_qe_score": 3.8898751735687256, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "L'expression est donc représentée par EIJOP.", "metrics": {"bleu_score": 7.64649370538093, "chrf_score": 61.31749886839668, "xcomet_score": 0.9785304069519043, "xcomet_qe_score": 0.9675105810165405, "metricx_score": 1.1124985218048096, "metricx_qe_score": 1.9465159177780151, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "où nous effectuons l'opérateur de QI à QJ, et cette expression est en fait dirigée.", "metrics": {"bleu_score": 50.73776480599196, "chrf_score": 85.33265077013259, "xcomet_score": 0.8674537539482117, "xcomet_qe_score": 0.8740264177322388, "metricx_score": 5.148040294647217, "metricx_qe_score": 7.734631538391113, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc également ici la soustraction inverse pour représenter la direction opposée.", "metrics": {"bleu_score": 43.94900482337444, "chrf_score": 76.7253145360072, "xcomet_score": 0.9056967496871948, "xcomet_qe_score": 0.9568901062011719, "metricx_score": 1.820184588432312, "metricx_qe_score": 2.885394334793091, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "Ceci est assez similaire à l'extraction de relations.", "metrics": {"bleu_score": 28.24099048856542, "chrf_score": 70.13435410341606, "xcomet_score": 0.909714937210083, "xcomet_qe_score": 0.929241418838501, "metricx_score": 1.5483946800231934, "metricx_qe_score": 2.768643617630005, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans un système déductif formel, à l'instant t, nous appliquons l'opérateur entre la paire qi et qj, et nous obtenons ensuite ces nouvelles expressions.", "metrics": {"bleu_score": 27.983469084065106, "chrf_score": 61.24527788795382, "xcomet_score": 0.9565976858139038, "xcomet_qe_score": 0.9770224094390869, "metricx_score": 2.037400245666504, "metricx_qe_score": 1.8775774240493774, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "nous l'ajoutons à l'état suivant pour former une nouvelle quantité.", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 83.94085872023808, "xcomet_score": 0.9786965847015381, "xcomet_qe_score": 0.9640134572982788, "metricx_score": 1.8613626956939697, "metricx_qe_score": 3.0376904010772705, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Cette diapositive visualise en fait l'évolution de l'état où nous ajoutons continuellement des expressions à l'état actuel.", "metrics": {"bleu_score": 29.270608034423432, "chrf_score": 64.27201083156874, "xcomet_score": 0.8601548671722412, "xcomet_qe_score": 0.7585431337356567, "metricx_score": 3.5131099224090576, "metricx_qe_score": 4.095529079437256, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Dans nos implémentations de modèle, nous utilisons d'abord un modèle de langage pré-entraîné qui peut être un modèle BERT ou RoBERTa, puis nous encodons une phrase, et enfin nous obtenons ces représentations quantitatives.", "metrics": {"bleu_score": 42.052935174095545, "chrf_score": 72.488313781534, "xcomet_score": 0.8573850393295288, "xcomet_qe_score": 0.8791095018386841, "metricx_score": 2.067915201187134, "metricx_qe_score": 1.6072299480438232, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Une fois que nous obtenons les représentations quantitatives, nous pouvons commencer à effectuer des inférences.", "metrics": {"bleu_score": 45.090228049186024, "chrf_score": 74.4130013088617, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.4022859334945679, "metricx_qe_score": 1.4757791757583618, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous présentons un exemple de Q1 pour obtenir la représentation de Q1 divisé par Q2, puis multiplié par Q4.", "metrics": {"bleu_score": 13.114780282367029, "chrf_score": 55.520005004931804, "xcomet_score": 0.6920814514160156, "xcomet_qe_score": 0.7531388998031616, "metricx_score": 14.378799438476562, "metricx_qe_score": 11.470455169677734, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous obtenons la représentation en paires, qui n'est en fait que la concaténation entre Q1 et Q2. Ensuite, nous appliquons un réseau de neurones feedforward, paramétré par l'opérateur.", "metrics": {"bleu_score": 34.1909312720893, "chrf_score": 61.92018167423091, "xcomet_score": 0.8316677808761597, "xcomet_qe_score": 0.9060226678848267, "metricx_score": 4.750333786010742, "metricx_qe_score": 4.477629661560059, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et finalement, nous obtenons la représentation de l'expression Q1 divisé par Q2.", "metrics": {"bleu_score": 35.52628897052406, "chrf_score": 74.72821336358648, "xcomet_score": 0.981063723564148, "xcomet_qe_score": 0.9777618646621704, "metricx_score": 2.3061907291412354, "metricx_qe_score": 3.3431310653686523, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "En réalité, dans la pratique, lors de l'étape d'inférence, nous pourrions également obtenir l'expression incorrecte.", "metrics": {"bleu_score": 43.12062617928647, "chrf_score": 79.81689186035737, "xcomet_score": 0.9840729236602783, "xcomet_qe_score": 0.994835615158081, "metricx_score": 1.4472002983093262, "metricx_qe_score": 1.8865435123443604, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, toutes les expressions possibles sont égales à 3 fois le nombre d'opérateurs.", "metrics": {"bleu_score": 26.760322756637922, "chrf_score": 64.64686416153279, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7868595123291016, "metricx_qe_score": 1.4702930450439453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, l'aspect intéressant ici est que nous pouvons facilement ajouter des contraintes pour contrôler cet espace de recherche.", "metrics": {"bleu_score": 60.91456162918895, "chrf_score": 80.13527714605317, "xcomet_score": 0.9865596294403076, "xcomet_qe_score": 0.9642374515533447, "metricx_score": 1.5025100708007812, "metricx_qe_score": 1.5551488399505615, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement supprimer cette expression dans notre espace de recherche.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9995723962783813, "xcomet_qe_score": 0.9972200393676758, "metricx_score": 0.43808066844940186, "metricx_qe_score": 0.45326462388038635, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la deuxième étape, nous faisons la même chose, mais la seule différence est une quantité supplémentaire.", "metrics": {"bleu_score": 57.47215610578097, "chrf_score": 75.8237765467595, "xcomet_score": 0.9499431848526001, "xcomet_qe_score": 0.9432872533798218, "metricx_score": 3.4691901206970215, "metricx_qe_score": 4.718902587890625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "Cette quantité découle de l'expression calculée précédente.", "metrics": {"bleu_score": 23.87517132417733, "chrf_score": 60.19805222442196, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8469800353050232, "metricx_qe_score": 0.9431749582290649, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous pouvons obtenir cette expression finale Q.", "metrics": {"bleu_score": 32.8060571266766, "chrf_score": 60.86808851263201, "xcomet_score": 0.6231732368469238, "xcomet_qe_score": 0.7044925689697266, "metricx_score": 11.781734466552734, "metricx_qe_score": 11.678666114807129, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "fois Q4. Et nous pouvons également constater que le nombre de toutes les expressions possibles est différent de l'étape précédente.", "metrics": {"bleu_score": 63.50869045864349, "chrf_score": 83.1670634764416, "xcomet_score": 0.47278231382369995, "xcomet_qe_score": 0.2984442114830017, "metricx_score": 6.996538162231445, "metricx_qe_score": 11.247941970825195, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "Une telle différence rend l'application de la recherche par faisceau difficile, car la distribution de probabilité entre ces deux étapes est déséquilibrée.", "metrics": {"bleu_score": 59.70228993860436, "chrf_score": 81.9998325192151, "xcomet_score": 0.9698398113250732, "xcomet_qe_score": 0.9811736345291138, "metricx_score": 1.9089010953903198, "metricx_qe_score": 1.8883767127990723, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "La procédure d'entraînement est donc similaire à celle d'un modèle séquence-à-séquence, où nous optimisons la perte à chaque pas de temps.", "metrics": {"bleu_score": 52.98134210609742, "chrf_score": 73.75570430399661, "xcomet_score": 0.6901940107345581, "xcomet_qe_score": 0.672497034072876, "metricx_score": 2.5416531562805176, "metricx_qe_score": 4.09617805480957, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également ce tau pour représenter le moment où nous devrions mettre fin à ce processus de génération.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.225374698638916, "metricx_qe_score": 3.699932813644409, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent d'une séquence à l'autre car l'espace varie à chaque pas de temps, alors que dans un modèle de séquence à séquence traditionnel, c'est le nombre de mots du vocabulaire qui est pris en compte.", "metrics": {"bleu_score": 52.426087858088806, "chrf_score": 76.91667958364104, "xcomet_score": 0.7958970069885254, "xcomet_qe_score": 0.7805081605911255, "metricx_score": 5.21420431137085, "metricx_qe_score": 6.328548908233643, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela nous permet également d'imposer certaines contraintes à partir de connaissances antérieures.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9521472454071045, "xcomet_qe_score": 0.90984046459198, "metricx_score": 1.2115706205368042, "metricx_qe_score": 1.5397331714630127, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Nous menons donc des expériences sur les ensembles de données de problèmes de méthode couramment utilisés MAWPS, MAT23K, MATQA et SWAMP.", "metrics": {"bleu_score": 39.082647724858255, "chrf_score": 66.9862111952053, "xcomet_score": 0.5574899911880493, "xcomet_qe_score": 0.5819680094718933, "metricx_score": 6.292076587677002, "metricx_qe_score": 5.64286994934082, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous présentons brièvement les résultats en comparaison avec les approches par lots précédentes.", "metrics": {"bleu_score": 22.048872820716333, "chrf_score": 58.04208706492505, "xcomet_score": 0.7409546375274658, "xcomet_qe_score": 0.7983187437057495, "metricx_score": 5.298527240753174, "metricx_qe_score": 4.879119873046875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, notre variante la plus performante est Robeta Dictative Reasoner.", "metrics": {"bleu_score": 63.15552371794033, "chrf_score": 84.42564148453565, "xcomet_score": 0.8280618786811829, "xcomet_qe_score": 0.8065529465675354, "metricx_score": 5.52499532699585, "metricx_qe_score": 5.5505781173706055, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "en fait, nous n'utilisons pas la recherche par faisceau, contrairement à d'autres approches évidentes utilisant cette méthode.", "metrics": {"bleu_score": 17.868702150275563, "chrf_score": 47.955540282074324, "xcomet_score": 0.7815004587173462, "xcomet_qe_score": 0.815398097038269, "metricx_score": 4.057100296020508, "metricx_qe_score": 3.625339984893799, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, donc les approches les plus efficaces sont souvent basées sur des modèles arborescents.", "metrics": {"bleu_score": 6.437165254072419, "chrf_score": 42.70134710407934, "xcomet_score": 0.9942612648010254, "xcomet_qe_score": 0.9909335970878601, "metricx_score": 0.7541457414627075, "metricx_qe_score": 0.6619858741760254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, notre raisonneur est en mesure de surperformer significativement ce modèle basé sur un arbre.", "metrics": {"bleu_score": 28.43329181530769, "chrf_score": 66.75712243219, "xcomet_score": 0.9795706272125244, "xcomet_qe_score": 0.9417070150375366, "metricx_score": 5.626899719238281, "metricx_qe_score": 7.842465400695801, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, nous pouvons constater que le nombre absolu sur Mathqa ou SWAM n'est pas réellement élevé.", "metrics": {"bleu_score": 5.875148471810145, "chrf_score": 45.99875443274443, "xcomet_score": 0.8652465343475342, "xcomet_qe_score": 0.8668637275695801, "metricx_score": 2.6719963550567627, "metricx_qe_score": 2.692922592163086, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Nous poursuivons donc l'investigation des résultats sur", "metrics": {"bleu_score": 8.820727472213227, "chrf_score": 43.129284913677665, "xcomet_score": 0.24228772521018982, "xcomet_qe_score": 0.5053406953811646, "metricx_score": 7.314019203186035, "metricx_qe_score": 6.251839637756348, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "Et ce jeu de données est difficile car l'auteur a tenté d'ajouter manuellement des éléments pour confondre le modèle de traitement du langage naturel (NLP), comme l'ajout d'informations irrelevantes et de quantités supplémentaires.", "metrics": {"bleu_score": 14.59890651518377, "chrf_score": 62.39047168048465, "xcomet_score": 0.8156487941741943, "xcomet_qe_score": 0.7443839311599731, "metricx_score": 1.7383331060409546, "metricx_qe_score": 1.8431684970855713, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre prédiction, nous constatons que certaines des valeurs intermédiaires sont en réalité négatives.", "metrics": {"bleu_score": 56.38653104251221, "chrf_score": 81.52075930892505, "xcomet_score": 0.9812169075012207, "xcomet_qe_score": 1.0, "metricx_score": 1.4195773601531982, "metricx_qe_score": 0.6893102526664734, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans ces questions, nous demandons combien de pommes Drake possède-t-il ?", "metrics": {"bleu_score": 57.81682559080759, "chrf_score": 82.01183486962968, "xcomet_score": 0.5652689933776855, "xcomet_qe_score": 0.572939932346344, "metricx_score": 5.263482570648193, "metricx_qe_score": 5.937765598297119, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous disposons d'informations supplémentaires, comme 17 lancers en moins. Et Steven a 8 lancers, ce qui est totalement insignifiant.", "metrics": {"bleu_score": 15.96188746647155, "chrf_score": 52.65232543690869, "xcomet_score": 0.5734556317329407, "xcomet_qe_score": 0.6675546169281006, "metricx_score": 8.143046379089355, "metricx_qe_score": 7.303012847900391, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait certaines prédictions de cette manière, ce qui génère des valeurs négatives.", "metrics": {"bleu_score": 27.694132751313415, "chrf_score": 50.483184501402164, "xcomet_score": 0.9684487581253052, "xcomet_qe_score": 0.9907879829406738, "metricx_score": 2.564526319503784, "metricx_qe_score": 1.739417552947998, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "et nous observons ces deux expressions", "metrics": {"bleu_score": 8.558153335723478, "chrf_score": 33.74871853387019, "xcomet_score": 0.1677292436361313, "xcomet_qe_score": 0.22412756085395813, "metricx_score": 18.77903175354004, "metricx_qe_score": 18.574827194213867, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons en fait limiter cet espace de recherche en éliminant les résultats négatifs afin de rendre la réponse correcte.", "metrics": {"bleu_score": 51.19139560355038, "chrf_score": 72.7461768399355, "xcomet_score": 0.8965953588485718, "xcomet_qe_score": 0.7425549030303955, "metricx_score": 2.877784252166748, "metricx_qe_score": 3.5193021297454834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Nous constatons donc que cette contrainte améliore en réalité de manière significative les performances de certains modèles.", "metrics": {"bleu_score": 41.180376356915765, "chrf_score": 68.69293804729512, "xcomet_score": 0.977615237236023, "xcomet_qe_score": 0.9818390607833862, "metricx_score": 1.2951353788375854, "metricx_qe_score": 1.4993716478347778, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, pour les oiseaux, nous avons amélioré sept points. Et ensuite, pour le modèle basé sur Robeta, nous avons en fait amélioré de deux points.", "metrics": {"bleu_score": 28.54879317075056, "chrf_score": 51.12787217321072, "xcomet_score": 0.4161912798881531, "xcomet_qe_score": 0.46069610118865967, "metricx_score": 12.958545684814453, "metricx_qe_score": 11.005509376525879, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Un meilleur modèle linguistique possède une meilleure capacité de compréhension du langage, de sorte que le nombre ici est plus élevé pour Robita et plus bas pour Bird.", "metrics": {"bleu_score": 31.419140425518076, "chrf_score": 52.00338927516482, "xcomet_score": 0.506202220916748, "xcomet_qe_score": 0.6348470449447632, "metricx_score": 14.558717727661133, "metricx_qe_score": 8.221386909484863, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous essayons également d'analyser la difficulté sous-jacente à cela.", "metrics": {"bleu_score": 53.8772222047036, "chrf_score": 67.6848913203522, "xcomet_score": 0.7969844341278076, "xcomet_qe_score": 0.6494433879852295, "metricx_score": 1.9355976581573486, "metricx_qe_score": 5.611979007720947, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "nous supposons que le nombre de quantités non utilisées peut être considéré comme une information sans pertinence ici.", "metrics": {"bleu_score": 40.202477345336675, "chrf_score": 82.75717732644713, "xcomet_score": 0.9628517627716064, "xcomet_qe_score": 0.9657429456710815, "metricx_score": 1.8378102779388428, "metricx_qe_score": 2.019749402999878, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous pouvons observer le pourcentage d'échantillons avec des quantités non utilisées, et le jeu de données SWAMP présente la plus grande proportion.", "metrics": {"bleu_score": 28.802579195096648, "chrf_score": 67.74893983128615, "xcomet_score": 0.9112779498100281, "xcomet_qe_score": 0.9151727557182312, "metricx_score": 3.919349193572998, "metricx_qe_score": 4.432734489440918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous présentons également la performance globale.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 84.01072369616061, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.136033058166504, "metricx_qe_score": 1.222168207168579, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "pour les échantillons sans quantités inutilisées. Ainsi, la performance globale est en réalité supérieure à la performance globale.", "metrics": {"bleu_score": 56.42499050012735, "chrf_score": 89.27657812098995, "xcomet_score": 0.4814428985118866, "xcomet_qe_score": 0.3922726809978485, "metricx_score": 7.098110675811768, "metricx_qe_score": 8.250353813171387, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "Mais pour ces échantillons dont la quantité non utilisée est en réalité bien pire que la précédente.", "metrics": {"bleu_score": 17.18548758791047, "chrf_score": 49.2946857532717, "xcomet_score": 0.7434684634208679, "xcomet_qe_score": 0.7238835096359253, "metricx_score": 10.810858726501465, "metricx_qe_score": 11.400924682617188, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "performance. Pour MAWPS, nous n'avons pas vraiment beaucoup de boîtiers de disques, donc je simplement ignore cette partie.", "metrics": {"bleu_score": 35.17636208847486, "chrf_score": 65.14641664295107, "xcomet_score": 0.4523255527019501, "xcomet_qe_score": 0.4555884599685669, "metricx_score": 7.9286065101623535, "metricx_qe_score": 8.533683776855469, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous souhaitons démontrer l'interprétabilité à travers un exemple de choc et de perturbation.", "metrics": {"bleu_score": 30.130404892785695, "chrf_score": 62.0775241776165, "xcomet_score": 0.6378946304321289, "xcomet_qe_score": 0.8122919201850891, "metricx_score": 5.800214767456055, "metricx_qe_score": 6.243072509765625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, notre modèle fait en réalité une prédiction erronée dès la première étape.", "metrics": {"bleu_score": 36.00565854285029, "chrf_score": 67.84706434636945, "xcomet_score": 0.99074387550354, "xcomet_qe_score": 0.9882351756095886, "metricx_score": 0.9161722660064697, "metricx_qe_score": 0.7885745763778687, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc en fait corréler cette expression avec la phrase ici.", "metrics": {"bleu_score": 45.736647398125, "chrf_score": 64.08091311368554, "xcomet_score": 0.9797580242156982, "xcomet_qe_score": 0.9950953722000122, "metricx_score": 1.7964975833892822, "metricx_qe_score": 3.175971746444702, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons donc que cette phrase pourrait induire le modèle en erreur et conduire à une prédiction incorrecte.", "metrics": {"bleu_score": 60.98820960308448, "chrf_score": 77.64040440972902, "xcomet_score": 0.9966170787811279, "xcomet_qe_score": 0.9823441505432129, "metricx_score": 0.770254373550415, "metricx_qe_score": 0.4123237133026123, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, imprimer 35 autres nombres fait croire au modèle qu'il devrait s'agir d'un opérateur d'addition.", "metrics": {"bleu_score": 21.47917245987805, "chrf_score": 55.384902532985144, "xcomet_score": 0.6639622449874878, "xcomet_qe_score": 0.5308455228805542, "metricx_score": 4.941363334655762, "metricx_qe_score": 3.984309673309326, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous essayons de réviser la phrase pour qu'elle soit formulée ainsi : le nombre de poiriers est inférieur de 55 à celui des pommiers.", "metrics": {"bleu_score": 41.79811495622785, "chrf_score": 63.498530120106835, "xcomet_score": 0.7408232688903809, "xcomet_qe_score": 0.7702229022979736, "metricx_score": 5.296214580535889, "metricx_qe_score": 5.942694664001465, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous le concevons pour transmettre une sémantique plus précise, de sorte que le modèle est en mesure de faire une prédiction correcte.", "metrics": {"bleu_score": 21.62050865049026, "chrf_score": 58.60289524169636, "xcomet_score": 0.9141780138015747, "xcomet_qe_score": 0.931564450263977, "metricx_score": 2.798694610595703, "metricx_qe_score": 2.1253511905670166, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Cette étude démontre ainsi comment les prédictions interprétables nous aident à comprendre le comportement du modèle.", "metrics": {"bleu_score": 56.33639605518702, "chrf_score": 83.79982807017629, "xcomet_score": 0.9970816373825073, "xcomet_qe_score": 1.0, "metricx_score": 0.9685249328613281, "metricx_qe_score": 0.7737677693367004, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure nos travaux, notre modèle s'avère donc plutôt efficace.", "metrics": {"bleu_score": 12.920606398131978, "chrf_score": 50.55801582666546, "xcomet_score": 0.996038556098938, "xcomet_qe_score": 0.9940167665481567, "metricx_score": 1.0721218585968018, "metricx_qe_score": 1.0528178215026855, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous sommes en mesure de fournir une procédure de résolution interprétable.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0080623626708984, "metricx_qe_score": 1.129818081855774, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "et nous pouvons facilement intégrer certaines connaissances préalables en tant que contraintes, ce qui peut aider à améliorer les performances.", "metrics": {"bleu_score": 21.338748895376348, "chrf_score": 71.17768698447084, "xcomet_score": 0.9579633474349976, "xcomet_qe_score": 0.9408139586448669, "metricx_score": 0.58148592710495, "metricx_qe_score": 0.6989648342132568, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, le mécanisme sous-jacent ne s'applique pas uniquement aux tâches de résolution de problèmes en cartographie, mais également à d'autres tâches impliquant un raisonnement en plusieurs étapes.", "metrics": {"bleu_score": 27.646664828898366, "chrf_score": 67.37311301237138, "xcomet_score": 0.7982684373855591, "xcomet_qe_score": 0.7668443918228149, "metricx_score": 6.233763694763184, "metricx_qe_score": 5.828054904937744, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons également certaines limitations.", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 84.91693802156698, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.18605005741119385, "metricx_qe_score": 0.20433780550956726, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée.", "metrics": {"bleu_score": 94.57416090031757, "chrf_score": 98.9525445252718, "xcomet_score": 0.9851295948028564, "xcomet_qe_score": 0.9756907820701599, "metricx_score": 1.2383146286010742, "metricx_qe_score": 1.2242019176483154, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est que, comme mentionné, étant donné que la distribution de probabilité est déséquilibrée à différents pas de temps, il est donc également assez difficile d'appliquer la recherche en faisceau.", "metrics": {"bleu_score": 63.27067557304968, "chrf_score": 78.08883341591088, "xcomet_score": 0.8115329742431641, "xcomet_qe_score": 0.8828939199447632, "metricx_score": 2.467641830444336, "metricx_qe_score": 2.5463509559631348, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici la fin de l'exposé, les questions sont les bienvenues. Merci.", "metrics": {"bleu_score": 38.594519944265, "chrf_score": 56.56852530250419, "xcomet_score": 0.990381121635437, "xcomet_qe_score": 0.9792724847793579, "metricx_score": 0.9507707953453064, "metricx_qe_score": 0.7709290981292725, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je viens de l'Université de Maastricht.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 90.46894018144044, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.377380132675171, "metricx_qe_score": 0.664887011051178, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai mon travail de recherche, en collaboration avec Jerry, sur un nouveau jeu de données pour la récupération d'articles législatifs.", "metrics": {"bleu_score": 10.048426812212309, "chrf_score": 46.93427127676613, "xcomet_score": 0.8621951341629028, "xcomet_qe_score": 0.8729780912399292, "metricx_score": 1.8980004787445068, "metricx_qe_score": 1.2749186754226685, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions juridiques font partie intégrante de la vie de nombreuses personnes.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4274544417858124, "metricx_qe_score": 0.3648781478404999, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "mais la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et les processus juridiques fondamentaux.", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 91.24584740555369, "xcomet_score": 0.966964602470398, "xcomet_qe_score": 0.9696496725082397, "metricx_score": 0.9958561062812805, "metricx_qe_score": 1.1265379190444946, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "En conséquence, de nombreux citoyens vulnérables qui ne peuvent se permettre l'assistance coûteuse d'un expert juridique restent sans protection ou, pis encore, sont exploités.", "metrics": {"bleu_score": 41.83238783963822, "chrf_score": 70.3754534378609, "xcomet_score": 0.9992573261260986, "xcomet_qe_score": 1.0, "metricx_score": 0.8920484185218811, "metricx_qe_score": 0.7984566688537598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Notre travail vise à combler le fossé entre les individus et la loi en développant des systèmes de récupération efficaces pour les articles législatifs.", "metrics": {"bleu_score": 37.49263325519968, "chrf_score": 61.835718599237, "xcomet_score": 0.9145265817642212, "xcomet_qe_score": 0.9359023571014404, "metricx_score": 3.924287796020508, "metricx_qe_score": 3.713315963745117, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "un tel système pourrait offrir un service d'aide juridique professionnelle gratuite aux personnes non qualifiées.", "metrics": {"bleu_score": 45.93073632354733, "chrf_score": 85.93550975059347, "xcomet_score": 0.9877320528030396, "xcomet_qe_score": 0.968658447265625, "metricx_score": 0.7838144302368164, "metricx_qe_score": 0.817165195941925, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de nous plonger dans la principale contribution de ce travail, décrivons d'abord le problème de la récupération d'articles législatifs.", "metrics": {"bleu_score": 42.911876041020285, "chrf_score": 68.11867364865248, "xcomet_score": 0.8619253039360046, "xcomet_qe_score": 0.9299176931381226, "metricx_score": 4.28786563873291, "metricx_qe_score": 2.662682056427002, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné une question simple sur une petite affaire, telle que quel risque cours-je si je viole la confidentialité professionnelle ?", "metrics": {"bleu_score": 30.20103087706165, "chrf_score": 59.55926287188492, "xcomet_score": 0.7633981704711914, "xcomet_qe_score": 0.6230282783508301, "metricx_score": 5.930944919586182, "metricx_qe_score": 5.929532527923584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "un modèle est requis pour extraire tous les articles législatifs pertinents d'un vaste corpus de lois.", "metrics": {"bleu_score": 29.48993986902436, "chrf_score": 66.27185561871208, "xcomet_score": 0.9762446880340576, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.1910226345062256, "metricx_qe_score": 1.3536781072616577, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche de récupération d'informations s'accompagne de ses propres défis.", "metrics": {"bleu_score": 10.234459018728545, "chrf_score": 49.148165506015786, "xcomet_score": 0.9879382848739624, "xcomet_qe_score": 1.0, "metricx_score": 1.4421614408493042, "metricx_qe_score": 1.2193554639816284, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, il traite de deux types de langage.", "metrics": {"bleu_score": 48.326978309062206, "chrf_score": 77.70626446580955, "xcomet_score": 0.7698017358779907, "xcomet_qe_score": 0.9778584241867065, "metricx_score": 2.369997024536133, "metricx_qe_score": 1.0847606658935547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "Un langage naturel courant pour les questions et un langage juridique complexe pour les statuts.", "metrics": {"bleu_score": 31.53554052490134, "chrf_score": 63.27213373253119, "xcomet_score": 0.7938545942306519, "xcomet_qe_score": 0.87550950050354, "metricx_score": 4.313218593597412, "metricx_qe_score": 2.758528709411621, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence dans la répartition des langues rend plus difficile pour un système la récupération de candidats pertinents, car elle exige indirectement un système d'interprétation inhérent capable de traduire une question naturelle en une question juridique correspondant à la terminologie des textes de loi.", "metrics": {"bleu_score": 52.087530999077565, "chrf_score": 79.13709746854495, "xcomet_score": 0.8894720077514648, "xcomet_qe_score": 0.8381671905517578, "metricx_score": 5.070718288421631, "metricx_qe_score": 6.006514072418213, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le droit législatif n'est pas une pile d'articles indépendants qui peuvent être traités comme une source d'information complète à eux seuls, contrairement aux nouvelles ou aux recettes, par exemple.", "metrics": {"bleu_score": 67.05212536468012, "chrf_score": 82.36910687595942, "xcomet_score": 0.9842531681060791, "xcomet_qe_score": 0.9773217439651489, "metricx_score": 4.247188091278076, "metricx_qe_score": 3.776221513748169, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'agit plutôt d'une collection structurée de dispositions légales qui n'acquièrent leur sens complet que lorsqu'elles sont considérées dans leur contexte global, c'est-à-dire en conjonction avec les informations complémentaires de leurs articles voisins, des domaines et sous-domaines auxquels elles appartiennent, et de leur place dans la structure de la loi.", "metrics": {"bleu_score": 40.81349668469883, "chrf_score": 76.01507919391506, "xcomet_score": 0.9794819355010986, "xcomet_qe_score": 1.0, "metricx_score": 1.329285979270935, "metricx_qe_score": 0.9305272698402405, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, les articles législatifs ne sont pas de petits paragraphes, qui constituent habituellement l'unité de récupération typique dans la plupart des travaux de récupération d'information.", "metrics": {"bleu_score": 43.31017716700229, "chrf_score": 69.66854262691653, "xcomet_score": 0.9261372089385986, "xcomet_qe_score": 0.9562656879425049, "metricx_score": 3.9934351444244385, "metricx_qe_score": 3.8294057846069336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, il y a des documents longs qui peuvent atteindre six pages.", "metrics": {"bleu_score": 29.677347795910823, "chrf_score": 52.26332223828245, "xcomet_score": 0.9623537063598633, "xcomet_qe_score": 0.953837513923645, "metricx_score": 5.9878153800964355, "metricx_qe_score": 6.990420818328857, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les récentes avancées en traitement automatique du langage naturel (TALN) ont suscité un vif intérêt pour de nombreuses tâches juridiques, telles que la prédiction de jugements ou la révision automatisée de contrats.", "metrics": {"bleu_score": 47.00519930422385, "chrf_score": 69.14140585485853, "xcomet_score": 0.9223983287811279, "xcomet_qe_score": 0.9648644924163818, "metricx_score": 1.0311826467514038, "metricx_qe_score": 0.7461313009262085, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, la récupération d'articles légaux est restée largement inchangée en raison du manque de grands ensembles de données de labels de haute qualité.", "metrics": {"bleu_score": 32.14110553053944, "chrf_score": 61.126279906881464, "xcomet_score": 0.6910638809204102, "xcomet_qe_score": 0.6972969174385071, "metricx_score": 6.666642189025879, "metricx_qe_score": 6.0580363273620605, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce travail, nous présentons un nouveau jeu de données natif français, centré sur les citoyens, pour étudier si un modèle de récupération peut approcher l'efficacité et la fiabilité d'un expert juridique pour la tâche de récupération d'articles de loi.", "metrics": {"bleu_score": 33.45889495007427, "chrf_score": 66.65037239298839, "xcomet_score": 0.5149397253990173, "xcomet_qe_score": 0.5490681529045105, "metricx_score": 6.024733066558838, "metricx_qe_score": 4.359062671661377, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "Notre ensemble de données de récupération d'articles légaux belges, PSART, se compose de plus de 1 100 documents juridiques.", "metrics": {"bleu_score": 7.932540359883352, "chrf_score": 40.85167175538801, "xcomet_score": 0.3046928644180298, "xcomet_qe_score": 0.4549458622932434, "metricx_score": 8.819246292114258, "metricx_qe_score": 9.62727165222168, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "Ces questions couvrent un large éventail de sujets, allant de la famille, du logement, de l'argent, au travail et à la sécurité sociale.", "metrics": {"bleu_score": 53.544522675366245, "chrf_score": 80.43253445272669, "xcomet_score": 0.9829789400100708, "xcomet_qe_score": 1.0, "metricx_score": 1.3764208555221558, "metricx_qe_score": 0.5793664455413818, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun d'eux a été étiqueté par des juristes expérimentés avec des références aux articles pertinents d'un corpus de plus de 22 600 textes.", "metrics": {"bleu_score": 33.827450539967614, "chrf_score": 56.10692853373088, "xcomet_score": 0.47941648960113525, "xcomet_qe_score": 0.7507668733596802, "metricx_score": 5.512662410736084, "metricx_qe_score": 5.3179497718811035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Codes de loi belges. Parlons maintenant de la manière dont nous avons collecté ces ensembles de données.", "metrics": {"bleu_score": 34.51395513935864, "chrf_score": 75.12558015028455, "xcomet_score": 0.1854272186756134, "xcomet_qe_score": 0.17712369561195374, "metricx_score": 14.32770824432373, "metricx_qe_score": 17.993621826171875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous avons commencé par compiler un vaste corpus d'articles juridiques.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 89.67261536267442, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5245909690856934, "metricx_qe_score": 0.7335225343704224, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons examiné 32 codes belges publiquement disponibles et extrait l'ensemble de leurs articles ainsi que les titres de sections correspondants.", "metrics": {"bleu_score": 33.6464490270417, "chrf_score": 67.89407977092262, "xcomet_score": 0.9907310009002686, "xcomet_qe_score": 1.0, "metricx_score": 2.300124168395996, "metricx_qe_score": 2.3974287509918213, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous avons recueilli des questions juridiques avec des références aux lois pertinentes.", "metrics": {"bleu_score": 49.35578819979934, "chrf_score": 82.09435374895043, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3494468927383423, "metricx_qe_score": 1.6452088356018066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous collaborons avec un cabinet d'avocats belge qui reçoit chaque année environ 4 000 courriels de citoyens belges demandant des conseils sur une question juridique personnelle.", "metrics": {"bleu_score": 72.03362668653467, "chrf_score": 84.13574613484107, "xcomet_score": 0.9958176612854004, "xcomet_qe_score": 0.9989476203918457, "metricx_score": 0.6241051554679871, "metricx_qe_score": 0.5225479602813721, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance d'obtenir un accès à leurs sites web, où leur équipe de juristes expérimentés aborde les questions juridiques les plus courantes en Belgique.", "metrics": {"bleu_score": 76.77026013716566, "chrf_score": 88.12777036883553, "xcomet_score": 0.9949733018875122, "xcomet_qe_score": 1.0, "metricx_score": 2.31860613822937, "metricx_qe_score": 1.9564908742904663, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons recueilli des milliers de questions, annotées avec des catégories, des sous-catégories et des références juridiques aux lois pertinentes.", "metrics": {"bleu_score": 87.87419089273847, "chrf_score": 97.83316694837981, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7929880619049072, "metricx_qe_score": 0.969219446182251, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons analysé les références juridiques et exclu les questions dont les références n'étaient pas des articles dans l'un des codes de loi que nous avons pris en compte.", "metrics": {"bleu_score": 61.14887872946488, "chrf_score": 76.78665295596075, "xcomet_score": 0.9581248760223389, "xcomet_qe_score": 0.9526392817497253, "metricx_score": 1.4249783754348755, "metricx_qe_score": 1.8531550168991089, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "Les références restantes ont été mises en correspondance et converties en identifiants d'articles correspondants à partir d'Ocorpus.", "metrics": {"bleu_score": 25.28116869739494, "chrf_score": 72.05226001137137, "xcomet_score": 0.8281960487365723, "xcomet_qe_score": 0.8578293323516846, "metricx_score": 3.5831663608551025, "metricx_qe_score": 3.804152488708496, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons finalement abouti à 1108 questions, chacune soigneusement étiquetée avec les identifiants des articles pertinents issus de", "metrics": {"bleu_score": 26.052674642472013, "chrf_score": 50.9045728825581, "xcomet_score": 0.12502329051494598, "xcomet_qe_score": 0.1094992533326149, "metricx_score": 13.264286041259766, "metricx_qe_score": 9.495576858520508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, chaque question est associée à une catégorie principale et à une concaténation de sous-catégories.", "metrics": {"bleu_score": 40.335820725998886, "chrf_score": 66.22500352337477, "xcomet_score": 0.9470884799957275, "xcomet_qe_score": 0.9659475684165955, "metricx_score": 4.806862831115723, "metricx_qe_score": 4.9145894050598145, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "et chaque article est accompagné d'une concaténation de leur sous-titre ultérieur dans la structure de la loi.", "metrics": {"bleu_score": 37.15770152515525, "chrf_score": 50.29554860055912, "xcomet_score": 0.5105437636375427, "xcomet_qe_score": 0.4814571738243103, "metricx_score": 10.140314102172852, "metricx_qe_score": 10.23281478881836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Ces informations supplémentaires ne sont pas utilisées dans le présent travail, mais elles pourraient s'avérer intéressantes pour de futures recherches sur la récupération d'informations juridiques ou la classification fiscale légale.", "metrics": {"bleu_score": 52.82440172753284, "chrf_score": 75.85419562718427, "xcomet_score": 0.7494397163391113, "xcomet_qe_score": 0.7601271867752075, "metricx_score": 6.49397611618042, "metricx_qe_score": 6.662307262420654, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons quelques caractéristiques de nos ensembles de données.", "metrics": {"bleu_score": 17.869400568145597, "chrf_score": 53.634061214757104, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6071538329124451, "metricx_qe_score": 0.6590412855148315, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions varient en longueur de 5 à 44 mots, avec une médiane de 14 mots.", "metrics": {"bleu_score": 7.994607499472017, "chrf_score": 33.67688029683031, "xcomet_score": 0.9427304863929749, "xcomet_qe_score": 0.8685332536697388, "metricx_score": 0.9677209258079529, "metricx_qe_score": 0.5089350938796997, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont beaucoup plus longs, avec une longueur médiane de 77 mots, et 142... \n(Note : Le texte anglais semble inachevé à la fin, donc la traduction reflète cette troncature.)", "metrics": {"bleu_score": 16.818675851617087, "chrf_score": 45.19295837363303, "xcomet_score": 0.27570369839668274, "xcomet_qe_score": 0.29236435890197754, "metricx_score": 12.20632266998291, "metricx_qe_score": 12.168198585510254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "dépassant 1000.", "metrics": {"bleu_score": 0.0, "chrf_score": 4.292004358446068, "xcomet_score": 0.15458077192306519, "xcomet_qe_score": 0.14678636193275452, "metricx_score": 21.61339569091797, "metricx_qe_score": 21.37859535217285, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "Comme mentionné précédemment, les questions couvrent un large éventail de sujets, avec environ 85 % d'entre elles portant soit sur la famille, le logement, l'argent ou la justice.", "metrics": {"bleu_score": 55.15685261379873, "chrf_score": 68.4966689718523, "xcomet_score": 0.9582245349884033, "xcomet_qe_score": 0.9955315589904785, "metricx_score": 1.1751364469528198, "metricx_qe_score": 0.8978332877159119, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que les 15 % restants concernent soit la sécurité sociale, soit les étrangers, soit le travail.", "metrics": {"bleu_score": 22.75948301279327, "chrf_score": 65.68191170012396, "xcomet_score": 0.9602397680282593, "xcomet_qe_score": 0.9703958034515381, "metricx_score": 1.2431013584136963, "metricx_qe_score": 1.2758214473724365, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très divers car ils proviennent de 32 codes belges différents qui couvrent un grand nombre de sujets juridiques.", "metrics": {"bleu_score": 53.39935148604844, "chrf_score": 77.24096766464558, "xcomet_score": 0.9098352193832397, "xcomet_qe_score": 0.9818813800811768, "metricx_score": 1.1662499904632568, "metricx_qe_score": 0.8779904246330261, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles recueillis à partir de chacun de ces codes belges.", "metrics": {"bleu_score": 80.03203203845001, "chrf_score": 85.33400976915524, "xcomet_score": 0.9932454824447632, "xcomet_qe_score": 1.0, "metricx_score": 1.5812472105026245, "metricx_qe_score": 2.8229246139526367, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Sur les 22 633 articles, seuls 1 612 sont considérés comme pertinents pour au moins", "metrics": {"bleu_score": 7.777443922955584, "chrf_score": 32.65303091977474, "xcomet_score": 0.3796849548816681, "xcomet_qe_score": 0.3178598880767822, "metricx_score": 8.998380661010742, "metricx_qe_score": 4.642595291137695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "une question dans les ensembles de données. Et environ 80 % de ces articles cités proviennent soit du code civil, du code de procédure judiciaire, du code d'instruction criminelle ou des codes pénaux.", "metrics": {"bleu_score": 29.880620222683383, "chrf_score": 63.20049890409247, "xcomet_score": 0.2549634277820587, "xcomet_qe_score": 0.39814266562461853, "metricx_score": 10.813248634338379, "metricx_qe_score": 13.04238224029541, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "Entre-temps, 18 des 32 codes comportent moins de 5 articles mentionnés comme pertinents pour au moins une question.", "metrics": {"bleu_score": 46.90985791861482, "chrf_score": 65.29925899927501, "xcomet_score": 0.6866828203201294, "xcomet_qe_score": 0.7254730463027954, "metricx_score": 1.5127389430999756, "metricx_qe_score": 1.6141916513442993, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Ce qui peut s'expliquer par le fait que ces codes se concentrent moins sur les individus et leurs préoccupations.", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 95.60854179149847, "xcomet_score": 0.9994888305664062, "xcomet_qe_score": 1.0, "metricx_score": 2.689072608947754, "metricx_qe_score": 3.129000663757324, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le nombre médian de citations pour ces articles cités est de 2, et moins de 25 % d'entre eux sont", "metrics": {"bleu_score": 44.008930612863544, "chrf_score": 62.78775100349725, "xcomet_score": 0.2923576235771179, "xcomet_qe_score": 0.6427922248840332, "metricx_score": 14.149847030639648, "metricx_qe_score": 13.466174125671387, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant nos ensembles de données, nous évaluons plusieurs approches de récupération, incluant les architectures lexicales et denses.", "metrics": {"bleu_score": 11.124661907380256, "chrf_score": 56.784078366023294, "xcomet_score": 0.7764801383018494, "xcomet_qe_score": 0.9090820550918579, "metricx_score": 4.261045932769775, "metricx_qe_score": 3.8446972370147705, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné une requête dans un article, un modèle lexical attribue un score à la paire requête-article en calculant la somme des poids de chacun de ces termes dans ledit article.", "metrics": {"bleu_score": 56.87128246286375, "chrf_score": 77.69949894064777, "xcomet_score": 0.929969310760498, "xcomet_qe_score": 0.9385838508605957, "metricx_score": 4.1153130531311035, "metricx_qe_score": 4.2601470947265625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec les fonctions de classement standard TF-IDF et BM25.", "metrics": {"bleu_score": 66.36154805687889, "chrf_score": 90.65201472600005, "xcomet_score": 0.9941763877868652, "xcomet_qe_score": 0.9998935461044312, "metricx_score": 1.1771973371505737, "metricx_qe_score": 2.00666880607605, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème avec ces approches est qu'elles ne peuvent récupérer que des articles contenant des mots-clés présents dans la requête.", "metrics": {"bleu_score": 64.7084148066781, "chrf_score": 85.61375321620676, "xcomet_score": 0.9920238256454468, "xcomet_qe_score": 1.0, "metricx_score": 0.9047468900680542, "metricx_qe_score": 0.9476295709609985, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour surmonter cette limitation, nous expérimentons avec une architecture basée sur les réseaux neuronaux qui peut saisir les relations sémantiques entre les requêtes et les articles.", "metrics": {"bleu_score": 45.617777001985004, "chrf_score": 80.99652935107778, "xcomet_score": 0.9026706218719482, "xcomet_qe_score": 0.9679667949676514, "metricx_score": 0.8684665560722351, "metricx_qe_score": 0.8838399052619934, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle de codage b qui cartographie les requêtes et les articles en représentations vectorielles denses et calcule un score de pertinence entre une paire requête-article en fonction de la similarité de leurs incorporations.", "metrics": {"bleu_score": 47.24944645262245, "chrf_score": 76.8781826143337, "xcomet_score": 0.7799540758132935, "xcomet_qe_score": 0.7991231679916382, "metricx_score": 4.624694347381592, "metricx_qe_score": 4.7795023918151855, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces embeddings résultent généralement d'une opération de pooling appliquée à la sortie d'un modèle d'embedding de mots.", "metrics": {"bleu_score": 34.49651062777743, "chrf_score": 61.62630342856708, "xcomet_score": 0.5897881984710693, "xcomet_qe_score": 0.7398167252540588, "metricx_score": 7.127813339233398, "metricx_qe_score": 7.859184265136719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous étudions l'efficacité des b-encodeurs siamois dans un contexte d'évaluation à zéro coup, ce qui signifie que les modèles d'embedding de bois pré-entraînés sont appliqués tels quels, sans aucun réglage fin supplémentaire.", "metrics": {"bleu_score": 30.56224907639654, "chrf_score": 63.49321410790489, "xcomet_score": 0.4266109764575958, "xcomet_qe_score": 0.346966028213501, "metricx_score": 9.781167984008789, "metricx_qe_score": 8.951138496398926, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec des encodeurs de texte indépendants du contexte, à savoir Word2Vec et FastText, ainsi qu'avec des modèles d'incrustation dépendants du contexte, à savoir Robota et plus spécifiquement Camembert, qui est un modèle Robota en français.", "metrics": {"bleu_score": 32.57286882567471, "chrf_score": 72.18874471826642, "xcomet_score": 0.8409905433654785, "xcomet_qe_score": 0.8525713682174683, "metricx_score": 4.977575778961182, "metricx_qe_score": 3.6116440296173096, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous entraînons notre propre modèle basé sur Camembert au-delà des programmeurs.", "metrics": {"bleu_score": 15.934326838673726, "chrf_score": 41.81817153254432, "xcomet_score": 0.3390405476093292, "xcomet_qe_score": 0.4262353479862213, "metricx_score": 12.230262756347656, "metricx_qe_score": 12.064165115356445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "sur tous les ensembles de données. Notez que pour l'entraînement, nous expérimentons avec les deux variantes de l'architecture Bianco.", "metrics": {"bleu_score": 30.09429889037876, "chrf_score": 64.19531706942759, "xcomet_score": 0.12685760855674744, "xcomet_qe_score": 0.10902904719114304, "metricx_score": 15.857402801513672, "metricx_qe_score": 15.363449096679688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "Siamés, qui utilise un modèle d'incrustation de mots unique qui cartographie la requête et l'article ensemble dans un espace vectoriel dense partagé. Et Tutowa, qui utilise deux modèles d'incrustation de mots indépendants qui codent la requête et l'article séparément dans différents espaces d'incrustation.", "metrics": {"bleu_score": 44.58473197859876, "chrf_score": 74.69902998734645, "xcomet_score": 0.47401049733161926, "xcomet_qe_score": 0.5395954847335815, "metricx_score": 7.889973163604736, "metricx_qe_score": 7.490020275115967, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec le pooling moyen, maximal et CLS, ainsi qu'avec le produit en décimales et le cosinus pour calculer les similarités.", "metrics": {"bleu_score": 24.09902916950188, "chrf_score": 66.37462861789162, "xcomet_score": 0.7712181210517883, "xcomet_qe_score": 0.7532644271850586, "metricx_score": 6.1842851638793945, "metricx_qe_score": 5.414853096008301, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre évaluation de référence sur l'ensemble de test.", "metrics": {"bleu_score": 16.26170171519489, "chrf_score": 57.85100289308392, "xcomet_score": 0.850960373878479, "xcomet_qe_score": 0.8101709485054016, "metricx_score": 3.1100480556488037, "metricx_qe_score": 3.5211687088012695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "avec les méthodes lexicales mentionnées ci-dessus, les b-encodeurs siamois évalués dans un contexte zéro-shot au milieu, et les b-encodeurs affinés en dessous.", "metrics": {"bleu_score": 24.64501369713124, "chrf_score": 68.95354610248245, "xcomet_score": 0.4004596173763275, "xcomet_qe_score": 0.37929701805114746, "metricx_score": 8.14591121673584, "metricx_qe_score": 9.304676055908203, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le B-encodeur affiné surpasse de manière significative toutes les autres lignes de basse.", "metrics": {"bleu_score": 43.85068972747104, "chrf_score": 80.05596636929667, "xcomet_score": 0.6932966709136963, "xcomet_qe_score": 0.7138023376464844, "metricx_score": 9.918527603149414, "metricx_qe_score": 8.953042030334473, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle à deux tours s'améliore par rapport à sa variante siamese en ce qui concerne le rappel à 100, mais il présente des performances similaires pour les autres métriques.", "metrics": {"bleu_score": 30.42164950089496, "chrf_score": 56.78926748928183, "xcomet_score": 0.7047369480133057, "xcomet_qe_score": 0.46262481808662415, "metricx_score": 4.2281599044799805, "metricx_qe_score": 4.610171794891357, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que BM25 ait significativement sous-performé la Biancoda entraînée, ses résultats montrent qu'il constitue toujours une solide ligne de base pour la récupération d'informations spécifique au domaine.", "metrics": {"bleu_score": 20.215568161603198, "chrf_score": 56.444862230648454, "xcomet_score": 0.616823673248291, "xcomet_qe_score": 0.6420818567276001, "metricx_score": 10.626562118530273, "metricx_qe_score": 10.937098503112793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation à zéro coup du Siamese biancodeur, nous constatons que l'utilisation directe des embeddings d'un modèle Camembert pré-entraîné, sans optimisation pour la tâche de récupération d'information, donne des résultats médiocres, ce qui est cohérent avec les découvertes antérieures.", "metrics": {"bleu_score": 36.95051560321088, "chrf_score": 68.08180308165822, "xcomet_score": 0.4342959523200989, "xcomet_qe_score": 0.4623997211456299, "metricx_score": 11.031402587890625, "metricx_qe_score": 8.911026954650879, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous avons constaté que le biancodeur basé sur Word2Vec a considérablement surpassé les modèles FastText et Bird, ce qui suggère que les embeddings de mots pré-entraînés au niveau des mots pourraient être plus adaptés à la tâche que les embeddings au niveau des caractères ou des sous-mots lorsqu'ils sont utilisés tels quels.", "metrics": {"bleu_score": 7.526165690837027, "chrf_score": 39.21755184143976, "xcomet_score": 0.24915263056755066, "xcomet_qe_score": 0.3216416835784912, "metricx_score": 10.864700317382812, "metricx_qe_score": 9.97321605682373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que prometteurs, ces résultats indiquent une marge de progression considérable par rapport à un expert juridique compétent qui est en mesure de retrouver, à terme, tous les articles pertinents relatifs à une question donnée et d'obtenir ainsi des scores parfaits.", "metrics": {"bleu_score": 27.682741009267335, "chrf_score": 55.36325120418052, "xcomet_score": 0.9850512742996216, "xcomet_qe_score": 1.0, "metricx_score": 1.155585527420044, "metricx_qe_score": 1.3659671545028687, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Terminons en abordant deux limitations inhérentes à toutes les bases de données.", "metrics": {"bleu_score": 7.768562846380176, "chrf_score": 44.240996601700836, "xcomet_score": 0.9963326454162598, "xcomet_qe_score": 1.0, "metricx_score": 3.8099722862243652, "metricx_qe_score": 2.3691582679748535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, le corpus d'articles est limité à ceux recueillis auprès des 32 codes belges considérés, ce qui ne couvre pas l'ensemble du droit belge, puisque les articles des décrets, directives et ordonnances font défaut.", "metrics": {"bleu_score": 56.930256289333, "chrf_score": 69.94482808791005, "xcomet_score": 0.9233851432800293, "xcomet_qe_score": 0.9405755996704102, "metricx_score": 2.9351248741149902, "metricx_qe_score": 2.6259548664093018, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Pendant la construction de l'ensemble de données, toutes les références à ces articles non collectés sont ignorées, ce qui fait que certaines questions se retrouvent avec seulement une fraction du nombre initial d'articles pertinents.", "metrics": {"bleu_score": 71.63123216653572, "chrf_score": 86.34629405659464, "xcomet_score": 0.9877351522445679, "xcomet_qe_score": 0.9937875270843506, "metricx_score": 1.6623467206954956, "metricx_qe_score": 1.8759636878967285, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cette perte d'information implique que la réponse contenue dans les articles pertinents restants pourrait être incomplète, bien qu'elle soit toujours tout à fait appropriée.", "metrics": {"bleu_score": 68.87246539984304, "chrf_score": 89.37236228825259, "xcomet_score": 0.9688940644264221, "xcomet_qe_score": 0.9670678377151489, "metricx_score": 2.134427785873413, "metricx_qe_score": 1.8046678304672241, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, il convient de noter que toutes les questions juridiques ne peuvent être résolues par la seule consultation des textes de loi.", "metrics": {"bleu_score": 32.04144198812986, "chrf_score": 64.07751823486994, "xcomet_score": 0.9523282051086426, "xcomet_qe_score": 0.9884613156318665, "metricx_score": 0.7909531593322754, "metricx_qe_score": 0.8412426114082336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question est de savoir si je peux sanctionner mes locataires s'ils font trop de bruit,", "metrics": {"bleu_score": 47.17689621306839, "chrf_score": 72.89986327416092, "xcomet_score": 0.9033716917037964, "xcomet_qe_score": 0.8681321144104004, "metricx_score": 3.6631155014038086, "metricx_qe_score": 1.7127561569213867, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "pourrait ne pas offrir de réponse détaillée dans le droit législatif qui quantifie un seuil de bruit spécifique à partir duquel une expulsion est autorisée.", "metrics": {"bleu_score": 59.970791883578045, "chrf_score": 80.75130036611424, "xcomet_score": 0.8423596024513245, "xcomet_qe_score": 0.7962362766265869, "metricx_score": 5.514702320098877, "metricx_qe_score": 5.551443099975586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, le propriétaire devrait probablement s'appuyer davantage sur la jurisprudence et trouver des précédents similaires à sa situation actuelle.", "metrics": {"bleu_score": 88.43865924896839, "chrf_score": 96.00693419793949, "xcomet_score": 0.9974983930587769, "xcomet_qe_score": 0.9999064207077026, "metricx_score": 0.9097432494163513, "metricx_qe_score": 1.021873950958252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le locataire organise deux soirées par semaine jusqu'à 2h du matin.", "metrics": {"bleu_score": 18.744150287621725, "chrf_score": 58.35322514327179, "xcomet_score": 0.9619570374488831, "xcomet_qe_score": 0.9634125828742981, "metricx_score": 2.5861082077026367, "metricx_qe_score": 0.8817316293716431, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, certaines questions sont mieux adaptées que d'autres à la tâche de récupération d'articles légaux, et le domaine de celles qui sont moins appropriées reste à déterminer.", "metrics": {"bleu_score": 56.64731353491229, "chrf_score": 77.12270476736994, "xcomet_score": 0.8461073637008667, "xcomet_qe_score": 0.6601830124855042, "metricx_score": 3.7983036041259766, "metricx_qe_score": 4.11455774307251, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que tous ces travaux susciteront un intérêt pour le développement de modèles de récupération d'articles légaux pratiques et fiables.", "metrics": {"bleu_score": 19.857943409196785, "chrf_score": 66.72675501334031, "xcomet_score": 0.7973412275314331, "xcomet_qe_score": 0.7741513848304749, "metricx_score": 4.01465368270874, "metricx_qe_score": 3.569023370742798, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut contribuer à améliorer l'accès à la justice pour tous.", "metrics": {"bleu_score": 76.91605673134588, "chrf_score": 86.50202009453643, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6813316941261292, "metricx_qe_score": 0.8533360958099365, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre article, DATSET&CODE, aux liens suivants. Merci.", "metrics": {"bleu_score": 56.60979188828385, "chrf_score": 69.66113673982726, "xcomet_score": 0.945110023021698, "xcomet_qe_score": 0.9469804167747498, "metricx_score": 7.905106544494629, "metricx_qe_score": 7.841402053833008, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour ! Nous sommes ravis de vous présenter notre travail sur VAUS, un benchmark indépendant de la tâche conçu pour évaluer les modèles de vision et de langage avec des phénomènes linguistiques spécifiques.", "metrics": {"bleu_score": 38.3141064208163, "chrf_score": 68.36649728539464, "xcomet_score": 0.5624337792396545, "xcomet_qe_score": 0.5908665060997009, "metricx_score": 5.34022331237793, "metricx_qe_score": 5.426114082336426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Pourquoi avons-nous pris la peine d'établir cette référence ?", "metrics": {"bleu_score": 29.453347733166957, "chrf_score": 63.545167064137296, "xcomet_score": 0.9426090717315674, "xcomet_qe_score": 0.9910906553268433, "metricx_score": 2.509566068649292, "metricx_qe_score": 2.9316372871398926, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Eh bien, au cours des dernières années, nous avons assisté à une explosion des modèles de vision et de langage basés sur les transformateurs, pré-entraînés sur de grandes quantités de paires image-texte.", "metrics": {"bleu_score": 46.65354628064651, "chrf_score": 72.88225762596427, "xcomet_score": 0.9456652402877808, "xcomet_qe_score": 0.9861211776733398, "metricx_score": 2.60099720954895, "metricx_qe_score": 3.024915933609009, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun de ces modèles repousse les limites de l'état de l'art dans les tâches de vision et de langage, telles que la réponse à des questions visuelles, le raisonnement de bon sens visuel, la récupération d'images, l'ancrage de phrases, etc.", "metrics": {"bleu_score": 39.412599734228394, "chrf_score": 72.44082981174701, "xcomet_score": 0.6482782959938049, "xcomet_qe_score": 0.7052236199378967, "metricx_score": 4.1494669914245605, "metricx_qe_score": 3.8355259895324707, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc reçu un message. Les précisions sur ces repères spécifiques aux tâches augmentent régulièrement.", "metrics": {"bleu_score": 35.4850304189188, "chrf_score": 72.3360413581871, "xcomet_score": 0.9744390249252319, "xcomet_qe_score": 0.9042901992797852, "metricx_score": 5.189937591552734, "metricx_qe_score": 6.67005729675293, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "Mais savons-nous réellement ce que les modèles ont appris ?", "metrics": {"bleu_score": 51.69731539571708, "chrf_score": 87.01056627810956, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2264529466629028, "metricx_qe_score": 2.1026551723480225, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce qu'un transformateur de vision et de langage a compris en attribuant un score élevé à cette image et à cette phrase pour les faire correspondre ?", "metrics": {"bleu_score": 10.48987838961543, "chrf_score": 65.31965858639798, "xcomet_score": 0.8188614845275879, "xcomet_qe_score": 0.7145155072212219, "metricx_score": 2.6937437057495117, "metricx_qe_score": 2.6948859691619873, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "et une faible note pour celui-ci.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 28.936700941948867, "xcomet_score": 0.8470749855041504, "xcomet_qe_score": 0.8590875864028931, "metricx_score": 3.9126739501953125, "metricx_qe_score": 1.5860621929168701, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur la bonne chose ?", "metrics": {"bleu_score": 32.281751885843555, "chrf_score": 68.20305147191763, "xcomet_score": 0.7724132537841797, "xcomet_qe_score": 0.7463480830192566, "metricx_score": 1.717067003250122, "metricx_qe_score": 2.1995620727539062, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "Ou bien se concentrent-ils sur les biais mis en évidence par les travaux antérieurs ?", "metrics": {"bleu_score": 26.760322756637922, "chrf_score": 60.01812587758526, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7396416664123535, "metricx_qe_score": 0.92469322681427, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour apporter davantage de clarté à cet aspect, nous proposons une approche plus agnostique quant aux tâches et introduisons des valves qui évaluent la sensibilité des modèles de vision et de langage à des phénomènes linguistiques spécifiques affectant à la fois les modalités linguistique et visuelle.", "metrics": {"bleu_score": 44.17938625618278, "chrf_score": 73.87915061739024, "xcomet_score": 0.5273905992507935, "xcomet_qe_score": 0.7249998450279236, "metricx_score": 6.886391639709473, "metricx_qe_score": 6.550241470336914, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la référence anaphorique des entités.", "metrics": {"bleu_score": 79.85065516266611, "chrf_score": 89.02024147659884, "xcomet_score": 0.7413095235824585, "xcomet_qe_score": 0.7701766490936279, "metricx_score": 2.6334290504455566, "metricx_qe_score": 3.7573862075805664, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "Mais comment tester si les modèles de vision et de langage ont capturé ces phénomènes ?", "metrics": {"bleu_score": 48.10977290978806, "chrf_score": 80.9244319176873, "xcomet_score": 0.9484028220176697, "xcomet_qe_score": 0.8684145212173462, "metricx_score": 1.5279712677001953, "metricx_qe_score": 1.7546184062957764, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "par la méthode FOIL, précédemment appliquée pour les modèles de vision et de langage, uniquement pour les groupes nominaux par Ravi Shekhar et ses collaborateurs, et pour le comptage par nos soins dans un travail antérieur.", "metrics": {"bleu_score": 24.36347870937363, "chrf_score": 59.79693811421603, "xcomet_score": 0.48741403222084045, "xcomet_qe_score": 0.6043701767921448, "metricx_score": 7.670248031616211, "metricx_qe_score": 7.245649337768555, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Le procédé de « foiling » consiste essentiellement à prendre la légende d'une image et à en créer une contre-légende en modifiant la légende originale de manière à ce qu'elle ne décrive plus l'image.", "metrics": {"bleu_score": 31.03910269754489, "chrf_score": 61.65882504951558, "xcomet_score": 0.9821842908859253, "xcomet_qe_score": 0.9888601303100586, "metricx_score": 1.7087990045547485, "metricx_qe_score": 1.912483811378479, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous effectuons ces modifications de phrases en nous concentrant sur six éléments spécifiques, tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la référence à l'entité, où chaque élément peut comprendre un ou plusieurs instruments, au cas où nous aurions découvert plusieurs manières intéressantes de créer des instances FOIL.", "metrics": {"bleu_score": 64.51113034070825, "chrf_score": 80.81544566777531, "xcomet_score": 0.6893516182899475, "xcomet_qe_score": 0.6791234612464905, "metricx_score": 3.5806732177734375, "metricx_qe_score": 4.362715721130371, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans le cas de la pièce sur les actions, nous disposons de deux instruments : l'un où le verbe d'action est modifié par une autre action, et l'autre où les actants sont échangés.", "metrics": {"bleu_score": 31.50184265965517, "chrf_score": 59.395226838840976, "xcomet_score": 0.6110454201698303, "xcomet_qe_score": 0.6428477764129639, "metricx_score": 6.551000118255615, "metricx_qe_score": 5.882761001586914, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la coréférence sont également des éléments qui possèdent plus d'un instrument.", "metrics": {"bleu_score": 64.1386525898168, "chrf_score": 82.61316620174543, "xcomet_score": 0.8936327695846558, "xcomet_qe_score": 0.7174829244613647, "metricx_score": 3.1626057624816895, "metricx_qe_score": 5.042752265930176, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous créons ces leurres en veillant à ce qu'ils ne décrivent pas l'image, qu'ils soient grammaticalement corrects et autrement valides en tant que phrases.", "metrics": {"bleu_score": 28.436025391440335, "chrf_score": 66.59435511211719, "xcomet_score": 0.9800900220870972, "xcomet_qe_score": 0.9906834363937378, "metricx_score": 3.6710290908813477, "metricx_qe_score": 5.159478187561035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "Ce n'est pas facile à faire, car une légende modifiée pourrait être moins probable que la légende originale.", "metrics": {"bleu_score": 58.94666012755862, "chrf_score": 76.27572715712346, "xcomet_score": 0.9729130268096924, "xcomet_qe_score": 0.9580751657485962, "metricx_score": 3.708343267440796, "metricx_qe_score": 2.432647466659546, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien que ce ne soit pas impossible, il est statistiquement moins probable que des plantes coupent un homme plutôt qu'un homme ne coupe des plantes, et de grands modèles de vision et de langage pourraient saisir cette nuance.", "metrics": {"bleu_score": 50.615515769007175, "chrf_score": 79.6511948572415, "xcomet_score": 0.9201494455337524, "xcomet_qe_score": 0.9393297433853149, "metricx_score": 3.2749545574188232, "metricx_qe_score": 3.468413829803467, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour obtenir des résultats valides, nous devons agir.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 86.73725624316575, "xcomet_score": 0.9702205657958984, "xcomet_qe_score": 0.919377326965332, "metricx_score": 3.293989896774292, "metricx_qe_score": 3.6436421871185303, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous utilisons des modèles linguistiques robustes pour proposer des contre-exemples.", "metrics": {"bleu_score": 50.698033524721, "chrf_score": 69.92222164871562, "xcomet_score": 0.7773253917694092, "xcomet_qe_score": 0.9211412668228149, "metricx_score": 3.1765124797821045, "metricx_qe_score": 0.9786009788513184, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence en langage naturel, ou NLI, pour éliminer les contre-exemples qui pourraient encore décrire l'image, car lors de la construction des contre-exemples, nous devons nous assurer qu'ils ne parviennent pas à décrire l'image.", "metrics": {"bleu_score": 51.167900592911536, "chrf_score": 73.19595681236719, "xcomet_score": 0.9155347347259521, "xcomet_qe_score": 0.9664161205291748, "metricx_score": 5.052675247192383, "metricx_qe_score": 4.491272926330566, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Pour tester cela automatiquement, nous appliquons l'inférence en langage naturel avec la logique suivante.", "metrics": {"bleu_score": 49.025517878204084, "chrf_score": 73.3542673880474, "xcomet_score": 0.9879379272460938, "xcomet_qe_score": 0.9977468252182007, "metricx_score": 1.0219922065734863, "metricx_qe_score": 0.8449519872665405, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "Nous considérons une image comme la prémisse et sa légende comme l'hypothèse qui en découle.", "metrics": {"bleu_score": 28.039501199940027, "chrf_score": 63.816214873974474, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.8965827226638794, "metricx_qe_score": 0.9560375809669495, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "En outre, nous considérons la légende comme la prémisse et le FOIL comme son hypothèse.", "metrics": {"bleu_score": 62.93749881454796, "chrf_score": 81.87389189154867, "xcomet_score": 0.8232618570327759, "xcomet_qe_score": 0.5707439184188843, "metricx_score": 2.4530093669891357, "metricx_qe_score": 4.228296279907227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit que le FOIL contredit ou est neutre par rapport à la légende, nous considérons cela comme un indicateur d'un FOIL valide.", "metrics": {"bleu_score": 59.817595536558535, "chrf_score": 73.33130145135452, "xcomet_score": 0.6695801019668579, "xcomet_qe_score": 0.6926940679550171, "metricx_score": 4.631582736968994, "metricx_qe_score": 5.547378063201904, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si un NLI prédit que le FOIL est impliqué par la légende, il ne peut s'agir d'un bon FOIL, car par transitivité, il fournira une description véridique de l'image et nous excluons ces FOILs.", "metrics": {"bleu_score": 34.29276904875691, "chrf_score": 55.695796706234745, "xcomet_score": 0.48370838165283203, "xcomet_qe_score": 0.49149784445762634, "metricx_score": 7.790414810180664, "metricx_qe_score": 9.253283500671387, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cette procédure n'est pas parfaite, elle est seulement un indicateur pour des feuilles de protection valides.", "metrics": {"bleu_score": 37.087658421061406, "chrf_score": 67.43629927941626, "xcomet_score": 0.8068387508392334, "xcomet_qe_score": 0.7689366936683655, "metricx_score": 2.6368768215179443, "metricx_qe_score": 2.0093932151794434, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, en tant que troisième mesure pour générer des FOI valides, nous utilisons des annotateurs humains pour valider les données utilisées dans le VALS.", "metrics": {"bleu_score": 54.60241725418134, "chrf_score": 79.33728303549412, "xcomet_score": 0.8123304843902588, "xcomet_qe_score": 0.9238539934158325, "metricx_score": 5.4773454666137695, "metricx_qe_score": 5.995234489440918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, après filtrage et évaluation humaine, nous disposons d'autant d'instances de test que décrites dans ce tableau.", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 84.22157908468806, "xcomet_score": 0.9969282150268555, "xcomet_qe_score": 0.9879427552223206, "metricx_score": 1.3790948390960693, "metricx_qe_score": 1.936598539352417, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez noter que VALS ne fournit aucune donnée d'entraînement, mais uniquement des données de test.", "metrics": {"bleu_score": 26.220676436185983, "chrf_score": 53.48421800733819, "xcomet_score": 0.8608989715576172, "xcomet_qe_score": 0.9507521390914917, "metricx_score": 2.5991342067718506, "metricx_qe_score": 4.291619777679443, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "puisqu'il s'agit uniquement d'un benchmark de test sans préparation préalable. Il est conçu pour exploiter les capacités existantes des modèles de vision et de langage après leur pré-entraînement.", "metrics": {"bleu_score": 21.194666502448257, "chrf_score": 56.974671229510896, "xcomet_score": 0.748708963394165, "xcomet_qe_score": 0.7770222425460815, "metricx_score": 4.490358829498291, "metricx_qe_score": 4.575817584991455, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "L'ajustement fin ne permettrait aux modèles que d'exploiter des artefacts ou des biais statistiques dans les données.", "metrics": {"bleu_score": 62.33473783356552, "chrf_score": 79.11121847166795, "xcomet_score": 0.9745557904243469, "xcomet_qe_score": 0.968670666217804, "metricx_score": 1.6052312850952148, "metricx_qe_score": 1.7789738178253174, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998902082443237, "xcomet_qe_score": 1.0, "metricx_score": 1.3476738929748535, "metricx_qe_score": 2.4462342262268066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Comme nous l'avons dit, nous sommes intéressés à évaluer les capacités que possèdent les modèles de vision et de langage après l'apprentissage préalable.", "metrics": {"bleu_score": 15.94000950514835, "chrf_score": 61.19565274407432, "xcomet_score": 0.9855061769485474, "xcomet_qe_score": 1.0, "metricx_score": 1.5771912336349487, "metricx_qe_score": 1.7629889249801636, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec cinq modèles de vision et de langage sur les voyelles, à savoir CLIP, LXMIRT, VILBERT, VILBERT12IN1 et VISUALBERT.", "metrics": {"bleu_score": 25.59667597084103, "chrf_score": 56.413687745986586, "xcomet_score": 0.49490588903427124, "xcomet_qe_score": 0.5163530111312866, "metricx_score": 6.820377826690674, "metricx_qe_score": 6.31925106048584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos métriques d'évaluation les plus importantes sont la précision des modèles dans la classification des paires image-phrase en légendes et en fausses pistes.", "metrics": {"bleu_score": 41.95311940818068, "chrf_score": 76.41403696765245, "xcomet_score": 0.682148277759552, "xcomet_qe_score": 0.7008519768714905, "metricx_score": 5.200956344604492, "metricx_qe_score": 4.083360195159912, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "Peut-être plus pertinent pour cette vidéo, nous présenterons notre métrique plus permissive, la précision par paire, qui mesure si le score d'alignement des phrases d'image est plus élevé pour la paire texte-image correcte que pour sa paire altérée.", "metrics": {"bleu_score": 55.18739176072437, "chrf_score": 73.49698533287851, "xcomet_score": 0.7118878364562988, "xcomet_qe_score": 0.6635900735855103, "metricx_score": 4.6216840744018555, "metricx_qe_score": 4.325948715209961, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "Pour plus de métriques et de résultats à leur sujet, veuillez consulter notre article.", "metrics": {"bleu_score": 17.915645938206772, "chrf_score": 62.83186212229461, "xcomet_score": 0.9481048583984375, "xcomet_qe_score": 0.9711786508560181, "metricx_score": 1.7641372680664062, "metricx_qe_score": 1.4938781261444092, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats avec précision paire sont présentés ici et ils sont cohérents avec ceux obtenus à partir des autres métriques. En effet, la meilleure performance en zéro-tir est atteinte par Wilbert 12 en 1, suivie de Wilbert, Alexmert, Klip, puis enfin Visualbert.", "metrics": {"bleu_score": 16.61024040426641, "chrf_score": 49.932899678451044, "xcomet_score": 0.361746609210968, "xcomet_qe_score": 0.3615700900554657, "metricx_score": 8.118069648742676, "metricx_qe_score": 8.356255531311035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est remarquable de constater que les instruments axés sur les objets individuels, tels que l'existence et les groupes nominaux, sont presque entièrement résolus par Wilbert 12 en 1, mettant en évidence la capacité des modèles à identifier les objets nommés et leur présence dans les images.", "metrics": {"bleu_score": 32.059697311299495, "chrf_score": 65.7598594456396, "xcomet_score": 0.6311020255088806, "xcomet_qe_score": 0.6416444778442383, "metricx_score": 4.4926042556762695, "metricx_qe_score": 4.982621669769287, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucune des pièces restantes ne peut être résolue de manière fiable dans nos paramètres de contournement adversarial.", "metrics": {"bleu_score": 40.1577332834242, "chrf_score": 67.96264289026772, "xcomet_score": 0.7646112442016602, "xcomet_qe_score": 0.8011974096298218, "metricx_score": 5.522130012512207, "metricx_qe_score": 5.017922401428223, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "Nous observons, à partir de la pluralité et des instruments de comptage, que les modèles de vision et de langage ont du mal à distinguer les références à un objet unique ou multiple, ou à les compter dans une image.", "metrics": {"bleu_score": 47.30874952206922, "chrf_score": 71.32483464724851, "xcomet_score": 0.9360548257827759, "xcomet_qe_score": 0.9677754640579224, "metricx_score": 3.3254971504211426, "metricx_qe_score": 3.9645068645477295, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "La pièce de relation révèle qu'ils ont des difficultés à classer correctement une relation spatiale nommée entre des objets dans une image,", "metrics": {"bleu_score": 75.16324170467026, "chrf_score": 86.06947904182975, "xcomet_score": 0.7131917476654053, "xcomet_qe_score": 0.7275265455245972, "metricx_score": 5.194698333740234, "metricx_qe_score": 5.633899211883545, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "Ils ont également du mal à distinguer les actions et à identifier leurs participants, même lorsqu'ils sont soutenus par des biais de plausibilité, comme nous le voyons dans la partie sur les actions.", "metrics": {"bleu_score": 68.04366873393866, "chrf_score": 87.57997878478315, "xcomet_score": 0.9312673807144165, "xcomet_qe_score": 0.9536677598953247, "metricx_score": 2.56169056892395, "metricx_qe_score": 3.9398341178894043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "À partir de la pièce de coréférence, nous découvrons que la traçabilité de multiples références au même objet dans une image en utilisant des pronoms est également difficile pour les modèles de vision et de langage.", "metrics": {"bleu_score": 64.39731260094547, "chrf_score": 80.3100714507055, "xcomet_score": 0.6610612869262695, "xcomet_qe_score": 0.7285345792770386, "metricx_score": 5.09498929977417, "metricx_qe_score": 5.334466457366943, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "À titre de vérification de cohérence et parce que c'est une expérience intéressante, nous évaluons également deux modèles textuels uniquement, GPT-1 et GPT-2, pour déterminer si VALS peut être résolu par ces modèles unimodaux en calculant la perplexité de la légende correcte et de la légende erronée, puis en prédisant l'entrée avec la perplexité la plus faible.", "metrics": {"bleu_score": 41.5603257938427, "chrf_score": 69.39002706779874, "xcomet_score": 0.7136715650558472, "xcomet_qe_score": 0.7566990852355957, "metricx_score": 6.471961498260498, "metricx_qe_score": 6.078841686248779, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "Si la perplexité est plus élevée pour le FOIL, nous interprétons cela comme un indice que la légende avec FOIL pourrait souffrir de biais de plausibilité ou d'autres biais linguistiques.", "metrics": {"bleu_score": 53.90981306241564, "chrf_score": 72.78660077594948, "xcomet_score": 0.747320294380188, "xcomet_qe_score": 0.6750609874725342, "metricx_score": 6.865423202514648, "metricx_qe_score": 8.599360466003418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est intéressant de constater que, dans certains cas, les modèles GPT textuels ont mieux saisi la plausibilité du monde que les modèles de vision et de langage.", "metrics": {"bleu_score": 46.735559022281684, "chrf_score": 69.13851530530818, "xcomet_score": 0.9117581248283386, "xcomet_qe_score": 0.8845317363739014, "metricx_score": 4.4716620445251465, "metricx_qe_score": 4.738437652587891, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, pour résumer, VALS est une référence qui utilise la perspective de constructions linguistiques pour aider la communauté à améliorer les modèles de vision et de langage en testant rigoureusement leurs capacités de référencement visuel.", "metrics": {"bleu_score": 43.090912931309944, "chrf_score": 73.5506439887408, "xcomet_score": 0.4826344847679138, "xcomet_qe_score": 0.6120538711547852, "metricx_score": 5.438168048858643, "metricx_qe_score": 5.858825206756592, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences démontrent que les modèles de vision et de langage identifient bien les objets nommés et leur présence dans les images, comme le montre l'exemple fourni, mais peinent à établir leur interdépendance et leurs relations dans des scènes visuelles lorsqu'ils sont contraints de respecter des indicateurs linguistiques.", "metrics": {"bleu_score": 64.53431177509263, "chrf_score": 81.94410061316363, "xcomet_score": 0.8742489814758301, "xcomet_qe_score": 0.9160560965538025, "metricx_score": 2.4039440155029297, "metricx_qe_score": 2.7501771450042725, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions vraiment encourager la communauté à utiliser VALS pour mesurer les progrès vers l'ancrage linguistique avec des modèles de vision et de langage.", "metrics": {"bleu_score": 49.546696992958005, "chrf_score": 79.8583513432121, "xcomet_score": 0.7642955780029297, "xcomet_qe_score": 0.8194398880004883, "metricx_score": 5.027274131774902, "metricx_qe_score": 6.2516093254089355, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, VALS pourrait être utilisé comme une évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou le réglage fin pour déterminer si un ensemble de données aide les modèles à s'améliorer sur l'un des aspects testés par VALS.", "metrics": {"bleu_score": 45.61994334543179, "chrf_score": 74.28834107639679, "xcomet_score": 0.9396458864212036, "xcomet_qe_score": 0.9837973117828369, "metricx_score": 2.644477128982544, "metricx_qe_score": 3.3416287899017334, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "Si vous êtes intéressé, n'hésitez pas à consulter les données VALS sur GitHub et, si vous avez des questions, veuillez nous contacter sans hésiter.", "metrics": {"bleu_score": 44.12598628712025, "chrf_score": 79.18628126524804, "xcomet_score": 0.8955976366996765, "xcomet_qe_score": 0.8930310010910034, "metricx_score": 2.463515043258667, "metricx_qe_score": 3.0951056480407715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kami Zerua de l'Université de Tokyo.", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 85.8385869806183, "xcomet_score": 0.6272016167640686, "xcomet_qe_score": 0.5381074547767639, "metricx_score": 3.4331846237182617, "metricx_qe_score": 4.228899002075195, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai un article intitulé RNSUM, un grand ensemble de données pour la notation automatique de listes via la synthèse des journaux de validation.", "metrics": {"bleu_score": 31.96359832321049, "chrf_score": 66.0251439119104, "xcomet_score": 0.6793574094772339, "xcomet_qe_score": 0.6845639944076538, "metricx_score": 6.027889728546143, "metricx_qe_score": 5.5010223388671875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "J'expliquerai dans cet ordre.", "metrics": {"bleu_score": 36.70124608961282, "chrf_score": 61.74235064629813, "xcomet_score": 0.9984650611877441, "xcomet_qe_score": 1.0, "metricx_score": 0.6378704905509949, "metricx_qe_score": 0.807305097579956, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je vais présenter la notification automatique des risques sur laquelle nous travaillons dans le cadre de cette recherche.", "metrics": {"bleu_score": 50.0494822043195, "chrf_score": 76.5149066178338, "xcomet_score": 0.6801316142082214, "xcomet_qe_score": 0.7273215651512146, "metricx_score": 2.903306484222412, "metricx_qe_score": 2.773003578186035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "ReleaseNode est un document technique qui résume les modifications distribuées avec chaque version d'un produit logiciel.", "metrics": {"bleu_score": 63.911674912072804, "chrf_score": 83.34746815097289, "xcomet_score": 0.7802062034606934, "xcomet_qe_score": 0.7483896017074585, "metricx_score": 9.185649871826172, "metricx_qe_score": 8.518582344055176, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'image présente les notes de mise à jour pour la version 2.6.1.", "metrics": {"bleu_score": 8.619158848176236, "chrf_score": 26.73916640424639, "xcomet_score": 0.18190708756446838, "xcomet_qe_score": 0.3243391513824463, "metricx_score": 3.174595832824707, "metricx_qe_score": 4.49772834777832, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Cela ne joue pas un rôle important dans le développement open source, mais leur préparation manuelle est chronophage.", "metrics": {"bleu_score": 38.25785820872566, "chrf_score": 55.39161932899304, "xcomet_score": 0.2809447646141052, "xcomet_qe_score": 0.16168716549873352, "metricx_score": 8.415704727172852, "metricx_qe_score": 10.22754192352295, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Il serait donc très utile de pouvoir générer automatiquement des notes de version de haute qualité.", "metrics": {"bleu_score": 72.83860464220109, "chrf_score": 83.3655136180521, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6620479822158813, "metricx_qe_score": 0.7192174196243286, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "Je me référerai à deux recherches antérieures sur la génération automatique d'auditeurs.", "metrics": {"bleu_score": 46.95736291157361, "chrf_score": 71.44460771993548, "xcomet_score": 0.49081411957740784, "xcomet_qe_score": 0.48721203207969666, "metricx_score": 8.985264778137207, "metricx_qe_score": 10.588987350463867, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier est un système appelé Arena, lancé en 2014.", "metrics": {"bleu_score": 23.462350320527996, "chrf_score": 39.10214845700059, "xcomet_score": 0.34549903869628906, "xcomet_qe_score": 0.6809924840927124, "metricx_score": 1.030144214630127, "metricx_qe_score": 1.1702663898468018, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il adopte une approche basée sur des règles, par exemple, en utilisant l'extracteur de changements pour extraire les différences fondamentales, les modifications de bibliothèque et les changements de documents à partir des différences entre les versions, puis en les combinant finalement.", "metrics": {"bleu_score": 59.190446625795566, "chrf_score": 82.58916076454504, "xcomet_score": 0.8905037641525269, "xcomet_qe_score": 0.9373623132705688, "metricx_score": 2.0333240032196045, "metricx_qe_score": 1.6328147649765015, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus remarquable de ce système est l'extracteur de problèmes situé dans le coin supérieur droit.", "metrics": {"bleu_score": 68.8836505346656, "chrf_score": 89.3701037983314, "xcomet_score": 0.9026151895523071, "xcomet_qe_score": 0.8860491514205933, "metricx_score": 2.06302809715271, "metricx_qe_score": 2.6778392791748047, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "qui doit être lié à Jira, le système de discussion des problèmes, et ne peut être appliqué qu'aux projets utilisant Jira.", "metrics": {"bleu_score": 37.76450518622723, "chrf_score": 71.92105736081523, "xcomet_score": 0.6282206773757935, "xcomet_qe_score": 0.6796348690986633, "metricx_score": 6.058278560638428, "metricx_qe_score": 5.2310051918029785, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, il ne peut être utilisé pour de nombreux projets sur GitHub.", "metrics": {"bleu_score": 67.05624049819114, "chrf_score": 83.8043038783597, "xcomet_score": 0.9997879266738892, "xcomet_qe_score": 0.9898210167884827, "metricx_score": 0.7139981389045715, "metricx_qe_score": 0.8693636655807495, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "Le second est GRIF. Annoncé récemment en 2020,", "metrics": {"bleu_score": 6.27465531099474, "chrf_score": 34.306085133877865, "xcomet_score": 0.2240617871284485, "xcomet_qe_score": 0.38760024309158325, "metricx_score": 8.185088157653809, "metricx_qe_score": 5.71429443359375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "Il est disponible sur Internet et peut être stocké via PIP.", "metrics": {"bleu_score": 22.781556051062047, "chrf_score": 59.40457871592192, "xcomet_score": 0.6234923601150513, "xcomet_qe_score": 0.8746084570884705, "metricx_score": 6.34021520614624, "metricx_qe_score": 5.257358551025391, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système intègre un module de classification de texte basé sur l'apprentissage, qui produit l'une des cinq variables, telles que des fonctionnalités ou des corrections de bogues, pour chaque message d'engagement d'entrée.", "metrics": {"bleu_score": 30.894994002746383, "chrf_score": 67.63806141574841, "xcomet_score": 0.58730149269104, "xcomet_qe_score": 0.5868992805480957, "metricx_score": 4.328354358673096, "metricx_qe_score": 4.037937164306641, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un exemple d'utilisation qui renvoie une étiquette de correction ou de correction de bogues.", "metrics": {"bleu_score": 68.89656775362826, "chrf_score": 83.36354877308032, "xcomet_score": 0.7354081273078918, "xcomet_qe_score": 0.7204704284667969, "metricx_score": 3.480973243713379, "metricx_qe_score": 3.5427937507629395, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "Les données d'entraînement de Goyafet sont relativement réduites, environ 5000, et seront présentées dans les expériences décrites ci-dessous.", "metrics": {"bleu_score": 31.32752091088918, "chrf_score": 61.094181210829156, "xcomet_score": 0.4050525426864624, "xcomet_qe_score": 0.48340946435928345, "metricx_score": 8.956151962280273, "metricx_qe_score": 9.15162181854248, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "la performance du modèle de classification de texte n'est pas élevée.", "metrics": {"bleu_score": 41.24914892312113, "chrf_score": 77.10724776309803, "xcomet_score": 0.9655879735946655, "xcomet_qe_score": 0.9404677748680115, "metricx_score": 0.8275324106216431, "metricx_qe_score": 1.2222881317138672, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches connexes, mais il y avait des problèmes de faible applicabilité et de ressources de données limitées.", "metrics": {"bleu_score": 34.53064989552127, "chrf_score": 72.61954541948231, "xcomet_score": 0.9368118047714233, "xcomet_qe_score": 0.9328769445419312, "metricx_score": 1.6846743822097778, "metricx_qe_score": 1.6151632070541382, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des nœuds de sortie de haute qualité.", "metrics": {"bleu_score": 70.85876411943929, "chrf_score": 84.67568915260534, "xcomet_score": 0.7376428842544556, "xcomet_qe_score": 0.7374168634414673, "metricx_score": 6.099264144897461, "metricx_qe_score": 5.697861671447754, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le programme d'applicabilité limitée, nous proposons une méthode de résumé par classification de haute qualité utilisant uniquement les messages de validation comme entrée.", "metrics": {"bleu_score": 42.252842981103534, "chrf_score": 74.36432652354175, "xcomet_score": 0.8133541345596313, "xcomet_qe_score": 0.7812878489494324, "metricx_score": 5.260457515716553, "metricx_qe_score": 4.719789505004883, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée pour toutes les bibliothèques anglaises.", "metrics": {"bleu_score": 54.91004867761124, "chrf_score": 74.34819229705005, "xcomet_score": 0.8684433698654175, "xcomet_qe_score": 1.0, "metricx_score": 4.022363185882568, "metricx_qe_score": 3.5499415397644043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème relatif à la rareté des ressources de données, nous avons constitué un ensemble de données RNSUM composé d'environ 82 000 éléments en collectant des données à partir de dépôts GitHub publics à l'aide de l'API GitHub.", "metrics": {"bleu_score": 30.40228571418911, "chrf_score": 64.28851009801052, "xcomet_score": 0.9321337938308716, "xcomet_qe_score": 1.0, "metricx_score": 1.215820550918579, "metricx_qe_score": 2.0721170902252197, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décris la manière dont ils sont assis.", "metrics": {"bleu_score": 14.991106946711685, "chrf_score": 41.1591743694116, "xcomet_score": 0.17629781365394592, "xcomet_qe_score": 0.205653116106987, "metricx_score": 8.143887519836426, "metricx_qe_score": 10.174015045166016, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de données.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998996257781982, "xcomet_qe_score": 0.9993472099304199, "metricx_score": 0.5450457334518433, "metricx_qe_score": 0.6231614351272583, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche présente le message de validation, tandis que le côté droit affiche la note de version.", "metrics": {"bleu_score": 20.15807475394783, "chrf_score": 69.34986818866766, "xcomet_score": 0.9798877239227295, "xcomet_qe_score": 0.8355048894882202, "metricx_score": 0.6842896342277527, "metricx_qe_score": 0.9445316195487976, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de mise à jour sont étiquetées comme des améliorations, des lieux de travail, etc.", "metrics": {"bleu_score": 17.636478563502965, "chrf_score": 59.760852973076936, "xcomet_score": 0.5912041664123535, "xcomet_qe_score": 0.6033951044082642, "metricx_score": 9.222025871276855, "metricx_qe_score": 9.637657165527344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons mis en place une tâche qui prend les messages engagés comme entrée et produit les nœuds de pièces brutes connectés.", "metrics": {"bleu_score": 47.479483628535654, "chrf_score": 53.183807595759156, "xcomet_score": 0.2975749969482422, "xcomet_qe_score": 0.4722646474838257, "metricx_score": 12.651101112365723, "metricx_qe_score": 12.474549293518066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de résumé.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 80.28616903243483, "xcomet_score": 0.9564080238342285, "xcomet_qe_score": 0.9850058555603027, "metricx_score": 1.28573477268219, "metricx_qe_score": 0.8809378743171692, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons prédéfini quatre niveaux : fonctionnalités, améliorations, corrections de bogues, dépréciations, suppressions et modifications rompant la compatibilité.", "metrics": {"bleu_score": 31.751444361869975, "chrf_score": 73.66378405600376, "xcomet_score": 0.5473688840866089, "xcomet_qe_score": 0.5109744071960449, "metricx_score": 5.800621032714844, "metricx_qe_score": 5.029304027557373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces affirmations ont été faites sur la base de recherches antérieures et d'autres facteurs.", "metrics": {"bleu_score": 36.15855225145533, "chrf_score": 63.99321444625235, "xcomet_score": 0.9822006225585938, "xcomet_qe_score": 0.9608100652694702, "metricx_score": 1.9362847805023193, "metricx_qe_score": 2.0865495204925537, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de guirlande en bas à droite sont extraites des notes de guirlande présentées en bas à gauche.", "metrics": {"bleu_score": 31.56961170682444, "chrf_score": 50.63081446319001, "xcomet_score": 0.563150942325592, "xcomet_qe_score": 0.5409743785858154, "metricx_score": 15.52810287475586, "metricx_qe_score": 12.064447402954102, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce stade, il est nécessaire de détecter les quatre niveaux qui ont été prédéfinis.", "metrics": {"bleu_score": 56.00239963704976, "chrf_score": 62.5331989737589, "xcomet_score": 0.8344663381576538, "xcomet_qe_score": 0.8893865346908569, "metricx_score": 4.60906457901001, "metricx_qe_score": 3.8453383445739746, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "mais les niveaux ne sont pas toujours cohérents d'une bibliothèque à l'autre.", "metrics": {"bleu_score": 21.401603033752977, "chrf_score": 47.683077160784066, "xcomet_score": 0.5159385204315186, "xcomet_qe_score": 0.5356714129447937, "metricx_score": 5.714294910430908, "metricx_qe_score": 4.306755542755127, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le niveau d'amélioration inclut les améliorations, les renforcements, les optimisations, et ainsi de suite.", "metrics": {"bleu_score": 10.862721615727713, "chrf_score": 62.022171372120624, "xcomet_score": 0.8241866827011108, "xcomet_qe_score": 0.8400049209594727, "metricx_score": 3.8472673892974854, "metricx_qe_score": 3.1581406593322754, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste de vocabulaire correspondant à différents niveaux d'étude pour chacune de ces variations notationnelles.", "metrics": {"bleu_score": 50.891751149357454, "chrf_score": 70.14588218678199, "xcomet_score": 0.5265576243400574, "xcomet_qe_score": 0.541220486164093, "metricx_score": 6.093936920166016, "metricx_qe_score": 6.444706916809082, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez-le pour détecter la classe de la note de version et corrigez le texte de la liste qui suit en tant que phrase de note de version pour la classe.", "metrics": {"bleu_score": 63.99998888050344, "chrf_score": 73.12659231851121, "xcomet_score": 0.4455258846282959, "xcomet_qe_score": 0.2865067720413208, "metricx_score": 8.580394744873047, "metricx_qe_score": 11.307628631591797, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Suivant est un message de validation.", "metrics": {"bleu_score": 40.04970149398301, "chrf_score": 67.08275926961048, "xcomet_score": 0.8556956052780151, "xcomet_qe_score": 0.6387121677398682, "metricx_score": 3.4169580936431885, "metricx_qe_score": 3.508037567138672, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de connexion ne sont pas associés à chaque liste.", "metrics": {"bleu_score": 24.808415001701803, "chrf_score": 59.76174463677174, "xcomet_score": 0.5736813545227051, "xcomet_qe_score": 0.5469635128974915, "metricx_score": 10.231550216674805, "metricx_qe_score": 8.97992992401123, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "Comme illustré dans l'image ci-dessous, si la liste actuelle est en version 2.5 à 19, nous devons identifier :", "metrics": {"bleu_score": 16.884135028903135, "chrf_score": 39.526145964435464, "xcomet_score": 0.1292811930179596, "xcomet_qe_score": 0.11927282810211182, "metricx_score": 16.016233444213867, "metricx_qe_score": 19.191511154174805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "la version précédente, 2.5.18, et explorez en profondeur. C'est un peu fastidieux, et il ne suffit pas d'obtenir une liste des versions et de comparer les changements avant et après.", "metrics": {"bleu_score": 30.598720167656328, "chrf_score": 68.53610672217386, "xcomet_score": 0.22449900209903717, "xcomet_qe_score": 0.20177865028381348, "metricx_score": 15.444358825683594, "metricx_qe_score": 16.053871154785156, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons élaboré une règle de correspondance heuristique pour obtenir les versions précédente et suivante.", "metrics": {"bleu_score": 57.914609264413414, "chrf_score": 78.87562479607854, "xcomet_score": 0.9929362535476685, "xcomet_qe_score": 0.997505784034729, "metricx_score": 0.9260656833648682, "metricx_qe_score": 1.281815528869629, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "Ceci est Tanarsis.", "metrics": {"bleu_score": 15.97357760615681, "chrf_score": 10.587823207234749, "xcomet_score": 0.13256151974201202, "xcomet_qe_score": 0.11238433420658112, "metricx_score": 4.668356418609619, "metricx_qe_score": 8.57442855834961, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "À la fin, 7200 dépôts.", "metrics": {"bleu_score": 1.4499508732277653, "chrf_score": 6.741845838363571, "xcomet_score": 0.14071419835090637, "xcomet_qe_score": 0.14523757994174957, "metricx_score": 21.391693115234375, "metricx_qe_score": 20.46234893798828, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de jetons de nœuds de sortie est de 63, ce qui est assez élevé pour une tâche de résumé.", "metrics": {"bleu_score": 50.64962285182339, "chrf_score": 53.23744836349563, "xcomet_score": 0.3339596092700958, "xcomet_qe_score": 0.2981179356575012, "metricx_score": 8.435704231262207, "metricx_qe_score": 7.700174808502197, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre de jetons uniques est assez élevé, atteignant 8 830 000.", "metrics": {"bleu_score": 17.89117353466845, "chrf_score": 36.79174660720656, "xcomet_score": 0.7966631650924683, "xcomet_qe_score": 0.9617805480957031, "metricx_score": 3.75752592086792, "metricx_qe_score": 1.8138340711593628, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "en raison du grand nombre de noms de classes et de méthodes uniques présents dans le dépôt.", "metrics": {"bleu_score": 23.293261526172028, "chrf_score": 54.59254796320404, "xcomet_score": 0.6296664476394653, "xcomet_qe_score": 0.6256282329559326, "metricx_score": 2.100766897201538, "metricx_qe_score": 1.208678126335144, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, j'expliquerai la méthode proposée.", "metrics": {"bleu_score": 36.74145494215666, "chrf_score": 75.59105076499984, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26971232891082764, "metricx_qe_score": 0.1778177171945572, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de résumé extractif puis abstrait par classe se compose de deux modules neuronaux,", "metrics": {"bleu_score": 54.237828377183035, "chrf_score": 72.68465915238245, "xcomet_score": 0.9579561948776245, "xcomet_qe_score": 0.9263694286346436, "metricx_score": 1.8663949966430664, "metricx_qe_score": 1.900746464729309, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "un classifieur utilisant BERT ou CodeBert, et un générateur utilisant BERT.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 78.80715189999249, "xcomet_score": 0.9577537178993225, "xcomet_qe_score": 0.9721221327781677, "metricx_score": 6.656346321105957, "metricx_qe_score": 5.512877464294434, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, CAS utilise un classifieur pour catégoriser chaque message de validation en cinq classes de notes de version : implémentations, corrections de bogues, dépréciations, améliorations et autres.", "metrics": {"bleu_score": 42.629362922455634, "chrf_score": 76.26066075203649, "xcomet_score": 0.557383120059967, "xcomet_qe_score": 0.3921482264995575, "metricx_score": 5.968993186950684, "metricx_qe_score": 7.289093017578125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de validation classés comme autres sont ignorés.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 84.01908136850463, "xcomet_score": 0.9876168966293335, "xcomet_qe_score": 0.9259141683578491, "metricx_score": 1.5207114219665527, "metricx_qe_score": 2.2877197265625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, CES applique le générateur aux quatre documents d'étiquetage indépendamment et génère des nœuds de sortie pour chaque classe.", "metrics": {"bleu_score": 48.82066497822451, "chrf_score": 78.68702868926582, "xcomet_score": 0.4801602065563202, "xcomet_qe_score": 0.5683256387710571, "metricx_score": 9.339947700500488, "metricx_qe_score": 8.588994026184082, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages d'engagement et les nœuds lus ne sont pas connues.", "metrics": {"bleu_score": 60.70819688690245, "chrf_score": 74.42044108693979, "xcomet_score": 0.5997096300125122, "xcomet_qe_score": 0.6075136065483093, "metricx_score": 6.060372829437256, "metricx_qe_score": 6.0347771644592285, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour entraîner le classifieur, nous attribuons des étiquettes sudo à chaque message de validation d'entrée en utilisant les 10 premiers caractères de chaque message de validation.", "metrics": {"bleu_score": 45.71858219135603, "chrf_score": 72.04295572319708, "xcomet_score": 0.6110523343086243, "xcomet_qe_score": 0.7351133823394775, "metricx_score": 8.528658866882324, "metricx_qe_score": 9.132741928100586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons la résumation abstraite par classe à travers notre approche par deux méthodes différentes.", "metrics": {"bleu_score": 31.53554052490134, "chrf_score": 63.828023775043185, "xcomet_score": 0.6518932580947876, "xcomet_qe_score": 0.7237686514854431, "metricx_score": 3.5261569023132324, "metricx_qe_score": 4.243900775909424, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons cssingle, se compose d'un réseau unique de sexe à sexe et génère un seul nœud de texte long, étant donné une concaténation de messages d'engagement d'entrée.", "metrics": {"bleu_score": 33.97355607250788, "chrf_score": 58.45890496469286, "xcomet_score": 0.08768615871667862, "xcomet_qe_score": 0.16933363676071167, "metricx_score": 17.98348617553711, "metricx_qe_score": 15.2940034866333, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte de sortie peut être divisé en segments à l'échelle de la classe en fonction de symboles d'extrémité spéciaux spécifiques à la classe.", "metrics": {"bleu_score": 20.83987439994524, "chrf_score": 58.31580592507728, "xcomet_score": 0.997178316116333, "xcomet_qe_score": 0.9790294170379639, "metricx_score": 4.288659572601318, "metricx_qe_score": 4.65181303024292, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons fusion CAS, se compose de quatre réseaux différents sec-à-sec, chacun correspondant à l'une des classes les moins connues.", "metrics": {"bleu_score": 36.64867143461359, "chrf_score": 62.91496730408455, "xcomet_score": 0.09228744357824326, "xcomet_qe_score": 0.15762202441692352, "metricx_score": 12.949067115783691, "metricx_qe_score": 11.367937088012695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, laissez-moi expliquer l'expérience.", "metrics": {"bleu_score": 6.4790667469036025, "chrf_score": 47.210365058958445, "xcomet_score": 0.9313861131668091, "xcomet_qe_score": 0.9775118827819824, "metricx_score": 1.1269221305847168, "metricx_qe_score": 0.8525193333625793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été comparées : CAS, CS simple, CS fusion, clustering et étude précédente sur le deuil.", "metrics": {"bleu_score": 27.021693845694813, "chrf_score": 47.27012833359765, "xcomet_score": 0.29953262209892273, "xcomet_qe_score": 0.3326526880264282, "metricx_score": 12.71729850769043, "metricx_qe_score": 13.848908424377441, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation, dans certains cas, ces nœuds sont produits dans plusieurs phrases.", "metrics": {"bleu_score": 53.948230957280764, "chrf_score": 74.85215687031405, "xcomet_score": 0.5981648564338684, "xcomet_qe_score": 0.5826228857040405, "metricx_score": 6.6705121994018555, "metricx_qe_score": 8.276771545410156, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné la difficulté de calculer le nombre de phrases, celles-ci sont combinées avec des espaces et traitées comme une seule phrase longue.", "metrics": {"bleu_score": 63.10436221329868, "chrf_score": 71.88986836590699, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0685065984725952, "metricx_qe_score": 1.846207857131958, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "Le bleu est panelisé lorsque le système génère une courte phrase.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 57.022192069117075, "xcomet_score": 0.8123294115066528, "xcomet_qe_score": 0.6901397705078125, "metricx_score": 8.23794174194336, "metricx_qe_score": 8.554224967956543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité se traduit par une valeur bleue plus faible dans les résultats expérimentaux décrits ci-après.", "metrics": {"bleu_score": 44.81501736040872, "chrf_score": 64.08153574038228, "xcomet_score": 0.9797064065933228, "xcomet_qe_score": 0.9818804860115051, "metricx_score": 1.6514867544174194, "metricx_qe_score": 3.4567620754241943, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous calculons également la spécificité, car les valeurs de « rouge » et de « bleu » ne peuvent être calculées si les nœuds de libération sont vides.", "metrics": {"bleu_score": 26.59887114061172, "chrf_score": 66.3345447495147, "xcomet_score": 0.555698037147522, "xcomet_qe_score": 0.5440869331359863, "metricx_score": 5.637903213500977, "metricx_qe_score": 3.8145229816436768, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une haute spécificité signifie que le modèle produit correctement un texte vide dans les cas où les nœuds de libération supposent un vide.", "metrics": {"bleu_score": 54.27639282491381, "chrf_score": 68.49228456298967, "xcomet_score": 0.7393578290939331, "xcomet_qe_score": 0.7302352786064148, "metricx_score": 4.590226173400879, "metricx_qe_score": 4.647611141204834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats.", "metrics": {"bleu_score": 11.521590992286539, "chrf_score": 34.57828622839441, "xcomet_score": 0.7604808807373047, "xcomet_qe_score": 1.0, "metricx_score": 0.15108263492584229, "metricx_qe_score": 0.03296280279755592, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que le jeu de données contient des adresses e-mail, des valeurs de hachage, etc., nous avons également évalué le jeu de données nettoyé, qui les exclut.", "metrics": {"bleu_score": 36.92890702094148, "chrf_score": 71.40503808631289, "xcomet_score": 0.8902179002761841, "xcomet_qe_score": 0.8629065752029419, "metricx_score": 2.754088878631592, "metricx_qe_score": 2.610138416290283, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "Le CEAS et le CAS ont obtenu des scores L approximatifs supérieurs de plus de 10 points aux valeurs de référence.", "metrics": {"bleu_score": 50.89664388134201, "chrf_score": 61.7875360938025, "xcomet_score": 0.6809560060501099, "xcomet_qe_score": 0.7720969915390015, "metricx_score": 8.610261917114258, "metricx_qe_score": 8.367392539978027, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur l'ensemble de test propre, l'écart de score entre les méthodes proposées et les bases de référence a bondi à plus de 20 points.", "metrics": {"bleu_score": 51.57115350821029, "chrf_score": 75.04712823675871, "xcomet_score": 0.8033596277236938, "xcomet_qe_score": 0.7676339149475098, "metricx_score": 4.977916240692139, "metricx_qe_score": 6.013523578643799, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent que le CES et le GS sont significativement efficaces.", "metrics": {"bleu_score": 35.416987661440594, "chrf_score": 55.19335691842152, "xcomet_score": 0.18175438046455383, "xcomet_qe_score": 0.21222606301307678, "metricx_score": 15.467076301574707, "metricx_qe_score": 13.658897399902344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "CAS a obtenu un meilleur score de défaillance racine que CAS, ce qui suggère que la combinaison d'un classifieur et d'un générateur est efficace pour l'entraînement du classifieur à l'aide de pseudo-doubles.", "metrics": {"bleu_score": 51.51316763028396, "chrf_score": 73.21505869120033, "xcomet_score": 0.16395780444145203, "xcomet_qe_score": 0.16132698953151703, "metricx_score": 15.655143737792969, "metricx_qe_score": 16.345195770263672, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "La couverture élevée du CAS peut probablement être obtenue parce que le classifieur peut se concentrer sur la sélection des messages de validation pertinents pour chaque classe.", "metrics": {"bleu_score": 60.46620633901227, "chrf_score": 86.56955091581928, "xcomet_score": 0.7453137636184692, "xcomet_qe_score": 0.7356066703796387, "metricx_score": 4.295961380004883, "metricx_qe_score": 4.736071586608887, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Les correspondances CAS ont tendance à produire des résultats plus élevés que les recherches uniques CAS.", "metrics": {"bleu_score": 6.256118460580956, "chrf_score": 34.84481366035995, "xcomet_score": 0.48611557483673096, "xcomet_qe_score": 0.5708038806915283, "metricx_score": 9.292293548583984, "metricx_qe_score": 8.695135116577148, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "suggérant qu'il est également efficace de développer indépendamment des modèles de résumé à absorption différente pour chaque classe de nœuds de diffusion.", "metrics": {"bleu_score": 45.685003363733905, "chrf_score": 71.33748735588733, "xcomet_score": 0.3199462294578552, "xcomet_qe_score": 0.3381527066230774, "metricx_score": 8.332769393920898, "metricx_qe_score": 7.895444869995117, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "Analyse du héros et des erreurs", "metrics": {"bleu_score": 0.0, "chrf_score": 37.57438999095656, "xcomet_score": 0.15974260866641998, "xcomet_qe_score": 0.16102465987205505, "metricx_score": 10.663134574890137, "metricx_qe_score": 14.886494636535645, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes de CS ont tendance à produire des phrases plus courtes que les phrases de référence humaines.", "metrics": {"bleu_score": 80.86627571031983, "chrf_score": 94.66279885743036, "xcomet_score": 0.7905377149581909, "xcomet_qe_score": 0.7156859636306763, "metricx_score": 4.612730026245117, "metricx_qe_score": 4.678327560424805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure à droite, la phrase de référence comporte 3 ou 4 phrases, tandis que le CAS n'en a qu'une seule.", "metrics": {"bleu_score": 57.15586618084643, "chrf_score": 76.10050291107112, "xcomet_score": 0.9516627788543701, "xcomet_qe_score": 0.6938718557357788, "metricx_score": 2.447848081588745, "metricx_qe_score": 6.170166015625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette réticence du modèle réside dans le fait que, dans les données d'entraînement, seulement 33 % des phrases sont présentes dans l'étiquette caractéristiques et 40 % dans l'étiquette améliorations.", "metrics": {"bleu_score": 23.42068324966726, "chrf_score": 60.36892489209825, "xcomet_score": 0.8253707885742188, "xcomet_qe_score": 0.9325274229049683, "metricx_score": 3.067291498184204, "metricx_qe_score": 2.907637357711792, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes CES ne peuvent pas générer de VsNode précis sans informations supplémentaires.", "metrics": {"bleu_score": 32.00938205435178, "chrf_score": 70.0283646504835, "xcomet_score": 0.5194815397262573, "xcomet_qe_score": 0.5396033525466919, "metricx_score": 11.781156539916992, "metricx_qe_score": 12.25851058959961, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple en haut à droite est un exemple de message de commentaire très désordonné, et la phrase complète ne peut être générée sans référence à la demande de retrait ou au problème correspondant.", "metrics": {"bleu_score": 67.0483368430225, "chrf_score": 79.71145229181914, "xcomet_score": 0.6679489612579346, "xcomet_qe_score": 0.5989177823066711, "metricx_score": 7.192013263702393, "metricx_qe_score": 6.39880895614624, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous illustre que les deux messages de validation dans l'entrée sont liés et devraient être combinés en une seule phrase, mais il échoue à le faire.", "metrics": {"bleu_score": 38.55843077233733, "chrf_score": 72.87038319757905, "xcomet_score": 0.9352969527244568, "xcomet_qe_score": 0.8995837569236755, "metricx_score": 2.760295867919922, "metricx_qe_score": 2.3535332679748535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, une conclusion.", "metrics": {"bleu_score": 20.252884954471366, "chrf_score": 51.7870301786907, "xcomet_score": 0.9809033870697021, "xcomet_qe_score": 1.0, "metricx_score": 1.8073315620422363, "metricx_qe_score": 2.418452262878418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons construit un nouveau système automatisé pour la notation des cas.", "metrics": {"bleu_score": 12.975280965814113, "chrf_score": 43.704326275530306, "xcomet_score": 0.5510796308517456, "xcomet_qe_score": 0.7203075885772705, "metricx_score": 6.0657501220703125, "metricx_qe_score": 4.624632358551025, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également formé une équipe chargée de saisir et de résumer les messages de validation (commit messages) de manière à ce qu'ils soient applicables à tous les projets rédigés en anglais.", "metrics": {"bleu_score": 28.63424630911014, "chrf_score": 67.89432488876608, "xcomet_score": 0.9503780603408813, "xcomet_qe_score": 0.9553557634353638, "metricx_score": 2.1219253540039062, "metricx_qe_score": 2.2803165912628174, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Notre expérience montre que la méthode proposée a produit des pistes moins bruyantes à une couverture plus élevée que les valeurs de référence.", "metrics": {"bleu_score": 45.66337854967315, "chrf_score": 67.97859207166468, "xcomet_score": 0.5938452482223511, "xcomet_qe_score": 0.591198205947876, "metricx_score": 6.393024444580078, "metricx_qe_score": 5.310923099517822, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez vérifier le code pour l'onglet d'audit du désert.", "metrics": {"bleu_score": 4.990049701936832, "chrf_score": 25.22075865204808, "xcomet_score": 0.11923462897539139, "xcomet_qe_score": 0.11578811705112457, "metricx_score": 12.262234687805176, "metricx_qe_score": 13.260802268981934, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10382990539073944, "metricx_qe_score": 0.4022793173789978, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Asaf Harari.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 83.1845583109951, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14045611023902893, "metricx_qe_score": 0.1951381266117096, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "et je présenterai notre article « Enrichissement de données tabulaires en quelques tirs en utilisant des architectures de transformateurs affinés ».", "metrics": {"bleu_score": 21.79301929852717, "chrf_score": 71.27028525154088, "xcomet_score": 0.7096900939941406, "xcomet_qe_score": 0.7143040895462036, "metricx_score": 4.827413558959961, "metricx_qe_score": 4.934776306152344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "C'est ainsi que les scientifiques analysent les données et se concentrent principalement sur la manipulation des caractéristiques existantes des données.", "metrics": {"bleu_score": 65.77160909911663, "chrf_score": 87.5476856033268, "xcomet_score": 0.7937742471694946, "xcomet_qe_score": 0.850911021232605, "metricx_score": 3.186272382736206, "metricx_qe_score": 3.85183048248291, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "mais parfois ces fonctionnalités sont limitées.", "metrics": {"bleu_score": 24.0785655451027, "chrf_score": 76.94819920746691, "xcomet_score": 0.9686001539230347, "xcomet_qe_score": 0.9744012951850891, "metricx_score": 0.21747228503227234, "metricx_qe_score": 0.22584828734397888, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "La génération de caractéristiques à partir d'une autre source de données peut ajouter une information substantielle.", "metrics": {"bleu_score": 37.709297891717654, "chrf_score": 69.01112048538039, "xcomet_score": 0.9180338382720947, "xcomet_qe_score": 0.9985805749893188, "metricx_score": 2.1714093685150146, "metricx_qe_score": 2.2942323684692383, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique de données tabulaires à l'aide de textes libres provenant de sources externes.", "metrics": {"bleu_score": 61.50523394042868, "chrf_score": 86.07454513632908, "xcomet_score": 0.9993120431900024, "xcomet_qe_score": 0.9955283403396606, "metricx_score": 0.6056214570999146, "metricx_qe_score": 0.7470424175262451, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Supposons que nous disposions d'un jeu de données tabulaire et d'une base de connaissances.", "metrics": {"bleu_score": 25.33654946448646, "chrf_score": 76.35941311948622, "xcomet_score": 0.9820908308029175, "xcomet_qe_score": 0.9741435050964355, "metricx_score": 0.848091721534729, "metricx_qe_score": 0.8073315024375916, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique qui intègre la liaison d'entités et l'analyse de texte pour extraire de nouvelles caractéristiques du texte libre de la base de connaissances.", "metrics": {"bleu_score": 80.96427216101601, "chrf_score": 88.36399971836985, "xcomet_score": 0.9642341136932373, "xcomet_qe_score": 0.9623830318450928, "metricx_score": 1.5087428092956543, "metricx_qe_score": 1.347353219985962, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre premier est exactement ce processus automatique.", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 84.02688189484688, "xcomet_score": 0.6334525346755981, "xcomet_qe_score": 0.6716132760047913, "metricx_score": 7.8165130615234375, "metricx_qe_score": 9.222997665405273, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple dans les ensembles de données alimentant FAST.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 44.17439878291417, "xcomet_score": 0.5318969488143921, "xcomet_qe_score": 0.6904699802398682, "metricx_score": 6.954460144042969, "metricx_qe_score": 7.893301010131836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le jeu de données est un jeu de données universitaire.", "metrics": {"bleu_score": 18.92240568795936, "chrf_score": 71.44394706558398, "xcomet_score": 0.9318212270736694, "xcomet_qe_score": 0.8916794657707214, "metricx_score": 0.7501013278961182, "metricx_qe_score": 0.731359601020813, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque son objectif est de classer les universités en universités mal classées et en universités bien classées.", "metrics": {"bleu_score": 38.95496694796876, "chrf_score": 67.37857203504288, "xcomet_score": 0.940272331237793, "xcomet_qe_score": 0.9685112833976746, "metricx_score": 2.191500663757324, "metricx_qe_score": 1.6604588031768799, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que base de connaissances, nous utilisons Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.37776264548301697, "metricx_qe_score": 0.43033844232559204, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase de FAST est la liaison d'entités.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 85.6985538876924, "xcomet_score": 0.6527090072631836, "xcomet_qe_score": 0.7127736806869507, "metricx_score": 5.735062122344971, "metricx_qe_score": 6.3583831787109375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque chaque entité, dans cet exemple le nom de l'université, est liée à une entité au sein de la base de connaissances.", "metrics": {"bleu_score": 85.46472208904508, "chrf_score": 95.63881225733785, "xcomet_score": 0.9727706909179688, "xcomet_qe_score": 0.9449424147605896, "metricx_score": 0.7676472067832947, "metricx_qe_score": 0.949158787727356, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "et le texte des entités de la base de connaissances est extrait et ajouté à l'ensemble de données.", "metrics": {"bleu_score": 69.29598487720368, "chrf_score": 87.87759123062597, "xcomet_score": 0.9580652713775635, "xcomet_qe_score": 0.922889232635498, "metricx_score": 1.268217921257019, "metricx_qe_score": 2.4010138511657715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le texte est l'abstract de la page Wikipédia.", "metrics": {"bleu_score": 70.4805090506219, "chrf_score": 80.25615613463867, "xcomet_score": 0.9735019207000732, "xcomet_qe_score": 1.0, "metricx_score": 2.88716983795166, "metricx_qe_score": 1.020815372467041, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Maintenant, nous devons générer ou extraire des caractéristiques à partir du texte récupéré.", "metrics": {"bleu_score": 66.06328636027618, "chrf_score": 74.38270866226682, "xcomet_score": 0.9849499464035034, "xcomet_qe_score": 1.0, "metricx_score": 2.2474172115325928, "metricx_qe_score": 1.7546055316925049, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'une phase d'extraction de caractéristiques qui inclut l'analyse de texte.", "metrics": {"bleu_score": 22.549907910826683, "chrf_score": 59.53483088783664, "xcomet_score": 0.9899022579193115, "xcomet_qe_score": 0.9816310405731201, "metricx_score": 4.072230339050293, "metricx_qe_score": 4.159135818481445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est là la principale nouveauté de cet article, et j'y reviendrai en détail dans les diapositives suivantes.", "metrics": {"bleu_score": 28.72797668292002, "chrf_score": 56.25777934856654, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3048774003982544, "metricx_qe_score": 0.3767305016517639, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction des caractéristiques, il y a une phase de génération de caractéristiques durant laquelle nous utilisons les caractéristiques extraites pour générer un petit nombre de nouvelles caractéristiques.", "metrics": {"bleu_score": 61.14887872946488, "chrf_score": 69.15063741560739, "xcomet_score": 0.9688011407852173, "xcomet_qe_score": 0.9981883764266968, "metricx_score": 2.111966848373413, "metricx_qe_score": 0.9248752593994141, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "générez d'abord des caractéristiques en fonction du nombre de classes du jeu de données d'origine.", "metrics": {"bleu_score": 16.451929399933114, "chrf_score": 67.92422513854012, "xcomet_score": 0.8124605417251587, "xcomet_qe_score": 0.7672670483589172, "metricx_score": 4.259880542755127, "metricx_qe_score": 3.2091941833496094, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le jeu de données original possède deux classes.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 67.70436694018464, "xcomet_score": 0.983077883720398, "xcomet_qe_score": 0.9392397999763489, "metricx_score": 1.2739492654800415, "metricx_qe_score": 1.855926275253296, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, FAST génère deux nouvelles caractéristiques.", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 52.18615998266372, "xcomet_score": 0.7941197752952576, "xcomet_qe_score": 0.823189377784729, "metricx_score": 7.081693172454834, "metricx_qe_score": 6.879763603210449, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, si le jeu de données comporte cinq classes, générez d'abord cinq nouvelles caractéristiques.", "metrics": {"bleu_score": 12.03921753741131, "chrf_score": 46.71262427836081, "xcomet_score": 0.31183648109436035, "xcomet_qe_score": 0.23353345692157745, "metricx_score": 8.351090431213379, "metricx_qe_score": 7.579161643981934, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque caractéristique représente la probabilité pour chaque classe.", "metrics": {"bleu_score": 75.06238537503395, "chrf_score": 78.89231057183392, "xcomet_score": 0.9665066003799438, "xcomet_qe_score": 1.0, "metricx_score": 1.271324634552002, "metricx_qe_score": 1.2625250816345215, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état actuel de l'art en matière d'analyse de texte, à savoir les modèles linguistiques basés sur des transformateurs tels que BERT, GPT, XNL, et autres.", "metrics": {"bleu_score": 26.724353604317542, "chrf_score": 55.240131431688496, "xcomet_score": 0.7266752123832703, "xcomet_qe_score": 0.8225573301315308, "metricx_score": 1.9811257123947144, "metricx_qe_score": 1.6443815231323242, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "mais il est peu probable que nous puissions entraîner un modèle linguistique à l'aide des jeux de données d'entrée.", "metrics": {"bleu_score": 32.64128346656048, "chrf_score": 55.7460034129885, "xcomet_score": 0.7945720553398132, "xcomet_qe_score": 0.8433791399002075, "metricx_score": 3.2209274768829346, "metricx_qe_score": 2.5025174617767334, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Une approche naïve sera donc une affinage de tâche ciblée.", "metrics": {"bleu_score": 14.375752314440927, "chrf_score": 55.29606836301358, "xcomet_score": 0.7702250480651855, "xcomet_qe_score": 0.7442228198051453, "metricx_score": 6.156423568725586, "metricx_qe_score": 6.838936805725098, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, lors de la phase d'extraction future, nous pouvons télécharger le modèle de langage peritrain, affiner le modèle de langage sur l'ensemble de données cible,", "metrics": {"bleu_score": 15.89651999211257, "chrf_score": 62.45404031289171, "xcomet_score": 0.553997278213501, "xcomet_qe_score": 0.5656371116638184, "metricx_score": 8.394530296325684, "metricx_qe_score": 7.884531497955322, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, pour affiner le modèle linguistique, on classe le texte en catégories, on l'abstrait en catégories, basses ou élevées.", "metrics": {"bleu_score": 19.435887726571906, "chrf_score": 55.255750723090635, "xcomet_score": 0.749521017074585, "xcomet_qe_score": 0.7021795511245728, "metricx_score": 4.627949237823486, "metricx_qe_score": 6.310476303100586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "recevoir la sortie du modèle de langage, qui est la probabilité pour chaque classe, et l'utiliser comme nouvelles caractéristiques.", "metrics": {"bleu_score": 26.728255206224986, "chrf_score": 66.09563887648686, "xcomet_score": 0.8602376580238342, "xcomet_qe_score": 0.8360263109207153, "metricx_score": 4.595983982086182, "metricx_qe_score": 3.682541847229004, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que le jeu de données peut contenir peu d'étiquettes d'entités distinctes.", "metrics": {"bleu_score": 29.963847019163083, "chrf_score": 69.84153656975558, "xcomet_score": 0.7417778968811035, "xcomet_qe_score": 0.7268737554550171, "metricx_score": 4.221433639526367, "metricx_qe_score": 4.6823320388793945, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, près de la moitié des ensembles de données contiennent moins de 400 échantillons, et le plus petit ensemble de données comprend 35 échantillons dans son ensemble d'entraînement.", "metrics": {"bleu_score": 36.80356839346386, "chrf_score": 66.80341612256568, "xcomet_score": 0.9251400232315063, "xcomet_qe_score": 0.9281143546104431, "metricx_score": 1.4545719623565674, "metricx_qe_score": 1.1972683668136597, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Aussi, affiner un modèle linguistique sur cet ensemble de données serait inefficace.", "metrics": {"bleu_score": 6.734395444347337, "chrf_score": 54.83351965298042, "xcomet_score": 0.9828609228134155, "xcomet_qe_score": 0.993891716003418, "metricx_score": 1.5055766105651855, "metricx_qe_score": 1.325007677078247, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "mais nous pouvons exploiter les connaissances préalables sur des ensembles de données préanalysées,", "metrics": {"bleu_score": 24.022110864391543, "chrf_score": 77.91817169162816, "xcomet_score": 0.9858936071395874, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.9012131690979004, "metricx_qe_score": 0.929633617401123, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "puisque nous appliquons la méthode FAST sur plusieurs ensembles de données, nous pouvons utiliser les N-1 ensembles de données pour recueillir des informations sur ces N-1 ensembles et exploiter ces informations lors de l'analyse du Nième ensemble de données.", "metrics": {"bleu_score": 21.58914621804856, "chrf_score": 60.18789803148671, "xcomet_score": 0.5359185934066772, "xcomet_qe_score": 0.609285831451416, "metricx_score": 4.680673122406006, "metricx_qe_score": 4.56749153137207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "Ce que nous suggérons, c'est d'ajouter une autre phase de réglage fin.", "metrics": {"bleu_score": 77.4403141014203, "chrf_score": 83.66255173202686, "xcomet_score": 0.9029428958892822, "xcomet_qe_score": 0.830672025680542, "metricx_score": 2.539712905883789, "metricx_qe_score": 2.851675033569336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "une phase préliminaire d'ajustement fin multitâche.", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 62.90491949323956, "xcomet_score": 0.9074496030807495, "xcomet_qe_score": 0.9253992438316345, "metricx_score": 4.255540370941162, "metricx_qe_score": 4.0610222816467285, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque vous affinez le modèle linguistique sur N-1 jeux de données,", "metrics": {"bleu_score": 7.545339613823573, "chrf_score": 54.01281449656117, "xcomet_score": 0.8932218551635742, "xcomet_qe_score": 0.9185634851455688, "metricx_score": 3.944619655609131, "metricx_qe_score": 3.07958984375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "puis nous exécutons une autre phase d'ajustement fin, qui est un ajustement fin par tâche cible, lorsque nous ajustons le modèle linguistique sur le n-ième jeu de données cible.", "metrics": {"bleu_score": 29.066145742597676, "chrf_score": 60.844999638584284, "xcomet_score": 0.7034206390380859, "xcomet_qe_score": 0.7031364440917969, "metricx_score": 6.150094509124756, "metricx_qe_score": 6.373996734619141, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "l'état de l'art dans l'ajustement fin multitâche appelé DNN vide.", "metrics": {"bleu_score": 5.300156689756295, "chrf_score": 41.34765940308567, "xcomet_score": 0.3270304799079895, "xcomet_qe_score": 0.29744604229927063, "metricx_score": 12.4638032913208, "metricx_qe_score": 12.395687103271484, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "Dans MTDNN, MTDNN conserve des têtes au nombre de tâches dans l'ensemble d'entraînement.", "metrics": {"bleu_score": 27.668736912821906, "chrf_score": 55.67679481232949, "xcomet_score": 0.4997149109840393, "xcomet_qe_score": 0.570670485496521, "metricx_score": 12.783002853393555, "metricx_qe_score": 12.358242988586426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, il y a quatre tâches dans l'ensemble d'entraînement. Donc, DNN vide, conservez quatre têtes, comme vous pouvez le voir sur l'image.", "metrics": {"bleu_score": 57.02524287955773, "chrf_score": 70.99047019207715, "xcomet_score": 0.4515528678894043, "xcomet_qe_score": 0.40020495653152466, "metricx_score": 11.268450736999512, "metricx_qe_score": 11.937691688537598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "et il extrait un lot aléatoire à partir de l'ensemble d'entraînement.", "metrics": {"bleu_score": 17.242221289766636, "chrf_score": 48.020721100370466, "xcomet_score": 0.6369655728340149, "xcomet_qe_score": 0.5057425498962402, "metricx_score": 4.417791366577148, "metricx_qe_score": 4.331109523773193, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot aléatoire appartient, par exemple, à des tâches de classification de phrases uniques, il exécute une passe avant et arrière à travers la première tête.", "metrics": {"bleu_score": 36.24361526582361, "chrf_score": 63.222756369896146, "xcomet_score": 0.6916722655296326, "xcomet_qe_score": 0.5925673246383667, "metricx_score": 6.321221828460693, "metricx_qe_score": 6.417605876922607, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Si le lot aléatoire appartient à la tâche de classement par paires, il effectue une passe avant et arrière à travers la dernière tête.", "metrics": {"bleu_score": 47.114811355950046, "chrf_score": 66.45167082601542, "xcomet_score": 0.7499496936798096, "xcomet_qe_score": 0.699907660484314, "metricx_score": 4.914085388183594, "metricx_qe_score": 5.4626054763793945, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, un jeu de données tabulaire déterminera le nombre de classes.", "metrics": {"bleu_score": 42.311785416105785, "chrf_score": 70.41571487467587, "xcomet_score": 0.8430848717689514, "xcomet_qe_score": 0.7373001575469971, "metricx_score": 5.579014778137207, "metricx_qe_score": 6.169387340545654, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a donc de nombreuses tâches à accomplir.", "metrics": {"bleu_score": 30.213753973567687, "chrf_score": 42.71790396639174, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5729197263717651, "metricx_qe_score": 0.5493391752243042, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "mtDNN maintient le nombre de têtes de classes, les couches de sortie,", "metrics": {"bleu_score": 20.752617988236555, "chrf_score": 61.42801287246969, "xcomet_score": 0.5600862503051758, "xcomet_qe_score": 0.45302361249923706, "metricx_score": 8.214519500732422, "metricx_qe_score": 6.945384979248047, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, emptyDNA doit initialiser de nouvelles têtes pour un nouveau jeu de données avec une nouvelle tâche.", "metrics": {"bleu_score": 49.030470692026626, "chrf_score": 70.86673744230802, "xcomet_score": 0.4971635043621063, "xcomet_qe_score": 0.4540475308895111, "metricx_score": 8.346831321716309, "metricx_qe_score": 10.817550659179688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche, appelée reformulation de tâche et accord fin, consiste, au lieu de maintenir plusieurs têtes, à reformuler chaque jeu de données en une phrase par problème de classification, ce qui correspond à des tâches à deux classes.", "metrics": {"bleu_score": 34.49506874882265, "chrf_score": 61.13087044907448, "xcomet_score": 0.5106926560401917, "xcomet_qe_score": 0.44443684816360474, "metricx_score": 8.458501815795898, "metricx_qe_score": 9.340601921081543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple.", "metrics": {"bleu_score": 46.30777161991026, "chrf_score": 48.32474847235818, "xcomet_score": 0.9386066198348999, "xcomet_qe_score": 0.9773107767105103, "metricx_score": 0.2514381408691406, "metricx_qe_score": 0.34026220440864563, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre jeu de données d'entrée, qui se compose d'entités, de caractéristiques, de texte et de classes.", "metrics": {"bleu_score": 38.75407750115177, "chrf_score": 64.35493576103265, "xcomet_score": 0.9333823323249817, "xcomet_qe_score": 0.9541884660720825, "metricx_score": 1.9032740592956543, "metricx_qe_score": 2.3668551445007324, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous reformulons la tâche, passant de la classification du texte en bas et haut, à la classification du texte, de l'abstrait et de la classe en vrai ou faux.", "metrics": {"bleu_score": 40.19046405329026, "chrf_score": 63.610529662105066, "xcomet_score": 0.6706863641738892, "xcomet_qe_score": 0.6560543775558472, "metricx_score": 4.036093711853027, "metricx_qe_score": 3.753934144973755, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous entraînons le modèle linguistique à classer les concepts abstraits et à déterminer, pour un concept abstrait donné, s'il appartient ou non à une classe spécifique.", "metrics": {"bleu_score": 5.262081568670928, "chrf_score": 39.017981412869624, "xcomet_score": 0.48934850096702576, "xcomet_qe_score": 0.4103388488292694, "metricx_score": 4.595658302307129, "metricx_qe_score": 6.766275405883789, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce cas, le vecteur étiquette reste toujours composé de deux classes.", "metrics": {"bleu_score": 36.6192636299943, "chrf_score": 67.30536270689946, "xcomet_score": 0.9543650150299072, "xcomet_qe_score": 0.9400254487991333, "metricx_score": 4.195050239562988, "metricx_qe_score": 6.4653425216674805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici l'algorithme de notre approche de réglage fin reformulée.", "metrics": {"bleu_score": 9.596928383261213, "chrf_score": 48.81723885164494, "xcomet_score": 0.9569264650344849, "xcomet_qe_score": 0.9744162559509277, "metricx_score": 6.84535551071167, "metricx_qe_score": 7.320859909057617, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons donc le cadre complet.", "metrics": {"bleu_score": 53.7284965911771, "chrf_score": 81.9759249161167, "xcomet_score": 0.9789191484451294, "xcomet_qe_score": 0.9587022066116333, "metricx_score": 1.1847355365753174, "metricx_qe_score": 3.205934524536133, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "Cela a déclenché une action rapide de la Fed.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 10.86968475439796, "xcomet_score": 0.13074153661727905, "xcomet_qe_score": 0.1029864028096199, "metricx_score": 18.29229736328125, "metricx_qe_score": 19.518831253051758, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "puis une phase d'exécution rapide de liaison d'entités", "metrics": {"bleu_score": 19.493995755254467, "chrf_score": 60.343862010231305, "xcomet_score": 0.4648198187351227, "xcomet_qe_score": 0.7518779635429382, "metricx_score": 9.096121788024902, "metricx_qe_score": 9.448729515075684, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "il extrait le texte de la base de connaissances, qui dans cet exemple est le résumé de la page Wikipédia.", "metrics": {"bleu_score": 95.10699415570296, "chrf_score": 98.8018938583582, "xcomet_score": 0.9654701948165894, "xcomet_qe_score": 0.9213699698448181, "metricx_score": 2.0358121395111084, "metricx_qe_score": 3.023637056350708, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "Puis, reformulez la tâche en une phrase par type de tâche de classification.", "metrics": {"bleu_score": 22.765694864430497, "chrf_score": 60.02879027547934, "xcomet_score": 0.17178061604499817, "xcomet_qe_score": 0.20489253103733063, "metricx_score": 13.81364631652832, "metricx_qe_score": 10.579093933105469, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "a appliqué le modèle linguistique à la nouvelle tâche et a calculé la probabilité de sortie pour chaque classe,", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 82.28848546209218, "xcomet_score": 0.5752702951431274, "xcomet_qe_score": 0.5779235363006592, "metricx_score": 2.807011365890503, "metricx_qe_score": 3.905904531478882, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que le modèle linguistique est déjà affiné sur l'ensemble de données N-1 à l'aide d'un affinage multitâche préliminaire.", "metrics": {"bleu_score": 9.856825562461765, "chrf_score": 50.07671659316316, "xcomet_score": 0.8324085474014282, "xcomet_qe_score": 0.7527263164520264, "metricx_score": 2.79549503326416, "metricx_qe_score": 2.9969098567962646, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous utilisons le vecteur de sortie du modèle linguistique en tant que nouvelle caractéristique générée dans le nombre de classes.", "metrics": {"bleu_score": 64.3604545490784, "chrf_score": 72.82942871306652, "xcomet_score": 0.8950217962265015, "xcomet_qe_score": 0.8771193623542786, "metricx_score": 3.722079277038574, "metricx_qe_score": 5.193233013153076, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un ensemble de données de classification tabulaire de 17 éléments, qui vérifie la taille, les caractéristiques, l'équilibre, le domaine et les performances initiales.", "metrics": {"bleu_score": 24.21409359743987, "chrf_score": 68.5368556746638, "xcomet_score": 0.6243096590042114, "xcomet_qe_score": 0.5405977964401245, "metricx_score": 3.9627482891082764, "metricx_qe_score": 4.569671630859375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "Et en tant que base de connaissances, nous utilisons Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.45528608560562134, "metricx_qe_score": 0.5316935777664185, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concevons notre expérience comme une évaluation en temps réel lors de l'entraînement rapide sur 16 ensembles de données et de son application au 17e ensemble de données.", "metrics": {"bleu_score": 22.798532589809895, "chrf_score": 55.45923268726766, "xcomet_score": 0.2713313698768616, "xcomet_qe_score": 0.2995569407939911, "metricx_score": 6.577378273010254, "metricx_qe_score": 6.663930892944336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "Nous divisons également chaque ensemble de données en quatre sous-ensembles et appliquons une validation croisée à quatre folds.", "metrics": {"bleu_score": 36.658827296012404, "chrf_score": 76.51418057271586, "xcomet_score": 0.7692850828170776, "xcomet_qe_score": 0.8146083950996399, "metricx_score": 6.107127666473389, "metricx_qe_score": 7.998240947723389, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous générons la nouvelle caractéristique et les évaluons à l'aide de cinq classifieurs d'évaluation.", "metrics": {"bleu_score": 23.693055763743093, "chrf_score": 65.17266127520178, "xcomet_score": 0.8220556974411011, "xcomet_qe_score": 0.8390675187110901, "metricx_score": 3.7473037242889404, "metricx_qe_score": 4.000733375549316, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "nous utilisons dans notre expérience une architecture basée sur BERT.", "metrics": {"bleu_score": 4.80771397503766, "chrf_score": 35.23441124689296, "xcomet_score": 0.4144206941127777, "xcomet_qe_score": 0.9463324546813965, "metricx_score": 5.0431976318359375, "metricx_qe_score": 2.022500991821289, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre expérience.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 82.16212638893361, "xcomet_score": 0.9823514223098755, "xcomet_qe_score": 0.9937252998352051, "metricx_score": 0.3568568527698517, "metricx_qe_score": 0.5269936919212341, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez constater que nous comparons notre cadre à l'ajustement fin sur l'ensemble de données cible, à l'ajustement fin sur la tâche cible, et à l'ajustement préliminaire du MTDNN.", "metrics": {"bleu_score": 19.685367150072832, "chrf_score": 60.22449304844996, "xcomet_score": 0.8492729663848877, "xcomet_qe_score": 0.7311034798622131, "metricx_score": 5.197943687438965, "metricx_qe_score": 4.873676776885986, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "et notre recalibrage reformulé atteint le meilleur résultat, la meilleure performance.", "metrics": {"bleu_score": 50.934984129906766, "chrf_score": 77.44946044238024, "xcomet_score": 0.8507115840911865, "xcomet_qe_score": 0.8988184928894043, "metricx_score": 2.156466484069824, "metricx_qe_score": 1.6812618970870972, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "tout en étant vide, il a atteint une amélioration de deux pour cent par rapport à l'ensemble de données cible, grâce à un réglage fin.", "metrics": {"bleu_score": 26.184495272448316, "chrf_score": 56.84483873437244, "xcomet_score": 0.15222609043121338, "xcomet_qe_score": 0.14282773435115814, "metricx_score": 14.06965446472168, "metricx_qe_score": 13.153197288513184, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "notre approche a permis une amélioration de 6 %.", "metrics": {"bleu_score": 18.60045401920258, "chrf_score": 58.189967586979705, "xcomet_score": 0.9715737104415894, "xcomet_qe_score": 0.9753538966178894, "metricx_score": 1.3482437133789062, "metricx_qe_score": 1.7589399814605713, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous examinons le petit jeu de données, nous constatons que les performances de mtDNN diminuent et que l'amélioration de la phase de réglage multitâche préliminaire se réduit à 1,5 pour cent.", "metrics": {"bleu_score": 20.3264842568494, "chrf_score": 58.341026502550875, "xcomet_score": 0.8300870656967163, "xcomet_qe_score": 0.768913984298706, "metricx_score": 3.776505947113037, "metricx_qe_score": 3.6501028537750244, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "mais nos performances ont augmenté de 11 % par rapport au simple réglage fin de la tâche cible.", "metrics": {"bleu_score": 5.32864224277779, "chrf_score": 40.834106815156844, "xcomet_score": 0.8400317430496216, "xcomet_qe_score": 0.7524071931838989, "metricx_score": 4.81402587890625, "metricx_qe_score": 4.261390209197998, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "Pour la somme, FAST permet un enrichissement en quelques tirs à partir de 35 échantillons dans notre expérience.", "metrics": {"bleu_score": 28.129148710958383, "chrf_score": 64.64654579660291, "xcomet_score": 0.3676927089691162, "xcomet_qe_score": 0.385023832321167, "metricx_score": 7.1477484703063965, "metricx_qe_score": 6.852819919586182, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "Il utilise une seule architecture pour tous les ensembles de données de tâches.", "metrics": {"bleu_score": 15.396503757846457, "chrf_score": 70.79872160547829, "xcomet_score": 0.98985356092453, "xcomet_qe_score": 0.9897725582122803, "metricx_score": 3.47694730758667, "metricx_qe_score": 3.310617208480835, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "Et il conserve la tête du modèle.", "metrics": {"bleu_score": 59.4603557501361, "chrf_score": 68.60498861472179, "xcomet_score": 0.9025007486343384, "xcomet_qe_score": 0.6470153331756592, "metricx_score": 3.7993338108062744, "metricx_qe_score": 6.2746782302856445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "mais cela ajoute une phase de reformulation.", "metrics": {"bleu_score": 84.08964152537145, "chrf_score": 97.17655303568617, "xcomet_score": 0.9731879234313965, "xcomet_qe_score": 0.9625337719917297, "metricx_score": 1.321225643157959, "metricx_qe_score": 2.584629774093628, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "son ensemble de trains augmenté et ses besoins, une valeur cible ayant un sens sémantique afin de pouvoir l'intégrer au modèle linguistique et l'utiliser dans la phrase selon le problème de classification.", "metrics": {"bleu_score": 17.882676493720624, "chrf_score": 59.229440501469554, "xcomet_score": 0.4254359006881714, "xcomet_qe_score": 0.4426272213459015, "metricx_score": 12.227463722229004, "metricx_qe_score": 12.366607666015625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Merci.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10382990539073944, "metricx_qe_score": 0.4022793173789978, "linguapy_score": [1, "ITALIAN"]}}
