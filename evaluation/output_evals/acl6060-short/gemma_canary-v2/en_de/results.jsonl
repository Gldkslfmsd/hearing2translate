{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Heute werde ich unsere Forschungsarbeit „Learning to Reason Deductively: Network Problem Solving as Complex Reasoning Extraction“ vorstellen.", "metrics": {"bleu_score": 53.79942002865989, "chrf_score": 82.93898279203242, "xcomet_score": 0.7666513919830322, "xcomet_qe_score": 0.8269264698028564, "metricx_score": 5.85103702545166, "metricx_qe_score": 5.3677077293396, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan vom KI-Labor von Biden und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas at Austin und Wayloo von SUDD.", "metrics": {"bleu_score": 35.92667191896008, "chrf_score": 64.73024114389084, "xcomet_score": 0.4889960289001465, "xcomet_qe_score": 0.492969274520874, "metricx_score": 9.948504447937012, "metricx_qe_score": 10.185702323913574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für Schlussfolgerungen sprechen.", "metrics": {"bleu_score": 63.981667416455416, "chrf_score": 74.82616881775952, "xcomet_score": 0.9902213215827942, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.5521533489227295, "metricx_qe_score": 1.7070937156677246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Schlussfolgern hilfreich ist.", "metrics": {"bleu_score": 16.21599014882373, "chrf_score": 54.7106146615, "xcomet_score": 0.9961855411529541, "xcomet_qe_score": 0.9882590770721436, "metricx_score": 0.7842031121253967, "metricx_qe_score": 0.5612658262252808, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung stammt aus dem PALM-Paper, in dem Promptings eingesetzt werden, um das Mathwork-Problem in einem Fusion-Learning-Szenario zu lösen.", "metrics": {"bleu_score": 33.11822752222957, "chrf_score": 64.86567240106126, "xcomet_score": 0.7159070372581482, "xcomet_qe_score": 0.744430661201477, "metricx_score": 5.958602428436279, "metricx_qe_score": 6.02423095703125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite, wenn wir einige Beispiele mit reinen Fragen und Antworten geben, können wir möglicherweise nicht die korrekten Antworten erhalten.", "metrics": {"bleu_score": 6.82168175817843, "chrf_score": 51.771018479051, "xcomet_score": 0.9572085738182068, "xcomet_qe_score": 0.9518412351608276, "metricx_score": 1.2207475900650024, "metricx_qe_score": 1.075688123703003, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir eine detailliertere Begründungsbeschreibung liefern, ist das Modell in der Lage, die Begründungsbeschreibung vorherzusagen und hier ebenfalls eine korrekte Vorhersage zu treffen.", "metrics": {"bleu_score": 52.664038784792645, "chrf_score": 64.56486245828728, "xcomet_score": 0.9968271255493164, "xcomet_qe_score": 1.0, "metricx_score": 0.5195226669311523, "metricx_qe_score": 0.915438711643219, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Da ist es daher gut, interpretierbare, mehrstufige Schlussfolgerungen als Ergebnis zu erhalten.", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 53.77832986952408, "xcomet_score": 0.9901835918426514, "xcomet_qe_score": 0.9864438772201538, "metricx_score": 1.135738492012024, "metricx_qe_score": 0.9193433523178101, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind auch der Ansicht, dass die Bearbeitung von Mathematikaufgaben eine unkomplizierte Anwendung darstellt, um solche Denkfähigkeiten zu evaluieren.", "metrics": {"bleu_score": 9.38687499151236, "chrf_score": 42.1589218013503, "xcomet_score": 0.9372318387031555, "xcomet_qe_score": 0.9875853061676025, "metricx_score": 0.8376214504241943, "metricx_qe_score": 1.0904216766357422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier in unserem Problemaufbau, unter Berücksichtigung der Fragen, müssen wir diese Frage lösen und die numerischen Antworten ermitteln.", "metrics": {"bleu_score": 34.68941568986593, "chrf_score": 68.06078564097137, "xcomet_score": 0.9692707657814026, "xcomet_qe_score": 0.9401687383651733, "metricx_score": 0.6461732387542725, "metricx_qe_score": 0.5225262641906738, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck gegeben, der zu dieser spezifischen Antwort führt.", "metrics": {"bleu_score": 17.01668259220275, "chrf_score": 65.93488383993986, "xcomet_score": 0.9701188802719116, "xcomet_qe_score": 0.9810088872909546, "metricx_score": 1.865307331085205, "metricx_qe_score": 2.960777759552002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Auch bestimmte Annahmen gelten daher wie in vorangegangener Arbeit.", "metrics": {"bleu_score": 10.753659580649467, "chrf_score": 49.26189390663331, "xcomet_score": 0.9998539686203003, "xcomet_qe_score": 1.0, "metricx_score": 1.2657629251480103, "metricx_qe_score": 1.252879023551941, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass die Genauigkeit der Größen bekannt ist.", "metrics": {"bleu_score": 40.17682558797496, "chrf_score": 63.075622805904494, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0996805429458618, "metricx_qe_score": 0.5371986627578735, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten dabei lediglich grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Potenzierung.", "metrics": {"bleu_score": 66.54377827941899, "chrf_score": 79.35249856143817, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.23488393425941467, "metricx_qe_score": 0.22034615278244019, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplexe Operatoren tatsächlich in diese grundlegenden Operatoren zerlegt werden.", "metrics": {"bleu_score": 22.62944003945279, "chrf_score": 73.75403468285792, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.32362839579582214, "metricx_qe_score": 0.37450793385505676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Die bisherige Arbeit im Bereich der methodischen Problemlösung lässt sich also in sequenz-zu-sequenz- und sequenz-zu-baum-Modelle einteilen.", "metrics": {"bleu_score": 11.64394847706997, "chrf_score": 51.04676366600751, "xcomet_score": 0.8663758039474487, "xcomet_qe_score": 0.8673856258392334, "metricx_score": 4.034867763519287, "metricx_qe_score": 4.3640828132629395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Da konvertiert ein traditionelles Sequence-to-Sequence-Modell die Expression in eine spezifische Sequenz zur Generierung.", "metrics": {"bleu_score": 17.725925674502374, "chrf_score": 54.57732433166515, "xcomet_score": 0.8761008381843567, "xcomet_qe_score": 0.9161547422409058, "metricx_score": 2.2938733100891113, "metricx_qe_score": 1.3581264019012451, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist recht einfach zu implementieren, und es kann auf viele verschiedene, komplexe Probleme verallgemeinert werden.", "metrics": {"bleu_score": 20.76047003130265, "chrf_score": 69.89259545412182, "xcomet_score": 0.9969620704650879, "xcomet_qe_score": 0.9928725957870483, "metricx_score": 0.1479509025812149, "metricx_qe_score": 0.21216891705989838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Nachteile sind, dass die Leistung tatsächlich meistens nicht besser ist als bei dem Strukturmodell, und es fehlt die Interpretierbarkeit für die Vorhersagen.", "metrics": {"bleu_score": 22.544215811932585, "chrf_score": 59.19495576707586, "xcomet_score": 0.982040286064148, "xcomet_qe_score": 0.9831024408340454, "metricx_score": 0.6202847361564636, "metricx_qe_score": 0.6469229459762573, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber tatsächlich ist diese Richtung dank des Transformer-Modells immer noch recht populär.", "metrics": {"bleu_score": 21.401603033752966, "chrf_score": 61.174919527593694, "xcomet_score": 0.9939911365509033, "xcomet_qe_score": 0.989454984664917, "metricx_score": 0.8818853497505188, "metricx_qe_score": 1.6735292673110962, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumartigen Modellen strukturieren wir diese Ausdrücke also in einer Baumform und verwenden bei der Baumgenerierung eine vorordnungs-Traversierung.", "metrics": {"bleu_score": 23.83041256525615, "chrf_score": 62.057140640530896, "xcomet_score": 0.8717978596687317, "xcomet_qe_score": 0.8636056184768677, "metricx_score": 3.371371269226074, "metricx_qe_score": 4.367401123046875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir weiterhin die Operatoren, bis wir die Blätter erreichen, welche die Größen darstellen.", "metrics": {"bleu_score": 34.04550327704256, "chrf_score": 66.46433864905553, "xcomet_score": 0.9948059320449829, "xcomet_qe_score": 0.9828276634216309, "metricx_score": 1.0681389570236206, "metricx_qe_score": 1.132956624031067, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist also der Vorteil, dass es tatsächlich diese binäre Baumstruktur liefert. Aber es ist eigentlich recht kontraintuitiv, da wir zuerst den Operator generieren und dann am Ende die Mengen.", "metrics": {"bleu_score": 29.44972018039, "chrf_score": 63.21898676915963, "xcomet_score": 0.9602541923522949, "xcomet_qe_score": 0.9445973634719849, "metricx_score": 2.4293863773345947, "metricx_qe_score": 3.3897788524627686, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und das zweite Problem ist, dass es auch einige redundante Berechnungen beinhaltet.", "metrics": {"bleu_score": 6.754312828675707, "chrf_score": 42.07233238963647, "xcomet_score": 0.9664793610572815, "xcomet_qe_score": 0.9869635105133057, "metricx_score": 0.5153752565383911, "metricx_qe_score": 0.3656591475009918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck ansehen, ergibt acht mal drei plus drei tatsächlich zweimal. Wir sollten die Ergebnisse jedoch eigentlich wiederverwenden.", "metrics": {"bleu_score": 32.65250726249787, "chrf_score": 65.5741077446661, "xcomet_score": 0.9639729261398315, "xcomet_qe_score": 0.9617578983306885, "metricx_score": 1.7192710638046265, "metricx_qe_score": 1.8260127305984497, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme schrittweise und interpretierbar lösen.", "metrics": {"bleu_score": 38.71551944619038, "chrf_score": 75.80935171254833, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.39517393708229065, "metricx_qe_score": 0.3752603828907013, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "So können wir beispielsweise hier im zweiten Schritt diesen Teiler, welcher 27 ist, erhalten.", "metrics": {"bleu_score": 12.729922658368396, "chrf_score": 57.717183334338216, "xcomet_score": 0.9180669784545898, "xcomet_qe_score": 0.9520081281661987, "metricx_score": 0.8827222585678101, "metricx_qe_score": 1.1319469213485718, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können uns auch auf die ursprünglichen Fragen beziehen, um die relevanten Inhalte zu finden.", "metrics": {"bleu_score": 66.75075987129311, "chrf_score": 81.4646452416743, "xcomet_score": 0.9883356690406799, "xcomet_qe_score": 0.9833909273147583, "metricx_score": 0.3822799623012543, "metricx_qe_score": 0.3101891875267029, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler.", "metrics": {"bleu_score": 72.59795291154772, "chrf_score": 95.55813636296386, "xcomet_score": 0.9975470304489136, "xcomet_qe_score": 0.9964474439620972, "metricx_score": 0.46138083934783936, "metricx_qe_score": 1.0272918939590454, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Also, im dritten Schritt erhalten wir dann tatsächlich den Quotienten.", "metrics": {"bleu_score": 42.40125351805035, "chrf_score": 74.49488799522102, "xcomet_score": 0.9989863634109497, "xcomet_qe_score": 0.9934114217758179, "metricx_score": 0.9883238673210144, "metricx_qe_score": 1.3680548667907715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Gut. Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse aus dem zweiten Schritt wiederverwenden und anschließend die Ergebnisse des vierten Schritts erhalten. Und schließlich können wir die Dividenden ermitteln.", "metrics": {"bleu_score": 31.47237572518304, "chrf_score": 79.31971868264895, "xcomet_score": 0.9813846349716187, "xcomet_qe_score": 0.9756678938865662, "metricx_score": 1.023571491241455, "metricx_qe_score": 1.5139100551605225, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu erzeugen.", "metrics": {"bleu_score": 5.675727444525874, "chrf_score": 46.703457460055716, "xcomet_score": 0.9845016002655029, "xcomet_qe_score": 0.9866928458213806, "metricx_score": 1.0455368757247925, "metricx_qe_score": 0.9161331653594971, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Das macht den Prozess also präziser.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 27.889702865473915, "xcomet_score": 0.9987103939056396, "xcomet_qe_score": 1.0, "metricx_score": 0.2284550815820694, "metricx_qe_score": 0.30078762769699097, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen vorgegeben sind, und beinhalten auch einige Konstanten als unser Anfangszustand.", "metrics": {"bleu_score": 53.996789256973415, "chrf_score": 73.39069531044984, "xcomet_score": 0.9540483951568604, "xcomet_qe_score": 0.9577597379684448, "metricx_score": 1.8783668279647827, "metricx_qe_score": 2.4821720123291016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Die Expression wird also durch EIJOP dargestellt.", "metrics": {"bleu_score": 15.678003406168177, "chrf_score": 54.34718254042614, "xcomet_score": 0.9686976671218872, "xcomet_qe_score": 0.9725936651229858, "metricx_score": 1.6179860830307007, "metricx_qe_score": 2.241274833679199, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "wobei wir Operatoren von Qi nach Qj ausführen und ein solcher Ausdruck tatsächlich gerichtet ist.", "metrics": {"bleu_score": 2.9103273021008236, "chrf_score": 49.941094198195216, "xcomet_score": 0.9221451878547668, "xcomet_qe_score": 0.9522415995597839, "metricx_score": 2.3107967376708984, "metricx_qe_score": 2.204752206802368, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Da haben wir hier also auch Subtraktionswörter, um die entgegengesetzte Richtung darzustellen.", "metrics": {"bleu_score": 21.446539598866316, "chrf_score": 61.57367484429117, "xcomet_score": 0.959867000579834, "xcomet_qe_score": 0.9002148509025574, "metricx_score": 1.0411087274551392, "metricx_qe_score": 1.0802383422851562, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Dies ähnelt in vielerlei Hinsicht der Strahlungsextraktion.", "metrics": {"bleu_score": 7.267884212102741, "chrf_score": 44.631543099120854, "xcomet_score": 0.845915675163269, "xcomet_qe_score": 0.8522455096244812, "metricx_score": 5.173623085021973, "metricx_qe_score": 4.302734851837158, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formalen deduktiven System wenden wir also zum Zeitpunkt t den Operator auf das Paar Qi und Qj an und erhalten daraus diese neuen Ausdrücke.", "metrics": {"bleu_score": 30.77048210384694, "chrf_score": 64.44734913730223, "xcomet_score": 0.9676576852798462, "xcomet_qe_score": 0.9759303331375122, "metricx_score": 0.9525159001350403, "metricx_qe_score": 1.7516868114471436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "wir fügen es dem nächsten Zustand hinzu, um eine neue Größe zu erhalten.", "metrics": {"bleu_score": 58.282339541526554, "chrf_score": 78.12797431770629, "xcomet_score": 0.9417880773544312, "xcomet_qe_score": 0.9314903020858765, "metricx_score": 2.3169167041778564, "metricx_qe_score": 2.2724215984344482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Slide visualisiert also die Entwicklung des Zustands, bei dem wir kontinuierlich Ausdrücke zum aktuellen Zustand hinzufügen.", "metrics": {"bleu_score": 32.91598889023261, "chrf_score": 60.634903681206765, "xcomet_score": 0.9267491102218628, "xcomet_qe_score": 0.8623470067977905, "metricx_score": 2.041005849838257, "metricx_qe_score": 1.940316081047058, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vortrainiertes Sprachmodell, das Vögel oder Roboter sein kann, anschließend kodieren wir einen Satz und erhalten so diese Mengenrepräsentationen.", "metrics": {"bleu_score": 28.604274967068704, "chrf_score": 67.32897824220623, "xcomet_score": 0.8441517353057861, "xcomet_qe_score": 0.7638704776763916, "metricx_score": 5.187214374542236, "metricx_qe_score": 5.685643196105957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengenrepräsentationen erhalten, können wir mit der Inferenz beginnen.", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 75.60591993827667, "xcomet_score": 0.9911001920700073, "xcomet_qe_score": 0.9966357946395874, "metricx_score": 1.1475334167480469, "metricx_qe_score": 5.120283126831055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q₁ zur Erlangung der Repräsentation für Q₁. Diese werden durch Q₂ dividiert und anschließend mit Q₄ multipliziert.", "metrics": {"bleu_score": 16.58561939940771, "chrf_score": 38.9014730715633, "xcomet_score": 0.8536492586135864, "xcomet_qe_score": 0.8595770597457886, "metricx_score": 12.572470664978027, "metricx_qe_score": 9.482916831970215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paardarstellung, welche im Wesentlichen nur die Konkatenation zwischen Q1 und Q2 ist. Und anschließend wenden wir ein Feedforward-Netzwerk an, das durch den Operator parametrisiert ist.", "metrics": {"bleu_score": 45.53170245670461, "chrf_score": 70.91101623045539, "xcomet_score": 0.9171313047409058, "xcomet_qe_score": 0.8912488222122192, "metricx_score": 2.0063679218292236, "metricx_qe_score": 2.501544713973999, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksdarstellung Q1 geteilt durch Q2.", "metrics": {"bleu_score": 9.119700296511436, "chrf_score": 73.27706161929275, "xcomet_score": 0.9956886768341064, "xcomet_qe_score": 0.9830245971679688, "metricx_score": 0.49059343338012695, "metricx_qe_score": 0.8244310617446899, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber tatsächlich, in der Praxis, während der Inferenzphase könnten wir auch den falschen Ausdruck erhalten.", "metrics": {"bleu_score": 40.052744847255724, "chrf_score": 80.15432285575628, "xcomet_score": 0.9990731477737427, "xcomet_qe_score": 0.9939751625061035, "metricx_score": 1.1930482387542725, "metricx_qe_score": 2.0923123359680176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Da ist also jede mögliche Ausdrucksform gleich dreimal der Anzahl der Operatoren.", "metrics": {"bleu_score": 29.12666304913957, "chrf_score": 54.24006417383516, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0418596267700195, "metricx_qe_score": 2.469684600830078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir problemlos Einschränkungen hinzufügen können, um diesen Suchraum zu steuern.", "metrics": {"bleu_score": 72.76817202342096, "chrf_score": 78.78809967748128, "xcomet_score": 0.978975772857666, "xcomet_qe_score": 0.9823535680770874, "metricx_score": 0.6564844846725464, "metricx_qe_score": 0.8040039539337158, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck nicht zulässig ist, können wir ihn schlichtweg aus unserem Suchraum entfernen.", "metrics": {"bleu_score": 48.3018816076337, "chrf_score": 66.81739988078414, "xcomet_score": 0.9977473020553589, "xcomet_qe_score": 0.9971873760223389, "metricx_score": 0.440348744392395, "metricx_qe_score": 1.3791751861572266, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt gehen wir also wieder genauso vor, wobei der einzige Unterschied lediglich eine weitere Größe ist.", "metrics": {"bleu_score": 12.619945086541668, "chrf_score": 49.303508484400794, "xcomet_score": 0.9095377326011658, "xcomet_qe_score": 0.9385271668434143, "metricx_score": 3.5761303901672363, "metricx_qe_score": 4.360754489898682, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe ergibt sich aus dem zuvor berechneten Ausdruck.", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 49.06511807332814, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0979747772216797, "metricx_qe_score": 3.3992669582366943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Somit können wir schliesslich diesen finalen Ausdruck Q dreizehn erhalten.", "metrics": {"bleu_score": 7.446204111187156, "chrf_score": 57.48697046497483, "xcomet_score": 0.8589743971824646, "xcomet_qe_score": 0.8571522235870361, "metricx_score": 8.948968887329102, "metricx_qe_score": 11.733574867248535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "drei mal Q vier. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke sich von dem vorherigen Schritt unterscheidet.", "metrics": {"bleu_score": 41.10433074789491, "chrf_score": 77.98187093384647, "xcomet_score": 0.8685836791992188, "xcomet_qe_score": 0.8337678909301758, "metricx_score": 11.389301300048828, "metricx_qe_score": 13.706242561340332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Solche Unterschiede erschweren die Anwendung der Beam-Suche, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgeglichen ist.", "metrics": {"bleu_score": 38.79454582371661, "chrf_score": 76.07548485197165, "xcomet_score": 0.906631350517273, "xcomet_qe_score": 0.8972688317298889, "metricx_score": 1.97523033618927, "metricx_qe_score": 3.3801519870758057, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Da ist das Trainingsverfahren dem Training eines Sequence-to-Sequence-Modells ähnlich, bei dem wir den Verlust in jedem Zeitschritt optimieren.", "metrics": {"bleu_score": 44.304031555249026, "chrf_score": 76.81722648430025, "xcomet_score": 0.8449366092681885, "xcomet_qe_score": 0.8666207790374756, "metricx_score": 1.377957820892334, "metricx_qe_score": 1.8689391613006592, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir ebenfalls dieses τ, um darzustellen, wann wir diesen Generationsprozess beenden sollten.", "metrics": {"bleu_score": 48.06604068305993, "chrf_score": 76.84458707405543, "xcomet_score": 0.9328410625457764, "xcomet_qe_score": 0.9443395733833313, "metricx_score": 2.3938586711883545, "metricx_qe_score": 1.9500792026519775, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier unterscheidet sich der Raum von Sequenz zu Sequenz, da er sich zu jedem Zeitpunkt verändert, während er im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl des Vokabulars darstellt.", "metrics": {"bleu_score": 41.54834754923292, "chrf_score": 76.16727824549437, "xcomet_score": 0.9390395283699036, "xcomet_qe_score": 0.932765007019043, "metricx_score": 0.9155726432800293, "metricx_qe_score": 1.463657259941101, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es erlaubt uns auch, bestimmte Einschränkungen aufgrund von Vorwissen zu definieren.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 66.05686859483899, "xcomet_score": 0.984488844871521, "xcomet_qe_score": 0.9782513380050659, "metricx_score": 0.9059350490570068, "metricx_qe_score": 1.0703606605529785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Da führen wir daher Experimente mit den gängigen Methoden-Problem-Datensätzen MAWPS, Math 23K, MathQA und SWAM durch.", "metrics": {"bleu_score": 14.243330727836577, "chrf_score": 55.1050462188144, "xcomet_score": 0.8113922476768494, "xcomet_qe_score": 0.8096809387207031, "metricx_score": 5.86685848236084, "metricx_qe_score": 5.634557723999023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den bisher besten Ansätzen.", "metrics": {"bleu_score": 64.75445426291287, "chrf_score": 89.47798483236559, "xcomet_score": 0.9912433624267578, "xcomet_qe_score": 0.9757281541824341, "metricx_score": 0.19505245983600616, "metricx_qe_score": 0.2699507772922516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Da ist unsere leistungsstärkste Variante der Roberta Deduktions-Reasoner.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 68.28904485692358, "xcomet_score": 0.9601802825927734, "xcomet_qe_score": 0.9398902654647827, "metricx_score": 1.2005248069763184, "metricx_qe_score": 2.2384626865386963, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir im Gegensatz zu offensichtlichen Ansätzen mit Beam Search keine Beam-Suche.", "metrics": {"bleu_score": 11.263067797674253, "chrf_score": 55.856669530361415, "xcomet_score": 0.8676781058311462, "xcomet_qe_score": 0.7481160759925842, "metricx_score": 4.556014060974121, "metricx_qe_score": 5.989205360412598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Gut. Die besten Ansätze sind also häufig ein baum-basiertes Modell.", "metrics": {"bleu_score": 8.516593018819643, "chrf_score": 50.846923272153646, "xcomet_score": 0.9871149063110352, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3910878002643585, "metricx_qe_score": 0.573839545249939, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ist unser Reasoning-Modul in der Lage, dieses baumbasierte Modell deutlich zu übertreffen.", "metrics": {"bleu_score": 54.01152096367801, "chrf_score": 75.8856031126511, "xcomet_score": 0.9537899494171143, "xcomet_qe_score": 0.9138352274894714, "metricx_score": 1.7657910585403442, "metricx_qe_score": 2.8914248943328857, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können feststellen, dass die absoluten Zahlen in der Mathematik-QA oder SWAM nicht besonders hoch sind.", "metrics": {"bleu_score": 32.51693345989927, "chrf_score": 61.65397077424348, "xcomet_score": 0.8827934265136719, "xcomet_qe_score": 0.8830133676528931, "metricx_score": 1.7518386840820312, "metricx_qe_score": 2.0453529357910156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Da untersuchen wir die Ergebnisse vor Ort weiter.", "metrics": {"bleu_score": 35.49481056010054, "chrf_score": 64.80716053593993, "xcomet_score": 0.9080785512924194, "xcomet_qe_score": 0.8887135982513428, "metricx_score": 3.5376052856445312, "metricx_qe_score": 5.288801193237305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Sumpf. Und dieser Datensatz ist herausfordernd, da der Autor versucht hat, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, beispielsweise irrelevante Informationen und zusätzliche Mengenangaben.", "metrics": {"bleu_score": 45.64246312328072, "chrf_score": 75.27427186240146, "xcomet_score": 0.8379580974578857, "xcomet_qe_score": 0.8176877498626709, "metricx_score": 5.790902614593506, "metricx_qe_score": 6.648422718048096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Folglich stellen wir in unserer Vorhersage fest, dass einige der Zwischenwerte tatsächlich negativ sind.", "metrics": {"bleu_score": 44.77118844014732, "chrf_score": 78.13202578813426, "xcomet_score": 0.9804964065551758, "xcomet_qe_score": 0.9700263738632202, "metricx_score": 0.250263512134552, "metricx_qe_score": 0.3628886938095093, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in dieser Frage, wie viele Äpfel Jake hat?", "metrics": {"bleu_score": 37.73213566354408, "chrf_score": 64.56525477349912, "xcomet_score": 0.9689842462539673, "xcomet_qe_score": 0.9290996193885803, "metricx_score": 0.8648968935012817, "metricx_qe_score": 0.8216575384140015, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige Zusatzinformationen, wie beispielsweise siebzehn weniger Würfe, und Stephen hat acht Würfe, was völlig irrelevant ist.", "metrics": {"bleu_score": 36.66340989897011, "chrf_score": 61.33655105869708, "xcomet_score": 0.8209881782531738, "xcomet_qe_score": 0.8318612575531006, "metricx_score": 3.723031759262085, "metricx_qe_score": 2.985602378845215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell trifft also Vorhersagen wie diese, welche negative Werte erzeugen.", "metrics": {"bleu_score": 16.664087508224515, "chrf_score": 62.25605734015899, "xcomet_score": 0.9894092082977295, "xcomet_qe_score": 0.9812815189361572, "metricx_score": 0.63606858253479, "metricx_qe_score": 0.6499210596084595, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke.", "metrics": {"bleu_score": 11.147892272337163, "chrf_score": 33.87680096462581, "xcomet_score": 0.7297190427780151, "xcomet_qe_score": 0.8604840636253357, "metricx_score": 6.011697769165039, "metricx_qe_score": 13.461858749389648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Suchraum also tatsächlich zu begrenzen, können wir beispielsweise Ergebnisse entfernen, die negativ sind, damit wir die Antwort korrekt gestalten können.", "metrics": {"bleu_score": 10.401577613691959, "chrf_score": 60.98128632670857, "xcomet_score": 0.9527806043624878, "xcomet_qe_score": 0.9203000664710999, "metricx_score": 2.141580820083618, "metricx_qe_score": 2.7453458309173584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Da stellen wir fest, dass diese Beschränkung tatsächlich die Leistung einiger Modelle erheblich verbessert.", "metrics": {"bleu_score": 9.929263644223568, "chrf_score": 47.8394737406253, "xcomet_score": 0.972712516784668, "xcomet_qe_score": 0.9497771263122559, "metricx_score": 0.9580904245376587, "metricx_qe_score": 0.8172096014022827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Für Vögel haben wir sieben Punkte verbessert.\nUnd dann haben wir beim Roberta-Basismodell tatsächlich zwei Punkte verbessert.", "metrics": {"bleu_score": 19.496626806250337, "chrf_score": 63.63009638929966, "xcomet_score": 0.8104064464569092, "xcomet_qe_score": 0.7963641285896301, "metricx_score": 8.959635734558105, "metricx_qe_score": 8.963866233825684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Da ein besseres Sprachmodell über bessere sprachverständliche Fähigkeiten verfügt, ist die hier angegebene Zahl für Roberta höher und für Bertha niedriger.", "metrics": {"bleu_score": 5.258518298635601, "chrf_score": 54.704246448676294, "xcomet_score": 0.9215661287307739, "xcomet_qe_score": 0.9349883198738098, "metricx_score": 3.2205567359924316, "metricx_qe_score": 2.8252692222595215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 66.69930586829759, "xcomet_score": 0.7862759828567505, "xcomet_qe_score": 0.7623720765113831, "metricx_score": 5.309876441955566, "metricx_qe_score": 7.541841983795166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information betrachtet werden kann.", "metrics": {"bleu_score": 84.92326635760686, "chrf_score": 96.6771628920515, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3140363097190857, "metricx_qe_score": 0.3209344446659088, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier können wir sehen, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben, und der „Swamp“-Datensatz weist den größten Anteil auf.", "metrics": {"bleu_score": 69.60917409740965, "chrf_score": 83.60519844274145, "xcomet_score": 0.9558230042457581, "xcomet_qe_score": 0.9409534931182861, "metricx_score": 3.129879951477051, "metricx_qe_score": 3.7779488563537598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtperformance.", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 68.06188470322297, "xcomet_score": 0.9839564561843872, "xcomet_qe_score": 0.9954792261123657, "metricx_score": 0.5273306369781494, "metricx_qe_score": 0.3154757618904114, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für jene Proben, bei denen keine ungenutzten Mengen vorhanden sind, ist die Gesamtleistung somit tatsächlich höher als die Gesamtleistung.", "metrics": {"bleu_score": 19.80316235382626, "chrf_score": 63.88442000723777, "xcomet_score": 0.8203321695327759, "xcomet_qe_score": 0.629540205001831, "metricx_score": 2.935262680053711, "metricx_qe_score": 4.515986442565918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei den Proben, bei denen eine ungenutzte Menge vorhanden ist, ist es tatsächlich deutlich schlimmer als – ähm – deutlich schlimmer.", "metrics": {"bleu_score": 3.9645132534206886, "chrf_score": 40.8892842922581, "xcomet_score": 0.886459469795227, "xcomet_qe_score": 0.8663592338562012, "metricx_score": 7.183557510375977, "metricx_qe_score": 7.447319030761719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Mangelhafte Leistung. Bei MAWPS gibt es kaum Schreibtischfälle, daher ignoriere ich diesen Abschnitt einfach.", "metrics": {"bleu_score": 12.936981168384865, "chrf_score": 45.13111897348266, "xcomet_score": 0.7789863348007202, "xcomet_qe_score": 0.6759896278381348, "metricx_score": 6.571981430053711, "metricx_qe_score": 6.963406562805176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Da wollen wir abschließend die Interpretierbarkeit anhand eines Beispiels für die Frageteilnahme demonstrieren.", "metrics": {"bleu_score": 21.97281387499715, "chrf_score": 61.65321205263934, "xcomet_score": 0.8101121187210083, "xcomet_qe_score": 0.8094708919525146, "metricx_score": 5.362640857696533, "metricx_qe_score": 5.332355976104736, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Hier macht unser Modell also tatsächlich eine fehlerhafte Vorhersage im ersten Schritt.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 88.81424403707663, "xcomet_score": 0.999197244644165, "xcomet_qe_score": 0.9771820306777954, "metricx_score": 0.5761969685554504, "metricx_qe_score": 0.4770207405090332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Also können wir diesen Ausdruck also tatsächlich mit diesem Satz hier in Beziehung setzen, richtig?", "metrics": {"bleu_score": 25.459845316736796, "chrf_score": 62.40730615306364, "xcomet_score": 0.9990854263305664, "xcomet_qe_score": 0.9898711442947388, "metricx_score": 1.3132933378219604, "metricx_qe_score": 1.4906450510025024, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Daher vermuten wir, dass dieser Satz das Modell zu einer fehlerhaften Vorhersage verleiten könnte.", "metrics": {"bleu_score": 45.788313721339826, "chrf_score": 66.03725309104345, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20489493012428284, "metricx_qe_score": 0.19624543190002441, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Da fügt das Hinzufügen von weiteren dreissigfünf Pflanzen dem Modell die Überlegung hinzu, ob es sich um eine Erweiterung der Operatoren handelt.", "metrics": {"bleu_score": 2.46233736722218, "chrf_score": 29.807545553613796, "xcomet_score": 0.6658850908279419, "xcomet_qe_score": 0.6657854318618774, "metricx_score": 6.439000606536865, "metricx_qe_score": 4.816260814666748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Da versuchen wir, den Satz so umzuformulieren, dass er in etwa besagt: Die Anzahl der Birnbäume ist fünfzig fünf geringer als die Anzahl der Apfelbäume.", "metrics": {"bleu_score": 26.66090188234886, "chrf_score": 70.98075525734387, "xcomet_score": 0.9647971391677856, "xcomet_qe_score": 0.9767197966575623, "metricx_score": 2.4160568714141846, "metricx_qe_score": 1.728079080581665, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Da stellen wir sicher, dass genauere Semantik vermittelt wird, sodass das Modell in der Lage ist, die korrekte Vorhersage zu treffen.", "metrics": {"bleu_score": 59.86517864980669, "chrf_score": 76.63153594799427, "xcomet_score": 0.9783099889755249, "xcomet_qe_score": 0.9562548398971558, "metricx_score": 1.1593886613845825, "metricx_qe_score": 1.5506787300109863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt somit, wie interpretierbare Vorhersagen uns helfen, das Modellverhalten zu verstehen.", "metrics": {"bleu_score": 48.18716588757115, "chrf_score": 81.2630078372006, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.39194005727767944, "metricx_qe_score": 0.6103874444961548, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell also tatsächlich recht effizient.", "metrics": {"bleu_score": 32.00286101270288, "chrf_score": 70.5761044214447, "xcomet_score": 0.9782370328903198, "xcomet_qe_score": 0.9677305221557617, "metricx_score": 0.5423935651779175, "metricx_qe_score": 0.9186235070228577, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "und wir sind in der Lage, eine interpretierbare Lösungsabfolge bereitzustellen.", "metrics": {"bleu_score": 33.18077402843942, "chrf_score": 60.753327079594975, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7509797811508179, "metricx_qe_score": 0.5060964226722717, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können problemlos vorhandenes Wissen als Nebenbedingung integrieren, was die Leistung verbessern kann.", "metrics": {"bleu_score": 7.473868453555444, "chrf_score": 43.3262587369447, "xcomet_score": 0.9955074787139893, "xcomet_qe_score": 0.9863694906234741, "metricx_score": 0.6063741445541382, "metricx_qe_score": 0.8086764216423035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das letzte ist, dass der zugrundeliegende Mechanismus nicht nur auf Aufgaben zur Netzwerkproblem-Lösung anwendbar ist, sondern auch auf andere Aufgaben, die mehrstufige Schlussfolgerungen erfordern.", "metrics": {"bleu_score": 26.234189765541814, "chrf_score": 65.9141533654007, "xcomet_score": 0.9778109788894653, "xcomet_qe_score": 0.9809716939926147, "metricx_score": 0.7489165663719177, "metricx_qe_score": 0.7580434679985046, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch gewisse Einschränkungen.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 27.78342294558877, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, kann der Speicherverbrauch recht hoch sein.", "metrics": {"bleu_score": 68.99302125555486, "chrf_score": 83.31750797481222, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4178113639354706, "metricx_qe_score": 0.449037104845047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das zweite Problem besteht darin, dass, wie bereits erwähnt, die Wahrscheinlichkeitsverteilung über verschiedene Zeitpunkte hinweg unausgeglichen ist, was die Anwendung von Beam Searches ebenfalls sehr erschwert.", "metrics": {"bleu_score": 3.9016631127179084, "chrf_score": 48.06655279814245, "xcomet_score": 0.9715570211410522, "xcomet_qe_score": 0.9588541984558105, "metricx_score": 1.5727770328521729, "metricx_qe_score": 2.768709897994995, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Damit ist der Vortrag nun beendet, und Fragen sind willkommen.\nVielen Dank.", "metrics": {"bleu_score": 10.18112825437689, "chrf_score": 41.23984071629887, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.242342010140419, "metricx_qe_score": 0.15473410487174988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich bin von der Maastricht University.", "metrics": {"bleu_score": 79.00555574972935, "chrf_score": 86.71167450637964, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3197808563709259, "metricx_qe_score": 0.2690771222114563, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine Arbeit mit Jerry vorstellen, die sich mit einem neuen Datensatz für die Recherche von Gesetzesartikeln befasst.", "metrics": {"bleu_score": 27.82354149317939, "chrf_score": 64.78401427216244, "xcomet_score": 0.9930891990661621, "xcomet_qe_score": 0.9939570426940918, "metricx_score": 1.519749641418457, "metricx_qe_score": 0.6390572786331177, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtliche Fragen sind ein integraler Bestandteil des Lebens vieler Menschen.", "metrics": {"bleu_score": 51.93071778680675, "chrf_score": 78.77400495094894, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4245132803916931, "metricx_qe_score": 0.3024641275405884, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Doch verfügen die meisten Bürgerinnen und Bürger über wenig bis gar kein Wissen über ihre Rechte und grundlegende rechtliche Verfahren.", "metrics": {"bleu_score": 43.00707823114161, "chrf_score": 71.13018243711868, "xcomet_score": 0.9996421337127686, "xcomet_qe_score": 1.0, "metricx_score": 0.329769492149353, "metricx_qe_score": 0.3810351490974426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind viele schutzbedürftige Bürger, die sich den kostenintensiven Beistand eines Rechtsanwalts nicht leisten können, ungeschützt oder gar ausgebeutet.", "metrics": {"bleu_score": 26.77977806054516, "chrf_score": 51.310049510165335, "xcomet_score": 0.9882155656814575, "xcomet_qe_score": 1.0, "metricx_score": 1.7056596279144287, "metricx_qe_score": 0.3918343484401703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Kluft zwischen Menschen und dem Gesetz zu überbrücken, indem wir ein effektives Suchsystem für Gesetzestexte entwickeln.", "metrics": {"bleu_score": 60.59985815633343, "chrf_score": 77.99691736731941, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3672736585140228, "metricx_qe_score": 0.1875501573085785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen professionellen Rechtsbeistand für ungelernte Personen bereitstellen.", "metrics": {"bleu_score": 50.08718428920986, "chrf_score": 66.01308914223583, "xcomet_score": 0.9757451415061951, "xcomet_qe_score": 0.9840689897537231, "metricx_score": 0.3389661908149719, "metricx_qe_score": 0.2388136386871338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns der Hauptleistung dieser Arbeit zuwenden, wollen wir zunächst das Problem der juristischen Artikelrecherche beschreiben.", "metrics": {"bleu_score": 35.16113805476334, "chrf_score": 61.40698642767081, "xcomet_score": 0.9386152029037476, "xcomet_qe_score": 0.9348930716514587, "metricx_score": 0.6070928573608398, "metricx_qe_score": 0.3326107859611511, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "bei einer einfachen Frage zu einem Rechtsgebiet, wie beispielsweise: Was riskiere ich, wenn ich die berufliche Schweigepflicht verletze?", "metrics": {"bleu_score": 21.79301929852717, "chrf_score": 53.26775060451951, "xcomet_score": 0.9628907442092896, "xcomet_qe_score": 0.9486135244369507, "metricx_score": 0.42145371437072754, "metricx_qe_score": 0.41544654965400696, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Bestimmungen aus einem umfangreichen Rechtskorpus abzurufen.", "metrics": {"bleu_score": 18.801961527567503, "chrf_score": 48.492942307869825, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.28140199184417725, "metricx_qe_score": 0.28958967328071594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsbeschaffungsaufgabe ist mit eigenen Herausforderungen verbunden.", "metrics": {"bleu_score": 10.816059393812111, "chrf_score": 70.04482617389466, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09750836342573166, "metricx_qe_score": 0.3181103467941284, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst befasst es sich mit zwei Arten von Sprache.", "metrics": {"bleu_score": 39.281465090051306, "chrf_score": 55.994172611278145, "xcomet_score": 0.9388857483863831, "xcomet_qe_score": 0.941964864730835, "metricx_score": 0.14668114483356476, "metricx_qe_score": 0.17115271091461182, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "gängige Umgangssprache für die Fragen und komplexe, juristische Fachsprache für die Gesetze.", "metrics": {"bleu_score": 32.59169224191723, "chrf_score": 61.81894899278196, "xcomet_score": 0.981691837310791, "xcomet_qe_score": 0.9875179529190063, "metricx_score": 0.5267072916030884, "metricx_qe_score": 0.4042091369628906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in der Sprachverteilung erschweren es einem System, relevante Kandidaten abzurufen, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine juristische Frage übersetzen kann, die mit der Terminologie von Gesetzen übereinstimmt.", "metrics": {"bleu_score": 47.0641752806796, "chrf_score": 74.03174909096198, "xcomet_score": 0.9247462749481201, "xcomet_qe_score": 0.8985425233840942, "metricx_score": 1.66623854637146, "metricx_qe_score": 1.3189868927001953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus ist Gesetzestext keine Sammlung unabhängiger Artikel, die wie Nachrichten oder Rezepte für sich genommen als vollständige Informationsquelle behandelt werden können.", "metrics": {"bleu_score": 19.53240775579311, "chrf_score": 65.58953890223728, "xcomet_score": 0.9997224807739258, "xcomet_qe_score": 1.0, "metricx_score": 0.48722243309020996, "metricx_qe_score": 0.4697709083557129, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen handelt es sich um eine Sammlung von Rechtsnormen, die erst in ihrer Gesamtheit eine Bedeutung erlangen, wenn sie im Gesamtkontext betrachtet werden, d.h. zusammen mit den ergänzenden Informationen aus den benachbarten Artikeln, den Bereichen und Teilbereichen, denen sie zuzuordnen sind, sowie ihrem Platz innerhalb der Rechtsstruktur.", "metrics": {"bleu_score": 41.500085942002805, "chrf_score": 64.53103412730682, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2631858289241791, "metricx_qe_score": 0.3307374119758606, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Zuletzt sind die gesetzlichen Bestimmungen in kleinen Abschnitten formuliert, welche üblicherweise die typische Retrieval-Einheit in den meisten Retrieval-Arbeiten darstellen.", "metrics": {"bleu_score": 18.37243666159123, "chrf_score": 58.20907859433727, "xcomet_score": 0.8395115733146667, "xcomet_qe_score": 0.8253980875015259, "metricx_score": 7.320700645446777, "metricx_qe_score": 6.080483913421631, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier liegen umfangreiche Dokumente vor, die bis zu sechzig Jahre alt sein können.", "metrics": {"bleu_score": 21.023693683267553, "chrf_score": 44.15949488364578, "xcomet_score": 0.5228864550590515, "xcomet_qe_score": 0.5203148126602173, "metricx_score": 6.640891075134277, "metricx_qe_score": 6.31022834777832, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in der NLP haben ein großes Interesse an zahlreichen juristischen Aufgaben geweckt, wie beispielsweise der Vorhersage von Gerichtsurteilen oder der automatisierten Vertragsprüfung.", "metrics": {"bleu_score": 19.244962037224823, "chrf_score": 70.25746456045148, "xcomet_score": 0.9854466915130615, "xcomet_qe_score": 0.9829672574996948, "metricx_score": 0.808276355266571, "metricx_qe_score": 1.3775169849395752, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die Recherche anhand von Gesetzestexten ist jedoch weitgehend unberührt geblieben, bedingt durch den Mangel an großen und hochwertigen, annotierten Datensätzen.", "metrics": {"bleu_score": 11.71291646655074, "chrf_score": 56.11974349540632, "xcomet_score": 0.9979908466339111, "xcomet_qe_score": 0.9987719058990479, "metricx_score": 0.837380588054657, "metricx_qe_score": 0.7975794076919556, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir einen neuen, französischen, bürgerzentrierten Datensatz, um zu untersuchen, ob Retrieval-Modelle die Effizienz und Zuverlässigkeit eines Rechtsexperten bei der Aufgabe der Retrieval von Gesetzesartikeln approximieren können.", "metrics": {"bleu_score": 25.885186785112726, "chrf_score": 65.40744493521544, "xcomet_score": 0.8760469555854797, "xcomet_qe_score": 0.8972365856170654, "metricx_score": 4.956851005554199, "metricx_qe_score": 5.4159932136535645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Unsere belgischen Datensätze zur Recherche von Gesetzestexten umfassen mehr als eintausendeinhundert Liter.", "metrics": {"bleu_score": 2.8578945586315685, "chrf_score": 30.59805171505326, "xcomet_score": 0.7308107018470764, "xcomet_qe_score": 0.7312240600585938, "metricx_score": 12.929309844970703, "metricx_qe_score": 11.614940643310547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen ein breites Themenspektrum, von Familie, Wohnen, Geld bis hin zu Arbeit und Sozialversicherung.", "metrics": {"bleu_score": 52.6530512455171, "chrf_score": 68.86276567930322, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10981128364801407, "metricx_qe_score": 0.08465220034122467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen wurde von erfahrenen Juristen unter Bezugnahme auf relevante Artikel aus einem Korpus von mehr als fünfundzwanzig Millionen sechsundzwanzigtausend Artikeln gekennzeichnet.", "metrics": {"bleu_score": 51.1309386709896, "chrf_score": 59.072689466633435, "xcomet_score": 0.7180818319320679, "xcomet_qe_score": 0.6567543745040894, "metricx_score": 9.099105834960938, "metricx_qe_score": 11.094575881958008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Rechtsvorschriften. Sprechen wir nun darüber, wie wir diese Datensätze erhoben haben.", "metrics": {"bleu_score": 14.377919100088198, "chrf_score": 46.67229909498926, "xcomet_score": 0.5148698091506958, "xcomet_qe_score": 0.4015795588493347, "metricx_score": 7.968938827514648, "metricx_qe_score": 12.551623344421387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst begannen wir damit, einen umfangreichen Korpus juristischer Artikel zusammenzustellen.", "metrics": {"bleu_score": 4.789232204309912, "chrf_score": 40.62601656445099, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.08541776984930038, "metricx_qe_score": 0.16475620865821838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysierten dreißig zwei öffentlich zugängliche belgische Normen und extrahierten sämtliche Artikel sowie die entsprechenden Abschnittsüberschriften.", "metrics": {"bleu_score": 31.007120066002052, "chrf_score": 69.22859525038102, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.1450954675674438, "metricx_qe_score": 0.39350491762161255, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann erfassten wir juristische Fragestellungen mit Bezugnahme auf einschlägige Gesetze.", "metrics": {"bleu_score": 15.74388460998318, "chrf_score": 53.968564299418034, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6758861541748047, "metricx_qe_score": 0.48906368017196655, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jährlich etwa viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten.", "metrics": {"bleu_score": 55.10449999281012, "chrf_score": 73.49313159038093, "xcomet_score": 0.9979974031448364, "xcomet_qe_score": 1.0, "metricx_score": 0.10287228971719742, "metricx_qe_score": 0.1696949303150177, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team aus erfahrenen Juristen die häufigsten rechtlichen Fragen in Belgien behandelt.", "metrics": {"bleu_score": 79.13547592495158, "chrf_score": 81.97132714174494, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5480829477310181, "metricx_qe_score": 0.6027296185493469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen erfasst, die mit Kategorien, Unterkategorien und juristischen Verweisen auf einschlägige Gesetze versehen sind.", "metrics": {"bleu_score": 46.2985228134777, "chrf_score": 75.74098659834532, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.42933106422424316, "metricx_qe_score": 0.3239193558692932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend überprüften wir die rechtlichen Verweise und filterten die Fragen heraus, deren Verweise keine Artikel in einem der von uns berücksichtigten Gesetzeskompendien waren.", "metrics": {"bleu_score": 37.56881561469425, "chrf_score": 70.51074462152718, "xcomet_score": 0.9794818162918091, "xcomet_qe_score": 0.9711732864379883, "metricx_score": 0.9039648771286011, "metricx_qe_score": 1.0783487558364868, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die übrigen Referenzen wurden abgeglichen und in die entsprechenden Artikel-IDs aus O Corpus umgewandelt.", "metrics": {"bleu_score": 53.03624596095554, "chrf_score": 74.60049322530264, "xcomet_score": 0.9652509093284607, "xcomet_qe_score": 0.9701719284057617, "metricx_score": 3.85561203956604, "metricx_qe_score": 3.635848045349121, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende landeten wir bei eintausendachthundert Fragen, die jeweils sorgfältig mit den IDs der relevanten Artikel aus dem Buch versehen waren.", "metrics": {"bleu_score": 30.67818654930256, "chrf_score": 47.67366402667598, "xcomet_score": 0.8774335384368896, "xcomet_qe_score": 0.855472207069397, "metricx_score": 4.045471668243408, "metricx_qe_score": 7.656734943389893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus ist jede Frage mit einer Hauptkategorie und einer Verkettung von Unterkategorien versehen.", "metrics": {"bleu_score": 16.620689217205012, "chrf_score": 78.96409343153779, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.48816657066345215, "metricx_qe_score": 1.003077745437622, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "und jeder Artikel wird begleitet von einer Verkettung der jeweils folgenden Überschrift innerhalb der Struktur des Gesetzes.", "metrics": {"bleu_score": 9.880782578056978, "chrf_score": 54.451092234332165, "xcomet_score": 0.9707506895065308, "xcomet_qe_score": 0.9413566589355469, "metricx_score": 1.696848750114441, "metricx_qe_score": 2.716045379638672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten aber für zukünftige Forschung im Bereich der juristischen Informationsbeschaffung oder der Klassifizierung juristischer Texte von Interesse sein.", "metrics": {"bleu_score": 53.46930670550587, "chrf_score": 78.27288769338247, "xcomet_score": 0.9925519227981567, "xcomet_qe_score": 0.999660849571228, "metricx_score": 0.768440842628479, "metricx_qe_score": 0.9724645614624023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Betrachten wir einige Eigenschaften unserer Datensätze.", "metrics": {"bleu_score": 6.495032985064742, "chrf_score": 35.45569485378652, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05069272592663765, "metricx_qe_score": 0.02726668119430542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen umfassen zwischen fünf und vierundvierzig Wörtern, wobei die Medianlänge vierzig Wörter beträgt.", "metrics": {"bleu_score": 12.455735564577523, "chrf_score": 43.33710436337388, "xcomet_score": 0.9837418794631958, "xcomet_qe_score": 0.9862300157546997, "metricx_score": 5.752420902252197, "metricx_qe_score": 4.362950801849365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind deutlich länger, mit einer Medianlänge von siebzig sieben Wörtern und einhundert vierzig Gramm.", "metrics": {"bleu_score": 9.20469716080042, "chrf_score": 36.91032594312526, "xcomet_score": 0.7332151532173157, "xcomet_qe_score": 0.7509745955467224, "metricx_score": 11.488395690917969, "metricx_qe_score": 15.35139274597168, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "davon über eintausend.", "metrics": {"bleu_score": 3.564186929405141, "chrf_score": 10.262554423338155, "xcomet_score": 0.17974138259887695, "xcomet_qe_score": 0.18398860096931458, "metricx_score": 18.25582504272461, "metricx_qe_score": 19.62674903869629, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Fragestellung ein breites Themenspektrum, wobei etwa fünfundachtzig Prozent der Themen sich entweder auf Familie, Wohnen, Geld oder Gerechtigkeit bezogen, oder", "metrics": {"bleu_score": 17.4706582843675, "chrf_score": 60.41135505569757, "xcomet_score": 0.9322884678840637, "xcomet_qe_score": 0.9439960718154907, "metricx_score": 3.1295182704925537, "metricx_qe_score": 0.9424359202384949, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "wobei die restlichen fünfzehn Prozent entweder die soziale Sicherheit, Ausländer oder die Arbeit betreffen.", "metrics": {"bleu_score": 27.88241097922203, "chrf_score": 75.48617835106748, "xcomet_score": 0.9896563291549683, "xcomet_qe_score": 0.9778392314910889, "metricx_score": 0.5481234788894653, "metricx_qe_score": 0.6547202467918396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind zudem sehr vielfältig, da sie aus dreißig zwei verschiedenen belgischen Gesetzestexten stammen, die eine große Anzahl juristischer Themen abdecken.", "metrics": {"bleu_score": 41.902845957302084, "chrf_score": 71.73347384427514, "xcomet_score": 0.9968242645263672, "xcomet_qe_score": 0.996863603591919, "metricx_score": 0.34396788477897644, "metricx_qe_score": 0.2955167889595032, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus diesen belgischen Rechtsvorschriften zusammengetragen wurden.", "metrics": {"bleu_score": 74.87402156832427, "chrf_score": 73.6764439121879, "xcomet_score": 0.9990042448043823, "xcomet_qe_score": 0.9935269355773926, "metricx_score": 0.5238919854164124, "metricx_qe_score": 1.5024633407592773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den zweitausendsiebenhundertdreiunddreißig Artikeln wurden lediglich eintausendsechshundertzölf als für mindestens eines der", "metrics": {"bleu_score": 6.988157272632075, "chrf_score": 37.02378275650769, "xcomet_score": 0.7195721864700317, "xcomet_qe_score": 0.7398868799209595, "metricx_score": 9.756462097167969, "metricx_qe_score": 11.918519973754883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "mindestens eine Frage in den Datensätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen entweder aus dem Bürgerlichen Gesetzbuch, dem Strafprozessgesetz, dem Strafregistergesetz oder dem Strafgesetzbuch.", "metrics": {"bleu_score": 34.93072415532013, "chrf_score": 61.8499601810302, "xcomet_score": 0.45378729701042175, "xcomet_qe_score": 0.6462911367416382, "metricx_score": 8.561941146850586, "metricx_qe_score": 11.1445951461792, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen haben achtzehn von dreißig-zwei Codes weniger als fünf Artikel, die für mindestens eine Frage als relevant angegeben sind.", "metrics": {"bleu_score": 26.153117750218023, "chrf_score": 56.79377424588363, "xcomet_score": 0.961713433265686, "xcomet_qe_score": 0.9590485095977783, "metricx_score": 4.263605117797852, "metricx_qe_score": 3.3374109268188477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Was dadurch erklärt werden kann, dass diese Codes weniger auf Individuen und deren Anliegen fokussieren.", "metrics": {"bleu_score": 11.022825290043492, "chrf_score": 42.247661185305624, "xcomet_score": 0.9803539514541626, "xcomet_qe_score": 0.9887915849685669, "metricx_score": 4.7524895668029785, "metricx_qe_score": 3.3725199699401855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt liegt die Mediananzahl der Zitationen für diese zitierten Artikel bei zwei, und weniger als fünfundzwanzig Prozent davon werden zitiert.", "metrics": {"bleu_score": 26.2580369530277, "chrf_score": 61.67089280658479, "xcomet_score": 0.8941612243652344, "xcomet_qe_score": 0.8779207468032837, "metricx_score": 8.445570945739746, "metricx_qe_score": 6.43747615814209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mithilfe unserer Datensätze bewerten wir verschiedene Retrieval-Ansätze, darunter lexikalische und dense Architektur.", "metrics": {"bleu_score": 14.79257593879102, "chrf_score": 51.81278037418462, "xcomet_score": 0.9789600372314453, "xcomet_qe_score": 0.9312331676483154, "metricx_score": 1.0110936164855957, "metricx_qe_score": 1.9303745031356812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts einer Anfrage in einem Artikel weist ein lexikalisches Modell dem Anfrage-Artikel-Paar eine Bewertung zu, indem es die Summe über die Anfragebegriffe der Gewichte jedes dieser Begriffe in diesem Artikel berechnet.", "metrics": {"bleu_score": 41.78364457486453, "chrf_score": 70.97943720293503, "xcomet_score": 0.9153857231140137, "xcomet_qe_score": 0.8723607063293457, "metricx_score": 4.537890434265137, "metricx_qe_score": 4.229085922241211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM25-Rankingfunktionen.", "metrics": {"bleu_score": 32.46679154750989, "chrf_score": 78.0582574014455, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.879295825958252, "metricx_qe_score": 1.2028472423553467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen besteht darin, dass sie nur Artikel abrufen können, die Schlüsselwörter enthalten, die in der Anfrage vorhanden sind.", "metrics": {"bleu_score": 62.56538561604213, "chrf_score": 84.29789145261367, "xcomet_score": 0.9924049377441406, "xcomet_qe_score": 0.989508867263794, "metricx_score": 0.48942047357559204, "metricx_qe_score": 0.6402365565299988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Suchanfragen und Artikeln erfassen kann.", "metrics": {"bleu_score": 75.22135016840222, "chrf_score": 90.65919573710315, "xcomet_score": 0.996170163154602, "xcomet_qe_score": 0.9968985319137573, "metricx_score": 0.36060380935668945, "metricx_qe_score": 0.21915337443351746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein BE-Encoder-Modell, das Anfragen und Artikel in dichte Vektordarstellungen abbildet und einen Relevanzwert zwischen einem Anfrage-Artikel-Paar anhand der Ähnlichkeit ihrer Einbettungen berechnet.", "metrics": {"bleu_score": 51.81964006039316, "chrf_score": 90.42288560008457, "xcomet_score": 0.8868670463562012, "xcomet_qe_score": 0.8761545419692993, "metricx_score": 2.066619634628296, "metricx_qe_score": 3.6637954711914062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen resultieren typischerweise aus einer Pooling-Operation auf der Ausgabe eines Wort-Einbettungsmodells.", "metrics": {"bleu_score": 50.78431769269645, "chrf_score": 84.46865075575558, "xcomet_score": 0.8949354887008667, "xcomet_qe_score": 0.865882396697998, "metricx_score": 1.5473191738128662, "metricx_qe_score": 2.746807813644409, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Effektivität von Siamese Biancodern in einer Zero-Shot-Evaluierungsumgebung, was bedeutet, dass vortrainierte Word-Embedding-Modelle ohne zusätzliche Feinabstimmung direkt angewendet werden.", "metrics": {"bleu_score": 29.984782355393406, "chrf_score": 72.8069355056318, "xcomet_score": 0.8333824872970581, "xcomet_qe_score": 0.7540378570556641, "metricx_score": 5.009586334228516, "metricx_qe_score": 3.6524147987365723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Textkodierern, namentlich Word to Vec und FastText, sowie mit kontextabhängigen Einbettungsmodellen, namentlich Roberta und, spezifischer, Camembert, welches ein französisches Roberta-Modell ist.", "metrics": {"bleu_score": 13.299435570305864, "chrf_score": 67.00694080411618, "xcomet_score": 0.9095592498779297, "xcomet_qe_score": 0.916400671005249, "metricx_score": 2.8319637775421143, "metricx_qe_score": 2.6558799743652344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus trainieren wir unser eigenes CamemBERT-basiertes Modell. Über Zitate hinaus,", "metrics": {"bleu_score": 28.67033581673066, "chrf_score": 57.79208833036809, "xcomet_score": 0.7632385492324829, "xcomet_qe_score": 0.7628468871116638, "metricx_score": 7.845998287200928, "metricx_qe_score": 10.178495407104492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "gilt für alle Datensätze. Beachten Sie, dass wir für das Training mit den beiden Varianten der Bianco-Architektur experimentieren.", "metrics": {"bleu_score": 42.18752038739221, "chrf_score": 79.60255684250404, "xcomet_score": 0.6771568059921265, "xcomet_qe_score": 0.6534854173660278, "metricx_score": 6.460378170013428, "metricx_qe_score": 5.763860702514648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das die Anfrage und den Artikel gemeinsam in einem gemeinsamen dichten Vektorraum abbildet, und Tutor, das zwei unabhängige Word-Embedding-Modelle verwendet, die die Anfrage und den Artikel getrennt in unterschiedliche Einbettungsräume kodieren.", "metrics": {"bleu_score": 45.08737548313823, "chrf_score": 73.72021103580167, "xcomet_score": 0.7171079516410828, "xcomet_qe_score": 0.7183966040611267, "metricx_score": 6.511962890625, "metricx_qe_score": 9.27063274383545, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentierten mit Mittelwert-, Maximum- und CLS-Pooling sowie mit dem Punktprodukt und dem Kosinus für die Berechnung von Ähnlichkeiten.", "metrics": {"bleu_score": 42.58744680390021, "chrf_score": 81.82322646196913, "xcomet_score": 0.8502039909362793, "xcomet_qe_score": 0.8457154035568237, "metricx_score": 1.6493552923202515, "metricx_qe_score": 2.2444262504577637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Basismodells auf den Testdatensätzen.", "metrics": {"bleu_score": 32.46679154750989, "chrf_score": 73.22219592770028, "xcomet_score": 0.9678322076797485, "xcomet_qe_score": 0.9406160712242126, "metricx_score": 0.7128231525421143, "metricx_qe_score": 0.7759717702865601, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den oben genannten lexikalischen Methoden wurden die Siamese B-Encoder in einer Zero-Shot-Konfiguration in der Mitte evaluiert, und die feinabgestimmten B-Encoder sind unten dargestellt.", "metrics": {"bleu_score": 9.22635643555325, "chrf_score": 62.89118725632702, "xcomet_score": 0.7283878326416016, "xcomet_qe_score": 0.7372441291809082, "metricx_score": 4.459654808044434, "metricx_qe_score": 5.0117573738098145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertrifft das feinabgestimmte Biancore alle anderen Basslinien deutlich.", "metrics": {"bleu_score": 13.152507170126716, "chrf_score": 71.57425091495062, "xcomet_score": 0.7721888422966003, "xcomet_qe_score": 0.7891359925270081, "metricx_score": 6.975095272064209, "metricx_qe_score": 8.27997875213623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Zwei-Turm-Modell übertrifft seine Siamese-Variante beim Recall bei hundert, weist jedoch bei den anderen Metriken eine ähnliche Leistung auf.", "metrics": {"bleu_score": 13.603570001688142, "chrf_score": 45.389447385443184, "xcomet_score": 0.7600058317184448, "xcomet_qe_score": 0.8096105456352234, "metricx_score": 5.96763801574707, "metricx_qe_score": 4.709254741668701, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM twenty five im Vergleich zum trainierten Biancoda deutlich schlechter abschnitt, deutete seine Leistung darauf hin, dass es sich dennoch um eine solide Grundlage für domänenspezifisches Retrieval handelt.", "metrics": {"bleu_score": 7.980117387982904, "chrf_score": 60.152384550211494, "xcomet_score": 0.7209272980690002, "xcomet_qe_score": 0.7156409025192261, "metricx_score": 7.559610843658447, "metricx_qe_score": 8.299213409423828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Null-Schuss-Evaluierung des Siamese Biencoders stellen wir fest, dass die direkte Verwendung der Einbettungen eines vortrainierten Kamembert-Modells ohne Optimierung für die Informationsbeschaffungsaufgabe zu schlechten Ergebnissen führt, was mit früheren Erkenntnissen übereinstimmt.", "metrics": {"bleu_score": 56.70739274528495, "chrf_score": 76.33457652281993, "xcomet_score": 0.7040467262268066, "xcomet_qe_score": 0.7296007871627808, "metricx_score": 4.841236114501953, "metricx_qe_score": 3.8492355346679688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir fest, dass das auf \"word to vec\" basierende Biancoder die Modelle Vastex und bird-basiert deutlich übertrifft. Dies deutet darauf hin, dass möglicherweise vortrainierte Wortebene-Einbettungen für diese Aufgabe besser geeignet sind als Zeichenebenen- oder Unterwortebene-Einbettungen, wenn sie direkt eingesetzt werden.", "metrics": {"bleu_score": 22.654999077204756, "chrf_score": 65.01759662427658, "xcomet_score": 0.6328284740447998, "xcomet_qe_score": 0.6514139771461487, "metricx_score": 9.05422306060791, "metricx_qe_score": 9.313044548034668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Ob vielversprechend, deuten diese Ergebnisse auf beträchtliche Verbesserungsmöglichkeiten hin, im Vergleich zu einem erfahrenen Juristen, der letztendlich alle relevanten Artikel zu jeder Fragestellung abrufen und somit perfekte Ergebnisse erzielen kann.", "metrics": {"bleu_score": 28.929041574103515, "chrf_score": 63.829268827103945, "xcomet_score": 0.9563347101211548, "xcomet_qe_score": 0.9586405158042908, "metricx_score": 0.9667032361030579, "metricx_qe_score": 0.9269471168518066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns abschließend zwei Einschränkungen aller Datensätze besprechen.", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 52.30130845255611, "xcomet_score": 0.9395738840103149, "xcomet_qe_score": 0.9316513538360596, "metricx_score": 3.0436573028564453, "metricx_qe_score": 1.8907723426818848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf diejenigen Artikel beschränkt, die aus den 32 berücksichtigten belgischen Kodizes entnommen wurden. Dies erfasst jedoch nicht das gesamte belgische Recht, da Artikel aus Dekreten, Richtlinien und Verordnungen fehlen.", "metrics": {"bleu_score": 44.910995009687426, "chrf_score": 71.21494709714412, "xcomet_score": 0.9942500591278076, "xcomet_qe_score": 0.9861437082290649, "metricx_score": 1.0458893775939941, "metricx_qe_score": 1.1952306032180786, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Verweise auf diese unbearbeiteten Artikel ignoriert, was dazu führt, dass einige Suchanfragen letztendlich nur noch einen Bruchteil der anfänglich relevanten Artikel liefern.", "metrics": {"bleu_score": 33.69508435740044, "chrf_score": 60.13273069796401, "xcomet_score": 0.9642881155014038, "xcomet_qe_score": 0.9571516513824463, "metricx_score": 1.8455393314361572, "metricx_qe_score": 1.639611005783081, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsverlust impliziert, dass die in den verbleibenden relevanten Artikeln enthaltene Antwort möglicherweise unvollständig ist, obwohl sie dennoch vollkommen angemessen ist.", "metrics": {"bleu_score": 14.881641751055097, "chrf_score": 65.03438979101544, "xcomet_score": 0.9679973125457764, "xcomet_qe_score": 0.9502992033958435, "metricx_score": 1.692258596420288, "metricx_qe_score": 1.9006580114364624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens ist anzumerken, dass nicht alle Rechtsfragen allein mit Gesetzen beantwortet werden können.", "metrics": {"bleu_score": 51.00714853814581, "chrf_score": 69.91243161258794, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09590335190296173, "metricx_qe_score": 0.2322302609682083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel die Frage, ob man seinen Mietern die Kündigung aussprechen kann, wenn diese zu viel Lärm verursachen?", "metrics": {"bleu_score": 13.65914929695546, "chrf_score": 60.083416847004344, "xcomet_score": 0.9610340595245361, "xcomet_qe_score": 0.9600843191146851, "metricx_score": 0.4454394280910492, "metricx_qe_score": 0.3580508232116699, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Es könnte sein, dass es im Gesetz keinen detaillierten Ausführungsbestimmungen gibt, die einen spezifischen Lärmpegel festlegen, ab dem eine Räumung zulässig ist.", "metrics": {"bleu_score": 21.94409743742214, "chrf_score": 57.35288766327516, "xcomet_score": 0.9591464996337891, "xcomet_qe_score": 0.9606868028640747, "metricx_score": 0.5403361320495605, "metricx_qe_score": 0.5714510679244995, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter sich wahrscheinlich stärker auf die Rechtsprechung stützen und Präzedenzfälle finden, die seiner aktuellen Situation ähneln.", "metrics": {"bleu_score": 45.02202390333309, "chrf_score": 77.93145886652168, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.23245738446712494, "metricx_qe_score": 0.19522951543331146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Der Mieter veranstaltet zwei Partys pro Woche bis zwei Uhr morgens.", "metrics": {"bleu_score": 61.73028691712478, "chrf_score": 71.96725086305344, "xcomet_score": 0.8973166346549988, "xcomet_qe_score": 0.8893753886222839, "metricx_score": 1.3743845224380493, "metricx_qe_score": 0.602257490158081, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser für die gesetzliche Artikelsuche geeignet als andere, und der Bereich der weniger geeigneten muss noch bestimmt werden.", "metrics": {"bleu_score": 21.485473484453124, "chrf_score": 55.5130487001711, "xcomet_score": 0.960568904876709, "xcomet_qe_score": 0.8561480045318604, "metricx_score": 1.5754201412200928, "metricx_qe_score": 1.7919573783874512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass alle Arbeiten Interesse wecken an der Entwicklung praktischer und zuverlässiger Modelle zur Gewinnung von Gesetzesartikeln.", "metrics": {"bleu_score": 41.709417232262034, "chrf_score": 72.29659920932427, "xcomet_score": 0.9353504180908203, "xcomet_qe_score": 0.9375276565551758, "metricx_score": 3.439173936843872, "metricx_qe_score": 2.494473934173584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "das dazu beitragen kann, den Zugang zur Justiz für alle zu verbessern.", "metrics": {"bleu_score": 74.19446627365011, "chrf_score": 87.44241398096229, "xcomet_score": 0.9258643388748169, "xcomet_qe_score": 0.9839063882827759, "metricx_score": 2.4480040073394775, "metricx_qe_score": 1.5926707983016968, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unser Paper, die zugehörigen Datensätze und den Code unter folgenden Links einsehen. Vielen Dank.", "metrics": {"bleu_score": 47.473549111732495, "chrf_score": 69.24957058592372, "xcomet_score": 0.9825286865234375, "xcomet_qe_score": 0.9985003471374512, "metricx_score": 3.7553627490997314, "metricx_qe_score": 2.312459945678711, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Sehr geehrte Damen und Herren,\n\nwir freuen uns, Ihnen unsere Arbeit zu Vowls vorzustellen, einem aufgabenunabhängigen Benchmark, der dazu dient, Vision- und Sprachmodelle anhand spezifischer linguistischer Phänomene zu testen.", "metrics": {"bleu_score": 23.65366891976307, "chrf_score": 54.84726975350709, "xcomet_score": 0.7848817110061646, "xcomet_qe_score": 0.7971148490905762, "metricx_score": 5.427303791046143, "metricx_qe_score": 5.407341480255127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark einzurichten?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998863935470581, "xcomet_qe_score": 0.9992614984512329, "metricx_score": 0.20635683834552765, "metricx_qe_score": 0.29098349809646606, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Nun, in den letzten Jahren haben wir eine Explosion von transformatorbasierten Vision- und Sprachmodellen erlebt, die auf großen Mengen von Bild-Text-Paaren vortrainiert wurden.", "metrics": {"bleu_score": 43.32008456263298, "chrf_score": 73.59546704907707, "xcomet_score": 0.9538336992263794, "xcomet_qe_score": 0.9737261533737183, "metricx_score": 2.4837522506713867, "metricx_qe_score": 2.3857572078704834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle verbessert den aktuellen Stand der Technik bei Aufgaben in den Bereichen Vision und Sprache, wie z.B. visuelles Fragebeantwortungssystem, visuelles Common-Sense-Reasoning, Bildabruf und Phrasenlokalisierung.", "metrics": {"bleu_score": 20.01167415873742, "chrf_score": 46.100473988366296, "xcomet_score": 0.8790450096130371, "xcomet_qe_score": 0.9047663807868958, "metricx_score": 3.3978331089019775, "metricx_qe_score": 2.901463270187378, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Also haben wir die Botschaft erhalten. Die Genauigkeiten bei diesen aufgaben-spezifischen Benchmarks steigen stetig.", "metrics": {"bleu_score": 10.197627106738862, "chrf_score": 65.29959908963555, "xcomet_score": 0.9822144508361816, "xcomet_qe_score": 0.9575159549713135, "metricx_score": 1.407226800918579, "metricx_qe_score": 1.715425729751587, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5102907419204712, "metricx_qe_score": 0.9778188467025757, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was genau verstand ein Vision-Language-Transformer, als er diesem Bild und diesem Satz eine hohe Übereinstimmung zuwies?", "metrics": {"bleu_score": 10.11945757660757, "chrf_score": 46.154870427700715, "xcomet_score": 0.8649851083755493, "xcomet_qe_score": 0.9229248762130737, "metricx_score": 1.1434242725372314, "metricx_qe_score": 0.8090669512748718, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "und die niedrige Bewertung dafür.", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 32.34064998432814, "xcomet_score": 0.9565343856811523, "xcomet_qe_score": 0.9668792486190796, "metricx_score": 1.4511585235595703, "metricx_qe_score": 1.0011112689971924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Visions- und Sprachmodelle auf das Wesentliche?", "metrics": {"bleu_score": 20.90067144241745, "chrf_score": 69.65621340003754, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3381624221801758, "metricx_qe_score": 0.2980896830558777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Verzerrungen, wie aus vorangegangener Forschung ersichtlich ist?", "metrics": {"bleu_score": 52.960749334062214, "chrf_score": 58.932040683845024, "xcomet_score": 0.9961044788360596, "xcomet_qe_score": 0.9380069971084595, "metricx_score": 0.361770898103714, "metricx_qe_score": 0.6976105570793152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt weiter zu beleuchten, schlagen wir einen stärker aufgabenunabhängigen Ansatz vor und führen Ventile ein, die die Sensitivität von Vision- und Sprachmodellen gegenüber spezifischen linguistischen Phänomenen testen, die sowohl die sprachliche als auch die visuelle Modalität beeinflussen.", "metrics": {"bleu_score": 23.164807310511666, "chrf_score": 61.33149569993005, "xcomet_score": 0.7686434388160706, "xcomet_qe_score": 0.8076244592666626, "metricx_score": 4.403619766235352, "metricx_qe_score": 3.683739185333252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir adressieren Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und die Ko-Referenz von Entitäten.", "metrics": {"bleu_score": 42.08598069524091, "chrf_score": 69.43846659932763, "xcomet_score": 0.9331076145172119, "xcomet_qe_score": 0.9528789520263672, "metricx_score": 1.7963409423828125, "metricx_qe_score": 2.2532317638397217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle diese Phänomene erfasst haben?", "metrics": {"bleu_score": 18.010019776510696, "chrf_score": 58.27132232830024, "xcomet_score": 0.9880971312522888, "xcomet_qe_score": 0.9893398284912109, "metricx_score": 1.2659409046173096, "metricx_qe_score": 0.7758669853210449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch das Foiling, eine Methode, die zuvor lediglich für Vision- und Sprachmodelle auf Nominalphrasen von Ravi Shakar und Mitarbeitern sowie von uns in früheren Arbeiten zur Zählung angewendet wurde.", "metrics": {"bleu_score": 15.815783405728006, "chrf_score": 54.636018889923996, "xcomet_score": 0.7762205600738525, "xcomet_qe_score": 0.8287414312362671, "metricx_score": 4.032983779907227, "metricx_qe_score": 3.664834976196289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Das Foilen bedeutet im Grunde, dass wir die Bildunterschrift nehmen und ein Gegenstück erstellen, indem wir die Bildunterschrift so verändern, dass sie das Bild nicht mehr beschreibt.", "metrics": {"bleu_score": 58.38575482179785, "chrf_score": 67.55565080937731, "xcomet_score": 0.9195148348808289, "xcomet_qe_score": 0.9694231748580933, "metricx_score": 3.435436248779297, "metricx_qe_score": 1.6211717128753662, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Phrasenänderungen durch, indem wir uns auf sechs spezifische Aspekte konzentrieren, wie beispielsweise Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entität-Koreferenz, wobei jeder Aspekt aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit finden, Folieninstanzen zu erzeugen.", "metrics": {"bleu_score": 51.35263910932554, "chrf_score": 76.78428049353893, "xcomet_score": 0.7653547525405884, "xcomet_qe_score": 0.7863614559173584, "metricx_score": 4.189754009246826, "metricx_qe_score": 3.1008360385894775, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Im Falle der Aktionsphrase haben wir zwei Konstrukte: eines, bei dem das Aktionsverb durch ein anderes ersetzt wird, und eines, bei dem die Aktanten ausgetauscht werden.", "metrics": {"bleu_score": 48.75363238194211, "chrf_score": 60.64320294618057, "xcomet_score": 0.935112476348877, "xcomet_qe_score": 0.9285848140716553, "metricx_score": 2.0232975482940674, "metricx_qe_score": 1.7791237831115723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Auch Zählen und Koreferenz sind Elemente, die mehr als ein Instrument umfassen.", "metrics": {"bleu_score": 45.72313446186435, "chrf_score": 67.42582015004113, "xcomet_score": 0.9269233345985413, "xcomet_qe_score": 0.8826777338981628, "metricx_score": 0.7854487895965576, "metricx_qe_score": 1.3551151752471924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir erzeugen diese Folien, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalisch korrekt und anderweitig gültige Sätze sind.", "metrics": {"bleu_score": 56.74773954614978, "chrf_score": 69.70305598772606, "xcomet_score": 0.8711141347885132, "xcomet_qe_score": 0.9058352112770081, "metricx_score": 3.8045449256896973, "metricx_qe_score": 2.2487430572509766, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach zu bewerkstelligen, da eine unterlötliche Bildunterschrift seltener sein kann als die ursprüngliche Bildunterschrift.", "metrics": {"bleu_score": 39.67088290836578, "chrf_score": 59.67773702860789, "xcomet_score": 0.9619346857070923, "xcomet_qe_score": 0.9617710113525391, "metricx_score": 5.714497089385986, "metricx_qe_score": 5.504390716552734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Ob es ausgeschlossen ist, ist es dennoch statistisch unwahrscheinlicher, dass Pflanzen einen Menschen verletzen, als dass ein Mensch Pflanzen verletzt, und große Sprach- und Visionmodelle könnten dies erkennen.", "metrics": {"bleu_score": 35.14747704023461, "chrf_score": 63.88044241416897, "xcomet_score": 0.8291566371917725, "xcomet_qe_score": 0.8735452890396118, "metricx_score": 7.619172096252441, "metricx_qe_score": 6.156876564025879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Daher müssen wir Maßnahmen ergreifen, um gültige Folien zu erhalten.", "metrics": {"bleu_score": 15.580105704117443, "chrf_score": 43.8251646982806, "xcomet_score": 0.914238691329956, "xcomet_qe_score": 0.9424629211425781, "metricx_score": 2.5128772258758545, "metricx_qe_score": 1.7270570993423462, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst setzen wir leistungsstarke Sprachmodelle ein, um Gegenentwürfe vorzuschlagen.", "metrics": {"bleu_score": 11.731175160263996, "chrf_score": 57.978875804583765, "xcomet_score": 0.9366036653518677, "xcomet_qe_score": 0.9789124727249146, "metricx_score": 0.6861486434936523, "metricx_qe_score": 0.6629177331924438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir Natural Language Inference, kurz NLI, um Ablenkobjekte herauszufiltern, die das Bild weiterhin beschreiben könnten, da wir bei der Konstruktion von Ablenkobjekten sicherstellen müssen, dass diese das Bild nicht beschreiben.", "metrics": {"bleu_score": 32.860782724612314, "chrf_score": 63.96540285128731, "xcomet_score": 0.8645709156990051, "xcomet_qe_score": 0.9358770251274109, "metricx_score": 4.788776874542236, "metricx_qe_score": 4.1931891441345215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisiert zu testen, wenden wir Natural Language Inference mit folgender Begründung an.", "metrics": {"bleu_score": 24.978982998684547, "chrf_score": 52.55037783401224, "xcomet_score": 0.8584754467010498, "xcomet_qe_score": 0.9638240933418274, "metricx_score": 3.018543243408203, "metricx_qe_score": 2.7888474464416504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Bildunterschrift als die daraus resultierende Hypothese.", "metrics": {"bleu_score": 64.1386525898168, "chrf_score": 75.84556907035325, "xcomet_score": 0.9998757839202881, "xcomet_qe_score": 1.0, "metricx_score": 0.24654972553253174, "metricx_qe_score": 0.2858521342277527, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus betrachten wir die Bildunterschrift als Prämiss und das Gegenstück als ihre Hypothese.", "metrics": {"bleu_score": 43.33207865423753, "chrf_score": 68.23165486920578, "xcomet_score": 0.8308014869689941, "xcomet_qe_score": 0.8902367353439331, "metricx_score": 0.835037350654602, "metricx_qe_score": 0.5645159482955933, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass das Ablenkobjekt im Widerspruch zum oder neutral gegenüber der Bildunterschrift steht, betrachten wir dies als Indikator für ein valides Ablenkobjekt.", "metrics": {"bleu_score": 22.50265947708922, "chrf_score": 51.99155333884651, "xcomet_score": 0.8782687187194824, "xcomet_qe_score": 0.9548639059066772, "metricx_score": 5.029438018798828, "metricx_qe_score": 2.3630480766296387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn eine NLI vorhersagt, dass das Ablenkerelement durch die Bildunterschrift impliziert wird, kann es kein gutes Ablenkerelement sein, da es durch Transitivität eine wahrheitsgemäße Beschreibung des Bildes liefern würde und wir diese Ablenkerelemente herausfiltern.", "metrics": {"bleu_score": 28.85724214902815, "chrf_score": 59.54888024106623, "xcomet_score": 0.7537261247634888, "xcomet_qe_score": 0.9145278930664062, "metricx_score": 4.487947463989258, "metricx_qe_score": 3.9009573459625244, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Doch diese Prozedur ist nicht perfekt. Sie ist lediglich ein Indikator für gültige Folie.", "metrics": {"bleu_score": 19.56475149792291, "chrf_score": 44.220693006709, "xcomet_score": 0.8116384744644165, "xcomet_qe_score": 0.834915280342102, "metricx_score": 3.922170400619507, "metricx_qe_score": 2.0378530025482178, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher setzen wir als dritte Maßnahme zur Erzeugung valider Testmuster menschliche Annotatoren ein, um die in den Validierungsdatensätzen verwendeten Daten zu validieren.", "metrics": {"bleu_score": 62.742088451809494, "chrf_score": 72.1128075151642, "xcomet_score": 0.9337248802185059, "xcomet_qe_score": 0.9314669370651245, "metricx_score": 1.3412965536117554, "metricx_qe_score": 1.475714087486267, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Filterung und menschlichen Bewertung haben wir so viele Testinstanzen wie in dieser Tabelle beschrieben.", "metrics": {"bleu_score": 35.316761612979036, "chrf_score": 68.38194687732626, "xcomet_score": 0.9971933364868164, "xcomet_qe_score": 0.9774442911148071, "metricx_score": 0.4844144284725189, "metricx_qe_score": 0.7066419124603271, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "VALS stellt keine Trainingsdaten bereit, sondern ausschließlich Testdaten.", "metrics": {"bleu_score": 8.804351806809393, "chrf_score": 49.95673148686581, "xcomet_score": 0.9819048047065735, "xcomet_qe_score": 0.9950305223464966, "metricx_score": 0.6553981304168701, "metricx_qe_score": 1.278916835784912, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich um einen Zero-Shot-Test-Benchmark handelt, ist er dazu konzipiert, die vorhandenen Fähigkeiten von Vision- und Sprachmodellen nach dem Vortraining zu nutzen.", "metrics": {"bleu_score": 33.09068084615651, "chrf_score": 73.34059309679571, "xcomet_score": 0.955204963684082, "xcomet_qe_score": 0.940962553024292, "metricx_score": 1.6535887718200684, "metricx_qe_score": 1.9913482666015625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmung würde Modelle lediglich befähigen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen.", "metrics": {"bleu_score": 55.09947345130995, "chrf_score": 79.2060358979814, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3292797803878784, "metricx_qe_score": 0.411990225315094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir wissen alle, dass diese Modelle dazu neigen, zu schummeln und Abkürzungen zu nehmen.", "metrics": {"bleu_score": 16.153228406487216, "chrf_score": 69.5226629080548, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7351046800613403, "metricx_qe_score": 0.8624871969223022, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie bereits erwähnt, sind wir daran interessiert, zu beurteilen, welche Fähigkeiten die Modelle für Vision und Sprache nach dem Vortraining aufweisen.", "metrics": {"bleu_score": 18.4527128711065, "chrf_score": 60.95514714323333, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 1.77510666847229, "metricx_qe_score": 1.3261027336120605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Language-Modellen für Vokale, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin one und VisualBERT.", "metrics": {"bleu_score": 29.968202984848773, "chrf_score": 51.37440835913871, "xcomet_score": 0.5337026119232178, "xcomet_qe_score": 0.510501503944397, "metricx_score": 7.537809371948242, "metricx_qe_score": 7.750189304351807, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satz-Paaren in Bildunterschriften und Ablenkern.", "metrics": {"bleu_score": 46.09603493497927, "chrf_score": 70.17443800046998, "xcomet_score": 0.9566291570663452, "xcomet_qe_score": 0.8547865152359009, "metricx_score": 1.8410574197769165, "metricx_qe_score": 2.2807741165161133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Für dieses Video möglicherweise relevanter ist die Demonstration unserer permissiveren Metrik, der paarweisen Genauigkeit, welche misst, ob die Übereinstimmungsbewertung von Bild und Satz für das korrekte Bild-Text-Paar höher ist als für dessen verfälschtes Pendant.", "metrics": {"bleu_score": 18.072843363234426, "chrf_score": 54.28408795398328, "xcomet_score": 0.9362257719039917, "xcomet_qe_score": 0.9143722057342529, "metricx_score": 1.9951717853546143, "metricx_qe_score": 1.7345768213272095, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Metriken und Ergebnisse dazu verweisen wir auf unser Papier.", "metrics": {"bleu_score": 22.416933501922287, "chrf_score": 63.588521252179675, "xcomet_score": 0.9358353614807129, "xcomet_qe_score": 0.9253038763999939, "metricx_score": 0.4478376507759094, "metricx_qe_score": 0.5647417306900024, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse bezüglich der paarweisen Genauigkeit werden hier dargestellt und stimmen mit den Ergebnissen überein, die wir anhand der anderen Metriken erzielt haben. Es scheint, dass Wilbert twelve in one die beste Zero-Shot-Performance erzielt, gefolgt von Wilbert, Alex Mert, Clip und schließlich VisualBird.", "metrics": {"bleu_score": 25.947865623329648, "chrf_score": 60.831896650301374, "xcomet_score": 0.5456513166427612, "xcomet_qe_score": 0.5836563110351562, "metricx_score": 6.466216087341309, "metricx_qe_score": 6.165368556976318, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nominalphrasen konzentrieren, durch Wilbert Twelve in One fast vollständig gelöst sind, was darauf hinweist, dass Modelle in der Lage sind, benannte Objekte und deren Vorhandensein in Bildern zu identifizieren.", "metrics": {"bleu_score": 50.27523975438432, "chrf_score": 66.71163626480357, "xcomet_score": 0.8561680316925049, "xcomet_qe_score": 0.8382186889648438, "metricx_score": 3.780243158340454, "metricx_qe_score": 3.181985855102539, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Jedoch können keines der verbleibenden Puzzleteile in unseren adversarial-foiling-Umgebungen zuverlässig gelöst werden.", "metrics": {"bleu_score": 24.19557280471989, "chrf_score": 57.91540315252479, "xcomet_score": 0.8969604969024658, "xcomet_qe_score": 0.8814119100570679, "metricx_score": 3.801055431365967, "metricx_qe_score": 2.953367233276367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen aus der Vielzahl von Zählwerkzeugen, dass Vision- und Sprachmodelle Schwierigkeiten haben, Referenzen auf einzelne versus mehrfache Objekte zu unterscheiden oder sie in einem Bild zu zählen.", "metrics": {"bleu_score": 45.32118515137504, "chrf_score": 64.8636859963902, "xcomet_score": 0.8692063093185425, "xcomet_qe_score": 0.7929531931877136, "metricx_score": 3.3341176509857178, "metricx_qe_score": 2.6772189140319824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Relation Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Relation zwischen Objekten in einem Bild korrekt zu klassifizieren.", "metrics": {"bleu_score": 73.78351342269066, "chrf_score": 84.50995086100652, "xcomet_score": 0.8823722004890442, "xcomet_qe_score": 0.8456829786300659, "metricx_score": 3.3901114463806152, "metricx_qe_score": 3.2838239669799805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben zudem Schwierigkeiten, Handlungen zu unterscheiden und ihre Akteure zu identifizieren, selbst wenn dies durch Glaubwürdigkeitsheuristiken unterstützt wird, wie wir im Abschnitt zu Handlungen sehen.", "metrics": {"bleu_score": 39.41622338155528, "chrf_score": 63.904127033609356, "xcomet_score": 0.9805386066436768, "xcomet_qe_score": 0.9398241639137268, "metricx_score": 0.919854998588562, "metricx_qe_score": 0.9114927053451538, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus der Analyse der Koreferenzinformationen geht hervor, dass auch für Vision- und Sprachmodelle die Verfolgung mehrerer Bezüge auf dasselbe Objekt in einem Bild mithilfe von Pronomen eine Herausforderung darstellt.", "metrics": {"bleu_score": 31.334523900626223, "chrf_score": 62.87221410860574, "xcomet_score": 0.9448038935661316, "xcomet_qe_score": 0.9167215824127197, "metricx_score": 1.3411649465560913, "metricx_qe_score": 1.192594289779663, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als einen Realitätscheck und da es sich außerdem um ein interessantes Experiment handelt, haben wir auch zwei Text-Only-Modelle, GPT eins und GPT zwei, evaluiert, um zu prüfen, ob das Valves-Problem durch diese unimodalen Modelle lösbar ist. Dies geschieht durch die Berechnung der Perplexität der korrekten und der vereitelten Bildunterschrift – hier kein Bild – und die Vorhersage des Eintrags mit der niedrigsten Perplexität.", "metrics": {"bleu_score": 23.492965061730647, "chrf_score": 58.2889638059499, "xcomet_score": 0.7936771512031555, "xcomet_qe_score": 0.806102991104126, "metricx_score": 4.8155741691589355, "metricx_qe_score": 4.675376892089844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Perplexität für die Ablenkungsoption höher ist, interpretieren wir dies als Hinweis darauf, dass die abgelenkte Bildunterschrift unter Plausibilitätsvoreingenommenheit oder anderen sprachlichen Voreingenommenheiten leiden könnte.", "metrics": {"bleu_score": 14.557496889528018, "chrf_score": 52.832960136694176, "xcomet_score": 0.9009385704994202, "xcomet_qe_score": 0.8803574442863464, "metricx_score": 6.290896415710449, "metricx_qe_score": 4.795899391174316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu beobachten, dass in manchen Fällen lediglich GPT-Modelle die Plausibilität der Welt besser erfasst haben als Vision- und Sprachmodelle.", "metrics": {"bleu_score": 38.795967525063965, "chrf_score": 70.37073812607349, "xcomet_score": 0.9540908336639404, "xcomet_qe_score": 0.954572319984436, "metricx_score": 4.43729829788208, "metricx_qe_score": 4.175185680389404, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VALSE ein Benchmark ist, der die Linse linguistischer Konstrukte nutzt, um die Community bei der Verbesserung von Vision- und Sprachmodellen zu unterstützen, indem seine visuellen Grounding-Fähigkeiten rigoros geprüft werden.", "metrics": {"bleu_score": 47.237467930803064, "chrf_score": 68.29198751341062, "xcomet_score": 0.9028655886650085, "xcomet_qe_score": 0.911986231803894, "metricx_score": 5.241839408874512, "metricx_qe_score": 4.72539758682251, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Vision- und Sprachmodelle benannte Objekte und deren Vorhandensein in Bildern gut identifizieren, wie das existierende Stück zeigt, aber Schwierigkeiten haben, ihre wechselseitige Abhängigkeit und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu beachten.", "metrics": {"bleu_score": 47.159679495942584, "chrf_score": 73.06620251104306, "xcomet_score": 0.8578601479530334, "xcomet_qe_score": 0.8551408052444458, "metricx_score": 4.858422756195068, "metricx_qe_score": 4.325009346008301, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community sehr gerne dazu ermutigen, Vals zur Messung des Fortschritts bei der sprachlichen Verankerung mit Vision- und Sprachmodellen zu nutzen.", "metrics": {"bleu_score": 33.21678143250398, "chrf_score": 68.05230638607426, "xcomet_score": 0.7916510105133057, "xcomet_qe_score": 0.8635503649711609, "metricx_score": 3.1814393997192383, "metricx_qe_score": 4.514121055603027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch wichtiger ist, dass Ventile als eine indirekte Bewertung von Datensätzen dienen können, da Modelle vor und nach dem Training oder Feintuning evaluiert werden können, um festzustellen, ob ein Datensatz dazu beiträgt, dass Modelle in Bezug auf die Aspekte, die von Ventilen geprüft werden, verbessert werden.", "metrics": {"bleu_score": 33.891986382057816, "chrf_score": 62.24867774872781, "xcomet_score": 0.728961706161499, "xcomet_qe_score": 0.7630159854888916, "metricx_score": 8.953316688537598, "metricx_qe_score": 8.660713195800781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, werfen Sie bitte einen Blick auf die VALSE-Daten auf GitHub. Bei Fragen zögern Sie bitte nicht, uns zu kontaktieren.", "metrics": {"bleu_score": 30.666475493383864, "chrf_score": 57.2580364476206, "xcomet_score": 0.9986728429794312, "xcomet_qe_score": 1.0, "metricx_score": 0.43706727027893066, "metricx_qe_score": 0.5339916348457336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, mein Name ist Kamisara, von der Universität Tokio.", "metrics": {"bleu_score": 48.44273237963865, "chrf_score": 72.4649759448025, "xcomet_score": 0.8484604358673096, "xcomet_qe_score": 0.8591925501823425, "metricx_score": 3.6263210773468018, "metricx_qe_score": 3.033175230026245, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Beitrag vorstellen mit dem Titel „R und Summe – Analyse eines großen Datensatzes zur automatischen Risikobewertung anstelle von Dauerbewertung durch logarithmische Summierung“.", "metrics": {"bleu_score": 3.435812002459847, "chrf_score": 28.261556048366298, "xcomet_score": 0.6003644466400146, "xcomet_qe_score": 0.6610321402549744, "metricx_score": 6.911102771759033, "metricx_qe_score": 7.599416732788086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erläutern.", "metrics": {"bleu_score": 27.890014303843827, "chrf_score": 71.2297392568974, "xcomet_score": 0.9984606504440308, "xcomet_qe_score": 0.9946349859237671, "metricx_score": 0.6730481386184692, "metricx_qe_score": 1.1522901058197021, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikoneutralisierung vorstellen, an der wir im Rahmen dieser Forschung arbeiten.", "metrics": {"bleu_score": 54.03204364769616, "chrf_score": 73.31666197183941, "xcomet_score": 0.7584599256515503, "xcomet_qe_score": 0.7763926982879639, "metricx_score": 5.789534568786621, "metricx_qe_score": 4.65115213394165, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Release Notes sind ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Version eines Softwareprodukts vertrieben werden.", "metrics": {"bleu_score": 84.55987220158333, "chrf_score": 85.74026048955471, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.4624202251434326, "metricx_qe_score": 1.1187723875045776, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt einen Forschungsbericht für Bajan zwei Punkt sechs.", "metrics": {"bleu_score": 25.965358893403383, "chrf_score": 32.41378216545676, "xcomet_score": 0.1747695356607437, "xcomet_qe_score": 0.20837144553661346, "metricx_score": 13.134857177734375, "metricx_qe_score": 15.709406852722168, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Serious Bibliotheken. Diese Knoten spielen eine wichtige Rolle in der Open-Source-Entwicklung, sind aber zeitaufwendig in der manuellen Erstellung.", "metrics": {"bleu_score": 10.108901518669624, "chrf_score": 61.186699269355174, "xcomet_score": 0.586563229560852, "xcomet_qe_score": 0.48622602224349976, "metricx_score": 11.259199142456055, "metricx_qe_score": 13.292316436767578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Da wäre es daher äußerst nützlich, Versionshinweise von hoher Qualität automatisch generieren zu können.", "metrics": {"bleu_score": 8.225964699966557, "chrf_score": 52.63173509981183, "xcomet_score": 0.9994724988937378, "xcomet_qe_score": 0.9965710639953613, "metricx_score": 0.38289666175842285, "metricx_qe_score": 0.5139636397361755, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mich auf zwei frühere Forschungsarbeiten zur automatischen Risiko­nicht­generierung beziehen.", "metrics": {"bleu_score": 12.192091596713041, "chrf_score": 51.03852377932759, "xcomet_score": 0.7511003017425537, "xcomet_qe_score": 0.7814216613769531, "metricx_score": 11.400662422180176, "metricx_qe_score": 9.85262680053711, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens Arena, das im Jahr 2014 veröffentlicht wurde. Es ist", "metrics": {"bleu_score": 45.27471870952891, "chrf_score": 62.919275527374595, "xcomet_score": 0.9222451448440552, "xcomet_qe_score": 0.8562582731246948, "metricx_score": 4.655970096588135, "metricx_qe_score": 1.039899468421936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es erfordert einen regelbasierten Ansatz, beispielsweise die Verwendung eines Änderungs-Extraktors, um Kernunterschiede, Bibliotheksänderungen und Dokumentationsänderungen aus den Unterschieden zwischen Releases zu extrahieren und diese abschließend zusammenzuführen.", "metrics": {"bleu_score": 15.565601603723767, "chrf_score": 62.894705496514845, "xcomet_score": 0.9269356727600098, "xcomet_qe_score": 0.9676891565322876, "metricx_score": 0.9227699041366577, "metricx_qe_score": 0.7472876310348511, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das auffälligste Merkmal dieses Systems ist der Issue-Extraktor in der oberen rechten Ecke.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 73.99906989083412, "xcomet_score": 0.8405122756958008, "xcomet_qe_score": 0.8606997132301331, "metricx_score": 3.5601298809051514, "metricx_qe_score": 4.184730529785156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Das muss mit Null verknüpft sein, um das Problem des Ökosystems anzugehen und kann nur auf Projekte angewendet werden, die Null verwenden.", "metrics": {"bleu_score": 35.668376829411216, "chrf_score": 55.39369149643735, "xcomet_score": 0.595669150352478, "xcomet_qe_score": 0.5487909317016602, "metricx_score": 15.96023941040039, "metricx_qe_score": 17.071910858154297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "hier. Anders ausgedrückt, es kann für viele Projekte auf GitHub nicht verwendet werden.", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 64.17858780152504, "xcomet_score": 0.8801695108413696, "xcomet_qe_score": 0.8683212995529175, "metricx_score": 2.4449243545532227, "metricx_qe_score": 2.899303674697876, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Punkt ist Trauer. Dieser Eintrag angekündigt in vierundzwanzig.", "metrics": {"bleu_score": 5.063996506781411, "chrf_score": 30.2027742331693, "xcomet_score": 0.5220434665679932, "xcomet_qe_score": 0.5310239195823669, "metricx_score": 17.914413452148438, "metricx_qe_score": 15.09627628326416, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Zwanzig Zwanzig. Es ist im Internet verfügbar und kann über PIP gespeichert werden.", "metrics": {"bleu_score": 52.025568808075846, "chrf_score": 72.65628964955071, "xcomet_score": 0.6447360515594482, "xcomet_qe_score": 0.6322594881057739, "metricx_score": 8.651634216308594, "metricx_qe_score": 10.543161392211914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, auf Laufzeit basierendes Textklassifikationsmodell und weist eine Form von fünf Labels – wie beispielsweise Features oder Bugfixes – für jede eingegebene Commit-Nachricht zu.", "metrics": {"bleu_score": 31.37211787812663, "chrf_score": 64.53334399925372, "xcomet_score": 0.9248827695846558, "xcomet_qe_score": 0.922166109085083, "metricx_score": 4.267268180847168, "metricx_qe_score": 3.8991620540618896, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Beispiel für eine Nutzung, die einen Korrekturmechanismus oder Fehlerbehebungs-Rebell zurückgibt.", "metrics": {"bleu_score": 9.103526405546068, "chrf_score": 55.963354275947175, "xcomet_score": 0.7575395703315735, "xcomet_qe_score": 0.7497419714927673, "metricx_score": 5.445652961730957, "metricx_qe_score": 5.206457614898682, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsdaten von Graves sind relativ klein und umfassen etwa fünf tausend Elemente, die in den nachfolgenden Experimenten verwendet werden.", "metrics": {"bleu_score": 10.26602363535547, "chrf_score": 46.09650669617453, "xcomet_score": 0.8075199127197266, "xcomet_qe_score": 0.8356790542602539, "metricx_score": 4.27217960357666, "metricx_qe_score": 5.571563243865967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistungsfähigkeit des statistischen Grafikplanungsmodells ist nicht höher.", "metrics": {"bleu_score": 11.99014838091355, "chrf_score": 51.96445798739232, "xcomet_score": 0.549812912940979, "xcomet_qe_score": 0.8002750873565674, "metricx_score": 7.514713287353516, "metricx_qe_score": 9.405122756958008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungsarbeiten, jedoch bestehen Probleme hinsichtlich der eingeschränkten Anwendbarkeit und knapper Datenressourcen.", "metrics": {"bleu_score": 11.589920791732357, "chrf_score": 64.5588550910594, "xcomet_score": 0.9793882369995117, "xcomet_qe_score": 1.0, "metricx_score": 0.06863760948181152, "metricx_qe_score": 0.10009263455867767, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Beitrag löst diese beiden Probleme und generiert automatisch hochwertige Versionshinweise.", "metrics": {"bleu_score": 18.15193004998874, "chrf_score": 63.56999015924971, "xcomet_score": 0.9467394351959229, "xcomet_qe_score": 0.9547514915466309, "metricx_score": 0.5930741429328918, "metricx_qe_score": 0.5757352113723755, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das Programm mit begrenzter Anwendbarkeit schlagen wir eine hochwertige Klassifizierungsmethodik zur Zusammenfassung vor, die ausschließlich auf die Ausgaben eines Komitees als Eingabe verwendet.", "metrics": {"bleu_score": 22.743363869750482, "chrf_score": 58.721740454644625, "xcomet_score": 0.8613547086715698, "xcomet_qe_score": 0.8130664825439453, "metricx_score": 8.067110061645508, "metricx_qe_score": 7.962859153747559, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischsprachigen Repositories verwendet werden.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 94.41091479316094, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.24755816161632538, "metricx_qe_score": 0.5410935878753662, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem knapper Datenressourcen erstellten wir einen RNSM-Datensatz, der etwa achtzigtausend Datenelemente umfasst, indem wir Daten aus öffentlichen GitHub-Repositories mithilfe der GitHub API sammelten.", "metrics": {"bleu_score": 17.34606741431802, "chrf_score": 61.553428478960406, "xcomet_score": 0.9986705780029297, "xcomet_qe_score": 1.0, "metricx_score": 1.3743525743484497, "metricx_qe_score": 1.4527578353881836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich unsere Wüste.", "metrics": {"bleu_score": 13.540372457315735, "chrf_score": 56.65371525150881, "xcomet_score": 0.7790601253509521, "xcomet_qe_score": 0.7862811088562012, "metricx_score": 7.6902995109558105, "metricx_qe_score": 8.631659507751465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel für unsere Daten.", "metrics": {"bleu_score": 59.4603557501361, "chrf_score": 81.41181438781946, "xcomet_score": 0.9848619699478149, "xcomet_qe_score": 0.9775080680847168, "metricx_score": 0.16544672846794128, "metricx_qe_score": 0.4477199614048004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist eine Commit-Nachricht und die rechte Seite ein Release-Hinweis.", "metrics": {"bleu_score": 25.82106689274053, "chrf_score": 55.59527695027269, "xcomet_score": 0.8998810052871704, "xcomet_qe_score": 0.8679523468017578, "metricx_score": 1.1636229753494263, "metricx_qe_score": 1.0302106142044067, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund, warum Notizen als Verbesserungen, Büros usw. geschätzt werden.", "metrics": {"bleu_score": 13.912311644176565, "chrf_score": 37.64294206816521, "xcomet_score": 0.22794564068317413, "xcomet_qe_score": 0.2595282793045044, "metricx_score": 19.09766960144043, "metricx_qe_score": 17.15708351135254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Commit-Nachrichten als Eingabe entgegennimmt und die unbearbeiteten Stücklisten-Notizen übertrifft.", "metrics": {"bleu_score": 41.83971038082779, "chrf_score": 63.719467279062535, "xcomet_score": 0.7586603760719299, "xcomet_qe_score": 0.7102756500244141, "metricx_score": 7.225205421447754, "metricx_qe_score": 6.057192802429199, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als eine Zusammenfassungaufgabe betrachtet werden.", "metrics": {"bleu_score": 50.000000000000014, "chrf_score": 93.57668560693398, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.03291880711913109, "metricx_qe_score": 0.07775469124317169, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Release-Features definiert: Verbesserungen, Fehlerbehebungen, Veraltungungen, Entfernungen und inkompatible Änderungen.", "metrics": {"bleu_score": 22.045650580086985, "chrf_score": 57.009699855826035, "xcomet_score": 0.7154595851898193, "xcomet_qe_score": 0.7601873874664307, "metricx_score": 4.515480995178223, "metricx_qe_score": 3.616398334503174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden auf Grundlage vorheriger Forschung und anderer Faktoren festgelegt.", "metrics": {"bleu_score": 21.0205253640269, "chrf_score": 69.7321135319204, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0859128087759018, "metricx_qe_score": 0.1298033893108368, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund dafür ist, dass die Notizen unten rechts aus den auf der linken Seite unten angezeigten Notizen extrahiert werden.", "metrics": {"bleu_score": 5.618923497225256, "chrf_score": 40.18787774783463, "xcomet_score": 0.9582175016403198, "xcomet_qe_score": 0.9053689241409302, "metricx_score": 3.1766650676727295, "metricx_qe_score": 4.3419928550720215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit ist es erforderlich, die vier zuvor eingerichteten Mülltonnen zu identifizieren.", "metrics": {"bleu_score": 6.423054510688479, "chrf_score": 24.246617579498526, "xcomet_score": 0.8039180636405945, "xcomet_qe_score": 0.8675354719161987, "metricx_score": 4.344189167022705, "metricx_qe_score": 3.9503626823425293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "aber das Gelächter ist nicht immer mit jeder Freiheit vereinbar.", "metrics": {"bleu_score": 14.991106946711685, "chrf_score": 33.112543674098085, "xcomet_score": 0.1256040334701538, "xcomet_qe_score": 0.10541810095310211, "metricx_score": 11.068963050842285, "metricx_qe_score": 8.365804672241211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Die Verbesserung durch den Treiber umfasst Verbesserungen, Erweiterungen, Optimierungen und dergleichen.", "metrics": {"bleu_score": 38.720157050710164, "chrf_score": 62.80403979914845, "xcomet_score": 0.8811849355697632, "xcomet_qe_score": 0.8626450300216675, "metricx_score": 3.150786876678467, "metricx_qe_score": 4.05301570892334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir erstellten für jede dieser Rotationsvarianten einen Wortschatz von etwa dreißig Zahlen.", "metrics": {"bleu_score": 12.661968357569915, "chrf_score": 57.70620408412349, "xcomet_score": 0.7259589433670044, "xcomet_qe_score": 0.809919536113739, "metricx_score": 9.070357322692871, "metricx_qe_score": 8.924041748046875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Nutzen Sie es, um das RIS zu erkennen, nicht die Krusten, und korrigieren Sie den restlichen Text entsprechend, da das RIS nicht der Satz für die Kruste ist.", "metrics": {"bleu_score": 4.180647946097228, "chrf_score": 27.21063427265083, "xcomet_score": 0.1399015486240387, "xcomet_qe_score": 0.12977062165737152, "metricx_score": 14.315751075744629, "metricx_qe_score": 12.337373733520508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes folgt eine Mitteilung des Ausschusses.", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 52.27051693738643, "xcomet_score": 0.8141655325889587, "xcomet_qe_score": 0.8496471643447876, "metricx_score": 5.343667984008789, "metricx_qe_score": 5.346264362335205, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Commit-Nachrichten sind nicht jeder einzelne Komponente zugeordnet.", "metrics": {"bleu_score": 19.493995755254467, "chrf_score": 59.38851533175368, "xcomet_score": 0.9384115934371948, "xcomet_qe_score": 0.9705687761306763, "metricx_score": 1.9788752794265747, "metricx_qe_score": 2.570110559463501, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der folgenden Abbildung dargestellt, ist der aktuelle Risikowert zwischen eintausendzweihundertfünf und neunzehn, müssen wir identifizieren", "metrics": {"bleu_score": 5.397468255995315, "chrf_score": 35.726659855345105, "xcomet_score": 0.3530580997467041, "xcomet_qe_score": 0.506492555141449, "metricx_score": 20.256284713745117, "metricx_qe_score": 19.659658432006836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Die vorherige Release-Version 2.5.2-18 einchecken und die Differenz ermitteln. Dies ist etwas mühsam, und es reicht nicht aus, lediglich eine Liste der Releases abzurufen und die Zustände vor und nach dem Vergleich anzusehen.", "metrics": {"bleu_score": 20.6651003266767, "chrf_score": 50.60342888897091, "xcomet_score": 0.8502620458602905, "xcomet_qe_score": 0.8183923959732056, "metricx_score": 7.256543159484863, "metricx_qe_score": 7.2007365226745605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er entwickelte eine Heuristik zur Farbanpassung von Blau, um die vorherige und nächste Schönheitskönigin zu ermitteln.", "metrics": {"bleu_score": 23.287896954139942, "chrf_score": 38.355362139920665, "xcomet_score": 0.3005705177783966, "xcomet_qe_score": 0.1973559409379959, "metricx_score": 13.352173805236816, "metricx_qe_score": 8.936075210571289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind sie, die Pferde.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 10.50727259570157, "xcomet_score": 0.12412470579147339, "xcomet_qe_score": 0.09917774796485901, "metricx_score": 5.151971340179443, "metricx_qe_score": 9.658624649047852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende waren es sieben tausend zweihundert Repositories.", "metrics": {"bleu_score": 10.147104008451905, "chrf_score": 38.276037108572716, "xcomet_score": 0.8927619457244873, "xcomet_qe_score": 0.8449629545211792, "metricx_score": 9.22396183013916, "metricx_qe_score": 13.274299621582031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus beträgt die durchschnittliche Anzahl der freigegebenen Knotentoken sechzig drei, was für eine Zusammenfassungaufgabe recht hoch ist.", "metrics": {"bleu_score": 35.95818888322725, "chrf_score": 65.79472928197474, "xcomet_score": 0.8722529411315918, "xcomet_qe_score": 0.8785040378570557, "metricx_score": 5.830876350402832, "metricx_qe_score": 4.137535572052002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Anzahl eindeutiger Token ist mit achtundachtzigtausenddreißigtausend beträchtlich. Dies ist eines der", "metrics": {"bleu_score": 19.104081613647544, "chrf_score": 42.05786494611014, "xcomet_score": 0.7497553825378418, "xcomet_qe_score": 0.708645224571228, "metricx_score": 6.143985271453857, "metricx_qe_score": 4.213557243347168, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl einzigartiger Klassen und Methoden, die im Repertorium gefunden wurden.", "metrics": {"bleu_score": 3.716499092256817, "chrf_score": 34.50560644009546, "xcomet_score": 0.9238916039466858, "xcomet_qe_score": 0.9245599508285522, "metricx_score": 1.2096428871154785, "metricx_qe_score": 1.148777961730957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes werde ich die vorgeschlagene Methode erläutern.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das querverlaufende, extraktive und abstrakte Summarisierungsmodell besteht aus zwei neueren Modulen.", "metrics": {"bleu_score": 17.474335703431752, "chrf_score": 55.64505691341224, "xcomet_score": 0.7871333360671997, "xcomet_qe_score": 0.8221263885498047, "metricx_score": 5.918342590332031, "metricx_qe_score": 5.945894241333008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifikator unter Verwendung eines Bots oder Code-Bots und ein Generator unter Verwendung eines Bots.", "metrics": {"bleu_score": 12.451643194233869, "chrf_score": 54.934964035427, "xcomet_score": 0.6408954858779907, "xcomet_qe_score": 0.641504168510437, "metricx_score": 8.337440490722656, "metricx_qe_score": 9.347890853881836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Kreuzwert, um jede Komitee-Nachricht in fünf Disnode-Klassen einzuteilen: Features, Verbesserungen, Fehlerbehebungen, Duplikate, Pluspunkte und Sonstiges.", "metrics": {"bleu_score": 14.505280277256835, "chrf_score": 46.98529360399942, "xcomet_score": 0.5441712737083435, "xcomet_qe_score": 0.5318869948387146, "metricx_score": 10.649994850158691, "metricx_qe_score": 10.2083158493042, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als Sonstiges klassifizierten Komitee-Nachrichten werden verworfen.", "metrics": {"bleu_score": 25.848657697858535, "chrf_score": 63.13488120164435, "xcomet_score": 0.9138315916061401, "xcomet_qe_score": 0.8505795001983643, "metricx_score": 3.570948600769043, "metricx_qe_score": 3.665945529937744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet GES den Generator unabhängig auf die vier Router-Dokumente an und generiert für jede Klasse Risikohinweise.", "metrics": {"bleu_score": 17.102846954548706, "chrf_score": 55.794886789363, "xcomet_score": 0.6998115181922913, "xcomet_qe_score": 0.7410707473754883, "metricx_score": 7.546914100646973, "metricx_qe_score": 7.942502021789551, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Entsprechungen zwischen Commit-Nachrichten und Lesehinweisen nicht bekannt.", "metrics": {"bleu_score": 53.33505353503043, "chrf_score": 77.00592384616233, "xcomet_score": 0.7993861436843872, "xcomet_qe_score": 0.8182448148727417, "metricx_score": 1.081460952758789, "metricx_qe_score": 1.8408814668655396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Daher weisen wir dem Klassifikator zur Schulung Pseudorubine für jede Eingabe-Commit-Nachricht zu, indem wir die ersten zehn Zeichen jeder Commit-Nachricht verwenden.", "metrics": {"bleu_score": 21.640699500167496, "chrf_score": 58.72481279598354, "xcomet_score": 0.788672685623169, "xcomet_qe_score": 0.796775758266449, "metricx_score": 8.318777084350586, "metricx_qe_score": 8.587081909179688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die querverlaufende zusammenfassende Übersicht, also den Ansatz, mit zwei verschiedenen Methoden.", "metrics": {"bleu_score": 3.6570159134143823, "chrf_score": 47.992556152435526, "xcomet_score": 0.8581768274307251, "xcomet_qe_score": 0.9038283824920654, "metricx_score": 6.355873107910156, "metricx_qe_score": 6.2732319831848145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzelnen Sekt-zu-Sekt-Netzwerk und generiert einen einzigen, langen isNote-Text, ausgehend von einer konkreten Eingabe von Commit-Nachrichten.", "metrics": {"bleu_score": 34.59894910015056, "chrf_score": 64.60851416194015, "xcomet_score": 0.5630307793617249, "xcomet_qe_score": 0.49943339824676514, "metricx_score": 14.192573547363281, "metricx_qe_score": 15.50261116027832, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Die Ausgabetext kann in quer verlaufende Segmente unterteilt werden, \nbasierend auf speziellen, kreuzspezifischen Endpunktsymbolen.", "metrics": {"bleu_score": 10.521495173810226, "chrf_score": 52.06747312709838, "xcomet_score": 0.8564417958259583, "xcomet_qe_score": 0.8653256893157959, "metricx_score": 6.133608818054199, "metricx_qe_score": 5.9119062423706055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir CSMarch nennen, besteht aus vier verschiedenen sec-to-sec-Netzwerken, die jeweils einer der List-Node-Klassen entsprechen.", "metrics": {"bleu_score": 42.76621024875847, "chrf_score": 62.077365274272466, "xcomet_score": 0.6105647087097168, "xcomet_qe_score": 0.6141690611839294, "metricx_score": 10.586730003356934, "metricx_qe_score": 10.458536148071289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das erklärt Fans Experiment.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 36.82617140297801, "xcomet_score": 0.8116499185562134, "xcomet_qe_score": 0.876292884349823, "metricx_score": 6.906456470489502, "metricx_qe_score": 5.262182712554932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen: CAS, CAS einzeln, CAS Mund, Prasseling und frühere Studienübersicht.", "metrics": {"bleu_score": 22.617373614366574, "chrf_score": 52.89452289127529, "xcomet_score": 0.6779521703720093, "xcomet_qe_score": 0.5959830284118652, "metricx_score": 12.801539421081543, "metricx_qe_score": 13.759961128234863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich Abtreibung werden diese Notizen in manchen Fällen in mehreren Sätzen ausgegeben.", "metrics": {"bleu_score": 23.909302951697416, "chrf_score": 46.065348577152314, "xcomet_score": 0.8063246011734009, "xcomet_qe_score": 0.8214951753616333, "metricx_score": 13.919320106506348, "metricx_qe_score": 7.456855297088623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen verbunden und als ein langer Satz behandelt.", "metrics": {"bleu_score": 65.98997557898731, "chrf_score": 80.20364101908358, "xcomet_score": 0.8746601343154907, "xcomet_qe_score": 0.8764029741287231, "metricx_score": 5.120721340179443, "metricx_qe_score": 6.254330158233643, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro wird durchdrungen, wenn das System einen kurzen Satz ausgibt.", "metrics": {"bleu_score": 66.52049901111006, "chrf_score": 64.95396607963228, "xcomet_score": 0.7861229181289673, "xcomet_qe_score": 0.78817218542099, "metricx_score": 10.322484016418457, "metricx_qe_score": 10.717365264892578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Brühvolumen in den nachfolgend beschriebenen experimentellen Ergebnissen.", "metrics": {"bleu_score": 26.58483576665878, "chrf_score": 58.846225736863936, "xcomet_score": 0.79487144947052, "xcomet_qe_score": 0.8202712535858154, "metricx_score": 5.518232822418213, "metricx_qe_score": 5.546098232269287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend korrelieren wir ebenfalls eine Spezifität, da Rot und Blau nicht korreliert werden können, wenn die Freigabeknoten leer sind.", "metrics": {"bleu_score": 28.261688976967957, "chrf_score": 48.38876912019239, "xcomet_score": 0.8604946136474609, "xcomet_qe_score": 0.8763387799263, "metricx_score": 7.361082553863525, "metricx_qe_score": 6.661812782287598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell korrekt leeren Text ausgibt, wenn die Begründungsnotizen Leerwerte annehmen.", "metrics": {"bleu_score": 24.798668260840483, "chrf_score": 52.19069057156555, "xcomet_score": 0.9745045900344849, "xcomet_qe_score": 0.9856587648391724, "metricx_score": 3.5377910137176514, "metricx_qe_score": 2.1625962257385254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse.", "metrics": {"bleu_score": 42.72870063962342, "chrf_score": 48.96283815298874, "xcomet_score": 0.9982582330703735, "xcomet_qe_score": 0.9951757192611694, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, vernichten wir auch den ausgedruckten Datensatz, der diese ausschließt.", "metrics": {"bleu_score": 64.87354270629037, "chrf_score": 78.67676001517893, "xcomet_score": 0.7448960542678833, "xcomet_qe_score": 0.7239847183227539, "metricx_score": 8.323514938354492, "metricx_qe_score": 7.8126959800720215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat Luftmesswerte erzielt, die um mehr als zehn Punkte über dem Referenzwert liegen.", "metrics": {"bleu_score": 27.22589423069701, "chrf_score": 40.7909446202467, "xcomet_score": 0.6543818712234497, "xcomet_qe_score": 0.7735073566436768, "metricx_score": 7.294485569000244, "metricx_qe_score": 7.637252330780029, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem grünen Testdatensatz sprang der quadratische Abstand zwischen der vorgeschlagenen Methode und dem Basisend auf mehr als zwanzig Punkte.", "metrics": {"bleu_score": 39.81101537239463, "chrf_score": 65.8587353054658, "xcomet_score": 0.7022834420204163, "xcomet_qe_score": 0.7185809016227722, "metricx_score": 9.455081939697266, "metricx_qe_score": 8.0439453125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse deuten darauf hin, dass sie und sie signifikant effektiv sind.", "metrics": {"bleu_score": 10.571070857151541, "chrf_score": 50.167600057994896, "xcomet_score": 0.21594172716140747, "xcomet_qe_score": 0.30029383301734924, "metricx_score": 12.574975967407227, "metricx_qe_score": 11.719698905944824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS erzielte einen besseren Rouge F-Wert als GAS, was darauf hindeutet, dass die Kombination eines Crossfires und eines Generators effektiv bei der Ausbildung des Crossfires mit Pseudobus ist.", "metrics": {"bleu_score": 33.949793453048855, "chrf_score": 58.228750494075584, "xcomet_score": 0.3347495198249817, "xcomet_qe_score": 0.3574911952018738, "metricx_score": 16.75897789001465, "metricx_qe_score": 17.166580200195312, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Abdeckung von GAS kann vermutlich dadurch erreicht werden, dass der Klassifikator sich darauf konzentrieren kann, für jede Klasse relevante Commit-Nachrichten auszuwählen.", "metrics": {"bleu_score": 20.61487201475908, "chrf_score": 68.94987715040227, "xcomet_score": 0.8111538887023926, "xcomet_qe_score": 0.8705427646636963, "metricx_score": 4.466128349304199, "metricx_qe_score": 5.484832286834717, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie wird dieses Jahr deutlich mehr essen als ledig.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 13.853395910563766, "xcomet_score": 0.11868644505739212, "xcomet_qe_score": 0.10595300793647766, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "was es ebenso wirksam sein könnte, für jedes Blickwinkels Notizgras unabhängig voneinander verschiedene Modellierungen zur Zusammenfassung über einen Zeitraum von zwei Jahren zu entwickeln.", "metrics": {"bleu_score": 7.79287571344171, "chrf_score": 45.71667074184817, "xcomet_score": 0.14750516414642334, "xcomet_qe_score": 0.15238846838474274, "metricx_score": 21.252500534057617, "metricx_qe_score": 20.022802352905273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Held und Eronasus", "metrics": {"bleu_score": 0.0, "chrf_score": 7.279375851520527, "xcomet_score": 0.20181190967559814, "xcomet_qe_score": 0.07988241314888, "metricx_score": 12.229496002197266, "metricx_qe_score": 21.2924861907959, "linguapy_score": [1, "ESTONIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xia's Methoden neigen dazu, kürzere Sätze zu erzeugen als Referenzsätze, die von Menschen verfasst wurden.", "metrics": {"bleu_score": 5.401157445454033, "chrf_score": 46.347855927663666, "xcomet_score": 0.8180805444717407, "xcomet_qe_score": 0.8225452899932861, "metricx_score": 3.458059787750244, "metricx_qe_score": 5.542179584503174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung rechts besteht der Referenzsatz aus drei oder vier Sätzen, während sie nur einen hat.", "metrics": {"bleu_score": 69.92829827815706, "chrf_score": 83.16270358421392, "xcomet_score": 0.8964582681655884, "xcomet_qe_score": 0.8328440189361572, "metricx_score": 4.375381946563721, "metricx_qe_score": 3.976447343826294, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzögerlichkeit ist, dass in den Trainingsdaten lediglich 33 % der Sätze in den Feature-Rubble und 40 % in den Verbesserungs-Rubble vorhanden sind.", "metrics": {"bleu_score": 24.41029622672016, "chrf_score": 50.25823874913456, "xcomet_score": 0.7339357733726501, "xcomet_qe_score": 0.7913932204246521, "metricx_score": 7.031785488128662, "metricx_qe_score": 7.177130699157715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES-Methoden ohne zusätzliche Informationen keine präzisen Risikobeurteilungen erstellen.", "metrics": {"bleu_score": 34.172334076593074, "chrf_score": 72.93585374065123, "xcomet_score": 0.7984039783477783, "xcomet_qe_score": 0.9031287431716919, "metricx_score": 3.9732236862182617, "metricx_qe_score": 3.0033535957336426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr unstrukturierte Mitteilung eines Ausschusses, und der vollständige Satz kann nicht generiert werden, ohne Bezugnahme auf die entsprechende Peru-Anfrage oder das Problem.", "metrics": {"bleu_score": 36.79055644576981, "chrf_score": 64.72332428520205, "xcomet_score": 0.7242910861968994, "xcomet_qe_score": 0.7233446836471558, "metricx_score": 10.340911865234375, "metricx_qe_score": 9.052282333374023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden Commit-Nachrichten in der Eingabe inhaltlich zusammengehören und zu einem Satz zusammengefasst werden sollten, dies jedoch nicht geschieht.", "metrics": {"bleu_score": 69.43209557830426, "chrf_score": 86.49335531775705, "xcomet_score": 0.9985967874526978, "xcomet_qe_score": 0.9986953735351562, "metricx_score": 0.44135814905166626, "metricx_qe_score": 0.7843931913375854, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend ein Fazit.", "metrics": {"bleu_score": 19.37692912686648, "chrf_score": 22.22550862450243, "xcomet_score": 0.9979766607284546, "xcomet_qe_score": 0.9868476390838623, "metricx_score": 0.12389075756072998, "metricx_qe_score": 0.03616045415401459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben ein neues Desk-Set für die automatische, personalisierte Generierung entwickelt.", "metrics": {"bleu_score": 15.727800941615351, "chrf_score": 51.98790939398125, "xcomet_score": 0.7021266222000122, "xcomet_qe_score": 0.679273247718811, "metricx_score": 6.773138523101807, "metricx_qe_score": 6.490085124969482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben uns ferner die Aufgabe gestellt, die Protokolle der Ausschüsse zu erfassen und zusammenzufassen, sodass sie für alle auf Englisch verfassten Projekte anwendbar sind.", "metrics": {"bleu_score": 26.43589525275459, "chrf_score": 48.733025283021114, "xcomet_score": 0.8900805711746216, "xcomet_qe_score": 0.8598352670669556, "metricx_score": 3.497950553894043, "metricx_qe_score": 2.543790340423584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode die besten verrauschten Begründungen nicht bei höherer Abdeckung als der Basislinie erzeugte.", "metrics": {"bleu_score": 35.61099807298961, "chrf_score": 63.182782853248, "xcomet_score": 0.7306634783744812, "xcomet_qe_score": 0.7427743077278137, "metricx_score": 7.722209930419922, "metricx_qe_score": 7.2195305824279785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte werfen Sie einen Blick auf unsere App zur Wüstenprüfung.", "metrics": {"bleu_score": 5.300156689756295, "chrf_score": 27.515205178371605, "xcomet_score": 0.4096716642379761, "xcomet_qe_score": 0.26634734869003296, "metricx_score": 6.923261642456055, "metricx_qe_score": 7.92039680480957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 87.72426647426647, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Safarari.", "metrics": {"bleu_score": 13.540372457315735, "chrf_score": 54.470301149696, "xcomet_score": 0.7555389404296875, "xcomet_qe_score": 0.734178900718689, "metricx_score": 5.610824108123779, "metricx_qe_score": 5.1651225090026855, "linguapy_score": [1, "ROMANIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unseren Artikel präsentieren: \"Few-Shot Tabellarische Datenanreicherung durch Feinabstimmung von Transformer-Architekturen.\"", "metrics": {"bleu_score": 3.2342452920962157, "chrf_score": 44.11419794276135, "xcomet_score": 0.8332476615905762, "xcomet_qe_score": 0.8702572584152222, "metricx_score": 4.330444812774658, "metricx_qe_score": 5.664970397949219, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Bearbeitung bestehender Merkmale.", "metrics": {"bleu_score": 52.812131374276895, "chrf_score": 72.57480699182383, "xcomet_score": 0.9887481927871704, "xcomet_qe_score": 0.9874833822250366, "metricx_score": 1.7915674448013306, "metricx_qe_score": 1.7699990272521973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen eingeschränkt.", "metrics": {"bleu_score": 27.77619034011791, "chrf_score": 62.176143357615935, "xcomet_score": 0.9869257211685181, "xcomet_qe_score": 0.9872435331344604, "metricx_score": 0.24367955327033997, "metricx_qe_score": 0.2614205479621887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Merkmalsgenerierung unter Verwendung einer anderen Datenquelle kann erhebliche Informationen liefern.", "metrics": {"bleu_score": 39.085161980674464, "chrf_score": 66.220726743675, "xcomet_score": 0.9662615060806274, "xcomet_qe_score": 0.979095458984375, "metricx_score": 0.49694159626960754, "metricx_qe_score": 0.3191392421722412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung tabellarischer Daten unter Verwendung von freiem Text aus externen Quellen.", "metrics": {"bleu_score": 69.64705665515706, "chrf_score": 91.67285270551058, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.23275642096996307, "metricx_qe_score": 0.3829061985015869, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben einen tabellarischen Datensatz und eine Wissensbasis.", "metrics": {"bleu_score": 73.61703354503862, "chrf_score": 87.5218203054179, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.16129517555236816, "metricx_qe_score": 0.22525914013385773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatisierten Prozess, der die Entitätserkennung und Textanalyse umfasst, um neue Merkmale aus dem freitextbasierten Wissensbestand zu extrahieren.", "metrics": {"bleu_score": 25.182193972686342, "chrf_score": 60.61428872102926, "xcomet_score": 0.9958059787750244, "xcomet_qe_score": 0.9968000650405884, "metricx_score": 0.5739733576774597, "metricx_qe_score": 0.6161917448043823, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework ist zunächst einmal genau dieser automatische Prozess.", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 66.4471771812067, "xcomet_score": 0.9280855059623718, "xcomet_qe_score": 0.9229410886764526, "metricx_score": 2.857262372970581, "metricx_qe_score": 4.042954921722412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Betrachten wir also ein Beispiel. In einem Datensatz wird es in FAST eingespeist.", "metrics": {"bleu_score": 12.802091018942972, "chrf_score": 59.07368821123063, "xcomet_score": 0.8751271367073059, "xcomet_qe_score": 0.8587246537208557, "metricx_score": 5.140000343322754, "metricx_qe_score": 5.280529499053955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Datensatz ein Hochschuldatensatz.", "metrics": {"bleu_score": 61.04735835807847, "chrf_score": 69.11856665348995, "xcomet_score": 0.999046802520752, "xcomet_qe_score": 0.9938042163848877, "metricx_score": 0.3661983907222748, "metricx_qe_score": 0.18683511018753052, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "wenn es darauf abzielt, Universitäten in niedrigrangige Universitäten und hochrangige Universitäten einzuteilen.", "metrics": {"bleu_score": 7.141816289329644, "chrf_score": 46.21618428452975, "xcomet_score": 0.929269552230835, "xcomet_qe_score": 0.9507719874382019, "metricx_score": 0.5390571355819702, "metricx_qe_score": 0.37677091360092163, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase von FEST ist die Entitätserkennung.", "metrics": {"bleu_score": 33.03164318013809, "chrf_score": 54.59270316705541, "xcomet_score": 0.8157185316085815, "xcomet_qe_score": 0.8002421855926514, "metricx_score": 3.6479270458221436, "metricx_qe_score": 4.152540683746338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "wenn jede Entität in diesem Beispiel, der Name der Universität, mit einer Entität innerhalb der Wissensbasis verknüpft ist.", "metrics": {"bleu_score": 54.10822690539394, "chrf_score": 87.11875991455962, "xcomet_score": 0.9586775302886963, "xcomet_qe_score": 0.9697237014770508, "metricx_score": 0.8074097037315369, "metricx_qe_score": 0.5089381337165833, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Wissensdatenbank wird extrahiert und dem Datensatz hinzugefügt.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 81.767360179553, "xcomet_score": 0.9777982831001282, "xcomet_qe_score": 0.9698386788368225, "metricx_score": 0.8740183115005493, "metricx_qe_score": 1.0021990537643433, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "Please provide the English text you want me to translate. I am ready when you are.", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 14.41428666450076, "xcomet_score": 0.160020649433136, "xcomet_qe_score": 0.16238999366760254, "metricx_score": 5.795701026916504, "metricx_qe_score": 3.6639530658721924, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Nun müssen wir Merkmale aus dem Retriever-Text generieren oder extrahieren.", "metrics": {"bleu_score": 34.53155548318878, "chrf_score": 63.98391559603801, "xcomet_score": 0.9082878232002258, "xcomet_qe_score": 0.9564100503921509, "metricx_score": 2.6036884784698486, "metricx_qe_score": 2.44445538520813, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Da benötigen wir also eine Phase der Feature-Extraktion, die eine Textanalyse umfasst.", "metrics": {"bleu_score": 19.684661233415397, "chrf_score": 48.85739241230087, "xcomet_score": 0.9858436584472656, "xcomet_qe_score": 0.997536301612854, "metricx_score": 4.551178455352783, "metricx_qe_score": 4.050971031188965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ist die Hauptneuheit dieser Arbeit, und ich werde in den nächsten Folien detailliert darauf eingehen.", "metrics": {"bleu_score": 11.268706361337427, "chrf_score": 43.22927557100127, "xcomet_score": 0.9771889448165894, "xcomet_qe_score": 0.9816554188728333, "metricx_score": 0.8838775157928467, "metricx_qe_score": 0.5360499620437622, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Merkmalsextraktionsphase folgt eine Merkmalsgenerierungsphase, in der wir die extrahierten Merkmale verwenden, um eine geringe Anzahl neuer Merkmale zu generieren.", "metrics": {"bleu_score": 31.274576035513448, "chrf_score": 54.32746935830804, "xcomet_score": 0.9563009738922119, "xcomet_qe_score": 0.9873381853103638, "metricx_score": 0.3686760365962982, "metricx_qe_score": 0.34214308857917786, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst werden Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes generiert.", "metrics": {"bleu_score": 75.39221180326287, "chrf_score": 78.75186003161342, "xcomet_score": 0.9084546566009521, "xcomet_qe_score": 0.9001879692077637, "metricx_score": 2.388313055038452, "metricx_qe_score": 2.943331241607666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel besitzt der ursprüngliche Datensatz zwei Klassen.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 90.13072260741531, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.016208626329898834, "metricx_qe_score": 0.20251250267028809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst also zwei neue Merkmale erzeugen.", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 39.38618825433576, "xcomet_score": 0.8831860423088074, "xcomet_qe_score": 0.8849543333053589, "metricx_score": 3.499605655670166, "metricx_qe_score": 3.2427384853363037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen aufweist, generieren Sie zunächst fünf neue Merkmale.", "metrics": {"bleu_score": 38.50322886878713, "chrf_score": 65.69380653320886, "xcomet_score": 0.8943959474563599, "xcomet_qe_score": 0.943703830242157, "metricx_score": 3.30256986618042, "metricx_qe_score": 3.6387534141540527, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jedes Merkmal repräsentiert die Wahrscheinlichkeit für jede Klasse.", "metrics": {"bleu_score": 41.80134288483487, "chrf_score": 66.03373064615856, "xcomet_score": 0.9946569204330444, "xcomet_qe_score": 0.9989062547683716, "metricx_score": 0.4736848473548889, "metricx_qe_score": 0.4538906514644623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Zur Analyse des Textes verwenden wir den aktuellen Stand der Technik der Textanalyse, beispielsweise Transformer-basierte Sprachmodelle wie BERT, GPT, XLEDs usw.", "metrics": {"bleu_score": 18.25898262695709, "chrf_score": 57.37871172104383, "xcomet_score": 0.900439977645874, "xcomet_qe_score": 0.8949083685874939, "metricx_score": 3.686591863632202, "metricx_qe_score": 4.765151023864746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir Sprachmodelle anhand der vorliegenden Datensätze trainieren können.", "metrics": {"bleu_score": 36.15855225145533, "chrf_score": 70.86367229014407, "xcomet_score": 0.991065502166748, "xcomet_qe_score": 0.989443302154541, "metricx_score": 0.6281458735466003, "metricx_qe_score": 0.8344877362251282, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wäre daher ein Feinabstimmung auf die Zielaufgabe.", "metrics": {"bleu_score": 15.851165692617148, "chrf_score": 50.31742031916342, "xcomet_score": 0.9752411842346191, "xcomet_qe_score": 0.9676204919815063, "metricx_score": 2.193761110305786, "metricx_qe_score": 3.2020928859710693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Merkmalsextraktion können wir also pro Trainingssprache ein Sprachmodell herunterladen und dieses anschließend über den Zielkorpus feinabstimmen.", "metrics": {"bleu_score": 21.992062963866637, "chrf_score": 63.44889874991829, "xcomet_score": 0.9026690721511841, "xcomet_qe_score": 0.9461548328399658, "metricx_score": 1.0634160041809082, "metricx_qe_score": 1.2703851461410522, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel zur Feinabstimmung des Sprachmodells, um Text in Klassen einzuteilen, abstrahiert in Klassen, niedrig oder hoch.", "metrics": {"bleu_score": 34.78721564491432, "chrf_score": 61.130217701926256, "xcomet_score": 0.866265058517456, "xcomet_qe_score": 0.8606667518615723, "metricx_score": 5.975860118865967, "metricx_qe_score": 4.4648261070251465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Ausgabewerte des Sprachmodells, welche die Wahrscheinlichkeit für jede Klasse darstellen, und verwenden Sie diese als neue Merkmale.", "metrics": {"bleu_score": 28.231469873854902, "chrf_score": 71.39345579063614, "xcomet_score": 0.9066693782806396, "xcomet_qe_score": 0.9565615057945251, "metricx_score": 1.263978362083435, "metricx_qe_score": 0.5578786134719849, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem mit diesem Ansatz besteht darin, dass Datensätze möglicherweise nur wenige unterschiedliche Entitätsebenen aufweisen.", "metrics": {"bleu_score": 40.37211700637277, "chrf_score": 75.7691001120604, "xcomet_score": 0.976874828338623, "xcomet_qe_score": 0.9577062726020813, "metricx_score": 1.007090449333191, "metricx_qe_score": 1.1540350914001465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als vierhundert Stichproben, und der kleinste Datensatz enthielt fünfunddreißig Stichproben in seinem Trainingsdatensatz.", "metrics": {"bleu_score": 41.072675483179786, "chrf_score": 78.42027445935781, "xcomet_score": 0.9737445116043091, "xcomet_qe_score": 0.9722537994384766, "metricx_score": 0.7674388885498047, "metricx_qe_score": 0.9445554614067078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Da wird eine Feinabstimmung eines Sprachmodells anhand dieses Datensatzes ineffektiv sein.", "metrics": {"bleu_score": 13.545994273378144, "chrf_score": 61.09967006525786, "xcomet_score": 0.9824721813201904, "xcomet_qe_score": 0.9782622456550598, "metricx_score": 0.5109017491340637, "metricx_qe_score": 0.5041483640670776, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können Vorwissen über zuvor analysierte Datensätze nutzen.", "metrics": {"bleu_score": 35.54333944875169, "chrf_score": 61.50263388577423, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.06750959903001785, "metricx_qe_score": 0.15996965765953064, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir die Methode schnell auf mehrere Datensätze anwenden, können wir die N-1 Datensätze nutzen, um Informationen über diese N-1 Datensätze zu gewinnen, und diese Informationen bei der Analyse des n-ten Datensatzes verwenden.", "metrics": {"bleu_score": 33.611507604345704, "chrf_score": 65.6974363835408, "xcomet_score": 0.7221524715423584, "xcomet_qe_score": 0.705988883972168, "metricx_score": 3.1028966903686523, "metricx_qe_score": 2.712238311767578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist das Hinzufügen einer weiteren Feinabstimmungsphase.", "metrics": {"bleu_score": 4.9323515694897075, "chrf_score": 64.0960257272637, "xcomet_score": 0.9768882989883423, "xcomet_qe_score": 0.9627068042755127, "metricx_score": 0.8942621350288391, "metricx_qe_score": 1.0932095050811768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "eine vorbereitende Feinabstimmungsphase für mehrere Aufgaben.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 48.457325446247225, "xcomet_score": 0.9417084455490112, "xcomet_qe_score": 0.9321449995040894, "metricx_score": 1.7460345029830933, "metricx_qe_score": 0.9900100231170654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir während des Trainings des Sprachmodells über n minus eins Datensätzen feststellen,", "metrics": {"bleu_score": 6.754312828675707, "chrf_score": 45.26541478019397, "xcomet_score": 0.7724007368087769, "xcomet_qe_score": 0.8181605339050293, "metricx_score": 7.906898498535156, "metricx_qe_score": 6.075198173522949, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Feinabstimmungsphase durch, welche eine zielorientierte Feinabstimmung darstellt, bei der wir das Sprachmodell anhand des n-ten Zieldatensatzes feinabstimmen.", "metrics": {"bleu_score": 32.264018310483756, "chrf_score": 74.08835586523928, "xcomet_score": 0.9498767852783203, "xcomet_qe_score": 0.9320211410522461, "metricx_score": 1.093768835067749, "metricx_qe_score": 1.3535397052764893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der aktuelle Stand der Technik im Bereich Multitask-Feinabstimmung, bezeichnet als MTDNN.", "metrics": {"bleu_score": 4.065425428798724, "chrf_score": 49.83963041551792, "xcomet_score": 0.9890034794807434, "xcomet_qe_score": 0.9954284429550171, "metricx_score": 0.971946656703949, "metricx_qe_score": 1.7393296957015991, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN verwaltet MTDNN eine Kopfzahl für die Anzahl der Aufgaben im Trainingsdatensatz.", "metrics": {"bleu_score": 12.571192676522521, "chrf_score": 41.721714826655365, "xcomet_score": 0.8433462381362915, "xcomet_qe_score": 0.8972615003585815, "metricx_score": 6.0138373374938965, "metricx_qe_score": 4.048817157745361, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainingsdatensatz. Somit leeres DNN und vier Köpfe beibehalten, wie Sie im Bild sehen können.", "metrics": {"bleu_score": 46.22377023605668, "chrf_score": 66.26922969483351, "xcomet_score": 0.822540283203125, "xcomet_qe_score": 0.8404268026351929, "metricx_score": 9.369543075561523, "metricx_qe_score": 9.191216468811035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "und es wählt eine zufällige Stichprobe aus dem Trainingsdatensatz aus.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 50.657651700977, "xcomet_score": 0.9474618434906006, "xcomet_qe_score": 0.9385164976119995, "metricx_score": 1.756471037864685, "metricx_qe_score": 2.185042381286621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "und wenn die zufällige Stichprobe beispielsweise zu den Klassifikationsaufgaben von Sing und Seldom gehört, dann wird ein Vorwärts- und Rückwärtsdurchlauf durch den ersten Head ausgeführt.", "metrics": {"bleu_score": 4.668049023095242, "chrf_score": 51.4405071068501, "xcomet_score": 0.61838299036026, "xcomet_qe_score": 0.6014386415481567, "metricx_score": 8.483176231384277, "metricx_qe_score": 9.141475677490234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zur paarweisen Ranking-Aufgabe gehört, wird sie über den letzten Head sowohl in den Forward- als auch in den Backward-Pfad integriert.", "metrics": {"bleu_score": 15.450079547146164, "chrf_score": 44.42711943316329, "xcomet_score": 0.6667079925537109, "xcomet_qe_score": 0.8103780746459961, "metricx_score": 6.50206995010376, "metricx_qe_score": 5.791040897369385, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario variiert eine Tabelle von Datensätzen die Anzahl der Klassen.", "metrics": {"bleu_score": 27.968424579665367, "chrf_score": 70.45771935845295, "xcomet_score": 0.9231967926025391, "xcomet_qe_score": 0.8989845514297485, "metricx_score": 3.026820659637451, "metricx_qe_score": 3.0675973892211914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Da gibt es also viele Aufgaben.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 78.41621817853421, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.17848727107048035, "metricx_qe_score": 0.18479487299919128, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN behielt die Anzahl der Klassenüberschichten aus.", "metrics": {"bleu_score": 3.983253478176822, "chrf_score": 29.66314606712976, "xcomet_score": 0.6311389803886414, "xcomet_qe_score": 0.8163491487503052, "metricx_score": 9.383525848388672, "metricx_qe_score": 15.141904830932617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus muss MTDN neue Köpfe für einen neuen Datensatz mit einer neuen Aufgabe initialisieren.", "metrics": {"bleu_score": 61.000344570143675, "chrf_score": 70.56314249699945, "xcomet_score": 0.8802145719528198, "xcomet_qe_score": 0.9043592214584351, "metricx_score": 5.5652594566345215, "metricx_qe_score": 5.705242156982422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, genannt Task Reformulation Fine-Tuning, ist in unserem Ansatz Task Reformulation Fine-Tuning. Anstatt mehrere Köpfe beizubehalten, reformulieren wir jeden Datensatz in einen Satz pro Klassifizierungsproblem, also Aufgaben mit zwei Klassen.", "metrics": {"bleu_score": 22.254547462837923, "chrf_score": 56.98025825099234, "xcomet_score": 0.6112813949584961, "xcomet_qe_score": 0.6374461054801941, "metricx_score": 11.084433555603027, "metricx_qe_score": 9.409871101379395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Betrachten wir also ein Beispiel.", "metrics": {"bleu_score": 16.341219448835542, "chrf_score": 47.718806735895576, "xcomet_score": 0.9777318239212036, "xcomet_qe_score": 0.9799123406410217, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Datensatz, der aus Entitäten, Merkmalen, Text und Klassen besteht.", "metrics": {"bleu_score": 64.52121005104219, "chrf_score": 73.91125005285495, "xcomet_score": 0.9887470006942749, "xcomet_qe_score": 0.9876417517662048, "metricx_score": 0.8849254846572876, "metricx_qe_score": 0.6319785714149475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir werden die Aufgabe formulieren, indem wir den Text in niedrig und hoch einteilen, um den Text und die Kategorie in wahr oder falsch zu klassifizieren.", "metrics": {"bleu_score": 12.288887055424896, "chrf_score": 45.22152183925316, "xcomet_score": 0.7956573367118835, "xcomet_qe_score": 0.7839838266372681, "metricx_score": 5.554934978485107, "metricx_qe_score": 3.513214349746704, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten trainierten wir das Sprachmodell darauf, Abstracts zu klassifizieren und festzustellen, ob ein Abstract zur Klasse gehört oder nicht.", "metrics": {"bleu_score": 23.09306131373764, "chrf_score": 58.302440143125956, "xcomet_score": 0.596163809299469, "xcomet_qe_score": 0.4696919620037079, "metricx_score": 2.098418951034546, "metricx_qe_score": 4.053382396697998, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Labelvektor bleibt in diesem Fall also stets erhalten, bestehend aus jeweils zwei Klassen.", "metrics": {"bleu_score": 13.259061490238889, "chrf_score": 46.611890433584705, "xcomet_score": 0.9867140054702759, "xcomet_qe_score": 0.9913808107376099, "metricx_score": 1.287715196609497, "metricx_qe_score": 2.5590806007385254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ist der Algorithmus für unseren formulierten Feinabstimmungsansatz.", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 84.07190845269585, "xcomet_score": 0.8987321853637695, "xcomet_qe_score": 0.8500218987464905, "metricx_score": 2.6611199378967285, "metricx_qe_score": 3.136827230453491, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Betrachten wir nun das vollständige Rahmenwerk.", "metrics": {"bleu_score": 5.868924818816531, "chrf_score": 27.52459945751425, "xcomet_score": 0.9966695308685303, "xcomet_qe_score": 1.0, "metricx_score": 0.9867606163024902, "metricx_qe_score": 0.5908951759338379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und Datensatz verblasst rasch.", "metrics": {"bleu_score": 8.51528917838043, "chrf_score": 26.313915723921365, "xcomet_score": 0.14881958067417145, "xcomet_qe_score": 0.1430351436138153, "metricx_score": 5.844228267669678, "metricx_qe_score": 5.893082141876221, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Ausführungsphase der Entitätensverknüpfung.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 21.243394598590164, "xcomet_score": 0.8945186138153076, "xcomet_qe_score": 0.8471006155014038, "metricx_score": 5.838418006896973, "metricx_qe_score": 6.419821739196777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensdatenbank, welcher in diesem Beispiel der Abstract der Wikipedia-Seite ist.", "metrics": {"bleu_score": 54.75235665340891, "chrf_score": 81.62578399889972, "xcomet_score": 0.9690573215484619, "xcomet_qe_score": 0.9376806020736694, "metricx_score": 1.284095287322998, "metricx_qe_score": 1.6879109144210815, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann reformuliert es die Aufgabe in einen Satz pro Klassifikationsaufgabe.", "metrics": {"bleu_score": 25.965358893403383, "chrf_score": 68.55976815811405, "xcomet_score": 0.8468418121337891, "xcomet_qe_score": 0.8563846349716187, "metricx_score": 3.936727523803711, "metricx_qe_score": 3.992219924926758, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "wenden Sie das Sprachmodell auf die neue Aufgabe und die jeweilige Wahrscheinlichkeit für jede Klasse an.", "metrics": {"bleu_score": 37.709297891717654, "chrf_score": 72.79906183924538, "xcomet_score": 0.9325603246688843, "xcomet_qe_score": 0.9213892221450806, "metricx_score": 0.7043943405151367, "metricx_qe_score": 1.6672768592834473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "und beachten Sie, dass das Sprachmodell bereits über einem n-1 Datensatz mit einer vorläufigen multimodalen Feinabstimmung trainiert wurde.", "metrics": {"bleu_score": 14.81394578697113, "chrf_score": 58.08231562322016, "xcomet_score": 0.8007491230964661, "xcomet_qe_score": 0.8010207414627075, "metricx_score": 2.3186800479888916, "metricx_qe_score": 2.638887643814087, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verwenden wir den Ausgabevektor des Sprachmodells als neu generiertes Merkmal für die Anzahl der Klassen.", "metrics": {"bleu_score": 25.550175948550987, "chrf_score": 70.07214655219283, "xcomet_score": 0.9838930368423462, "xcomet_qe_score": 0.9853460788726807, "metricx_score": 0.6045604944229126, "metricx_qe_score": 0.7417617440223694, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zur Evaluation unseres Frameworks verwenden wir einen tabellarischen Klassifikationsdatensatz mit siebzehn Datensätzen, die sich in Größe, Merkmalen, Ausgewogenheit, Domäne und anfänglicher Leistung unterscheiden.", "metrics": {"bleu_score": 51.497322032579355, "chrf_score": 81.40962323346179, "xcomet_score": 0.9599964618682861, "xcomet_qe_score": 0.9728168249130249, "metricx_score": 1.9893357753753662, "metricx_qe_score": 1.735663652420044, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir konzipieren unser Experiment als LiveOneOut-Evaluation, indem wir das Modell anhand von mehr als 16 Datensätzen trainieren und es anschließend auf den 17. Datensatz anwenden.", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 75.9805722795739, "xcomet_score": 0.7596938610076904, "xcomet_qe_score": 0.7671389579772949, "metricx_score": 3.494236707687378, "metricx_qe_score": 3.5852627754211426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen jeden Datensatz ebenfalls in vier Teilmengen auf und wenden eine Kreuzvalidierung mit vier Teilmengen an.", "metrics": {"bleu_score": 21.042990347620457, "chrf_score": 58.0853538733654, "xcomet_score": 0.967310905456543, "xcomet_qe_score": 0.9594831466674805, "metricx_score": 2.8011484146118164, "metricx_qe_score": 2.655702590942383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir das neue Feature und evaluieren es mithilfe von fünf Evaluationsklassifikatoren.", "metrics": {"bleu_score": 12.571192676522521, "chrf_score": 60.24021099946215, "xcomet_score": 0.9902020692825317, "xcomet_qe_score": 0.9970136880874634, "metricx_score": 0.5507785081863403, "metricx_qe_score": 0.8791326880455017, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine BERT-basierte Architektur.", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 67.01704524996944, "xcomet_score": 0.9981297254562378, "xcomet_qe_score": 1.0, "metricx_score": 0.40447700023651123, "metricx_qe_score": 0.7780464887619019, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 85.51131524815735, "xcomet_score": 0.9987486600875854, "xcomet_qe_score": 0.9999598264694214, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Framework mit der Feinabstimmung auf dem Ziel-Datensatz, der Feinabstimmung auf der Zielaufgabe und der vorläufigen Feinabstimmung mit MTDNN vergleichen.", "metrics": {"bleu_score": 29.579846078012388, "chrf_score": 73.07009034373101, "xcomet_score": 0.9036614298820496, "xcomet_qe_score": 0.9016708135604858, "metricx_score": 1.9098047018051147, "metricx_qe_score": 1.8029437065124512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unser überarbeitetes Fein-Tuning erzielte das beste Ergebnis, die beste Leistung.", "metrics": {"bleu_score": 27.968424579665367, "chrf_score": 50.54202382396935, "xcomet_score": 0.9745522141456604, "xcomet_qe_score": 0.9829258322715759, "metricx_score": 0.812908411026001, "metricx_qe_score": 0.4454668164253235, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "während MTDNN eine Verbesserung von 2 % über dem Ziel-Datensatz durch Feinabstimmung erreichte.", "metrics": {"bleu_score": 4.246549372656572, "chrf_score": 55.03726277542257, "xcomet_score": 0.9646322727203369, "xcomet_qe_score": 0.9759839177131653, "metricx_score": 2.5516505241394043, "metricx_qe_score": 2.483096122741699, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Pfannekocher erreichte eine Verbesserung von sechs Prozent.", "metrics": {"bleu_score": 33.471898740037666, "chrf_score": 62.17337873231116, "xcomet_score": 0.7693033218383789, "xcomet_qe_score": 0.7746405005455017, "metricx_score": 8.51584529876709, "metricx_qe_score": 8.256719589233398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns den kleinen Datensatz ansehen, können wir feststellen, dass die Performance von MTDNN abnimmt und die Verbesserung der vorbereitenden, mehrfachparallelen Feinabstimmungsphase auf 1,5 Prozent sinkt.", "metrics": {"bleu_score": 49.611334615935625, "chrf_score": 72.45543232160804, "xcomet_score": 0.9809238910675049, "xcomet_qe_score": 0.963646411895752, "metricx_score": 1.4703822135925293, "metricx_qe_score": 1.6829299926757812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung stieg im Vergleich zur alleinigen Zielaufgabenoptimierung auf 11 % an.", "metrics": {"bleu_score": 25.491833774890388, "chrf_score": 51.556884871634324, "xcomet_score": 0.9550360441207886, "xcomet_qe_score": 0.9809841513633728, "metricx_score": 1.386612057685852, "metricx_qe_score": 0.8296055793762207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Summierung ermöglicht FAST die Ansicht von angereicherten Aufnahmen aus dreißigfünf Proben in unserem Experiment.", "metrics": {"bleu_score": 17.026024721767097, "chrf_score": 56.6081146128805, "xcomet_score": 0.8370015621185303, "xcomet_qe_score": 0.8351548910140991, "metricx_score": 6.303843975067139, "metricx_qe_score": 6.516762733459473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben und Datensätze.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9911325573921204, "xcomet_qe_score": 0.990761399269104, "metricx_score": 0.262288898229599, "metricx_qe_score": 0.4292936623096466, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er bewahrt den Kopf des Modells auf.", "metrics": {"bleu_score": 11.99014838091355, "chrf_score": 38.37430501651239, "xcomet_score": 0.766689121723175, "xcomet_qe_score": 0.7753586769104004, "metricx_score": 6.123333930969238, "metricx_qe_score": 8.557061195373535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt drei Formulierungsphasen hinzu.", "metrics": {"bleu_score": 30.739407647563215, "chrf_score": 69.56309781514227, "xcomet_score": 0.8870311975479126, "xcomet_qe_score": 0.8799574971199036, "metricx_score": 3.54874587059021, "metricx_qe_score": 4.899776458740234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es handelt sich um ein erweitertes Modelleisenbahnsystem und es benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einspeisen und in der Satzpaarabstufungsproblematik verwenden können.", "metrics": {"bleu_score": 53.46930670550587, "chrf_score": 72.22464594820674, "xcomet_score": 0.8701863288879395, "xcomet_qe_score": 0.8989313840866089, "metricx_score": 4.100063323974609, "metricx_qe_score": 2.166918992996216, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 87.72426647426647, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
